{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexRaudvee/MultiArchPDD-CV/blob/main/main_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hf4gDl7uDSH"
      },
      "source": [
        "### Setup of environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7TLPdrWx1evU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "def mount_google_drive(mount_point: Path = Path('/content/drive')) -> Path:\n",
        "    \"\"\"Mounts Google Drive and returns the mount point.\"\"\"\n",
        "    drive.mount(str(mount_point))\n",
        "    return mount_point\n",
        "\n",
        "def extract_zip(zip_path: Path, extract_to: Path) -> None:\n",
        "    \"\"\"Extracts a zip file to the given directory.\"\"\"\n",
        "    if not zip_path.is_file():\n",
        "        raise FileNotFoundError(f\"Could not find zip file at {zip_path}\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "        z.extractall(str(extract_to))\n",
        "\n",
        "def move_contents(src_dir: Path, dst_dir: Path) -> None:\n",
        "    \"\"\"\n",
        "    Moves everything from src_dir into dst_dir.\n",
        "    Overwrites any existing files or folders of the same name.\n",
        "    Cleans up the now-empty src_dir at the end.\n",
        "    \"\"\"\n",
        "    if not src_dir.is_dir():\n",
        "        raise FileNotFoundError(f\"{src_dir} does not exist\")\n",
        "    for item in src_dir.iterdir():\n",
        "        target = dst_dir / item.name\n",
        "        if target.exists():\n",
        "            print(f\"Warning: {target} already exists, overwriting\")\n",
        "            if target.is_dir():\n",
        "                shutil.rmtree(target)\n",
        "            else:\n",
        "                target.unlink()\n",
        "        shutil.move(str(item), str(target))\n",
        "    src_dir.rmdir()\n",
        "\n",
        "def setup_directories(*dirs: Path) -> None:\n",
        "    \"\"\"Ensures that each directory in `dirs` exists.\"\"\"\n",
        "    for d in dirs:\n",
        "        d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def zip_folder(folder_path: Path, output_path: Path) -> None:\n",
        "    \"\"\"\n",
        "    Recursively zip the contents of folder_path into a .zip file at output_path.\n",
        "    \"\"\"\n",
        "    with zipfile.ZipFile(output_path, 'w', compression=zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, _, files in os.walk(folder_path):\n",
        "            for fname in files:\n",
        "                fpath = Path(root) / fname\n",
        "                arcname = fpath.relative_to(folder_path)\n",
        "                zipf.write(str(fpath), arcname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BMMZhtK1uDSJ",
        "outputId": "f6d715fb-9043-4285-bbef-0769e8e4b95e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# ——— Constants ———\n",
        "DRIVE_MOUNT_POINT = Path('/content/drive')\n",
        "ZIP_PATH            = DRIVE_MOUNT_POINT / 'MyDrive/.colab.zip'\n",
        "EXTRACT_TO          = Path('/content')\n",
        "SRC_DIR             = EXTRACT_TO / '.colab'\n",
        "DST_DIR             = EXTRACT_TO\n",
        "DISTILLED_DIR       = EXTRACT_TO / 'data' / 'Distilled'\n",
        "MODEL_DIR           = EXTRACT_TO / 'data' / 'checkpoints'\n",
        "ASSETS_DIR          = EXTRACT_TO / 'assets' / 'viz_synthetic'\n",
        "\n",
        "# ——— SetUp ———\n",
        "mount_google_drive(DRIVE_MOUNT_POINT)\n",
        "extract_zip(ZIP_PATH, EXTRACT_TO)\n",
        "move_contents(SRC_DIR, DST_DIR)\n",
        "setup_directories(DISTILLED_DIR)\n",
        "setup_directories(ASSETS_DIR)\n",
        "setup_directories(MODEL_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nekRueufuDSJ",
        "outputId": "421f21a6-a819-4081-90ec-322c1e6a44f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cef9uMpmuDSJ"
      },
      "source": [
        "### Launch of Dataset Distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9cTnLJkuDSJ",
        "outputId": "bde3c74b-4378-4ea2-f3f8-a3d9fc5c1cf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Dataloader]:\n",
            "     - Loading...\n",
            "     - Done.\n",
            "[Distillator]:\n",
            "/usr/local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Stage 1/5:   0%|                                         | 0/50 [00:00<?, ?it/s]T Loss=2.3053462505340576\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2303.702880859375\n",
            "||∇_X meta|| = 4.426256055012345e-05\n",
            "ΔX norm: 4.4262552023610624e-07\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/5:   2%|▋                                | 1/50 [00:00<00:24,  2.02it/s]T Loss=2.3036932945251465\n",
            "g_norm = tensor(0.0792, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2304.285400390625\n",
            "||∇_X meta|| = 3.970310717704706e-05\n",
            "ΔX norm: 3.9703087395537295e-07\n",
            "Stage 1/5:   4%|█▎                               | 2/50 [00:00<00:21,  2.29it/s]T Loss=2.3041889667510986\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2305.0849609375\n",
            "||∇_X meta|| = 5.7964574807556346e-05\n",
            "ΔX norm: 5.796455866402539e-07\n",
            "Stage 1/5:   6%|█▉                               | 3/50 [00:01<00:18,  2.57it/s]T Loss=2.303156614303589\n",
            "g_norm = tensor(0.0884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2296.941650390625\n",
            "||∇_X meta|| = 5.426033021649346e-05\n",
            "ΔX norm: 5.426031179922575e-07\n",
            "Stage 1/5:   8%|██▋                              | 4/50 [00:01<00:16,  2.81it/s]T Loss=2.3028340339660645\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2297.93310546875\n",
            "||∇_X meta|| = 4.417716263560578e-05\n",
            "ΔX norm: 4.417716183979792e-07\n",
            "Stage 1/5:  10%|███▎                             | 5/50 [00:01<00:15,  2.86it/s]T Loss=2.304776668548584\n",
            "g_norm = tensor(0.0928, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2312.29052734375\n",
            "||∇_X meta|| = 5.816936754854396e-05\n",
            "ΔX norm: 5.816933708047145e-07\n",
            "Stage 1/5:  12%|███▉                             | 6/50 [00:02<00:14,  3.03it/s]T Loss=2.3044838905334473\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2298.88818359375\n",
            "||∇_X meta|| = 4.9889727961272e-05\n",
            "ΔX norm: 4.988972932551405e-07\n",
            "Stage 1/5:  14%|████▌                            | 7/50 [00:02<00:14,  2.90it/s]T Loss=2.3037922382354736\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2304.452392578125\n",
            "||∇_X meta|| = 7.422245107591152e-05\n",
            "ΔX norm: 7.422241878884961e-07\n",
            "Stage 1/5:  16%|█████▎                           | 8/50 [00:02<00:13,  3.01it/s]T Loss=2.302677631378174\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2305.759033203125\n",
            "||∇_X meta|| = 4.0782775613479316e-05\n",
            "ΔX norm: 4.078277697772137e-07\n",
            "Stage 1/5:  18%|█████▉                           | 9/50 [00:03<00:13,  3.10it/s]T Loss=2.3044731616973877\n",
            "g_norm = tensor(0.0828, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2303.4765625\n",
            "||∇_X meta|| = 3.679047949844971e-05\n",
            "ΔX norm: 3.679047608784458e-07\n",
            "Stage 1/5:  20%|██████▍                         | 10/50 [00:03<00:12,  3.21it/s]T Loss=2.3027186393737793\n",
            "g_norm = tensor(0.0819, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2309.806884765625\n",
            "||∇_X meta|| = 9.221020445693284e-05\n",
            "ΔX norm: 9.221021173289046e-07\n",
            "Stage 1/5:  22%|███████                         | 11/50 [00:03<00:11,  3.28it/s]T Loss=2.303173303604126\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2297.155517578125\n",
            "||∇_X meta|| = 6.747908628312871e-05\n",
            "ΔX norm: 6.747907832505007e-07\n",
            "Stage 1/5:  24%|███████▋                        | 12/50 [00:04<00:11,  3.31it/s]T Loss=2.3029215335845947\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2327.43701171875\n",
            "||∇_X meta|| = 8.477774099446833e-05\n",
            "ΔX norm: 8.477774713355757e-07\n",
            "Stage 1/5:  26%|████████▎                       | 13/50 [00:04<00:11,  3.22it/s]T Loss=2.3023037910461426\n",
            "g_norm = tensor(0.0672, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2302.68505859375\n",
            "||∇_X meta|| = 4.048876144224778e-05\n",
            "ΔX norm: 4.04887714466895e-07\n",
            "Stage 1/5:  28%|████████▉                       | 14/50 [00:04<00:11,  3.20it/s]T Loss=2.303872585296631\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2302.24072265625\n",
            "||∇_X meta|| = 0.00011095685476902872\n",
            "ΔX norm: 1.1095680747530423e-06\n",
            "Stage 1/5:  30%|█████████▌                      | 15/50 [00:04<00:10,  3.25it/s]T Loss=2.3038578033447266\n",
            "g_norm = tensor(0.0878, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2296.89501953125\n",
            "||∇_X meta|| = 4.8650548706064e-05\n",
            "ΔX norm: 4.865054847869033e-07\n",
            "Stage 1/5:  32%|██████████▏                     | 16/50 [00:05<00:11,  3.08it/s]T Loss=2.3052773475646973\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2302.39404296875\n",
            "||∇_X meta|| = 4.097520650248043e-05\n",
            "ΔX norm: 4.097521468793275e-07\n",
            "Stage 1/5:  34%|██████████▉                     | 17/50 [00:05<00:10,  3.08it/s]T Loss=2.3026559352874756\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2309.513916015625\n",
            "||∇_X meta|| = 4.7017816541483626e-05\n",
            "ΔX norm: 4.701782927440945e-07\n",
            "Stage 1/5:  36%|███████████▌                    | 18/50 [00:05<00:10,  3.06it/s]T Loss=2.3038735389709473\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2312.695556640625\n",
            "||∇_X meta|| = 0.00010628341988194734\n",
            "ΔX norm: 1.062834257936629e-06\n",
            "Stage 1/5:  38%|████████████▏                   | 19/50 [00:06<00:09,  3.10it/s]T Loss=2.303919553756714\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2302.632080078125\n",
            "||∇_X meta|| = 5.4105035815155134e-05\n",
            "ΔX norm: 5.410502694758179e-07\n",
            "Stage 1/5:  40%|████████████▊                   | 20/50 [00:06<00:10,  2.96it/s]T Loss=2.303220748901367\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2309.0810546875\n",
            "||∇_X meta|| = 4.400414400151931e-05\n",
            "ΔX norm: 4.400415036798222e-07\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/5:  42%|█████████████▍                  | 21/50 [00:07<00:09,  2.91it/s]T Loss=2.3044068813323975\n",
            "g_norm = tensor(0.0797, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2305.810302734375\n",
            "||∇_X meta|| = 6.0907659644726664e-05\n",
            "ΔX norm: 6.090766078159504e-07\n",
            "Stage 1/5:  44%|██████████████                  | 22/50 [00:07<00:09,  2.97it/s]T Loss=2.303473711013794\n",
            "g_norm = tensor(0.0879, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2303.066650390625\n",
            "||∇_X meta|| = 4.241945134708658e-05\n",
            "ΔX norm: 4.2419449641784013e-07\n",
            "Stage 1/5:  46%|██████████████▋                 | 23/50 [00:07<00:08,  3.12it/s]T Loss=2.30470609664917\n",
            "g_norm = tensor(0.0797, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2284.86962890625\n",
            "||∇_X meta|| = 4.137908763368614e-05\n",
            "ΔX norm: 4.1379084336767846e-07\n",
            "Stage 1/5:  48%|███████████████▎                | 24/50 [00:07<00:08,  3.24it/s]T Loss=2.3052444458007812\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2299.03857421875\n",
            "||∇_X meta|| = 6.047258648322895e-05\n",
            "ΔX norm: 6.047258125363442e-07\n",
            "Stage 1/5:  50%|████████████████                | 25/50 [00:08<00:07,  3.30it/s]T Loss=2.302949905395508\n",
            "g_norm = tensor(0.0818, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2308.67431640625\n",
            "||∇_X meta|| = 3.991988705820404e-05\n",
            "ΔX norm: 3.991990809026902e-07\n",
            "Stage 1/5:  52%|████████████████▋               | 26/50 [00:08<00:07,  3.22it/s]T Loss=2.3032143115997314\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2299.399169921875\n",
            "||∇_X meta|| = 0.00012300389062147588\n",
            "ΔX norm: 1.2300388334551826e-06\n",
            "Stage 1/5:  54%|█████████████████▎              | 27/50 [00:08<00:07,  3.09it/s]T Loss=2.3042941093444824\n",
            "g_norm = tensor(0.0793, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2305.2470703125\n",
            "||∇_X meta|| = 5.511952986125834e-05\n",
            "ΔX norm: 5.511951712833252e-07\n",
            "Stage 1/5:  56%|█████████████████▉              | 28/50 [00:09<00:07,  3.07it/s]T Loss=2.30385160446167\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2300.977783203125\n",
            "||∇_X meta|| = 4.5720258640358225e-05\n",
            "ΔX norm: 4.5720261709902843e-07\n",
            "Stage 1/5:  58%|██████████████████▌             | 29/50 [00:09<00:07,  2.82it/s]T Loss=2.302793025970459\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2311.23681640625\n",
            "||∇_X meta|| = 6.938901788089424e-05\n",
            "ΔX norm: 6.938901719877322e-07\n",
            "Stage 1/5:  60%|███████████████████▏            | 30/50 [00:09<00:06,  2.94it/s]T Loss=2.3048126697540283\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2298.333740234375\n",
            "||∇_X meta|| = 8.003808034118265e-05\n",
            "ΔX norm: 8.003808602552454e-07\n",
            "Stage 1/5:  62%|███████████████████▊            | 31/50 [00:10<00:06,  3.01it/s]T Loss=2.303114175796509\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2301.39111328125\n",
            "||∇_X meta|| = 6.017402120050974e-05\n",
            "ΔX norm: 6.017400551172614e-07\n",
            "Stage 1/5:  64%|████████████████████▍           | 32/50 [00:10<00:05,  3.14it/s]T Loss=2.304062604904175\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2310.338134765625\n",
            "||∇_X meta|| = 9.165405936073512e-05\n",
            "ΔX norm: 9.165406709144008e-07\n",
            "Stage 1/5:  66%|█████████████████████           | 33/50 [00:10<00:05,  3.20it/s]T Loss=2.3036441802978516\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2280.605712890625\n",
            "||∇_X meta|| = 0.00012741031241603196\n",
            "ΔX norm: 1.2741029422613792e-06\n",
            "Stage 1/5:  68%|█████████████████████▊          | 34/50 [00:11<00:05,  3.12it/s]T Loss=2.3027310371398926\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2304.61181640625\n",
            "||∇_X meta|| = 7.662634016014636e-05\n",
            "ΔX norm: 7.662635539418261e-07\n",
            "Stage 1/5:  70%|██████████████████████▍         | 35/50 [00:11<00:04,  3.05it/s]T Loss=2.305854082107544\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2300.339599609375\n",
            "||∇_X meta|| = 6.87462161295116e-05\n",
            "ΔX norm: 6.874622044961143e-07\n",
            "Stage 1/5:  72%|███████████████████████         | 36/50 [00:11<00:04,  2.88it/s]T Loss=2.303068161010742\n",
            "g_norm = tensor(0.1213, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2281.557373046875\n",
            "||∇_X meta|| = 0.00010018592001870275\n",
            "ΔX norm: 1.0018591183325043e-06\n",
            "Stage 1/5:  74%|███████████████████████▋        | 37/50 [00:12<00:04,  2.92it/s]T Loss=2.3043806552886963\n",
            "g_norm = tensor(0.1271, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2307.6533203125\n",
            "||∇_X meta|| = 9.089329250855371e-05\n",
            "ΔX norm: 9.089332024814212e-07\n",
            "Stage 1/5:  76%|████████████████████████▎       | 38/50 [00:12<00:04,  3.00it/s]T Loss=2.304105281829834\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2298.511962890625\n",
            "||∇_X meta|| = 0.00013107217091601342\n",
            "ΔX norm: 1.310721359004674e-06\n",
            "Stage 1/5:  78%|████████████████████████▉       | 39/50 [00:12<00:03,  3.05it/s]T Loss=2.303267002105713\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2284.143798828125\n",
            "||∇_X meta|| = 5.834427793161012e-05\n",
            "ΔX norm: 5.834427838635747e-07\n",
            "Stage 1/5:  80%|█████████████████████████▌      | 40/50 [00:13<00:03,  2.92it/s]T Loss=2.3029356002807617\n",
            "g_norm = tensor(0.0794, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2311.973388671875\n",
            "||∇_X meta|| = 6.958582525840029e-05\n",
            "ΔX norm: 6.958581479921122e-07\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/5:  82%|██████████████████████████▏     | 41/50 [00:13<00:03,  2.86it/s]T Loss=2.30344820022583\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2299.95703125\n",
            "||∇_X meta|| = 7.815595745341852e-05\n",
            "ΔX norm: 7.815595495230809e-07\n",
            "Stage 1/5:  84%|██████████████████████████▉     | 42/50 [00:14<00:03,  2.30it/s]T Loss=2.3052761554718018\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2297.984375\n",
            "||∇_X meta|| = 5.3802967158844694e-05\n",
            "ΔX norm: 5.380295533541357e-07\n",
            "Stage 1/5:  86%|███████████████████████████▌    | 43/50 [00:14<00:02,  2.47it/s]T Loss=2.303933620452881\n",
            "g_norm = tensor(0.0764, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2305.59765625\n",
            "||∇_X meta|| = 4.62721727672033e-05\n",
            "ΔX norm: 4.627217435881903e-07\n",
            "Stage 1/5:  88%|████████████████████████████▏   | 44/50 [00:14<00:02,  2.51it/s]T Loss=2.3056418895721436\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2284.063232421875\n",
            "||∇_X meta|| = 0.00016992089513223618\n",
            "ΔX norm: 1.6992086102618487e-06\n",
            "Stage 1/5:  90%|████████████████████████████▊   | 45/50 [00:15<00:01,  2.66it/s]T Loss=2.3021368980407715\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2286.164306640625\n",
            "||∇_X meta|| = 4.883709698333405e-05\n",
            "ΔX norm: 4.883711426373338e-07\n",
            "Stage 1/5:  92%|█████████████████████████████▍  | 46/50 [00:15<00:01,  2.72it/s]T Loss=2.3039934635162354\n",
            "g_norm = tensor(0.0884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2311.374267578125\n",
            "||∇_X meta|| = 6.947469228180125e-05\n",
            "ΔX norm: 6.947471433704777e-07\n",
            "Stage 1/5:  94%|██████████████████████████████  | 47/50 [00:15<00:01,  2.91it/s]T Loss=2.3025975227355957\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2310.495849609375\n",
            "||∇_X meta|| = 5.84983681619633e-05\n",
            "ΔX norm: 5.849835815752158e-07\n",
            "Stage 1/5:  96%|██████████████████████████████▋ | 48/50 [00:16<00:00,  3.00it/s]T Loss=2.303040027618408\n",
            "g_norm = tensor(0.0831, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2309.44140625\n",
            "||∇_X meta|| = 3.581361670512706e-05\n",
            "ΔX norm: 3.581360772386688e-07\n",
            "Stage 1/5:  98%|███████████████████████████████▎| 49/50 [00:16<00:00,  3.12it/s]T Loss=2.30465030670166\n",
            "g_norm = tensor(0.0837, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2311.096435546875\n",
            "||∇_X meta|| = 6.21847648289986e-05\n",
            "ΔX norm: 6.218475050445704e-07\n",
            "Stage 0, class 0, loss 2.292                                                    \n",
            "Stage 0, class 1, loss 2.295\n",
            "Stage 0, class 2, loss 2.285\n",
            "Stage 0, class 3, loss 2.271\n",
            "Stage 0, class 4, loss 2.300\n",
            "Stage 0, class 5, loss 2.246\n",
            "Stage 0, class 6, loss 2.330\n",
            "Stage 0, class 7, loss 2.343\n",
            "Stage 0, class 8, loss 2.417\n",
            "Stage 0, class 9, loss 2.252\n",
            "Stage 2/5:   0%|                                         | 0/50 [00:00<?, ?it/s]T Loss=2.303205728530884\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2303.742919921875\n",
            "||∇_X meta|| = 3.494629345368594e-05\n",
            "ΔX norm: 3.4946293681059615e-07\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 2/5:   2%|▋                                | 1/50 [00:00<00:21,  2.33it/s]T Loss=2.3056797981262207\n",
            "g_norm = tensor(0.0873, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2314.62353515625\n",
            "||∇_X meta|| = 4.032443030155264e-05\n",
            "ΔX norm: 4.0324420069737243e-07\n",
            "Stage 2/5:   4%|█▎                               | 2/50 [00:00<00:20,  2.39it/s]T Loss=2.3030009269714355\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2318.258544921875\n",
            "||∇_X meta|| = 4.2407311411807314e-05\n",
            "ΔX norm: 4.2407316414028173e-07\n",
            "Stage 2/5:   6%|█▉                               | 3/50 [00:01<00:18,  2.58it/s]T Loss=2.303562641143799\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2292.06884765625\n",
            "||∇_X meta|| = 0.00010547981219133362\n",
            "ΔX norm: 1.0547980764386011e-06\n",
            "Stage 2/5:   8%|██▋                              | 4/50 [00:01<00:18,  2.55it/s]T Loss=2.304121732711792\n",
            "g_norm = tensor(0.0876, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2299.064208984375\n",
            "||∇_X meta|| = 4.1006525862030685e-05\n",
            "ΔX norm: 4.100651267435751e-07\n",
            "Stage 2/5:  10%|███▎                             | 5/50 [00:02<00:18,  2.44it/s]T Loss=2.304100513458252\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2316.48095703125\n",
            "||∇_X meta|| = 5.5121639888966456e-05\n",
            "ΔX norm: 5.512164307219791e-07\n",
            "Stage 2/5:  12%|███▉                             | 6/50 [00:02<00:16,  2.63it/s]T Loss=2.304372787475586\n",
            "g_norm = tensor(0.1154, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2282.0546875\n",
            "||∇_X meta|| = 5.107892502564937e-05\n",
            "ΔX norm: 5.107889933242404e-07\n",
            "Stage 2/5:  14%|████▌                            | 7/50 [00:02<00:15,  2.82it/s]T Loss=2.303541660308838\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2297.54443359375\n",
            "||∇_X meta|| = 5.055614747107029e-05\n",
            "ΔX norm: 5.05561501995544e-07\n",
            "Stage 2/5:  16%|█████▎                           | 8/50 [00:02<00:14,  2.96it/s]T Loss=2.304227352142334\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2303.774658203125\n",
            "||∇_X meta|| = 6.553457205882296e-05\n",
            "ΔX norm: 6.553456159963389e-07\n",
            "Stage 2/5:  18%|█████▉                           | 9/50 [00:03<00:13,  3.04it/s]T Loss=2.3028340339660645\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2300.138671875\n",
            "||∇_X meta|| = 4.7856021410552785e-05\n",
            "ΔX norm: 4.785603664458904e-07\n",
            "Stage 2/5:  20%|██████▍                         | 10/50 [00:03<00:13,  3.07it/s]T Loss=2.302900791168213\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2295.186279296875\n",
            "||∇_X meta|| = 5.0016977183986455e-05\n",
            "ΔX norm: 5.001698468731774e-07\n",
            "Stage 2/5:  22%|███████                         | 11/50 [00:03<00:12,  3.10it/s]T Loss=2.303522825241089\n",
            "g_norm = tensor(0.0983, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2304.5673828125\n",
            "||∇_X meta|| = 3.1450694223167375e-05\n",
            "ΔX norm: 3.1450704796043283e-07\n",
            "Stage 2/5:  24%|███████▋                        | 12/50 [00:04<00:11,  3.18it/s]T Loss=2.302610397338867\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2311.023681640625\n",
            "||∇_X meta|| = 3.180887142661959e-05\n",
            "ΔX norm: 3.1808875178285234e-07\n",
            "Stage 2/5:  26%|████████▎                       | 13/50 [00:04<00:11,  3.09it/s]T Loss=2.303584098815918\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2302.541259765625\n",
            "||∇_X meta|| = 3.8221558497752994e-05\n",
            "ΔX norm: 3.822155463240051e-07\n",
            "Stage 2/5:  28%|████████▉                       | 14/50 [00:04<00:11,  3.14it/s]T Loss=2.303812026977539\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2305.154541015625\n",
            "||∇_X meta|| = 8.09933480923064e-05\n",
            "ΔX norm: 8.099335673250607e-07\n",
            "Stage 2/5:  30%|█████████▌                      | 15/50 [00:05<00:11,  3.16it/s]T Loss=2.3042542934417725\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2303.29931640625\n",
            "||∇_X meta|| = 3.960670801461674e-05\n",
            "ΔX norm: 3.960670653668785e-07\n",
            "Stage 2/5:  32%|██████████▏                     | 16/50 [00:05<00:10,  3.18it/s]T Loss=2.3027820587158203\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2317.79833984375\n",
            "||∇_X meta|| = 7.759337313473225e-05\n",
            "ΔX norm: 7.759335858281702e-07\n",
            "Stage 2/5:  34%|██████████▉                     | 17/50 [00:05<00:10,  3.20it/s]T Loss=2.3041322231292725\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2298.398681640625\n",
            "||∇_X meta|| = 3.1088620744412765e-05\n",
            "ΔX norm: 3.108862642875465e-07\n",
            "Stage 2/5:  36%|███████████▌                    | 18/50 [00:06<00:09,  3.25it/s]T Loss=2.30362606048584\n",
            "g_norm = tensor(0.0807, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2304.581298828125\n",
            "||∇_X meta|| = 3.4392611269140616e-05\n",
            "ΔX norm: 3.43926160439878e-07\n",
            "Stage 2/5:  38%|████████████▏                   | 19/50 [00:06<00:09,  3.30it/s]T Loss=2.3050620555877686\n",
            "g_norm = tensor(0.1423, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2325.007568359375\n",
            "||∇_X meta|| = 8.045548020163551e-05\n",
            "ΔX norm: 8.045548725021945e-07\n",
            "Stage 2/5:  40%|████████████▊                   | 20/50 [00:06<00:09,  3.33it/s]T Loss=2.302577495574951\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2308.4873046875\n",
            "||∇_X meta|| = 5.2263796533225104e-05\n",
            "ΔX norm: 5.226378902989381e-07\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 2/5:  42%|█████████████▍                  | 21/50 [00:07<00:09,  3.06it/s]T Loss=2.303387403488159\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2294.337890625\n",
            "||∇_X meta|| = 5.8605575759429485e-05\n",
            "ΔX norm: 5.860557052983495e-07\n",
            "Stage 2/5:  44%|██████████████                  | 22/50 [00:07<00:09,  2.87it/s]T Loss=2.3048665523529053\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2296.56005859375\n",
            "||∇_X meta|| = 4.8885885917115957e-05\n",
            "ΔX norm: 4.888589728579973e-07\n",
            "Stage 2/5:  46%|██████████████▋                 | 23/50 [00:07<00:08,  3.01it/s]T Loss=2.3035337924957275\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2292.784423828125\n",
            "||∇_X meta|| = 8.909036841941997e-05\n",
            "ΔX norm: 8.909037774174067e-07\n",
            "Stage 2/5:  48%|███████████████▎                | 24/50 [00:08<00:08,  3.05it/s]T Loss=2.304211139678955\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2304.177734375\n",
            "||∇_X meta|| = 6.436710827983916e-05\n",
            "ΔX norm: 6.436710577872873e-07\n",
            "Stage 2/5:  50%|████████████████                | 25/50 [00:08<00:08,  3.04it/s]T Loss=2.3019309043884277\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2296.05029296875\n",
            "||∇_X meta|| = 0.00010952719458146021\n",
            "ΔX norm: 1.0952715001621982e-06\n",
            "Stage 2/5:  52%|████████████████▋               | 26/50 [00:08<00:07,  3.04it/s]T Loss=2.3039443492889404\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2319.999755859375\n",
            "||∇_X meta|| = 4.476082540350035e-05\n",
            "ΔX norm: 4.4760841433344467e-07\n",
            "Stage 2/5:  54%|█████████████████▎              | 27/50 [00:09<00:07,  3.12it/s]T Loss=2.3051724433898926\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2336.868896484375\n",
            "||∇_X meta|| = 4.7871380957076326e-05\n",
            "ΔX norm: 4.787139005202334e-07\n",
            "Stage 2/5:  56%|█████████████████▉              | 28/50 [00:09<00:07,  3.12it/s]T Loss=2.304032564163208\n",
            "g_norm = tensor(0.0815, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2293.61767578125\n",
            "||∇_X meta|| = 2.9819713745382614e-05\n",
            "ΔX norm: 2.9819719316037663e-07\n",
            "Stage 2/5:  58%|██████████████████▌             | 29/50 [00:09<00:06,  3.21it/s]T Loss=2.3036208152770996\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2299.31396484375\n",
            "||∇_X meta|| = 4.911895302939229e-05\n",
            "ΔX norm: 4.911895530312904e-07\n",
            "Stage 2/5:  60%|███████████████████▏            | 30/50 [00:09<00:06,  3.30it/s]T Loss=2.3027026653289795\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2292.274169921875\n",
            "||∇_X meta|| = 4.9149966798722744e-05\n",
            "ΔX norm: 4.914995770377573e-07\n",
            "Stage 2/5:  62%|███████████████████▊            | 31/50 [00:10<00:05,  3.32it/s]T Loss=2.3041749000549316\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2305.799072265625\n",
            "||∇_X meta|| = 5.355467874323949e-05\n",
            "ΔX norm: 5.355466896617145e-07\n",
            "Stage 2/5:  64%|████████████████████▍           | 32/50 [00:10<00:05,  3.38it/s]T Loss=2.3033804893493652\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2297.815673828125\n",
            "||∇_X meta|| = 3.1485393265029415e-05\n",
            "ΔX norm: 3.148538496589026e-07\n",
            "Stage 2/5:  66%|█████████████████████           | 33/50 [00:10<00:04,  3.42it/s]T Loss=2.302678346633911\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2314.4375\n",
            "||∇_X meta|| = 5.9426092775538564e-05\n",
            "ΔX norm: 5.942606549069751e-07\n",
            "Stage 2/5:  68%|█████████████████████▊          | 34/50 [00:11<00:04,  3.44it/s]T Loss=2.30342173576355\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2302.230712890625\n",
            "||∇_X meta|| = 0.0001200237384182401\n",
            "ΔX norm: 1.2002369658148382e-06\n",
            "Stage 2/5:  70%|██████████████████████▍         | 35/50 [00:11<00:04,  3.39it/s]T Loss=2.30328106880188\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2299.33203125\n",
            "||∇_X meta|| = 5.817553756060079e-05\n",
            "ΔX norm: 5.817552732878539e-07\n",
            "Stage 2/5:  72%|███████████████████████         | 36/50 [00:11<00:04,  3.42it/s]T Loss=2.302595615386963\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2299.819580078125\n",
            "||∇_X meta|| = 4.612237535184249e-05\n",
            "ΔX norm: 4.6122369212753256e-07\n",
            "Stage 2/5:  74%|███████████████████████▋        | 37/50 [00:11<00:03,  3.39it/s]T Loss=2.3035271167755127\n",
            "g_norm = tensor(0.1491, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2287.485107421875\n",
            "||∇_X meta|| = 8.943488501245156e-05\n",
            "ΔX norm: 8.943486591306282e-07\n",
            "Stage 2/5:  76%|████████████████████████▎       | 38/50 [00:12<00:03,  3.43it/s]T Loss=2.303715229034424\n",
            "g_norm = tensor(0.0725, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2313.650390625\n",
            "||∇_X meta|| = 3.727594958036207e-05\n",
            "ΔX norm: 3.7275950148796255e-07\n",
            "Stage 2/5:  78%|████████████████████████▉       | 39/50 [00:12<00:03,  3.46it/s]T Loss=2.3069329261779785\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2306.744140625\n",
            "||∇_X meta|| = 4.127991269342601e-05\n",
            "ΔX norm: 4.1279926676907053e-07\n",
            "Stage 2/5:  80%|█████████████████████████▌      | 40/50 [00:12<00:02,  3.45it/s]T Loss=2.3042545318603516\n",
            "g_norm = tensor(0.1479, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2309.287109375\n",
            "||∇_X meta|| = 9.002572915051132e-05\n",
            "ΔX norm: 9.002572483041149e-07\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 2/5:  82%|██████████████████████████▏     | 41/50 [00:13<00:02,  3.44it/s]T Loss=2.30362868309021\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2302.371337890625\n",
            "||∇_X meta|| = 5.041658369009383e-05\n",
            "ΔX norm: 5.041658255322545e-07\n",
            "Stage 2/5:  84%|██████████████████████████▉     | 42/50 [00:13<00:02,  3.27it/s]T Loss=2.3044118881225586\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2320.865966796875\n",
            "||∇_X meta|| = 5.0204012950416654e-05\n",
            "ΔX norm: 5.020400521971169e-07\n",
            "Stage 2/5:  86%|███████████████████████████▌    | 43/50 [00:13<00:02,  3.27it/s]T Loss=2.3041417598724365\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2298.515869140625\n",
            "||∇_X meta|| = 4.8488189349882305e-05\n",
            "ΔX norm: 4.84881866213982e-07\n",
            "Stage 2/5:  88%|████████████████████████████▏   | 44/50 [00:14<00:01,  3.29it/s]T Loss=2.3042445182800293\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2316.9599609375\n",
            "||∇_X meta|| = 5.391855302150361e-05\n",
            "ΔX norm: 5.391852937464137e-07\n",
            "Stage 2/5:  90%|████████████████████████████▊   | 45/50 [00:14<00:01,  3.22it/s]T Loss=2.30489444732666\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2308.22314453125\n",
            "||∇_X meta|| = 6.174189911689609e-05\n",
            "ΔX norm: 6.174190616548003e-07\n",
            "Stage 2/5:  92%|█████████████████████████████▍  | 46/50 [00:14<00:01,  3.24it/s]T Loss=2.303661823272705\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2297.787109375\n",
            "||∇_X meta|| = 3.128621756331995e-05\n",
            "ΔX norm: 3.1286211310543877e-07\n",
            "Stage 2/5:  94%|██████████████████████████████  | 47/50 [00:14<00:00,  3.29it/s]T Loss=2.303241729736328\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2308.70263671875\n",
            "||∇_X meta|| = 4.483830343815498e-05\n",
            "ΔX norm: 4.483829343371326e-07\n",
            "Stage 2/5:  96%|██████████████████████████████▋ | 48/50 [00:15<00:00,  3.32it/s]T Loss=2.305271625518799\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2314.0068359375\n",
            "||∇_X meta|| = 4.2865063733188435e-05\n",
            "ΔX norm: 4.286506509743049e-07\n",
            "Stage 2/5:  98%|███████████████████████████████▎| 49/50 [00:15<00:00,  3.35it/s]T Loss=2.304588794708252\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2286.965576171875\n",
            "||∇_X meta|| = 6.727589789079502e-05\n",
            "ΔX norm: 6.727591426169965e-07\n",
            "Stage 1, class 0, loss 2.291                                                    \n",
            "Stage 1, class 1, loss 2.294\n",
            "Stage 1, class 2, loss 2.286\n",
            "Stage 1, class 3, loss 2.272\n",
            "Stage 1, class 4, loss 2.301\n",
            "Stage 1, class 5, loss 2.246\n",
            "Stage 1, class 6, loss 2.329\n",
            "Stage 1, class 7, loss 2.342\n",
            "Stage 1, class 8, loss 2.414\n",
            "Stage 1, class 9, loss 2.252\n",
            "Stage 3/5:   0%|                                         | 0/50 [00:00<?, ?it/s]T Loss=2.3042540550231934\n",
            "g_norm = tensor(0.0908, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2285.99755859375\n",
            "||∇_X meta|| = 3.93317241105251e-05\n",
            "ΔX norm: 3.933170376058115e-07\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 3/5:   2%|▋                                | 1/50 [00:00<00:18,  2.71it/s]T Loss=2.3040871620178223\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2289.305908203125\n",
            "||∇_X meta|| = 3.656346598290838e-05\n",
            "ΔX norm: 3.656345768376923e-07\n",
            "Stage 3/5:   4%|█▎                               | 2/50 [00:00<00:19,  2.49it/s]T Loss=2.3031773567199707\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2315.019775390625\n",
            "||∇_X meta|| = 0.0001029973936965689\n",
            "ΔX norm: 1.02997387330106e-06\n",
            "Stage 3/5:   6%|█▉                               | 3/50 [00:01<00:17,  2.66it/s]T Loss=2.302445650100708\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2306.883056640625\n",
            "||∇_X meta|| = 6.518752343254164e-05\n",
            "ΔX norm: 6.5187515474463e-07\n",
            "Stage 3/5:   8%|██▋                              | 4/50 [00:01<00:15,  2.88it/s]T Loss=2.3028247356414795\n",
            "g_norm = tensor(0.1213, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2301.9765625\n",
            "||∇_X meta|| = 4.506828190642409e-05\n",
            "ΔX norm: 4.506827337991126e-07\n",
            "Stage 3/5:  10%|███▎                             | 5/50 [00:01<00:16,  2.80it/s]T Loss=2.303252696990967\n",
            "g_norm = tensor(0.1157, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2302.6962890625\n",
            "||∇_X meta|| = 3.809414556599222e-05\n",
            "ΔX norm: 3.8094154319878726e-07\n",
            "Stage 3/5:  12%|███▉                             | 6/50 [00:02<00:16,  2.69it/s]T Loss=2.30332612991333\n",
            "g_norm = tensor(0.1011, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2301.119384765625\n",
            "||∇_X meta|| = 4.037066173623316e-05\n",
            "ΔX norm: 4.0370667875322397e-07\n",
            "Stage 3/5:  14%|████▌                            | 7/50 [00:02<00:15,  2.83it/s]T Loss=2.30465030670166\n",
            "g_norm = tensor(0.0795, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2288.55908203125\n",
            "||∇_X meta|| = 4.994136543245986e-05\n",
            "ΔX norm: 4.994136020286533e-07\n",
            "Stage 3/5:  16%|█████▎                           | 8/50 [00:02<00:14,  2.94it/s]T Loss=2.3051114082336426\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2296.166015625\n",
            "||∇_X meta|| = 4.6728473535040393e-05\n",
            "ΔX norm: 4.672847921938228e-07\n",
            "Stage 3/5:  18%|█████▉                           | 9/50 [00:03<00:13,  2.94it/s]T Loss=2.3047001361846924\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2310.653564453125\n",
            "||∇_X meta|| = 5.938453978160396e-05\n",
            "ΔX norm: 5.938455842624535e-07\n",
            "Stage 3/5:  20%|██████▍                         | 10/50 [00:03<00:13,  3.02it/s]T Loss=2.303891897201538\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2298.728271484375\n",
            "||∇_X meta|| = 4.76629393233452e-05\n",
            "ΔX norm: 4.766292533986416e-07\n",
            "Stage 3/5:  22%|███████                         | 11/50 [00:03<00:12,  3.04it/s]T Loss=2.304659128189087\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2301.052001953125\n",
            "||∇_X meta|| = 3.761108746402897e-05\n",
            "ΔX norm: 3.7611087577715807e-07\n",
            "Stage 3/5:  24%|███████▋                        | 12/50 [00:04<00:12,  3.13it/s]T Loss=2.3029720783233643\n",
            "g_norm = tensor(0.0814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2304.0419921875\n",
            "||∇_X meta|| = 2.9711718525504693e-05\n",
            "ΔX norm: 2.971171966237307e-07\n",
            "Stage 3/5:  26%|████████▎                       | 13/50 [00:04<00:11,  3.14it/s]T Loss=2.305253505706787\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2329.12744140625\n",
            "||∇_X meta|| = 3.895718327839859e-05\n",
            "ΔX norm: 3.895717384239106e-07\n",
            "Stage 3/5:  28%|████████▉                       | 14/50 [00:04<00:10,  3.29it/s]T Loss=2.3036723136901855\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2302.65234375\n",
            "||∇_X meta|| = 3.129699325654656e-05\n",
            "ΔX norm: 3.129699450710177e-07\n",
            "Stage 3/5:  30%|█████████▌                      | 15/50 [00:05<00:10,  3.30it/s]T Loss=2.3048431873321533\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2313.332763671875\n",
            "||∇_X meta|| = 7.63516072765924e-05\n",
            "ΔX norm: 7.635157430740946e-07\n",
            "Stage 3/5:  32%|██████████▏                     | 16/50 [00:05<00:10,  3.33it/s]T Loss=2.302884340286255\n",
            "g_norm = tensor(0.0845, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2306.332763671875\n",
            "||∇_X meta|| = 4.4542586692841724e-05\n",
            "ΔX norm: 4.4542582600115566e-07\n",
            "Stage 3/5:  34%|██████████▉                     | 17/50 [00:05<00:09,  3.33it/s]T Loss=2.303410053253174\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2308.304443359375\n",
            "||∇_X meta|| = 3.184728484484367e-05\n",
            "ΔX norm: 3.1847278592067596e-07\n",
            "Stage 3/5:  36%|███████████▌                    | 18/50 [00:05<00:09,  3.40it/s]T Loss=2.3030998706817627\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2300.340576171875\n",
            "||∇_X meta|| = 4.4166103180032223e-05\n",
            "ΔX norm: 4.416609726831666e-07\n",
            "Stage 3/5:  38%|████████████▏                   | 19/50 [00:06<00:09,  3.15it/s]T Loss=2.3045854568481445\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2289.790771484375\n",
            "||∇_X meta|| = 9.922467143042013e-05\n",
            "ΔX norm: 9.922466688294662e-07\n",
            "Stage 3/5:  40%|████████████▊                   | 20/50 [00:06<00:09,  3.22it/s]T Loss=2.3047595024108887\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2293.017578125\n",
            "||∇_X meta|| = 5.865043567609973e-05\n",
            "ΔX norm: 5.86504313559999e-07\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 3/5:  42%|█████████████▍                  | 21/50 [00:06<00:09,  3.11it/s]T Loss=2.3034801483154297\n",
            "g_norm = tensor(0.0878, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2298.348876953125\n",
            "||∇_X meta|| = 3.715268030646257e-05\n",
            "ΔX norm: 3.7152679510654707e-07\n",
            "Stage 3/5:  44%|██████████████                  | 22/50 [00:07<00:09,  3.01it/s]T Loss=2.304382085800171\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2300.273681640625\n",
            "||∇_X meta|| = 3.036748785234522e-05\n",
            "ΔX norm: 3.036749092188984e-07\n",
            "Stage 3/5:  46%|██████████████▋                 | 23/50 [00:07<00:08,  3.05it/s]T Loss=2.3036417961120605\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2304.750244140625\n",
            "||∇_X meta|| = 5.476591832120903e-05\n",
            "ΔX norm: 5.476588853525755e-07\n",
            "Stage 3/5:  48%|███████████████▎                | 24/50 [00:07<00:08,  3.09it/s]T Loss=2.3035967350006104\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2299.564697265625\n",
            "||∇_X meta|| = 2.8198224754305556e-05\n",
            "ΔX norm: 2.819821816046897e-07\n",
            "Stage 3/5:  50%|████████████████                | 25/50 [00:08<00:08,  2.98it/s]T Loss=2.3044657707214355\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2310.443359375\n",
            "||∇_X meta|| = 4.334225377533585e-05\n",
            "ΔX norm: 4.33422542300832e-07\n",
            "Stage 3/5:  52%|████████████████▋               | 26/50 [00:08<00:08,  2.97it/s]T Loss=2.3021936416625977\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2300.34716796875\n",
            "||∇_X meta|| = 2.6255962438881397e-05\n",
            "ΔX norm: 2.6255966645294393e-07\n",
            "Stage 3/5:  54%|█████████████████▎              | 27/50 [00:08<00:08,  2.78it/s]T Loss=2.3034520149230957\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2316.236083984375\n",
            "||∇_X meta|| = 2.6360856281826273e-05\n",
            "ΔX norm: 2.63608569639473e-07\n",
            "Stage 3/5:  56%|█████████████████▉              | 28/50 [00:09<00:09,  2.23it/s]T Loss=2.3045873641967773\n",
            "g_norm = tensor(0.0811, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2316.4892578125\n",
            "||∇_X meta|| = 4.6377557737287134e-05\n",
            "ΔX norm: 4.6377579110412626e-07\n",
            "Stage 3/5:  58%|██████████████████▌             | 29/50 [00:10<00:10,  2.09it/s]T Loss=2.303694009780884\n",
            "g_norm = tensor(0.0730, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2314.38232421875\n",
            "||∇_X meta|| = 4.5876458898419514e-05\n",
            "ΔX norm: 4.587644752973574e-07\n",
            "Stage 3/5:  60%|███████████████████▏            | 30/50 [00:10<00:10,  1.95it/s]T Loss=2.3029961585998535\n",
            "g_norm = tensor(0.0752, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2302.957275390625\n",
            "||∇_X meta|| = 3.251207817811519e-05\n",
            "ΔX norm: 3.2512079428670404e-07\n",
            "Stage 3/5:  62%|███████████████████▊            | 31/50 [00:11<00:09,  2.10it/s]T Loss=2.30391001701355\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2314.992431640625\n",
            "||∇_X meta|| = 5.766471440438181e-05\n",
            "ΔX norm: 5.766472668256029e-07\n",
            "Stage 3/5:  64%|████████████████████▍           | 32/50 [00:11<00:07,  2.32it/s]T Loss=2.3041229248046875\n",
            "g_norm = tensor(0.0942, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2308.71337890625\n",
            "||∇_X meta|| = 2.4844324798323214e-05\n",
            "ΔX norm: 2.4844314339134144e-07\n",
            "Stage 3/5:  66%|█████████████████████           | 33/50 [00:11<00:06,  2.54it/s]T Loss=2.303952693939209\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2309.139892578125\n",
            "||∇_X meta|| = 3.4944583603646606e-05\n",
            "ΔX norm: 3.4944591220664734e-07\n",
            "Stage 3/5:  68%|█████████████████████▊          | 34/50 [00:12<00:05,  2.68it/s]T Loss=2.30334734916687\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2302.919189453125\n",
            "||∇_X meta|| = 4.622506457963027e-05\n",
            "ΔX norm: 4.622505400675436e-07\n",
            "Stage 3/5:  70%|██████████████████████▍         | 35/50 [00:12<00:05,  2.70it/s]T Loss=2.3030943870544434\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2299.2744140625\n",
            "||∇_X meta|| = 3.474948607617989e-05\n",
            "ΔX norm: 3.474947618542501e-07\n",
            "Stage 3/5:  72%|███████████████████████         | 36/50 [00:12<00:05,  2.78it/s]T Loss=2.3034541606903076\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2310.64892578125\n",
            "||∇_X meta|| = 2.527097603888251e-05\n",
            "ΔX norm: 2.5270978198932426e-07\n",
            "Stage 3/5:  74%|███████████████████████▋        | 37/50 [00:13<00:06,  2.08it/s]T Loss=2.3037784099578857\n",
            "g_norm = tensor(0.0709, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2294.808837890625\n",
            "||∇_X meta|| = 2.281373781443108e-05\n",
            "ΔX norm: 2.2813740940819116e-07\n",
            "Stage 3/5:  76%|████████████████████████▎       | 38/50 [00:13<00:05,  2.26it/s]T Loss=2.304196357727051\n",
            "g_norm = tensor(0.0777, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2334.979736328125\n",
            "||∇_X meta|| = 5.9691381466109306e-05\n",
            "ΔX norm: 5.969137646388845e-07\n",
            "Stage 3/5:  78%|████████████████████████▉       | 39/50 [00:14<00:04,  2.44it/s]T Loss=2.3029696941375732\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2304.6171875\n",
            "||∇_X meta|| = 4.285924296709709e-05\n",
            "ΔX norm: 4.2859238646997255e-07\n",
            "Stage 3/5:  80%|█████████████████████████▌      | 40/50 [00:14<00:04,  2.46it/s]T Loss=2.302976608276367\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2309.79638671875\n",
            "||∇_X meta|| = 3.1601990485796705e-05\n",
            "ΔX norm: 3.1601987870999437e-07\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 3/5:  82%|██████████████████████████▏     | 41/50 [00:15<00:03,  2.60it/s]T Loss=2.303818464279175\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2308.94873046875\n",
            "||∇_X meta|| = 6.563073111465201e-05\n",
            "ΔX norm: 6.563073498000449e-07\n",
            "Stage 3/5:  84%|██████████████████████████▉     | 42/50 [00:15<00:03,  2.59it/s]T Loss=2.3043556213378906\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2298.321533203125\n",
            "||∇_X meta|| = 8.329876436619088e-05\n",
            "ΔX norm: 8.329876095558575e-07\n",
            "Stage 3/5:  86%|███████████████████████████▌    | 43/50 [00:15<00:02,  2.64it/s]T Loss=2.303943395614624\n",
            "g_norm = tensor(0.0919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2298.60888671875\n",
            "||∇_X meta|| = 5.409548248280771e-05\n",
            "ΔX norm: 5.409547156887129e-07\n",
            "Stage 3/5:  88%|████████████████████████████▏   | 44/50 [00:16<00:02,  2.62it/s]T Loss=2.3035130500793457\n",
            "g_norm = tensor(0.1225, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2293.621826171875\n",
            "||∇_X meta|| = 4.0340819396078587e-05\n",
            "ΔX norm: 4.03408137117367e-07\n",
            "Stage 3/5:  90%|████████████████████████████▊   | 45/50 [00:16<00:01,  2.82it/s]T Loss=2.3037269115448\n",
            "g_norm = tensor(0.0815, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2300.579345703125\n",
            "||∇_X meta|| = 3.294447742518969e-05\n",
            "ΔX norm: 3.2944493000286457e-07\n",
            "Stage 3/5:  92%|█████████████████████████████▍  | 46/50 [00:16<00:01,  2.93it/s]T Loss=2.302182674407959\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2302.705322265625\n",
            "||∇_X meta|| = 6.21838407823816e-05\n",
            "ΔX norm: 6.21838296410715e-07\n",
            "Stage 3/5:  94%|██████████████████████████████  | 47/50 [00:17<00:00,  3.02it/s]T Loss=2.3026371002197266\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2303.5439453125\n",
            "||∇_X meta|| = 6.771959306206554e-05\n",
            "ΔX norm: 6.771958851459203e-07\n",
            "Stage 3/5:  96%|██████████████████████████████▋ | 48/50 [00:17<00:00,  3.05it/s]T Loss=2.304028272628784\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2312.410888671875\n",
            "||∇_X meta|| = 3.589415064197965e-05\n",
            "ΔX norm: 3.58941520062217e-07\n",
            "Stage 3/5:  98%|███████████████████████████████▎| 49/50 [00:17<00:00,  3.07it/s]T Loss=2.3034355640411377\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2302.650390625\n",
            "||∇_X meta|| = 2.931085145974066e-05\n",
            "ΔX norm: 2.931085703039571e-07\n",
            "Stage 2, class 0, loss 2.291                                                    \n",
            "Stage 2, class 1, loss 2.293\n",
            "Stage 2, class 2, loss 2.286\n",
            "Stage 2, class 3, loss 2.273\n",
            "Stage 2, class 4, loss 2.300\n",
            "Stage 2, class 5, loss 2.248\n",
            "Stage 2, class 6, loss 2.328\n",
            "Stage 2, class 7, loss 2.344\n",
            "Stage 2, class 8, loss 2.415\n",
            "Stage 2, class 9, loss 2.253\n",
            "Stage 4/5:   0%|                                         | 0/50 [00:00<?, ?it/s]T Loss=2.303696632385254\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2314.382080078125\n",
            "||∇_X meta|| = 3.762948472285643e-05\n",
            "ΔX norm: 3.7629473581546335e-07\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 4/5:   2%|▋                                | 1/50 [00:00<00:20,  2.34it/s]T Loss=2.3036556243896484\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2285.114501953125\n",
            "||∇_X meta|| = 3.8242898881435394e-05\n",
            "ΔX norm: 3.824288512532803e-07\n",
            "Stage 4/5:   4%|█▎                               | 2/50 [00:00<00:19,  2.52it/s]T Loss=2.3041372299194336\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2317.61328125\n",
            "||∇_X meta|| = 4.5526554458774626e-05\n",
            "ΔX norm: 4.552657628664747e-07\n",
            "Stage 4/5:   6%|█▉                               | 3/50 [00:01<00:16,  2.80it/s]T Loss=2.3032066822052\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2299.205322265625\n",
            "||∇_X meta|| = 4.717068804893643e-05\n",
            "ΔX norm: 4.7170684069897106e-07\n",
            "Stage 4/5:   8%|██▋                              | 4/50 [00:01<00:15,  2.93it/s]T Loss=2.3041443824768066\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2313.648681640625\n",
            "||∇_X meta|| = 5.0173290219390765e-05\n",
            "ΔX norm: 5.017327566747554e-07\n",
            "Stage 4/5:  10%|███▎                             | 5/50 [00:01<00:16,  2.66it/s]T Loss=2.304504871368408\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2304.36962890625\n",
            "||∇_X meta|| = 4.319047002354637e-05\n",
            "ΔX norm: 4.3190473775212013e-07\n",
            "Stage 4/5:  12%|███▉                             | 6/50 [00:02<00:15,  2.79it/s]T Loss=2.303816318511963\n",
            "g_norm = tensor(0.1415, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2297.074951171875\n",
            "||∇_X meta|| = 5.3385254432214424e-05\n",
            "ΔX norm: 5.338524715625681e-07\n",
            "Stage 4/5:  14%|████▌                            | 7/50 [00:02<00:15,  2.85it/s]T Loss=2.304975986480713\n",
            "g_norm = tensor(0.0845, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2319.327392578125\n",
            "||∇_X meta|| = 3.8600643165409565e-05\n",
            "ΔX norm: 3.8600637708441354e-07\n",
            "Stage 4/5:  16%|█████▎                           | 8/50 [00:02<00:14,  2.96it/s]T Loss=2.3035366535186768\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2306.801025390625\n",
            "||∇_X meta|| = 3.301347533124499e-05\n",
            "ΔX norm: 3.3013469646903104e-07\n",
            "Stage 4/5:  18%|█████▉                           | 9/50 [00:03<00:13,  3.06it/s]T Loss=2.304831027984619\n",
            "g_norm = tensor(0.0778, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2301.1650390625\n",
            "||∇_X meta|| = 2.910763578256592e-05\n",
            "ΔX norm: 2.9107636123626435e-07\n",
            "Stage 4/5:  20%|██████▍                         | 10/50 [00:03<00:12,  3.15it/s]T Loss=2.304342031478882\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2302.977783203125\n",
            "||∇_X meta|| = 3.33105017489288e-05\n",
            "ΔX norm: 3.3310493563476484e-07\n",
            "Stage 4/5:  22%|███████                         | 11/50 [00:03<00:12,  3.13it/s]T Loss=2.304518938064575\n",
            "g_norm = tensor(0.0838, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2293.5869140625\n",
            "||∇_X meta|| = 3.218082565581426e-05\n",
            "ΔX norm: 3.2180841458284704e-07\n",
            "Stage 4/5:  24%|███████▋                        | 12/50 [00:04<00:11,  3.23it/s]T Loss=2.303485155105591\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2305.960693359375\n",
            "||∇_X meta|| = 4.1180577682098374e-05\n",
            "ΔX norm: 4.118057290725119e-07\n",
            "Stage 4/5:  26%|████████▎                       | 13/50 [00:04<00:11,  3.30it/s]T Loss=2.303905487060547\n",
            "g_norm = tensor(0.0885, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2282.89990234375\n",
            "||∇_X meta|| = 3.010707769135479e-05\n",
            "ΔX norm: 3.010708269357565e-07\n",
            "Stage 4/5:  28%|████████▉                       | 14/50 [00:04<00:10,  3.32it/s]T Loss=2.3040037155151367\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2298.26513671875\n",
            "||∇_X meta|| = 3.5527540603652596e-05\n",
            "ΔX norm: 3.5527543218449864e-07\n",
            "Stage 4/5:  30%|█████████▌                      | 15/50 [00:04<00:10,  3.30it/s]T Loss=2.3034567832946777\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2303.95751953125\n",
            "||∇_X meta|| = 5.231913746683858e-05\n",
            "ΔX norm: 5.231912609815481e-07\n",
            "Stage 4/5:  32%|██████████▏                     | 16/50 [00:05<00:10,  3.36it/s]T Loss=2.3034987449645996\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2294.179931640625\n",
            "||∇_X meta|| = 2.8177364583825693e-05\n",
            "ΔX norm: 2.8177367994430824e-07\n",
            "Stage 4/5:  34%|██████████▉                     | 17/50 [00:05<00:09,  3.34it/s]T Loss=2.306300401687622\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2323.20654296875\n",
            "||∇_X meta|| = 5.2785220759687945e-05\n",
            "ΔX norm: 5.278520802676212e-07\n",
            "Stage 4/5:  36%|███████████▌                    | 18/50 [00:05<00:09,  3.34it/s]T Loss=2.30336332321167\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2293.624755859375\n",
            "||∇_X meta|| = 2.787391895253677e-05\n",
            "ΔX norm: 2.787391792935523e-07\n",
            "Stage 4/5:  38%|████████████▏                   | 19/50 [00:06<00:09,  3.40it/s]T Loss=2.3028321266174316\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2301.13232421875\n",
            "||∇_X meta|| = 2.71986336883856e-05\n",
            "ΔX norm: 2.719862663980166e-07\n",
            "Stage 4/5:  40%|████████████▊                   | 20/50 [00:06<00:09,  3.33it/s]T Loss=2.3032333850860596\n",
            "g_norm = tensor(0.0673, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2304.330810546875\n",
            "||∇_X meta|| = 2.76443715847563e-05\n",
            "ΔX norm: 2.76443785196534e-07\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 4/5:  42%|█████████████▍                  | 21/50 [00:06<00:08,  3.32it/s]T Loss=2.303687810897827\n",
            "g_norm = tensor(0.0799, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2309.3623046875\n",
            "||∇_X meta|| = 4.829471436096355e-05\n",
            "ΔX norm: 4.829468593925412e-07\n",
            "Stage 4/5:  44%|██████████████                  | 22/50 [00:07<00:09,  3.10it/s]T Loss=2.3049442768096924\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2294.022216796875\n",
            "||∇_X meta|| = 5.7774162996793166e-05\n",
            "ΔX norm: 5.777416163255111e-07\n",
            "Stage 4/5:  46%|██████████████▋                 | 23/50 [00:07<00:08,  3.20it/s]T Loss=2.305265426635742\n",
            "g_norm = tensor(0.0766, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2323.534423828125\n",
            "||∇_X meta|| = 3.448315692367032e-05\n",
            "ΔX norm: 3.4483164768062124e-07\n",
            "Stage 4/5:  48%|███████████████▎                | 24/50 [00:07<00:07,  3.30it/s]T Loss=2.303995370864868\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2301.574951171875\n",
            "||∇_X meta|| = 2.4987106371554546e-05\n",
            "ΔX norm: 2.4987099322970607e-07\n",
            "Stage 4/5:  50%|████████████████                | 25/50 [00:08<00:10,  2.36it/s]T Loss=2.3049864768981934\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2307.6962890625\n",
            "||∇_X meta|| = 2.692342059162911e-05\n",
            "ΔX norm: 2.6923424911728944e-07\n",
            "Stage 4/5:  52%|████████████████▋               | 26/50 [00:08<00:10,  2.32it/s]T Loss=2.3048510551452637\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2311.15869140625\n",
            "||∇_X meta|| = 3.0484066883218475e-05\n",
            "ΔX norm: 3.048407108963147e-07\n",
            "Stage 4/5:  54%|█████████████████▎              | 27/50 [00:09<00:09,  2.53it/s]T Loss=2.3036422729492188\n",
            "g_norm = tensor(0.1432, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2295.7861328125\n",
            "||∇_X meta|| = 6.432416557800025e-05\n",
            "ΔX norm: 6.432413783841184e-07\n",
            "Stage 4/5:  56%|█████████████████▉              | 28/50 [00:09<00:08,  2.68it/s]T Loss=2.3033924102783203\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2311.955078125\n",
            "||∇_X meta|| = 5.018886076868512e-05\n",
            "ΔX norm: 5.01888507642434e-07\n",
            "Stage 4/5:  58%|██████████████████▌             | 29/50 [00:09<00:07,  2.87it/s]T Loss=2.303758144378662\n",
            "g_norm = tensor(0.0908, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2313.49462890625\n",
            "||∇_X meta|| = 2.6197725674137473e-05\n",
            "ΔX norm: 2.619773624701338e-07\n",
            "Stage 4/5:  60%|███████████████████▏            | 30/50 [00:10<00:06,  3.01it/s]T Loss=2.304015874862671\n",
            "g_norm = tensor(0.1118, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2304.70654296875\n",
            "||∇_X meta|| = 4.0801955037750304e-05\n",
            "ΔX norm: 4.080195310507406e-07\n",
            "Stage 4/5:  62%|███████████████████▊            | 31/50 [00:10<00:06,  3.03it/s]T Loss=2.303025960922241\n",
            "g_norm = tensor(0.0759, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2297.541748046875\n",
            "||∇_X meta|| = 2.295490230608266e-05\n",
            "ΔX norm: 2.295490872938899e-07\n",
            "Stage 4/5:  64%|████████████████████▍           | 32/50 [00:10<00:05,  3.08it/s]T Loss=2.3033182621002197\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2302.44921875\n",
            "||∇_X meta|| = 8.446294668829069e-05\n",
            "ΔX norm: 8.446294259556453e-07\n",
            "Stage 4/5:  66%|█████████████████████           | 33/50 [00:10<00:05,  3.16it/s]T Loss=2.303596258163452\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2307.571044921875\n",
            "||∇_X meta|| = 3.466671842033975e-05\n",
            "ΔX norm: 3.466671785190556e-07\n",
            "Stage 4/5:  68%|█████████████████████▊          | 34/50 [00:11<00:04,  3.22it/s]T Loss=2.3024814128875732\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2320.005859375\n",
            "||∇_X meta|| = 4.6994013246148825e-05\n",
            "ΔX norm: 4.6994023250590544e-07\n",
            "Stage 4/5:  70%|██████████████████████▍         | 35/50 [00:11<00:04,  3.29it/s]T Loss=2.3031234741210938\n",
            "g_norm = tensor(0.0801, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2298.47998046875\n",
            "||∇_X meta|| = 3.253832983318716e-05\n",
            "ΔX norm: 3.253832687732938e-07\n",
            "Stage 4/5:  72%|███████████████████████         | 36/50 [00:11<00:04,  3.26it/s]T Loss=2.304762601852417\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2301.9736328125\n",
            "||∇_X meta|| = 3.0430854167207144e-05\n",
            "ΔX norm: 3.0430857123064925e-07\n",
            "Stage 4/5:  74%|███████████████████████▋        | 37/50 [00:12<00:04,  3.23it/s]T Loss=2.3042469024658203\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2301.3935546875\n",
            "||∇_X meta|| = 5.709899778594263e-05\n",
            "ΔX norm: 5.709900392503187e-07\n",
            "Stage 4/5:  76%|████████████████████████▎       | 38/50 [00:12<00:03,  3.23it/s]T Loss=2.303086042404175\n",
            "g_norm = tensor(0.0817, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2302.914794921875\n",
            "||∇_X meta|| = 2.567123738117516e-05\n",
            "ΔX norm: 2.567123544849892e-07\n",
            "Stage 4/5:  78%|████████████████████████▉       | 39/50 [00:12<00:03,  3.25it/s]T Loss=2.3017396926879883\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2305.05517578125\n",
            "||∇_X meta|| = 5.374567990656942e-05\n",
            "ΔX norm: 5.374566285354376e-07\n",
            "Stage 4/5:  80%|█████████████████████████▌      | 40/50 [00:13<00:03,  2.84it/s]T Loss=2.3039989471435547\n",
            "g_norm = tensor(0.1364, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2300.10986328125\n",
            "||∇_X meta|| = 7.597798685310408e-05\n",
            "ΔX norm: 7.597798230563058e-07\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 4/5:  82%|██████████████████████████▏     | 41/50 [00:13<00:03,  2.90it/s]T Loss=2.305257558822632\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2304.291015625\n",
            "||∇_X meta|| = 6.310130265774205e-05\n",
            "ΔX norm: 6.310128810582682e-07\n",
            "Stage 4/5:  84%|██████████████████████████▉     | 42/50 [00:13<00:02,  2.85it/s]T Loss=2.303694486618042\n",
            "g_norm = tensor(0.0656, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2300.171630859375\n",
            "||∇_X meta|| = 3.0510638680425473e-05\n",
            "ΔX norm: 3.0510651072290784e-07\n",
            "Stage 4/5:  86%|███████████████████████████▌    | 43/50 [00:14<00:02,  2.99it/s]T Loss=2.302938938140869\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2303.4384765625\n",
            "||∇_X meta|| = 3.43262727255933e-05\n",
            "ΔX norm: 3.432626272115158e-07\n",
            "Stage 4/5:  88%|████████████████████████████▏   | 44/50 [00:14<00:01,  3.02it/s]T Loss=2.3045713901519775\n",
            "g_norm = tensor(0.0871, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2306.069091796875\n",
            "||∇_X meta|| = 3.079386806348339e-05\n",
            "ΔX norm: 3.0793870564593817e-07\n",
            "Stage 4/5:  90%|████████████████████████████▊   | 45/50 [00:14<00:01,  2.97it/s]T Loss=2.30318021774292\n",
            "g_norm = tensor(0.0808, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2311.93603515625\n",
            "||∇_X meta|| = 2.703705831663683e-05\n",
            "ΔX norm: 2.7037049221689813e-07\n",
            "Stage 4/5:  92%|█████████████████████████████▍  | 46/50 [00:15<00:01,  3.03it/s]T Loss=2.3030507564544678\n",
            "g_norm = tensor(0.0846, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2313.779296875\n",
            "||∇_X meta|| = 3.625743556767702e-05\n",
            "ΔX norm: 3.625742408530641e-07\n",
            "Stage 4/5:  94%|██████████████████████████████  | 47/50 [00:15<00:00,  3.16it/s]T Loss=2.3036346435546875\n",
            "g_norm = tensor(0.1486, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2317.062744140625\n",
            "||∇_X meta|| = 0.0001640900009078905\n",
            "ΔX norm: 1.6409003364969976e-06\n",
            "Stage 4/5:  96%|██████████████████████████████▋ | 48/50 [00:15<00:00,  3.19it/s]T Loss=2.3025870323181152\n",
            "g_norm = tensor(0.0851, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2306.559814453125\n",
            "||∇_X meta|| = 5.557234544539824e-05\n",
            "ΔX norm: 5.557233180297771e-07\n",
            "Stage 4/5:  98%|███████████████████████████████▎| 49/50 [00:16<00:00,  3.24it/s]T Loss=2.3042094707489014\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2315.3740234375\n",
            "||∇_X meta|| = 2.2254782379604876e-05\n",
            "ΔX norm: 2.2254783971220604e-07\n",
            "Stage 3, class 0, loss 2.291                                                    \n",
            "Stage 3, class 1, loss 2.296\n",
            "Stage 3, class 2, loss 2.287\n",
            "Stage 3, class 3, loss 2.273\n",
            "Stage 3, class 4, loss 2.300\n",
            "Stage 3, class 5, loss 2.248\n",
            "Stage 3, class 6, loss 2.327\n",
            "Stage 3, class 7, loss 2.342\n",
            "Stage 3, class 8, loss 2.414\n",
            "Stage 3, class 9, loss 2.253\n",
            "Stage 5/5:   0%|                                         | 0/50 [00:00<?, ?it/s]T Loss=2.304133176803589\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2294.5341796875\n",
            "||∇_X meta|| = 3.471952004474588e-05\n",
            "ΔX norm: 3.471951401934348e-07\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 5/5:   2%|▋                                | 1/50 [00:00<00:18,  2.69it/s]T Loss=2.305314540863037\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2311.76611328125\n",
            "||∇_X meta|| = 3.771864066948183e-05\n",
            "ΔX norm: 3.7718632484029513e-07\n",
            "Stage 5/5:   4%|█▎                               | 2/50 [00:00<00:19,  2.50it/s]T Loss=2.3027615547180176\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2305.876953125\n",
            "||∇_X meta|| = 3.1539308110950515e-05\n",
            "ΔX norm: 3.153931231736351e-07\n",
            "Stage 5/5:   6%|█▉                               | 3/50 [00:01<00:17,  2.70it/s]T Loss=2.3030965328216553\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2294.42529296875\n",
            "||∇_X meta|| = 3.514718991937116e-05\n",
            "ΔX norm: 3.5147209587194084e-07\n",
            "Stage 5/5:   8%|██▋                              | 4/50 [00:01<00:15,  2.91it/s]T Loss=2.3042657375335693\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2300.161865234375\n",
            "||∇_X meta|| = 3.566179657354951e-05\n",
            "ΔX norm: 3.566179600511532e-07\n",
            "Stage 5/5:  10%|███▎                             | 5/50 [00:01<00:15,  2.90it/s]T Loss=2.301180362701416\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2301.57763671875\n",
            "||∇_X meta|| = 5.681266338797286e-05\n",
            "ΔX norm: 5.681266657120432e-07\n",
            "Stage 5/5:  12%|███▉                             | 6/50 [00:02<00:15,  2.87it/s]T Loss=2.3047585487365723\n",
            "g_norm = tensor(0.0923, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2308.4970703125\n",
            "||∇_X meta|| = 6.343051791191101e-05\n",
            "ΔX norm: 6.343051381918485e-07\n",
            "Stage 5/5:  14%|████▌                            | 7/50 [00:02<00:14,  2.98it/s]T Loss=2.3040261268615723\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2309.6044921875\n",
            "||∇_X meta|| = 3.714279955602251e-05\n",
            "ΔX norm: 3.714280296662764e-07\n",
            "Stage 5/5:  16%|█████▎                           | 8/50 [00:02<00:13,  3.08it/s]T Loss=2.3032968044281006\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2295.435302734375\n",
            "||∇_X meta|| = 3.170742638758384e-05\n",
            "ΔX norm: 3.170742672864435e-07\n",
            "Stage 5/5:  18%|█████▉                           | 9/50 [00:03<00:13,  3.09it/s]T Loss=2.302638053894043\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2307.852294921875\n",
            "||∇_X meta|| = 3.637788540800102e-05\n",
            "ΔX norm: 3.6377886658556235e-07\n",
            "Stage 5/5:  20%|██████▍                         | 10/50 [00:03<00:13,  2.96it/s]T Loss=2.3040452003479004\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2310.13525390625\n",
            "||∇_X meta|| = 4.3209136492805555e-05\n",
            "ΔX norm: 4.3209143996136845e-07\n",
            "Stage 5/5:  22%|███████                         | 11/50 [00:03<00:12,  3.07it/s]T Loss=2.303597927093506\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2296.97607421875\n",
            "||∇_X meta|| = 3.510643364279531e-05\n",
            "ΔX norm: 3.5106435802845226e-07\n",
            "Stage 5/5:  24%|███████▋                        | 12/50 [00:04<00:11,  3.17it/s]T Loss=2.3035566806793213\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2295.972412109375\n",
            "||∇_X meta|| = 4.1588107706047595e-05\n",
            "ΔX norm: 4.1588114640944696e-07\n",
            "Stage 5/5:  26%|████████▎                       | 13/50 [00:04<00:11,  3.09it/s]T Loss=2.3032732009887695\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2304.888427734375\n",
            "||∇_X meta|| = 2.6900463126366958e-05\n",
            "ΔX norm: 2.6900468697022006e-07\n",
            "Stage 5/5:  28%|████████▉                       | 14/50 [00:04<00:11,  3.05it/s]T Loss=2.304290771484375\n",
            "g_norm = tensor(0.1110, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2314.9375\n",
            "||∇_X meta|| = 2.8884367566206492e-05\n",
            "ΔX norm: 2.8884366543024953e-07\n",
            "Stage 5/5:  30%|█████████▌                      | 15/50 [00:05<00:11,  3.03it/s]T Loss=2.3034770488739014\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2302.885009765625\n",
            "||∇_X meta|| = 5.589444117504172e-05\n",
            "ΔX norm: 5.589443503595248e-07\n",
            "Stage 5/5:  32%|██████████▏                     | 16/50 [00:05<00:10,  3.11it/s]T Loss=2.3046369552612305\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2293.791015625\n",
            "||∇_X meta|| = 4.3258110963506624e-05\n",
            "ΔX norm: 4.325810323280166e-07\n",
            "Stage 5/5:  34%|██████████▉                     | 17/50 [00:05<00:10,  3.16it/s]T Loss=2.303278923034668\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2291.413330078125\n",
            "||∇_X meta|| = 2.9191412977525033e-05\n",
            "ΔX norm: 2.9191403427830664e-07\n",
            "Stage 5/5:  36%|███████████▌                    | 18/50 [00:05<00:10,  3.17it/s]T Loss=2.3052167892456055\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2313.03271484375\n",
            "||∇_X meta|| = 4.4279182475293055e-05\n",
            "ΔX norm: 4.427918725014024e-07\n",
            "Stage 5/5:  38%|████████████▏                   | 19/50 [00:06<00:09,  3.20it/s]T Loss=2.3029873371124268\n",
            "g_norm = tensor(0.0733, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2314.828857421875\n",
            "||∇_X meta|| = 2.9049771910649724e-05\n",
            "ΔX norm: 2.9049780891909904e-07\n",
            "Stage 5/5:  40%|████████████▊                   | 20/50 [00:06<00:09,  3.23it/s]T Loss=2.303069829940796\n",
            "g_norm = tensor(0.0902, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2306.3447265625\n",
            "||∇_X meta|| = 4.358279693406075e-05\n",
            "ΔX norm: 4.3582809894360253e-07\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 5/5:  42%|█████████████▍                  | 21/50 [00:06<00:08,  3.25it/s]T Loss=2.3015689849853516\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2298.74755859375\n",
            "||∇_X meta|| = 2.5362640371895395e-05\n",
            "ΔX norm: 2.5362643896187365e-07\n",
            "Stage 5/5:  44%|██████████████                  | 22/50 [00:07<00:09,  3.06it/s]T Loss=2.3048195838928223\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2316.903564453125\n",
            "||∇_X meta|| = 2.7041138309868984e-05\n",
            "ΔX norm: 2.704113342133496e-07\n",
            "Stage 5/5:  46%|██████████████▋                 | 23/50 [00:07<00:08,  3.05it/s]T Loss=2.303830623626709\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2308.252197265625\n",
            "||∇_X meta|| = 2.7202275305171497e-05\n",
            "ΔX norm: 2.720227030295064e-07\n",
            "Stage 5/5:  48%|███████████████▎                | 24/50 [00:07<00:08,  3.08it/s]T Loss=2.3056843280792236\n",
            "g_norm = tensor(0.1210, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2301.410400390625\n",
            "||∇_X meta|| = 3.269275475759059e-05\n",
            "ΔX norm: 3.269275623551948e-07\n",
            "Stage 5/5:  50%|████████████████                | 25/50 [00:08<00:08,  2.81it/s]T Loss=2.3036563396453857\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2292.61865234375\n",
            "||∇_X meta|| = 5.7069581089308485e-05\n",
            "ΔX norm: 5.70695874557714e-07\n",
            "Stage 5/5:  52%|████████████████▋               | 26/50 [00:08<00:08,  2.93it/s]T Loss=2.3028979301452637\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2301.634521484375\n",
            "||∇_X meta|| = 3.1592746381647885e-05\n",
            "ΔX norm: 3.1592750815434556e-07\n",
            "Stage 5/5:  54%|█████████████████▎              | 27/50 [00:08<00:07,  3.05it/s]T Loss=2.3046059608459473\n",
            "g_norm = tensor(0.1304, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2294.137451171875\n",
            "||∇_X meta|| = 0.0001294951216550544\n",
            "ΔX norm: 1.2949503798154183e-06\n",
            "Stage 5/5:  56%|█████████████████▉              | 28/50 [00:09<00:07,  3.07it/s]T Loss=2.3046274185180664\n",
            "g_norm = tensor(0.1499, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2306.5498046875\n",
            "||∇_X meta|| = 7.26698272046633e-05\n",
            "ΔX norm: 7.266980333042738e-07\n",
            "Stage 5/5:  58%|██████████████████▌             | 29/50 [00:09<00:06,  3.12it/s]T Loss=2.303537607192993\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2301.63916015625\n",
            "||∇_X meta|| = 2.4617178496555425e-05\n",
            "ΔX norm: 2.4617176563879184e-07\n",
            "Stage 5/5:  60%|███████████████████▏            | 30/50 [00:09<00:06,  3.15it/s]T Loss=2.3040270805358887\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2322.131103515625\n",
            "||∇_X meta|| = 3.078808367718011e-05\n",
            "ΔX norm: 3.0788092431066616e-07\n",
            "Stage 5/5:  62%|███████████████████▊            | 31/50 [00:10<00:06,  3.15it/s]T Loss=2.303737163543701\n",
            "g_norm = tensor(0.0923, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2307.26611328125\n",
            "||∇_X meta|| = 2.839077751559671e-05\n",
            "ΔX norm: 2.839078092620184e-07\n",
            "Stage 5/5:  64%|████████████████████▍           | 32/50 [00:10<00:05,  3.18it/s]T Loss=2.3038554191589355\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2312.92041015625\n",
            "||∇_X meta|| = 2.8276059310883284e-05\n",
            "ΔX norm: 2.82760623804279e-07\n",
            "Stage 5/5:  66%|█████████████████████           | 33/50 [00:10<00:05,  3.22it/s]T Loss=2.304656982421875\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2306.410888671875\n",
            "||∇_X meta|| = 9.786363079911098e-05\n",
            "ΔX norm: 9.786363079911098e-07\n",
            "Stage 5/5:  68%|█████████████████████▊          | 34/50 [00:11<00:04,  3.23it/s]T Loss=2.304591655731201\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2325.355224609375\n",
            "||∇_X meta|| = 2.4037130060605705e-05\n",
            "ΔX norm: 2.403711789611407e-07\n",
            "Stage 5/5:  70%|██████████████████████▍         | 35/50 [00:11<00:04,  3.27it/s]T Loss=2.3049471378326416\n",
            "g_norm = tensor(0.0811, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2317.17041015625\n",
            "||∇_X meta|| = 2.727275204961188e-05\n",
            "ΔX norm: 2.727274761582521e-07\n",
            "Stage 5/5:  72%|███████████████████████         | 36/50 [00:11<00:04,  3.21it/s]T Loss=2.3030953407287598\n",
            "g_norm = tensor(0.0885, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2317.813232421875\n",
            "||∇_X meta|| = 2.8596376068890095e-05\n",
            "ΔX norm: 2.8596383572221384e-07\n",
            "Stage 5/5:  74%|███████████████████████▋        | 37/50 [00:12<00:03,  3.27it/s]T Loss=2.3029003143310547\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2300.566162109375\n",
            "||∇_X meta|| = 2.3251273887581192e-05\n",
            "ΔX norm: 2.325126899904717e-07\n",
            "Stage 5/5:  76%|████████████████████████▎       | 38/50 [00:12<00:03,  3.30it/s]T Loss=2.304544448852539\n",
            "g_norm = tensor(0.0854, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2306.923095703125\n",
            "||∇_X meta|| = 2.992126792378258e-05\n",
            "ΔX norm: 2.9921261557319667e-07\n",
            "Stage 5/5:  78%|████████████████████████▉       | 39/50 [00:12<00:03,  3.16it/s]T Loss=2.304753541946411\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2305.057373046875\n",
            "||∇_X meta|| = 3.0909715860616416e-05\n",
            "ΔX norm: 3.09097146100612e-07\n",
            "Stage 5/5:  80%|█████████████████████████▌      | 40/50 [00:12<00:03,  3.18it/s]T Loss=2.304117441177368\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2322.1240234375\n",
            "||∇_X meta|| = 2.390737245150376e-05\n",
            "ΔX norm: 2.390737847690616e-07\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 5/5:  82%|██████████████████████████▏     | 41/50 [00:13<00:02,  3.11it/s]T Loss=2.3048980236053467\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2302.217529296875\n",
            "||∇_X meta|| = 3.2142077543539926e-05\n",
            "ΔX norm: 3.214207424662163e-07\n",
            "Stage 5/5:  84%|██████████████████████████▉     | 42/50 [00:13<00:02,  3.11it/s]T Loss=2.3030905723571777\n",
            "g_norm = tensor(0.0869, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2290.0419921875\n",
            "||∇_X meta|| = 4.6747059968765825e-05\n",
            "ΔX norm: 4.674705280649505e-07\n",
            "Stage 5/5:  86%|███████████████████████████▌    | 43/50 [00:13<00:02,  3.16it/s]T Loss=2.303709030151367\n",
            "g_norm = tensor(0.0819, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2298.217041015625\n",
            "||∇_X meta|| = 2.23059905692935e-05\n",
            "ΔX norm: 2.2305987101844948e-07\n",
            "Stage 5/5:  88%|████████████████████████████▏   | 44/50 [00:14<00:01,  3.19it/s]T Loss=2.304494857788086\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2298.8291015625\n",
            "||∇_X meta|| = 4.9419471906730905e-05\n",
            "ΔX norm: 4.941946372127859e-07\n",
            "Stage 5/5:  90%|████████████████████████████▊   | 45/50 [00:14<00:01,  3.12it/s]T Loss=2.3050308227539062\n",
            "g_norm = tensor(0.1216, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2311.140380859375\n",
            "||∇_X meta|| = 2.0924984710291028e-05\n",
            "ΔX norm: 2.0924983346048975e-07\n",
            "Stage 5/5:  92%|█████████████████████████████▍  | 46/50 [00:14<00:01,  3.12it/s]T Loss=2.3041162490844727\n",
            "g_norm = tensor(0.1326, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2303.975341796875\n",
            "||∇_X meta|| = 4.4970442104386166e-05\n",
            "ΔX norm: 4.4970460066906526e-07\n",
            "Stage 5/5:  94%|██████████████████████████████  | 47/50 [00:15<00:00,  3.10it/s]T Loss=2.3053629398345947\n",
            "g_norm = tensor(0.1289, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2291.736083984375\n",
            "||∇_X meta|| = 2.6337938834331e-05\n",
            "ΔX norm: 2.6337943381804507e-07\n",
            "Stage 5/5:  96%|██████████████████████████████▋ | 48/50 [00:15<00:00,  3.13it/s]T Loss=2.3049614429473877\n",
            "g_norm = tensor(0.0849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2298.76220703125\n",
            "||∇_X meta|| = 5.162103843758814e-05\n",
            "ΔX norm: 5.162103207112523e-07\n",
            "Stage 5/5:  98%|███████████████████████████████▎| 49/50 [00:15<00:00,  3.14it/s]T Loss=2.304532289505005\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =2300.117431640625\n",
            "||∇_X meta|| = 3.276573261246085e-05\n",
            "ΔX norm: 3.2765746027507703e-07\n",
            "Stage 4, class 0, loss 2.292                                                    \n",
            "Stage 4, class 1, loss 2.294\n",
            "Stage 4, class 2, loss 2.284\n",
            "Stage 4, class 3, loss 2.271\n",
            "Stage 4, class 4, loss 2.300\n",
            "Stage 4, class 5, loss 2.248\n",
            "Stage 4, class 6, loss 2.327\n",
            "Stage 4, class 7, loss 2.341\n",
            "Stage 4, class 8, loss 2.414\n",
            "Stage 4, class 9, loss 2.253\n",
            "     - Distilled time = 168.79 seconds\n",
            "     - Saving...\n",
            "     - model saved to data/checkpoints/meta-model-matching_mnist_convnet.pth\n",
            "     - distilled dataset & history saved to data/Distilled/meta-model-matching_mnist_convnet.pt\n",
            "     - Plotted & saved stage 1 → assets/viz_synthetic/synthetic_stage_01.png\n",
            "     - Plotted & saved stage 2 → assets/viz_synthetic/synthetic_stage_02.png\n",
            "     - Plotted & saved stage 3 → assets/viz_synthetic/synthetic_stage_03.png\n",
            "     - Plotted & saved stage 4 → assets/viz_synthetic/synthetic_stage_04.png\n",
            "     - Plotted & saved stage 5 → assets/viz_synthetic/synthetic_stage_05.png\n",
            "     - Done.\n"
          ]
        }
      ],
      "source": [
        "!python main.py meta-model-matching \\\n",
        "    --dataset mnist \\\n",
        "    --model convnet \\\n",
        "    --batch-size 32 \\\n",
        "    --ipc 1 \\\n",
        "    --P 5 \\\n",
        "    --K 50 \\\n",
        "    --T 1 \\\n",
        "    --lr-model 1e-3 \\\n",
        "    --lr-syn-data 1e-2 \\\n",
        "    --syn-optimizer momentum \\\n",
        "    --inner-optimizer momentum \\\n",
        "    --debug True \\\n",
        "    --out-dir data/Distilled \\\n",
        "    --ckpt-dir data/checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpGtlJ2juDSK",
        "outputId": "2581a1c4-e94d-4888-b6ed-70b24176701d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Dataloader]:\n",
            "     - Loading...\n",
            "     - Done.\n",
            "[Distillator]:\n",
            "/usr/local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Stage 1/10:   0%|                                       | 0/300 [00:00<?, ?it/s]T Loss=2.305534601211548\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032116889953613\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034181594848633\n",
            "g_norm = tensor(0.0868, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034520149230957\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303032636642456\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1239471435547\n",
            "||∇_X meta|| = 0.003849260974675417\n",
            "ΔX norm: 3.849255881505087e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/10:   0%|                               | 1/300 [00:02<11:19,  2.27s/it]T Loss=2.304659366607666\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037445545196533\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039443492889404\n",
            "g_norm = tensor(0.0764, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303344964981079\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304625988006592\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.35659790039062\n",
            "||∇_X meta|| = 0.0036430826876312494\n",
            "ΔX norm: 3.6430756154004484e-05\n",
            "Stage 1/10:   1%|▏                              | 2/300 [00:04<10:29,  2.11s/it]T Loss=2.304030656814575\n",
            "g_norm = tensor(0.0941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042151927948\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034539222717285\n",
            "g_norm = tensor(0.0825, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038220405578613\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302748203277588\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.01004028320312\n",
            "||∇_X meta|| = 0.003939403686672449\n",
            "ΔX norm: 3.9394053601427004e-05\n",
            "Stage 1/10:   1%|▎                              | 3/300 [00:06<09:37,  1.95s/it]T Loss=2.30465030670166\n",
            "g_norm = tensor(0.1301, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305589199066162\n",
            "g_norm = tensor(0.1273, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036649227142334\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306724786758423\n",
            "g_norm = tensor(0.1255, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053531646728516\n",
            "g_norm = tensor(0.1395, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1986083984375\n",
            "||∇_X meta|| = 0.003619314171373844\n",
            "ΔX norm: 3.619315248215571e-05\n",
            "Stage 1/10:   1%|▍                              | 4/300 [00:07<08:59,  1.82s/it]T Loss=2.3040637969970703\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035621643066406\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304572105407715\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303492307662964\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303734064102173\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.07203674316406\n",
            "||∇_X meta|| = 0.0035895470064133406\n",
            "ΔX norm: 3.5895496694138274e-05\n",
            "Stage 1/10:   2%|▌                              | 5/300 [00:09<08:33,  1.74s/it]T Loss=2.3038525581359863\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037471771240234\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304048538208008\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038573265075684\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303035259246826\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.97061157226562\n",
            "||∇_X meta|| = 0.003968298900872469\n",
            "ΔX norm: 3.96831201214809e-05\n",
            "Stage 1/10:   2%|▌                              | 6/300 [00:10<08:22,  1.71s/it]T Loss=2.3031392097473145\n",
            "g_norm = tensor(0.0697, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302825450897217\n",
            "g_norm = tensor(0.0788, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025147914886475\n",
            "g_norm = tensor(0.0665, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030505180358887\n",
            "g_norm = tensor(0.0676, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031935691833496\n",
            "g_norm = tensor(0.0853, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.81753540039062\n",
            "||∇_X meta|| = 0.003959886729717255\n",
            "ΔX norm: 3.959889363613911e-05\n",
            "Stage 1/10:   2%|▋                              | 7/300 [00:12<08:04,  1.66s/it]T Loss=2.3041839599609375\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041832447052\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038246631622314\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303783655166626\n",
            "g_norm = tensor(0.0890, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302926540374756\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2148895263672\n",
            "||∇_X meta|| = 0.0036446985322982073\n",
            "ΔX norm: 3.644695971161127e-05\n",
            "Stage 1/10:   3%|▊                              | 8/300 [00:13<07:44,  1.59s/it]T Loss=2.304262638092041\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305551052093506\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304725170135498\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304755687713623\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040080070495605\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.22402954101562\n",
            "||∇_X meta|| = 0.0033994284458458424\n",
            "ΔX norm: 3.399435445317067e-05\n",
            "Stage 1/10:   3%|▉                              | 9/300 [00:15<07:27,  1.54s/it]T Loss=2.3046023845672607\n",
            "g_norm = tensor(0.1163, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045578002929688\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039629459381104\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304483652114868\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304948091506958\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.44032287597656\n",
            "||∇_X meta|| = 0.0033061853609979153\n",
            "ΔX norm: 3.3061893191188574e-05\n",
            "Stage 1/10:   3%|█                             | 10/300 [00:17<07:57,  1.65s/it]T Loss=2.303804397583008\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036651611328125\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303154706954956\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30427885055542\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304274797439575\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.22239685058594\n",
            "||∇_X meta|| = 0.003652202198281884\n",
            "ΔX norm: 3.6522058508126065e-05\n",
            "Stage 1/10:   4%|█                             | 11/300 [00:18<07:47,  1.62s/it]T Loss=2.302682876586914\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027944564819336\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026363849639893\n",
            "g_norm = tensor(0.0873, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029470443725586\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303218126296997\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7838134765625\n",
            "||∇_X meta|| = 0.0038874445017427206\n",
            "ΔX norm: 3.887443745043129e-05\n",
            "Stage 1/10:   4%|█▏                            | 12/300 [00:20<07:34,  1.58s/it]T Loss=2.303828239440918\n",
            "g_norm = tensor(0.0873, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302938461303711\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042662143707275\n",
            "g_norm = tensor(0.0780, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303830862045288\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30432391166687\n",
            "g_norm = tensor(0.0884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.0463409423828\n",
            "||∇_X meta|| = 0.003355602966621518\n",
            "ΔX norm: 3.355604349053465e-05\n",
            "Stage 1/10:   4%|█▎                            | 13/300 [00:22<08:03,  1.68s/it]T Loss=2.304391384124756\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303772211074829\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304142475128174\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303877115249634\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052496910095215\n",
            "g_norm = tensor(0.1183, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4744110107422\n",
            "||∇_X meta|| = 0.0036164354532957077\n",
            "ΔX norm: 3.616431058617309e-05\n",
            "Stage 1/10:   5%|█▍                            | 14/300 [00:23<08:12,  1.72s/it]T Loss=2.304741621017456\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304861545562744\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045811653137207\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303895950317383\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052287101745605\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.0420684814453\n",
            "||∇_X meta|| = 0.0034837108105421066\n",
            "ΔX norm: 3.483711770968512e-05\n",
            "Stage 1/10:   5%|█▌                            | 15/300 [00:25<07:58,  1.68s/it]T Loss=2.3036084175109863\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302555799484253\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303356885910034\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302372932434082\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034751415252686\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.92172241210938\n",
            "||∇_X meta|| = 0.003396573243662715\n",
            "ΔX norm: 3.3965781767619774e-05\n",
            "Stage 1/10:   5%|█▌                            | 16/300 [00:27<07:55,  1.68s/it]T Loss=2.3032805919647217\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032050132751465\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033876419067383\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041181564331055\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303292751312256\n",
            "g_norm = tensor(0.0884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0920867919922\n",
            "||∇_X meta|| = 0.003291521919891238\n",
            "ΔX norm: 3.2915162591962144e-05\n",
            "Stage 1/10:   6%|█▋                            | 17/300 [00:28<07:48,  1.66s/it]T Loss=2.3032052516937256\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303434371948242\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040013313293457\n",
            "g_norm = tensor(0.1269, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028504848480225\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035054206848145\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5844268798828\n",
            "||∇_X meta|| = 0.0034484739881008863\n",
            "ΔX norm: 3.4484739444451407e-05\n",
            "Stage 1/10:   6%|█▊                            | 18/300 [00:30<07:38,  1.63s/it]T Loss=2.3035340309143066\n",
            "g_norm = tensor(0.1283, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305152416229248\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035576343536377\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304098606109619\n",
            "g_norm = tensor(0.1075, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304255485534668\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.77589416503906\n",
            "||∇_X meta|| = 0.003423280082643032\n",
            "ΔX norm: 3.423282760195434e-05\n",
            "Stage 1/10:   6%|█▉                            | 19/300 [00:32<07:46,  1.66s/it]T Loss=2.3031301498413086\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303762435913086\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301975965499878\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302105665206909\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303734302520752\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3179931640625\n",
            "||∇_X meta|| = 0.003847114508971572\n",
            "ΔX norm: 3.8471138395834714e-05\n",
            "Stage 1/10:   7%|██                            | 20/300 [00:33<07:38,  1.64s/it]T Loss=2.303074836730957\n",
            "g_norm = tensor(0.0855, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030638694763184\n",
            "g_norm = tensor(0.0731, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031582832336426\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303478956222534\n",
            "g_norm = tensor(0.0795, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028512001037598\n",
            "g_norm = tensor(0.0873, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.70201110839844\n",
            "||∇_X meta|| = 0.0032989950850605965\n",
            "ΔX norm: 3.298999581602402e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/10:   7%|██                            | 21/300 [00:35<07:33,  1.62s/it]T Loss=2.3050646781921387\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306035041809082\n",
            "g_norm = tensor(0.1772, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303844928741455\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304489850997925\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048019409179688\n",
            "g_norm = tensor(0.1285, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.21072387695312\n",
            "||∇_X meta|| = 0.003425125265493989\n",
            "ΔX norm: 3.425114482524805e-05\n",
            "Stage 1/10:   7%|██▏                           | 22/300 [00:37<08:22,  1.81s/it]T Loss=2.30391263961792\n",
            "g_norm = tensor(0.1560, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304948329925537\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304839611053467\n",
            "g_norm = tensor(0.1446, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038573265075684\n",
            "g_norm = tensor(0.1351, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041207790374756\n",
            "g_norm = tensor(0.1285, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.08172607421875\n",
            "||∇_X meta|| = 0.003214336698874831\n",
            "ΔX norm: 3.214335811208002e-05\n",
            "Stage 1/10:   8%|██▎                           | 23/300 [00:39<08:16,  1.79s/it]T Loss=2.304064989089966\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032755851745605\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303642988204956\n",
            "g_norm = tensor(0.0902, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036460876464844\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303131103515625\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.85073852539062\n",
            "||∇_X meta|| = 0.0031456961296498775\n",
            "ΔX norm: 3.145696973660961e-05\n",
            "Stage 1/10:   8%|██▍                           | 24/300 [00:41<08:40,  1.89s/it]T Loss=2.3021275997161865\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045761585235596\n",
            "g_norm = tensor(0.1354, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036513328552246\n",
            "g_norm = tensor(0.1334, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303431510925293\n",
            "g_norm = tensor(0.1415, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304013729095459\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.41639709472656\n",
            "||∇_X meta|| = 0.002868776675313711\n",
            "ΔX norm: 2.8687903977697715e-05\n",
            "Stage 1/10:   8%|██▌                           | 25/300 [00:43<08:40,  1.89s/it]T Loss=2.303441047668457\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303685188293457\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037357330322266\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303755521774292\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041834831237793\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.0726776123047\n",
            "||∇_X meta|| = 0.00317323743365705\n",
            "ΔX norm: 3.173236837028526e-05\n",
            "Stage 1/10:   9%|██▌                           | 26/300 [00:44<08:20,  1.83s/it]T Loss=2.303574800491333\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032844066619873\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038158416748047\n",
            "g_norm = tensor(0.0928, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032383918762207\n",
            "g_norm = tensor(0.1080, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037989139556885\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0947265625\n",
            "||∇_X meta|| = 0.00276465667411685\n",
            "ΔX norm: 2.7646568923955783e-05\n",
            "Stage 1/10:   9%|██▋                           | 27/300 [00:46<08:10,  1.80s/it]T Loss=2.3037760257720947\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039069175720215\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303532123565674\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304368019104004\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30354642868042\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.78829956054688\n",
            "||∇_X meta|| = 0.003032985143363476\n",
            "ΔX norm: 3.032979839190375e-05\n",
            "Stage 1/10:   9%|██▊                           | 28/300 [00:48<07:46,  1.72s/it]T Loss=2.3050642013549805\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044936656951904\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046162128448486\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30499529838562\n",
            "g_norm = tensor(0.0942, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045952320098877\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5277862548828\n",
            "||∇_X meta|| = 0.0026696177665144205\n",
            "ΔX norm: 2.6696157874539495e-05\n",
            "Stage 1/10:  10%|██▉                           | 29/300 [00:49<07:36,  1.68s/it]T Loss=2.3031857013702393\n",
            "g_norm = tensor(0.1022, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036413192749023\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039681911468506\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037214279174805\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038227558135986\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.96493530273438\n",
            "||∇_X meta|| = 0.002619714941829443\n",
            "ΔX norm: 2.619722181407269e-05\n",
            "Stage 1/10:  10%|███                           | 30/300 [00:51<07:29,  1.66s/it]T Loss=2.303813934326172\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022162914276123\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304868221282959\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303473949432373\n",
            "g_norm = tensor(0.0945, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038928508758545\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.68795776367188\n",
            "||∇_X meta|| = 0.002972902962937951\n",
            "ΔX norm: 2.9729057132499292e-05\n",
            "Stage 1/10:  10%|███                           | 31/300 [00:53<07:19,  1.63s/it]T Loss=2.3040544986724854\n",
            "g_norm = tensor(0.0803, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30448579788208\n",
            "g_norm = tensor(0.0856, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040671348571777\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303138256072998\n",
            "g_norm = tensor(0.0816, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304316282272339\n",
            "g_norm = tensor(0.0767, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.63294982910156\n",
            "||∇_X meta|| = 0.003076032502576709\n",
            "ΔX norm: 3.0760373192606494e-05\n",
            "Stage 1/10:  11%|███▏                          | 32/300 [00:54<07:09,  1.60s/it]T Loss=2.3048253059387207\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303353786468506\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048930168151855\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304354429244995\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304114580154419\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.78846740722656\n",
            "||∇_X meta|| = 0.0029478303622454405\n",
            "ΔX norm: 2.9478425858542323e-05\n",
            "Stage 1/10:  11%|███▎                          | 33/300 [00:56<07:02,  1.58s/it]T Loss=2.305105209350586\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303332805633545\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047127723693848\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035871982574463\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304854154586792\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.56423950195312\n",
            "||∇_X meta|| = 0.002986568259075284\n",
            "ΔX norm: 2.9865666874684393e-05\n",
            "Stage 1/10:  11%|███▍                          | 34/300 [00:57<07:00,  1.58s/it]T Loss=2.3039493560791016\n",
            "g_norm = tensor(0.1248, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044087886810303\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302677869796753\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301896095275879\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049416542053223\n",
            "g_norm = tensor(0.1369, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7852325439453\n",
            "||∇_X meta|| = 0.0024000052362680435\n",
            "ΔX norm: 2.3999989934964105e-05\n",
            "Stage 1/10:  12%|███▌                          | 35/300 [00:59<06:50,  1.55s/it]T Loss=2.3053646087646484\n",
            "g_norm = tensor(0.1561, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038926124572754\n",
            "g_norm = tensor(0.1253, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039519786834717\n",
            "g_norm = tensor(0.1424, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056931495666504\n",
            "g_norm = tensor(0.1346, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303072452545166\n",
            "g_norm = tensor(0.1421, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.78118896484375\n",
            "||∇_X meta|| = 0.003164083231240511\n",
            "ΔX norm: 3.164086228935048e-05\n",
            "Stage 1/10:  12%|███▌                          | 36/300 [01:00<06:47,  1.54s/it]T Loss=2.3035812377929688\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039298057556152\n",
            "g_norm = tensor(0.0648, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041791915893555\n",
            "g_norm = tensor(0.0753, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045144081115723\n",
            "g_norm = tensor(0.0713, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034236431121826\n",
            "g_norm = tensor(0.0707, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.37779235839844\n",
            "||∇_X meta|| = 0.002666908549144864\n",
            "ΔX norm: 2.666912041604519e-05\n",
            "Stage 1/10:  12%|███▋                          | 37/300 [01:02<06:46,  1.54s/it]T Loss=2.3055472373962402\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033854961395264\n",
            "g_norm = tensor(0.1487, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304413318634033\n",
            "g_norm = tensor(0.1432, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035590648651123\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304546356201172\n",
            "g_norm = tensor(0.1118, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3917999267578\n",
            "||∇_X meta|| = 0.0028929640538990498\n",
            "ΔX norm: 2.8929634936503135e-05\n",
            "Stage 1/10:  13%|███▊                          | 38/300 [01:03<06:34,  1.51s/it]T Loss=2.3028149604797363\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021936416625977\n",
            "g_norm = tensor(0.0880, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303488254547119\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032851219177246\n",
            "g_norm = tensor(0.1022, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028335571289062\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2235565185547\n",
            "||∇_X meta|| = 0.0026653106324374676\n",
            "ΔX norm: 2.6653093300410546e-05\n",
            "Stage 1/10:  13%|███▉                          | 39/300 [01:05<06:29,  1.49s/it]T Loss=2.304744243621826\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041577339172363\n",
            "g_norm = tensor(0.1235, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30383038520813\n",
            "g_norm = tensor(0.1417, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303217887878418\n",
            "g_norm = tensor(0.1494, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038330078125\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.69549560546875\n",
            "||∇_X meta|| = 0.0024976390413939953\n",
            "ΔX norm: 2.497635614417959e-05\n",
            "Stage 1/10:  13%|████                          | 40/300 [01:06<06:24,  1.48s/it]T Loss=2.3034491539001465\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046164512634277\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042938709259033\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30346941947937\n",
            "g_norm = tensor(0.0816, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045334815979004\n",
            "g_norm = tensor(0.0824, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.78404235839844\n",
            "||∇_X meta|| = 0.0028505173977464437\n",
            "ΔX norm: 2.8505177397164516e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/10:  14%|████                          | 41/300 [01:08<06:25,  1.49s/it]T Loss=2.3064122200012207\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041272163391113\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031790256500244\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038344383239746\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039209842681885\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.75645446777344\n",
            "||∇_X meta|| = 0.0026206811890006065\n",
            "ΔX norm: 2.6206811526208185e-05\n",
            "Stage 1/10:  14%|████▏                         | 42/300 [01:09<06:42,  1.56s/it]T Loss=2.3031983375549316\n",
            "g_norm = tensor(0.1222, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042683601379395\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304596424102783\n",
            "g_norm = tensor(0.1335, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042147159576416\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303894519805908\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.07850646972656\n",
            "||∇_X meta|| = 0.002961029065772891\n",
            "ΔX norm: 2.9610326237161644e-05\n",
            "Stage 1/10:  14%|████▎                         | 43/300 [01:11<06:40,  1.56s/it]T Loss=2.3035151958465576\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304774045944214\n",
            "g_norm = tensor(0.1022, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039188385009766\n",
            "g_norm = tensor(0.1022, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302870273590088\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039584159851074\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2412872314453\n",
            "||∇_X meta|| = 0.002663710853084922\n",
            "ΔX norm: 2.6637073460733518e-05\n",
            "Stage 1/10:  15%|████▍                         | 44/300 [01:12<06:32,  1.53s/it]T Loss=2.30232572555542\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303926944732666\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304133892059326\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304727792739868\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302730083465576\n",
            "g_norm = tensor(0.0816, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.78976440429688\n",
            "||∇_X meta|| = 0.0025482072960585356\n",
            "ΔX norm: 2.5482047931291163e-05\n",
            "Stage 1/10:  15%|████▌                         | 45/300 [01:14<06:42,  1.58s/it]T Loss=2.3040053844451904\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052637577056885\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047749996185303\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304300546646118\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303901195526123\n",
            "g_norm = tensor(0.0933, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.78439331054688\n",
            "||∇_X meta|| = 0.0026043455582112074\n",
            "ΔX norm: 2.6043424441013485e-05\n",
            "Stage 1/10:  15%|████▌                         | 46/300 [01:16<07:07,  1.68s/it]T Loss=2.304408550262451\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040010929107666\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303931713104248\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305239200592041\n",
            "g_norm = tensor(0.0813, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047614097595215\n",
            "g_norm = tensor(0.0796, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.91163635253906\n",
            "||∇_X meta|| = 0.00265613105148077\n",
            "ΔX norm: 2.6561345293885097e-05\n",
            "Stage 1/10:  16%|████▋                         | 47/300 [01:17<06:54,  1.64s/it]T Loss=2.301831007003784\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041768074035645\n",
            "g_norm = tensor(0.1187, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035976886749268\n",
            "g_norm = tensor(0.1472, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041770458221436\n",
            "g_norm = tensor(0.1426, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034563064575195\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4678955078125\n",
            "||∇_X meta|| = 0.002531585982069373\n",
            "ΔX norm: 2.531582686060574e-05\n",
            "Stage 1/10:  16%|████▊                         | 48/300 [01:19<06:45,  1.61s/it]T Loss=2.3038904666900635\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303758144378662\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30328631401062\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041205406188965\n",
            "g_norm = tensor(0.1178, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305116653442383\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.675048828125\n",
            "||∇_X meta|| = 0.002396393334493041\n",
            "ΔX norm: 2.3963966668816283e-05\n",
            "Stage 1/10:  16%|████▉                         | 49/300 [01:21<07:28,  1.79s/it]T Loss=2.3047585487365723\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039040565490723\n",
            "g_norm = tensor(0.1110, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039214611053467\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304710626602173\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304556369781494\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.82040405273438\n",
            "||∇_X meta|| = 0.002819739980623126\n",
            "ΔX norm: 2.819745714077726e-05\n",
            "Stage 1/10:  17%|█████                         | 50/300 [01:23<07:47,  1.87s/it]T Loss=2.303412914276123\n",
            "g_norm = tensor(0.0675, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034632205963135\n",
            "g_norm = tensor(0.0756, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303581953048706\n",
            "g_norm = tensor(0.0751, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039004802703857\n",
            "g_norm = tensor(0.0703, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044114112854004\n",
            "g_norm = tensor(0.0687, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.64862060546875\n",
            "||∇_X meta|| = 0.0024659009650349617\n",
            "ΔX norm: 2.4659062546561472e-05\n",
            "Stage 1/10:  17%|█████                         | 51/300 [01:25<07:37,  1.84s/it]T Loss=2.304238796234131\n",
            "g_norm = tensor(0.1379, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305634021759033\n",
            "g_norm = tensor(0.1466, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3015189170837402\n",
            "g_norm = tensor(0.1381, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302870512008667\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305004358291626\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.68653869628906\n",
            "||∇_X meta|| = 0.0022033003624528646\n",
            "ΔX norm: 2.2032976630725898e-05\n",
            "Stage 1/10:  17%|█████▏                        | 52/300 [01:26<07:06,  1.72s/it]T Loss=2.304217576980591\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031535148620605\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041625022888184\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304399251937866\n",
            "g_norm = tensor(0.1021, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30298113822937\n",
            "g_norm = tensor(0.1118, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.89231872558594\n",
            "||∇_X meta|| = 0.002554206410422921\n",
            "ΔX norm: 2.5542069124639966e-05\n",
            "Stage 1/10:  18%|█████▎                        | 53/300 [01:28<06:55,  1.68s/it]T Loss=2.3027565479278564\n",
            "g_norm = tensor(0.0841, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037025928497314\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304184913635254\n",
            "g_norm = tensor(0.0813, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037593364715576\n",
            "g_norm = tensor(0.0866, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048081398010254\n",
            "g_norm = tensor(0.0748, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.21328735351562\n",
            "||∇_X meta|| = 0.002637026598677039\n",
            "ΔX norm: 2.6370269551989622e-05\n",
            "Stage 1/10:  18%|█████▍                        | 54/300 [01:30<07:19,  1.79s/it]T Loss=2.304396152496338\n",
            "g_norm = tensor(0.1022, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304537057876587\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30395245552063\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042855262756348\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048787117004395\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1524200439453\n",
            "||∇_X meta|| = 0.002408120781183243\n",
            "ΔX norm: 2.408117870800197e-05\n",
            "Stage 1/10:  18%|█████▌                        | 55/300 [01:31<06:46,  1.66s/it]T Loss=2.3033010959625244\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303591251373291\n",
            "g_norm = tensor(0.0845, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036162853240967\n",
            "g_norm = tensor(0.0762, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038814067840576\n",
            "g_norm = tensor(0.0747, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303630828857422\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6784210205078\n",
            "||∇_X meta|| = 0.002373685361817479\n",
            "ΔX norm: 2.3736809453112073e-05\n",
            "Stage 1/10:  19%|█████▌                        | 56/300 [01:33<06:16,  1.54s/it]T Loss=2.303285598754883\n",
            "g_norm = tensor(0.1099, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045716285705566\n",
            "g_norm = tensor(0.0960, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30326509475708\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037986755371094\n",
            "g_norm = tensor(0.0778, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044867515563965\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8905487060547\n",
            "||∇_X meta|| = 0.00232870364561677\n",
            "ΔX norm: 2.3286995201488025e-05\n",
            "Stage 1/10:  19%|█████▋                        | 57/300 [01:34<05:54,  1.46s/it]T Loss=2.304532527923584\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034656047821045\n",
            "g_norm = tensor(0.1259, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045496940612793\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303886651992798\n",
            "g_norm = tensor(0.1283, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304187536239624\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.09422302246094\n",
            "||∇_X meta|| = 0.0025826944038271904\n",
            "ΔX norm: 2.5826979253906757e-05\n",
            "Stage 1/10:  19%|█████▊                        | 58/300 [01:35<05:39,  1.40s/it]T Loss=2.30309796333313\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033502101898193\n",
            "g_norm = tensor(0.0871, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030028343200684\n",
            "g_norm = tensor(0.0884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304744005203247\n",
            "g_norm = tensor(0.0934, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030314445495605\n",
            "g_norm = tensor(0.0784, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2981414794922\n",
            "||∇_X meta|| = 0.0023887595161795616\n",
            "ΔX norm: 2.3887589122750796e-05\n",
            "Stage 1/10:  20%|█████▉                        | 59/300 [01:37<05:28,  1.36s/it]T Loss=2.3034138679504395\n",
            "g_norm = tensor(0.0945, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046469688415527\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048577308654785\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038136959075928\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303992748260498\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0190887451172\n",
            "||∇_X meta|| = 0.002207014709711075\n",
            "ΔX norm: 2.207017496402841e-05\n",
            "Stage 1/10:  20%|██████                        | 60/300 [01:38<05:16,  1.32s/it]T Loss=2.304412841796875\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032798767089844\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304666519165039\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304544687271118\n",
            "g_norm = tensor(0.1143, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055641651153564\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.37220764160156\n",
            "||∇_X meta|| = 0.0025589624419808388\n",
            "ΔX norm: 2.55896411545109e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/10:  20%|██████                        | 61/300 [01:39<05:07,  1.29s/it]T Loss=2.305363893508911\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039984703063965\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305094003677368\n",
            "g_norm = tensor(0.1408, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305168628692627\n",
            "g_norm = tensor(0.1143, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3061747550964355\n",
            "g_norm = tensor(0.1243, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.82276916503906\n",
            "||∇_X meta|| = 0.0024168742820620537\n",
            "ΔX norm: 2.4168748495867476e-05\n",
            "Stage 1/10:  21%|██████▏                       | 62/300 [01:41<05:40,  1.43s/it]T Loss=2.3038601875305176\n",
            "g_norm = tensor(0.0678, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040084838867188\n",
            "g_norm = tensor(0.0647, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304108142852783\n",
            "g_norm = tensor(0.0646, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303908109664917\n",
            "g_norm = tensor(0.0668, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042500019073486\n",
            "g_norm = tensor(0.0702, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8042449951172\n",
            "||∇_X meta|| = 0.002231763442978263\n",
            "ΔX norm: 2.2317612092592753e-05\n",
            "Stage 1/10:  21%|██████▎                       | 63/300 [01:42<05:34,  1.41s/it]T Loss=2.3044934272766113\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033814430236816\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303903102874756\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035988807678223\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042473793029785\n",
            "g_norm = tensor(0.1325, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.56454467773438\n",
            "||∇_X meta|| = 0.002205983269959688\n",
            "ΔX norm: 2.2059861294110306e-05\n",
            "Stage 1/10:  21%|██████▍                       | 64/300 [01:43<05:22,  1.37s/it]T Loss=2.303123712539673\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040547370910645\n",
            "g_norm = tensor(0.0820, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303995132446289\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30346417427063\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037145137786865\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.58895874023438\n",
            "||∇_X meta|| = 0.002310345182195306\n",
            "ΔX norm: 2.3103541025193408e-05\n",
            "Stage 1/10:  22%|██████▌                       | 65/300 [01:45<05:13,  1.33s/it]T Loss=2.304227113723755\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038811683654785\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058109283447266\n",
            "g_norm = tensor(0.0928, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304105281829834\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3062572479248047\n",
            "g_norm = tensor(0.0942, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.09201049804688\n",
            "||∇_X meta|| = 0.002315620891749859\n",
            "ΔX norm: 2.3156218958320096e-05\n",
            "Stage 1/10:  22%|██████▌                       | 66/300 [01:46<05:09,  1.32s/it]T Loss=2.303480625152588\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040719032287598\n",
            "g_norm = tensor(0.0942, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303704023361206\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037171363830566\n",
            "g_norm = tensor(0.0980, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302980661392212\n",
            "g_norm = tensor(0.0862, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.53807067871094\n",
            "||∇_X meta|| = 0.002107505686581135\n",
            "ΔX norm: 2.1075093172839843e-05\n",
            "Stage 1/10:  22%|██████▋                       | 67/300 [01:47<05:05,  1.31s/it]T Loss=2.3042049407958984\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032522201538086\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303662061691284\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035571575164795\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302499294281006\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.79449462890625\n",
            "||∇_X meta|| = 0.002303633838891983\n",
            "ΔX norm: 2.3036312995827757e-05\n",
            "Stage 1/10:  23%|██████▊                       | 68/300 [01:48<04:59,  1.29s/it]T Loss=2.3033559322357178\n",
            "g_norm = tensor(0.1361, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304445505142212\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303602457046509\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302489757537842\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025550842285156\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.44891357421875\n",
            "||∇_X meta|| = 0.0023585644084960222\n",
            "ΔX norm: 2.3585662347613834e-05\n",
            "Stage 1/10:  23%|██████▉                       | 69/300 [01:50<04:58,  1.29s/it]T Loss=2.3043935298919678\n",
            "g_norm = tensor(0.0746, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049519062042236\n",
            "g_norm = tensor(0.0824, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305204391479492\n",
            "g_norm = tensor(0.0715, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305384397506714\n",
            "g_norm = tensor(0.0805, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304832935333252\n",
            "g_norm = tensor(0.0811, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2311553955078\n",
            "||∇_X meta|| = 0.002161130541935563\n",
            "ΔX norm: 2.1611287593259476e-05\n",
            "Stage 1/10:  23%|███████                       | 70/300 [01:51<04:56,  1.29s/it]T Loss=2.3030080795288086\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303844928741455\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303312301635742\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036694526672363\n",
            "g_norm = tensor(0.0908, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031885623931885\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.324462890625\n",
            "||∇_X meta|| = 0.0023570486810058355\n",
            "ΔX norm: 2.3570513803861104e-05\n",
            "Stage 1/10:  24%|███████                       | 71/300 [01:52<04:53,  1.28s/it]T Loss=2.302875518798828\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037352561950684\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043110370635986\n",
            "g_norm = tensor(0.1362, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032760620117188\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041346073150635\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4676971435547\n",
            "||∇_X meta|| = 0.002410740125924349\n",
            "ΔX norm: 2.4107364879455417e-05\n",
            "Stage 1/10:  24%|███████▏                      | 72/300 [01:54<04:52,  1.28s/it]T Loss=2.302603244781494\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303725242614746\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302586555480957\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303942918777466\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301910638809204\n",
            "g_norm = tensor(0.1075, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.21206665039062\n",
            "||∇_X meta|| = 0.002159355441108346\n",
            "ΔX norm: 2.159351970476564e-05\n",
            "Stage 1/10:  24%|███████▎                      | 73/300 [01:55<04:47,  1.27s/it]T Loss=2.303877830505371\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303896427154541\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303344964981079\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303018569946289\n",
            "g_norm = tensor(0.1243, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304403066635132\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.4532928466797\n",
            "||∇_X meta|| = 0.002270912053063512\n",
            "ΔX norm: 2.2709133190801367e-05\n",
            "Stage 1/10:  25%|███████▍                      | 74/300 [01:56<04:50,  1.28s/it]T Loss=2.3039333820343018\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031930923461914\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034627437591553\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3013973236083984\n",
            "g_norm = tensor(0.1368, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303438186645508\n",
            "g_norm = tensor(0.1731, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4414520263672\n",
            "||∇_X meta|| = 0.002200119895860553\n",
            "ΔX norm: 2.2001302568241954e-05\n",
            "Stage 1/10:  25%|███████▌                      | 75/300 [01:57<04:49,  1.29s/it]T Loss=2.304743766784668\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045105934143066\n",
            "g_norm = tensor(0.0890, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038694858551025\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047266006469727\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042566776275635\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.17230224609375\n",
            "||∇_X meta|| = 0.0020964269060641527\n",
            "ΔX norm: 2.0964258510502987e-05\n",
            "Stage 1/10:  25%|███████▌                      | 76/300 [01:59<04:47,  1.29s/it]T Loss=2.3039956092834473\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032851219177246\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044512271881104\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042943477630615\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038604259490967\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.99258422851562\n",
            "||∇_X meta|| = 0.0020762814674526453\n",
            "ΔX norm: 2.0762838175869547e-05\n",
            "Stage 1/10:  26%|███████▋                      | 77/300 [02:00<04:45,  1.28s/it]T Loss=2.3044815063476562\n",
            "g_norm = tensor(0.0796, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303819179534912\n",
            "g_norm = tensor(0.0784, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30393648147583\n",
            "g_norm = tensor(0.0869, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30369234085083\n",
            "g_norm = tensor(0.0883, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036627769470215\n",
            "g_norm = tensor(0.0729, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.30226135253906\n",
            "||∇_X meta|| = 0.0022321329452097416\n",
            "ΔX norm: 2.2321321011986583e-05\n",
            "Stage 1/10:  26%|███████▊                      | 78/300 [02:01<04:46,  1.29s/it]T Loss=2.304546594619751\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038811683654785\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304142713546753\n",
            "g_norm = tensor(0.0850, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041622638702393\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304083824157715\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.6663055419922\n",
            "||∇_X meta|| = 0.002156969392672181\n",
            "ΔX norm: 2.1569705495494418e-05\n",
            "Stage 1/10:  26%|███████▉                      | 79/300 [02:03<04:47,  1.30s/it]T Loss=2.3028438091278076\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022656440734863\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303044557571411\n",
            "g_norm = tensor(0.1447, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031187057495117\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028881549835205\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8718719482422\n",
            "||∇_X meta|| = 0.0022678780369460583\n",
            "ΔX norm: 2.2678730601910502e-05\n",
            "Stage 1/10:  27%|████████                      | 80/300 [02:04<04:42,  1.28s/it]T Loss=2.3040895462036133\n",
            "g_norm = tensor(0.0637, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045897483825684\n",
            "g_norm = tensor(0.0841, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046562671661377\n",
            "g_norm = tensor(0.0791, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304069757461548\n",
            "g_norm = tensor(0.0759, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304244041442871\n",
            "g_norm = tensor(0.0837, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.08023071289062\n",
            "||∇_X meta|| = 0.0024446367751806974\n",
            "ΔX norm: 2.444631900289096e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/10:  27%|████████                      | 81/300 [02:05<04:39,  1.28s/it]T Loss=2.3044161796569824\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040449619293213\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049776554107666\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046138286590576\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304117441177368\n",
            "g_norm = tensor(0.1053, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.0563201904297\n",
            "||∇_X meta|| = 0.002076714299619198\n",
            "ΔX norm: 2.076715463772416e-05\n",
            "Stage 1/10:  27%|████████▏                     | 82/300 [02:07<05:01,  1.38s/it]T Loss=2.3040213584899902\n",
            "g_norm = tensor(0.0867, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303353786468506\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039495944976807\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042232990264893\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304659128189087\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3184051513672\n",
            "||∇_X meta|| = 0.0018761544488370419\n",
            "ΔX norm: 1.8761533283395693e-05\n",
            "Stage 1/10:  28%|████████▎                     | 83/300 [02:08<04:59,  1.38s/it]T Loss=2.3036937713623047\n",
            "g_norm = tensor(0.0610, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303013324737549\n",
            "g_norm = tensor(0.0715, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303894519805908\n",
            "g_norm = tensor(0.0776, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303429126739502\n",
            "g_norm = tensor(0.0752, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026700019836426\n",
            "g_norm = tensor(0.0682, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.57662963867188\n",
            "||∇_X meta|| = 0.001883205957710743\n",
            "ΔX norm: 1.8832060959539376e-05\n",
            "Stage 1/10:  28%|████████▍                     | 84/300 [02:10<04:59,  1.39s/it]T Loss=2.3043205738067627\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304671287536621\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032891750335693\n",
            "g_norm = tensor(0.1350, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022379875183105\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305366277694702\n",
            "g_norm = tensor(0.1289, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.11622619628906\n",
            "||∇_X meta|| = 0.001993754180148244\n",
            "ΔX norm: 1.9937580873374827e-05\n",
            "Stage 1/10:  28%|████████▌                     | 85/300 [02:11<04:54,  1.37s/it]T Loss=2.3026227951049805\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027255535125732\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030121326446533\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026652336120605\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029685020446777\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1028594970703\n",
            "||∇_X meta|| = 0.002156090224161744\n",
            "ΔX norm: 2.1560936147579923e-05\n",
            "Stage 1/10:  29%|████████▌                     | 86/300 [02:12<04:49,  1.35s/it]T Loss=2.3044612407684326\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045315742492676\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041703701019287\n",
            "g_norm = tensor(0.0833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045732975006104\n",
            "g_norm = tensor(0.1253, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303773880004883\n",
            "g_norm = tensor(0.0834, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.41554260253906\n",
            "||∇_X meta|| = 0.002005636226385832\n",
            "ΔX norm: 2.0056328139617108e-05\n",
            "Stage 1/10:  29%|████████▋                     | 87/300 [02:13<04:40,  1.32s/it]T Loss=2.3041844367980957\n",
            "g_norm = tensor(0.0711, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303734064102173\n",
            "g_norm = tensor(0.0775, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033149242401123\n",
            "g_norm = tensor(0.0760, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303682804107666\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303546667098999\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.96499633789062\n",
            "||∇_X meta|| = 0.0018658031476661563\n",
            "ΔX norm: 1.865802551037632e-05\n",
            "Stage 1/10:  29%|████████▊                     | 88/300 [02:15<04:36,  1.30s/it]T Loss=2.3034539222717285\n",
            "g_norm = tensor(0.1393, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303462266921997\n",
            "g_norm = tensor(0.1384, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030996322631836\n",
            "g_norm = tensor(0.1614, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034615516662598\n",
            "g_norm = tensor(0.1118, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021225929260254\n",
            "g_norm = tensor(0.1780, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.17770385742188\n",
            "||∇_X meta|| = 0.0018952557584270835\n",
            "ΔX norm: 1.8952598111354746e-05\n",
            "Stage 1/10:  30%|████████▉                     | 89/300 [02:16<04:35,  1.31s/it]T Loss=2.3043770790100098\n",
            "g_norm = tensor(0.1535, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305593252182007\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305386543273926\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305361270904541\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032619953155518\n",
            "g_norm = tensor(0.1372, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3180389404297\n",
            "||∇_X meta|| = 0.002029262250289321\n",
            "ΔX norm: 2.0292603949201293e-05\n",
            "Stage 1/10:  30%|█████████                     | 90/300 [02:17<04:33,  1.30s/it]T Loss=2.3043744564056396\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054378032684326\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034451007843018\n",
            "g_norm = tensor(0.0868, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043017387390137\n",
            "g_norm = tensor(0.0898, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052217960357666\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.47740173339844\n",
            "||∇_X meta|| = 0.002110899891704321\n",
            "ΔX norm: 2.110895911755506e-05\n",
            "Stage 1/10:  30%|█████████                     | 91/300 [02:19<04:27,  1.28s/it]T Loss=2.30249285697937\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304352283477783\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304854393005371\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302994966506958\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303293228149414\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.78591918945312\n",
            "||∇_X meta|| = 0.002205455210059881\n",
            "ΔX norm: 2.205448799941223e-05\n",
            "Stage 1/10:  31%|█████████▏                    | 92/300 [02:20<04:24,  1.27s/it]T Loss=2.3042941093444824\n",
            "g_norm = tensor(0.1622, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044321537017822\n",
            "g_norm = tensor(0.1671, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303170919418335\n",
            "g_norm = tensor(0.1646, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042588233947754\n",
            "g_norm = tensor(0.1513, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040173053741455\n",
            "g_norm = tensor(0.1410, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.79225158691406\n",
            "||∇_X meta|| = 0.001866169273853302\n",
            "ΔX norm: 1.8661656213225797e-05\n",
            "Stage 1/10:  31%|█████████▎                    | 93/300 [02:22<04:53,  1.42s/it]T Loss=2.3033509254455566\n",
            "g_norm = tensor(0.1218, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303697109222412\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031601905822754\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047046661376953\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050785064697266\n",
            "g_norm = tensor(0.1378, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.13320922851562\n",
            "||∇_X meta|| = 0.0020425759721547365\n",
            "ΔX norm: 2.0425744878593832e-05\n",
            "Stage 1/10:  31%|█████████▍                    | 94/300 [02:23<05:00,  1.46s/it]T Loss=2.303736686706543\n",
            "g_norm = tensor(0.0830, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038382530212402\n",
            "g_norm = tensor(0.0866, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050029277801514\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037073612213135\n",
            "g_norm = tensor(0.0830, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048768043518066\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.02516174316406\n",
            "||∇_X meta|| = 0.0018948931246995926\n",
            "ΔX norm: 1.8948961951537058e-05\n",
            "Stage 1/10:  32%|█████████▌                    | 95/300 [02:24<04:53,  1.43s/it]T Loss=2.3033194541931152\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304504632949829\n",
            "g_norm = tensor(0.1107, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046107292175293\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303948402404785\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049073219299316\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.80174255371094\n",
            "||∇_X meta|| = 0.002018991857767105\n",
            "ΔX norm: 2.01899583771592e-05\n",
            "Stage 1/10:  32%|█████████▌                    | 96/300 [02:26<04:41,  1.38s/it]T Loss=2.3030550479888916\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040261268615723\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037145137786865\n",
            "g_norm = tensor(0.0934, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303967237472534\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031203746795654\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.59591674804688\n",
            "||∇_X meta|| = 0.0020167212933301926\n",
            "ΔX norm: 2.0167202819720842e-05\n",
            "Stage 1/10:  32%|█████████▋                    | 97/300 [02:27<04:43,  1.40s/it]T Loss=2.3045613765716553\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034348487854004\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026607036590576\n",
            "g_norm = tensor(0.1374, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303199291229248\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020567893981934\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3310089111328\n",
            "||∇_X meta|| = 0.0021264723036438227\n",
            "ΔX norm: 2.1264746465021744e-05\n",
            "Stage 1/10:  33%|█████████▊                    | 98/300 [02:29<04:52,  1.45s/it]T Loss=2.303764581680298\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304468870162964\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023288249969482\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303694486618042\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044540882110596\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.34869384765625\n",
            "||∇_X meta|| = 0.001962114591151476\n",
            "ΔX norm: 1.9621127648861147e-05\n",
            "Stage 1/10:  33%|█████████▉                    | 99/300 [02:30<04:59,  1.49s/it]T Loss=2.30448317527771\n",
            "g_norm = tensor(0.1353, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303989887237549\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304248332977295\n",
            "g_norm = tensor(0.1364, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056139945983887\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305433750152588\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.69235229492188\n",
            "||∇_X meta|| = 0.0019612587057054043\n",
            "ΔX norm: 1.9612529285950586e-05\n",
            "Stage 1/10:  33%|█████████▋                   | 100/300 [02:32<04:59,  1.50s/it]T Loss=2.3040771484375\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303683042526245\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054022789001465\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303819179534912\n",
            "g_norm = tensor(0.0878, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049397468566895\n",
            "g_norm = tensor(0.0956, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.88104248046875\n",
            "||∇_X meta|| = 0.0016597731737419963\n",
            "ΔX norm: 1.6597719877609052e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/10:  34%|█████████▊                   | 101/300 [02:33<04:48,  1.45s/it]T Loss=2.3048205375671387\n",
            "g_norm = tensor(0.1364, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306453227996826\n",
            "g_norm = tensor(0.1537, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304426908493042\n",
            "g_norm = tensor(0.1436, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045544624328613\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305166482925415\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =234.1602020263672\n",
            "||∇_X meta|| = 0.0019156376365572214\n",
            "ΔX norm: 1.9156355847371742e-05\n",
            "Stage 1/10:  34%|█████████▊                   | 102/300 [02:35<04:53,  1.48s/it]T Loss=2.303679943084717\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304518699645996\n",
            "g_norm = tensor(0.1222, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051810264587402\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024678230285645\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304931879043579\n",
            "g_norm = tensor(0.1344, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.11610412597656\n",
            "||∇_X meta|| = 0.0018552870023995638\n",
            "ΔX norm: 1.855286245699972e-05\n",
            "Stage 1/10:  34%|█████████▉                   | 103/300 [02:36<04:57,  1.51s/it]T Loss=2.3044090270996094\n",
            "g_norm = tensor(0.1216, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304386615753174\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038876056671143\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046507835388184\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024768829345703\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.81982421875\n",
            "||∇_X meta|| = 0.001724607776850462\n",
            "ΔX norm: 1.7246033166884445e-05\n",
            "Stage 1/10:  35%|██████████                   | 104/300 [02:38<04:42,  1.44s/it]T Loss=2.303600549697876\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303569793701172\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30446195602417\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038549423217773\n",
            "g_norm = tensor(0.0825, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031582832336426\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.53094482421875\n",
            "||∇_X meta|| = 0.002197547582909465\n",
            "ΔX norm: 2.1975480194669217e-05\n",
            "Stage 1/10:  35%|██████████▏                  | 105/300 [02:39<04:31,  1.39s/it]T Loss=2.3038928508758545\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304182529449463\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045458793640137\n",
            "g_norm = tensor(0.0727, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033149242401123\n",
            "g_norm = tensor(0.0783, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303828477859497\n",
            "g_norm = tensor(0.0797, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5169219970703\n",
            "||∇_X meta|| = 0.0020818912889808416\n",
            "ΔX norm: 2.0818912162212655e-05\n",
            "Stage 1/10:  35%|██████████▏                  | 106/300 [02:40<04:25,  1.37s/it]T Loss=2.304413080215454\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055288791656494\n",
            "g_norm = tensor(0.1377, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047804832458496\n",
            "g_norm = tensor(0.1357, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303550958633423\n",
            "g_norm = tensor(0.1437, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302969455718994\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.19912719726562\n",
            "||∇_X meta|| = 0.0018973569385707378\n",
            "ΔX norm: 1.8973614714923315e-05\n",
            "Stage 1/10:  36%|██████████▎                  | 107/300 [02:41<04:20,  1.35s/it]T Loss=2.3030543327331543\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304948329925537\n",
            "g_norm = tensor(0.1741, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303948163986206\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045332431793213\n",
            "g_norm = tensor(0.1406, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3060431480407715\n",
            "g_norm = tensor(0.1374, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.57150268554688\n",
            "||∇_X meta|| = 0.0017646068008616567\n",
            "ΔX norm: 1.7645985280978493e-05\n",
            "Stage 1/10:  36%|██████████▍                  | 108/300 [02:43<04:14,  1.33s/it]T Loss=2.3033530712127686\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30424427986145\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30580472946167\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028297424316406\n",
            "g_norm = tensor(0.1234, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30371356010437\n",
            "g_norm = tensor(0.1618, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9624481201172\n",
            "||∇_X meta|| = 0.0018545290222391486\n",
            "ΔX norm: 1.8545246348367073e-05\n",
            "Stage 1/10:  36%|██████████▌                  | 109/300 [02:44<04:09,  1.31s/it]T Loss=2.3048877716064453\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306119918823242\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30385160446167\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041281700134277\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3060288429260254\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.53103637695312\n",
            "||∇_X meta|| = 0.0016648181481286883\n",
            "ΔX norm: 1.6648169548716396e-05\n",
            "Stage 1/10:  37%|██████████▋                  | 110/300 [02:45<04:07,  1.30s/it]T Loss=2.304347276687622\n",
            "g_norm = tensor(0.0888, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026177883148193\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030006885528564\n",
            "g_norm = tensor(0.0858, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303549289703369\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038792610168457\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0237274169922\n",
            "||∇_X meta|| = 0.0016891731647774577\n",
            "ΔX norm: 1.6891750419745222e-05\n",
            "Stage 1/10:  37%|██████████▋                  | 111/300 [02:47<04:03,  1.29s/it]T Loss=2.3028979301452637\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031768798828125\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037073612213135\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027658462524414\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040711879730225\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.21688842773438\n",
            "||∇_X meta|| = 0.0015993984416127205\n",
            "ΔX norm: 1.599399183760397e-05\n",
            "Stage 1/10:  37%|██████████▊                  | 112/300 [02:48<04:08,  1.32s/it]T Loss=2.304439067840576\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028881549835205\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029916286468506\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044674396514893\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049237728118896\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.71792602539062\n",
            "||∇_X meta|| = 0.0018081768648698926\n",
            "ΔX norm: 1.80817733053118e-05\n",
            "Stage 1/10:  38%|██████████▉                  | 113/300 [02:49<04:02,  1.30s/it]T Loss=2.303121328353882\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303823709487915\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043501377105713\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034355640411377\n",
            "g_norm = tensor(0.0993, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304595470428467\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.63983154296875\n",
            "||∇_X meta|| = 0.0018058107234537601\n",
            "ΔX norm: 1.8058095520245843e-05\n",
            "Stage 1/10:  38%|███████████                  | 114/300 [02:50<03:58,  1.28s/it]T Loss=2.303046464920044\n",
            "g_norm = tensor(0.0773, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031792640686035\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037238121032715\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303640842437744\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304185152053833\n",
            "g_norm = tensor(0.0843, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.32421875\n",
            "||∇_X meta|| = 0.0019055773736909032\n",
            "ΔX norm: 1.9055807570111938e-05\n",
            "Stage 1/10:  38%|███████████                  | 115/300 [02:52<03:58,  1.29s/it]T Loss=2.3032021522521973\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302459955215454\n",
            "g_norm = tensor(0.1394, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043875694274902\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303605794906616\n",
            "g_norm = tensor(0.1276, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305817127227783\n",
            "g_norm = tensor(0.1425, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.22227478027344\n",
            "||∇_X meta|| = 0.0017950834007933736\n",
            "ΔX norm: 1.7950767869479023e-05\n",
            "Stage 1/10:  39%|███████████▏                 | 116/300 [02:53<03:58,  1.30s/it]T Loss=2.3021655082702637\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032591342926025\n",
            "g_norm = tensor(0.0771, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037729263305664\n",
            "g_norm = tensor(0.0794, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30310320854187\n",
            "g_norm = tensor(0.0871, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303112506866455\n",
            "g_norm = tensor(0.0639, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.35829162597656\n",
            "||∇_X meta|| = 0.0017464361153542995\n",
            "ΔX norm: 1.7464362827013247e-05\n",
            "Stage 1/10:  39%|███████████▎                 | 117/300 [02:54<03:57,  1.30s/it]T Loss=2.3043346405029297\n",
            "g_norm = tensor(0.0947, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30306339263916\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030524253845215\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040661811828613\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302765369415283\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1672821044922\n",
            "||∇_X meta|| = 0.0017905250424519181\n",
            "ΔX norm: 1.7905254935612902e-05\n",
            "Stage 1/10:  39%|███████████▍                 | 118/300 [02:56<03:56,  1.30s/it]T Loss=2.303760290145874\n",
            "g_norm = tensor(0.0919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303309917449951\n",
            "g_norm = tensor(0.0702, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303745985031128\n",
            "g_norm = tensor(0.0832, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035640716552734\n",
            "g_norm = tensor(0.0731, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304381847381592\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.61734008789062\n",
            "||∇_X meta|| = 0.0016217236407101154\n",
            "ΔX norm: 1.6217216398217715e-05\n",
            "Stage 1/10:  40%|███████████▌                 | 119/300 [02:57<03:53,  1.29s/it]T Loss=2.3053689002990723\n",
            "g_norm = tensor(0.0942, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305708408355713\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055522441864014\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304774045944214\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304607629776001\n",
            "g_norm = tensor(0.0928, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.74176025390625\n",
            "||∇_X meta|| = 0.0019176675705239177\n",
            "ΔX norm: 1.917665395012591e-05\n",
            "Stage 1/10:  40%|███████████▌                 | 120/300 [02:58<03:55,  1.31s/it]T Loss=2.3028221130371094\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302722454071045\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303032159805298\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035149574279785\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026528358459473\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.01675415039062\n",
            "||∇_X meta|| = 0.001677755848504603\n",
            "ΔX norm: 1.6777579730842263e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/10:  40%|███████████▋                 | 121/300 [03:00<03:54,  1.31s/it]T Loss=2.3045737743377686\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302903652191162\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033101558685303\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302842617034912\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047385215759277\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.99188232421875\n",
            "||∇_X meta|| = 0.0017215581610798836\n",
            "ΔX norm: 1.721555418043863e-05\n",
            "Stage 1/10:  41%|███████████▊                 | 122/300 [03:01<04:21,  1.47s/it]T Loss=2.3043906688690186\n",
            "g_norm = tensor(0.0738, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304809093475342\n",
            "g_norm = tensor(0.0879, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303269624710083\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302960157394409\n",
            "g_norm = tensor(0.0902, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026881217956543\n",
            "g_norm = tensor(0.0845, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6286163330078\n",
            "||∇_X meta|| = 0.0017375883180648088\n",
            "ΔX norm: 1.737585262162611e-05\n",
            "Stage 1/10:  41%|███████████▉                 | 123/300 [03:03<04:24,  1.49s/it]T Loss=2.305088520050049\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305631399154663\n",
            "g_norm = tensor(0.1492, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035552501678467\n",
            "g_norm = tensor(0.1344, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028810024261475\n",
            "g_norm = tensor(0.1342, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3062891960144043\n",
            "g_norm = tensor(0.1427, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.28924560546875\n",
            "||∇_X meta|| = 0.0017844497924670577\n",
            "ΔX norm: 1.7844440662884153e-05\n",
            "Stage 1/10:  41%|███████████▉                 | 124/300 [03:04<04:13,  1.44s/it]T Loss=2.305405616760254\n",
            "g_norm = tensor(0.1405, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303816556930542\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040616512298584\n",
            "g_norm = tensor(0.1187, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038594722747803\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303018093109131\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.33143615722656\n",
            "||∇_X meta|| = 0.0017658310243859887\n",
            "ΔX norm: 1.7658221622696146e-05\n",
            "Stage 1/10:  42%|████████████                 | 125/300 [03:06<04:04,  1.40s/it]T Loss=2.3043391704559326\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304555654525757\n",
            "g_norm = tensor(0.0828, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303954601287842\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040356636047363\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30480694770813\n",
            "g_norm = tensor(0.0836, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.42112731933594\n",
            "||∇_X meta|| = 0.0017223809845745564\n",
            "ΔX norm: 1.7223816030309536e-05\n",
            "Stage 1/10:  42%|████████████▏                | 126/300 [03:07<04:15,  1.47s/it]T Loss=2.304138660430908\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034749031066895\n",
            "g_norm = tensor(0.0942, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302899122238159\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042654991149902\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305014133453369\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.26844787597656\n",
            "||∇_X meta|| = 0.001848799642175436\n",
            "ΔX norm: 1.8487968191038817e-05\n",
            "Stage 1/10:  42%|████████████▎                | 127/300 [03:09<04:11,  1.45s/it]T Loss=2.3030731678009033\n",
            "g_norm = tensor(0.1309, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024039268493652\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031458854675293\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039703369140625\n",
            "g_norm = tensor(0.1336, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303769588470459\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.23077392578125\n",
            "||∇_X meta|| = 0.0016874716384336352\n",
            "ΔX norm: 1.6874670109245926e-05\n",
            "Stage 1/10:  43%|████████████▎                | 128/300 [03:10<04:05,  1.43s/it]T Loss=2.3031697273254395\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047826290130615\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037922382354736\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039774894714355\n",
            "g_norm = tensor(0.1249, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031599521636963\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4735107421875\n",
            "||∇_X meta|| = 0.0015823477879166603\n",
            "ΔX norm: 1.5823454305063933e-05\n",
            "Stage 1/10:  43%|████████████▍                | 129/300 [03:11<03:55,  1.37s/it]T Loss=2.304335117340088\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304410219192505\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303091526031494\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020107746124268\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033761978149414\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.45872497558594\n",
            "||∇_X meta|| = 0.0017952293856069446\n",
            "ΔX norm: 1.7952275811694562e-05\n",
            "Stage 1/10:  43%|████████████▌                | 130/300 [03:13<03:53,  1.38s/it]T Loss=2.3033246994018555\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041975498199463\n",
            "g_norm = tensor(0.0841, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032965660095215\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038344383239746\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303374767303467\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.31529235839844\n",
            "||∇_X meta|| = 0.002035625046119094\n",
            "ΔX norm: 2.0356235836516134e-05\n",
            "Stage 1/10:  44%|████████████▋                | 131/300 [03:14<03:50,  1.36s/it]T Loss=2.3033833503723145\n",
            "g_norm = tensor(0.0861, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045599460601807\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034846782684326\n",
            "g_norm = tensor(0.0827, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043930530548096\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035988807678223\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.28460693359375\n",
            "||∇_X meta|| = 0.0017736871959641576\n",
            "ΔX norm: 1.77368910954101e-05\n",
            "Stage 1/10:  44%|████████████▊                | 132/300 [03:15<03:51,  1.38s/it]T Loss=2.3042871952056885\n",
            "g_norm = tensor(0.0858, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038582801818848\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042192459106445\n",
            "g_norm = tensor(0.0883, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304713249206543\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048486709594727\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.99351501464844\n",
            "||∇_X meta|| = 0.0015146820805966854\n",
            "ΔX norm: 1.5146797522902489e-05\n",
            "Stage 1/10:  44%|████████████▊                | 133/300 [03:17<03:47,  1.36s/it]T Loss=2.3039181232452393\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032310009002686\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044514656066895\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038103580474854\n",
            "g_norm = tensor(0.0831, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023815155029297\n",
            "g_norm = tensor(0.0864, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.46463012695312\n",
            "||∇_X meta|| = 0.0017031539464369416\n",
            "ΔX norm: 1.7031512470566668e-05\n",
            "Stage 1/10:  45%|████████████▉                | 134/300 [03:18<03:44,  1.35s/it]T Loss=2.303884506225586\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039638996124268\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036949634552\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041415214538574\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042685985565186\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.1206817626953\n",
            "||∇_X meta|| = 0.001530997222289443\n",
            "ΔX norm: 1.5310009985114448e-05\n",
            "Stage 1/10:  45%|█████████████                | 135/300 [03:19<03:44,  1.36s/it]T Loss=2.304166793823242\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044192790985107\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304713726043701\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043224811553955\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303896903991699\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.37530517578125\n",
            "||∇_X meta|| = 0.001688100048340857\n",
            "ΔX norm: 1.6880989278433844e-05\n",
            "Stage 1/10:  45%|█████████████▏               | 136/300 [03:21<03:52,  1.42s/it]T Loss=2.3046677112579346\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035857677459717\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044023513793945\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304520606994629\n",
            "g_norm = tensor(0.1107, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037936687469482\n",
            "g_norm = tensor(0.1187, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.0094757080078\n",
            "||∇_X meta|| = 0.0018767572473734617\n",
            "ΔX norm: 1.8767563233268447e-05\n",
            "Stage 1/10:  46%|█████████████▏               | 137/300 [03:23<04:01,  1.48s/it]T Loss=2.3042030334472656\n",
            "g_norm = tensor(0.1357, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051862716674805\n",
            "g_norm = tensor(0.1355, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047285079956055\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041622638702393\n",
            "g_norm = tensor(0.1453, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043994903564453\n",
            "g_norm = tensor(0.1286, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3758544921875\n",
            "||∇_X meta|| = 0.001612156629562378\n",
            "ΔX norm: 1.6121583030326292e-05\n",
            "Stage 1/10:  46%|█████████████▎               | 138/300 [03:24<03:59,  1.48s/it]T Loss=2.3047122955322266\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303846836090088\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303057909011841\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303666353225708\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036246299743652\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.00460815429688\n",
            "||∇_X meta|| = 0.0015964418416842818\n",
            "ΔX norm: 1.5964398698997684e-05\n",
            "Stage 1/10:  46%|█████████████▍               | 139/300 [03:25<03:47,  1.41s/it]T Loss=2.303246259689331\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303401470184326\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040950298309326\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044705390930176\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303560256958008\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.39840698242188\n",
            "||∇_X meta|| = 0.0016377620631828904\n",
            "ΔX norm: 1.637764580664225e-05\n",
            "Stage 1/10:  47%|█████████████▌               | 140/300 [03:27<03:47,  1.42s/it]T Loss=2.30348539352417\n",
            "g_norm = tensor(0.1218, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045544624328613\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048648834228516\n",
            "g_norm = tensor(0.1230, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301915407180786\n",
            "g_norm = tensor(0.1262, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039608001708984\n",
            "g_norm = tensor(0.1225, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7908172607422\n",
            "||∇_X meta|| = 0.0016332254745066166\n",
            "ΔX norm: 1.6332274753949605e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/10:  47%|█████████████▋               | 141/300 [03:28<03:48,  1.43s/it]T Loss=2.304192066192627\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045756816864014\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303649663925171\n",
            "g_norm = tensor(0.1360, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037781715393066\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304553985595703\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.81947326660156\n",
            "||∇_X meta|| = 0.001818624441511929\n",
            "ΔX norm: 1.818617238313891e-05\n",
            "Stage 1/10:  47%|█████████████▋               | 142/300 [03:30<04:00,  1.52s/it]T Loss=2.303983211517334\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041763305664062\n",
            "g_norm = tensor(0.0880, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041067123413086\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303988218307495\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303967237472534\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1158447265625\n",
            "||∇_X meta|| = 0.0018064858159050345\n",
            "ΔX norm: 1.8064893083646894e-05\n",
            "Stage 1/10:  48%|█████████████▊               | 143/300 [03:31<03:54,  1.49s/it]T Loss=2.3031177520751953\n",
            "g_norm = tensor(0.0780, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039541244506836\n",
            "g_norm = tensor(0.0753, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303384780883789\n",
            "g_norm = tensor(0.0714, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303572177886963\n",
            "g_norm = tensor(0.0698, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304185628890991\n",
            "g_norm = tensor(0.0782, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1758575439453\n",
            "||∇_X meta|| = 0.0016306519974023104\n",
            "ΔX norm: 1.6306521501974203e-05\n",
            "Stage 1/10:  48%|█████████████▉               | 144/300 [03:33<03:50,  1.48s/it]T Loss=2.3036980628967285\n",
            "g_norm = tensor(0.1454, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301624298095703\n",
            "g_norm = tensor(0.1465, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035101890563965\n",
            "g_norm = tensor(0.1766, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033275604248047\n",
            "g_norm = tensor(0.1439, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301976442337036\n",
            "g_norm = tensor(0.1565, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.45358276367188\n",
            "||∇_X meta|| = 0.0015959131997078657\n",
            "ΔX norm: 1.59591236297274e-05\n",
            "Stage 1/10:  48%|██████████████               | 145/300 [03:34<03:42,  1.44s/it]T Loss=2.305708169937134\n",
            "g_norm = tensor(0.1273, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040783405303955\n",
            "g_norm = tensor(0.1352, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304844379425049\n",
            "g_norm = tensor(0.1396, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303581714630127\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303917407989502\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.58419799804688\n",
            "||∇_X meta|| = 0.001669847290031612\n",
            "ΔX norm: 1.6698473700671457e-05\n",
            "Stage 1/10:  49%|██████████████               | 146/300 [03:35<03:35,  1.40s/it]T Loss=2.3055336475372314\n",
            "g_norm = tensor(0.1555, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042008876800537\n",
            "g_norm = tensor(0.1488, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304398536682129\n",
            "g_norm = tensor(0.1370, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304182529449463\n",
            "g_norm = tensor(0.1268, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030736446380615\n",
            "g_norm = tensor(0.1629, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.75450134277344\n",
            "||∇_X meta|| = 0.0015536075225099921\n",
            "ΔX norm: 1.5536028513452038e-05\n",
            "Stage 1/10:  49%|██████████████▏              | 147/300 [03:37<03:30,  1.37s/it]T Loss=2.304090738296509\n",
            "g_norm = tensor(0.1555, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022854328155518\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043646812438965\n",
            "g_norm = tensor(0.1847, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027825355529785\n",
            "g_norm = tensor(0.1570, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302858829498291\n",
            "g_norm = tensor(0.1556, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.19876098632812\n",
            "||∇_X meta|| = 0.0017867827555164695\n",
            "ΔX norm: 1.7867778296931647e-05\n",
            "Stage 1/10:  49%|██████████████▎              | 148/300 [03:38<03:23,  1.34s/it]T Loss=2.302170753479004\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302543878555298\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303323268890381\n",
            "g_norm = tensor(0.1154, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305734157562256\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032193183898926\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.11102294921875\n",
            "||∇_X meta|| = 0.0017001512460410595\n",
            "ΔX norm: 1.700152461125981e-05\n",
            "Stage 1/10:  50%|██████████████▍              | 149/300 [03:39<03:19,  1.32s/it]T Loss=2.305690050125122\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30377197265625\n",
            "g_norm = tensor(0.0956, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035974502563477\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040032386779785\n",
            "g_norm = tensor(0.1259, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303410053253174\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.75643920898438\n",
            "||∇_X meta|| = 0.0015228163683786988\n",
            "ΔX norm: 1.5228217307594605e-05\n",
            "Stage 1/10:  50%|██████████████▌              | 150/300 [03:41<03:20,  1.34s/it]T Loss=2.3045456409454346\n",
            "g_norm = tensor(0.0840, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031067848205566\n",
            "g_norm = tensor(0.0782, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034675121307373\n",
            "g_norm = tensor(0.0780, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024144172668457\n",
            "g_norm = tensor(0.0794, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303710699081421\n",
            "g_norm = tensor(0.0767, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2797088623047\n",
            "||∇_X meta|| = 0.0018087398493662477\n",
            "ΔX norm: 1.8087357602780685e-05\n",
            "Stage 1/10:  50%|██████████████▌              | 151/300 [03:42<03:19,  1.34s/it]T Loss=2.3035967350006104\n",
            "g_norm = tensor(0.0626, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038861751556396\n",
            "g_norm = tensor(0.0692, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035998344421387\n",
            "g_norm = tensor(0.0556, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303178071975708\n",
            "g_norm = tensor(0.0629, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035709857940674\n",
            "g_norm = tensor(0.0684, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5414276123047\n",
            "||∇_X meta|| = 0.0017847686540335417\n",
            "ΔX norm: 1.7847674826043658e-05\n",
            "Stage 1/10:  51%|██████████████▋              | 152/300 [03:43<03:17,  1.33s/it]T Loss=2.3045859336853027\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045554161071777\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034844398498535\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038227558135986\n",
            "g_norm = tensor(0.0846, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039426803588867\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.97042846679688\n",
            "||∇_X meta|| = 0.0017440835945308208\n",
            "ΔX norm: 1.744087967381347e-05\n",
            "Stage 1/10:  51%|██████████████▊              | 153/300 [03:45<03:18,  1.35s/it]T Loss=2.30480694770813\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303527593612671\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025856018066406\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036863803863525\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304272174835205\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2611083984375\n",
            "||∇_X meta|| = 0.0017647240310907364\n",
            "ΔX norm: 1.7647213098825887e-05\n",
            "Stage 1/10:  51%|██████████████▉              | 154/300 [03:46<03:19,  1.37s/it]T Loss=2.304609775543213\n",
            "g_norm = tensor(0.2003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303969383239746\n",
            "g_norm = tensor(0.1472, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30413818359375\n",
            "g_norm = tensor(0.1694, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3012473583221436\n",
            "g_norm = tensor(0.1564, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302480459213257\n",
            "g_norm = tensor(0.1406, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5286407470703\n",
            "||∇_X meta|| = 0.0016991206211969256\n",
            "ΔX norm: 1.6991194570437074e-05\n",
            "Stage 1/10:  52%|██████████████▉              | 155/300 [03:47<03:15,  1.35s/it]T Loss=2.3044638633728027\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050804138183594\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305485486984253\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304948329925537\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304032802581787\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.04103088378906\n",
            "||∇_X meta|| = 0.0015438176924362779\n",
            "ΔX norm: 1.543821235827636e-05\n",
            "Stage 1/10:  52%|███████████████              | 156/300 [03:49<03:10,  1.33s/it]T Loss=2.3048787117004395\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032784461975098\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037450313568115\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30295729637146\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304378032684326\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9212188720703\n",
            "||∇_X meta|| = 0.0015232987934723496\n",
            "ΔX norm: 1.5233012163662352e-05\n",
            "Stage 1/10:  52%|███████████████▏             | 157/300 [03:50<03:09,  1.32s/it]T Loss=2.3031420707702637\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041772842407227\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038694858551025\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035695552825928\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030905723571777\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.48971557617188\n",
            "||∇_X meta|| = 0.0015525422058999538\n",
            "ΔX norm: 1.5525452909059823e-05\n",
            "Stage 1/10:  53%|███████████████▎             | 158/300 [03:52<03:12,  1.36s/it]T Loss=2.3043932914733887\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037800788879395\n",
            "g_norm = tensor(0.0888, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048465251922607\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032121658325195\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303333044052124\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3522491455078\n",
            "||∇_X meta|| = 0.0016597192734479904\n",
            "ΔX norm: 1.659724148339592e-05\n",
            "Stage 1/10:  53%|███████████████▎             | 159/300 [03:53<03:13,  1.37s/it]T Loss=2.305079221725464\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304408311843872\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048996925354004\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304029703140259\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039498329162598\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.58961486816406\n",
            "||∇_X meta|| = 0.001669161720201373\n",
            "ΔX norm: 1.669161611062009e-05\n",
            "Stage 1/10:  53%|███████████████▍             | 160/300 [03:54<03:09,  1.35s/it]T Loss=2.302438974380493\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033525943756104\n",
            "g_norm = tensor(0.0871, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304386615753174\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030591011047363\n",
            "g_norm = tensor(0.0890, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033556938171387\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.69595336914062\n",
            "||∇_X meta|| = 0.0015695483889430761\n",
            "ΔX norm: 1.569551750435494e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/10:  54%|███████████████▌             | 161/300 [03:56<03:10,  1.37s/it]T Loss=2.302903652191162\n",
            "g_norm = tensor(0.1292, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053407669067383\n",
            "g_norm = tensor(0.1593, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304894208908081\n",
            "g_norm = tensor(0.1360, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304612398147583\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304844379425049\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.39280700683594\n",
            "||∇_X meta|| = 0.0016929568955674767\n",
            "ΔX norm: 1.692961268418003e-05\n",
            "Stage 1/10:  54%|███████████████▋             | 162/300 [03:57<03:28,  1.51s/it]T Loss=2.306271553039551\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036909103393555\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304701089859009\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037631511688232\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040859699249268\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.82081604003906\n",
            "||∇_X meta|| = 0.0016437503509223461\n",
            "ΔX norm: 1.6437477825093083e-05\n",
            "Stage 1/10:  54%|███████████████▊             | 163/300 [03:59<03:35,  1.57s/it]T Loss=2.3037757873535156\n",
            "g_norm = tensor(0.1253, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303609848022461\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303391933441162\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303422451019287\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304016351699829\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.48658752441406\n",
            "||∇_X meta|| = 0.0015868281479924917\n",
            "ΔX norm: 1.5868312402744778e-05\n",
            "Stage 1/10:  55%|███████████████▊             | 164/300 [04:01<03:29,  1.54s/it]T Loss=2.30375337600708\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033931255340576\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044400215148926\n",
            "g_norm = tensor(0.0883, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303682804107666\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040623664855957\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.44264221191406\n",
            "||∇_X meta|| = 0.00170544208958745\n",
            "ΔX norm: 1.705441354715731e-05\n",
            "Stage 1/10:  55%|███████████████▉             | 165/300 [04:02<03:23,  1.51s/it]T Loss=2.303769588470459\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304976463317871\n",
            "g_norm = tensor(0.1465, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304267168045044\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046934604644775\n",
            "g_norm = tensor(0.1578, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048338890075684\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =227.665283203125\n",
            "||∇_X meta|| = 0.0015829105395823717\n",
            "ΔX norm: 1.5829084077267908e-05\n",
            "Stage 1/10:  55%|████████████████             | 166/300 [04:03<03:14,  1.45s/it]T Loss=2.3046395778656006\n",
            "g_norm = tensor(0.0746, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036952018737793\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303515911102295\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044543266296387\n",
            "g_norm = tensor(0.0764, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036117553710938\n",
            "g_norm = tensor(0.0739, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7888641357422\n",
            "||∇_X meta|| = 0.0016011124243959785\n",
            "ΔX norm: 1.6011128536774777e-05\n",
            "Stage 1/10:  56%|████████████████▏            | 167/300 [04:05<03:09,  1.42s/it]T Loss=2.305980920791626\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048787117004395\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3067760467529297\n",
            "g_norm = tensor(0.1462, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054585456848145\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305424213409424\n",
            "g_norm = tensor(0.1332, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.80328369140625\n",
            "||∇_X meta|| = 0.0015505584888160229\n",
            "ΔX norm: 1.5505580449826084e-05\n",
            "Stage 1/10:  56%|████████████████▏            | 168/300 [04:06<03:07,  1.42s/it]T Loss=2.303507089614868\n",
            "g_norm = tensor(0.1717, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040714263916016\n",
            "g_norm = tensor(0.1410, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040671348571777\n",
            "g_norm = tensor(0.1418, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036160469055176\n",
            "g_norm = tensor(0.1684, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055574893951416\n",
            "g_norm = tensor(0.1258, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2038116455078\n",
            "||∇_X meta|| = 0.0018116924911737442\n",
            "ΔX norm: 1.811692891351413e-05\n",
            "Stage 1/10:  56%|████████████████▎            | 169/300 [04:07<03:01,  1.38s/it]T Loss=2.304637908935547\n",
            "g_norm = tensor(0.1306, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042550086975098\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052749633789062\n",
            "g_norm = tensor(0.1437, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303563117980957\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303157329559326\n",
            "g_norm = tensor(0.1154, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.23431396484375\n",
            "||∇_X meta|| = 0.0015134840505197644\n",
            "ΔX norm: 1.5134847672015894e-05\n",
            "Stage 1/10:  57%|████████████████▍            | 170/300 [04:09<02:57,  1.36s/it]T Loss=2.303593158721924\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303797960281372\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303241014480591\n",
            "g_norm = tensor(0.1216, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035778999328613\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037805557250977\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.83412170410156\n",
            "||∇_X meta|| = 0.0015637646429240704\n",
            "ΔX norm: 1.5637649994459935e-05\n",
            "Stage 1/10:  57%|████████████████▌            | 171/300 [04:10<02:55,  1.36s/it]T Loss=2.30446195602417\n",
            "g_norm = tensor(0.1221, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302628993988037\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031420707702637\n",
            "g_norm = tensor(0.1140, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024725914001465\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302999496459961\n",
            "g_norm = tensor(0.0888, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.58497619628906\n",
            "||∇_X meta|| = 0.0014886651188135147\n",
            "ΔX norm: 1.488666111981729e-05\n",
            "Stage 1/10:  57%|████████████████▋            | 172/300 [04:11<02:53,  1.36s/it]T Loss=2.304549217224121\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041577339172363\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051862716674805\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041396141052246\n",
            "g_norm = tensor(0.1163, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304532289505005\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.75323486328125\n",
            "||∇_X meta|| = 0.0014688196824863553\n",
            "ΔX norm: 1.4688204828416929e-05\n",
            "Stage 1/10:  58%|████████████████▋            | 173/300 [04:13<02:53,  1.37s/it]T Loss=2.3045105934143066\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3012876510620117\n",
            "g_norm = tensor(0.1253, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302825927734375\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017590045928955\n",
            "g_norm = tensor(0.1218, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303842067718506\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.37579345703125\n",
            "||∇_X meta|| = 0.0016361614689230919\n",
            "ΔX norm: 1.6361587768187746e-05\n",
            "Stage 1/10:  58%|████████████████▊            | 174/300 [04:14<02:50,  1.35s/it]T Loss=2.3029303550720215\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303560733795166\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043298721313477\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041226863861084\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305939197540283\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8383331298828\n",
            "||∇_X meta|| = 0.001550728571601212\n",
            "ΔX norm: 1.5507319403695874e-05\n",
            "Stage 1/10:  58%|████████████████▉            | 175/300 [04:15<02:46,  1.34s/it]T Loss=2.3022308349609375\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303734302520752\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018131256103516\n",
            "g_norm = tensor(0.1263, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301804304122925\n",
            "g_norm = tensor(0.1266, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026483058929443\n",
            "g_norm = tensor(0.1309, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3618927001953\n",
            "||∇_X meta|| = 0.0014054805506020784\n",
            "ΔX norm: 1.4054807252250612e-05\n",
            "Stage 1/10:  59%|█████████████████            | 176/300 [04:17<02:46,  1.34s/it]T Loss=2.3043532371520996\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303771495819092\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036317825317383\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033246994018555\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036797046661377\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.3911590576172\n",
            "||∇_X meta|| = 0.0015698752831667662\n",
            "ΔX norm: 1.5698708011768758e-05\n",
            "Stage 1/10:  59%|█████████████████            | 177/300 [04:18<02:47,  1.36s/it]T Loss=2.3051421642303467\n",
            "g_norm = tensor(0.1337, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301629066467285\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045551776885986\n",
            "g_norm = tensor(0.1075, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039391040802\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303626775741577\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.71170043945312\n",
            "||∇_X meta|| = 0.0014797127805650234\n",
            "ΔX norm: 1.4797152289247606e-05\n",
            "Stage 1/10:  59%|█████████████████▏           | 178/300 [04:20<02:44,  1.35s/it]T Loss=2.303964614868164\n",
            "g_norm = tensor(0.1270, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303166151046753\n",
            "g_norm = tensor(0.1390, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039443492889404\n",
            "g_norm = tensor(0.1107, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302960157394409\n",
            "g_norm = tensor(0.0942, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304264783859253\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.105712890625\n",
            "||∇_X meta|| = 0.0015807588351890445\n",
            "ΔX norm: 1.580752905283589e-05\n",
            "Stage 1/10:  60%|█████████████████▎           | 179/300 [04:22<03:16,  1.62s/it]T Loss=2.3036646842956543\n",
            "g_norm = tensor(0.0885, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303022861480713\n",
            "g_norm = tensor(0.1213, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038687705993652\n",
            "g_norm = tensor(0.1263, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304487943649292\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303852081298828\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.54214477539062\n",
            "||∇_X meta|| = 0.0017109556356444955\n",
            "ΔX norm: 1.710954893496819e-05\n",
            "Stage 1/10:  60%|█████████████████▍           | 180/300 [04:23<03:09,  1.58s/it]T Loss=2.304021120071411\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040432929992676\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304110527038574\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042712211608887\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038063049316406\n",
            "g_norm = tensor(0.0838, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.28680419921875\n",
            "||∇_X meta|| = 0.001498975558206439\n",
            "ΔX norm: 1.49897769006202e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/10:  60%|█████████████████▍           | 181/300 [04:25<03:06,  1.57s/it]T Loss=2.3031461238861084\n",
            "g_norm = tensor(0.0934, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029892444610596\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303102493286133\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033883571624756\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30427885055542\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.6206817626953\n",
            "||∇_X meta|| = 0.0013700021663680673\n",
            "ΔX norm: 1.370005338685587e-05\n",
            "Stage 1/10:  61%|█████████████████▌           | 182/300 [04:27<03:15,  1.65s/it]T Loss=2.3039944171905518\n",
            "g_norm = tensor(0.0933, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034231662750244\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038482666015625\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303680896759033\n",
            "g_norm = tensor(0.0845, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303617000579834\n",
            "g_norm = tensor(0.0723, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6392364501953\n",
            "||∇_X meta|| = 0.0016695843078196049\n",
            "ΔX norm: 1.6695883459760807e-05\n",
            "Stage 1/10:  61%|█████████████████▋           | 183/300 [04:28<03:14,  1.66s/it]T Loss=2.303865909576416\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034451007843018\n",
            "g_norm = tensor(0.1139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047397136688232\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049261569976807\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304792642593384\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.42141723632812\n",
            "||∇_X meta|| = 0.001600397634319961\n",
            "ΔX norm: 1.600397990841884e-05\n",
            "Stage 1/10:  61%|█████████████████▊           | 184/300 [04:30<03:22,  1.75s/it]T Loss=2.3043720722198486\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039705753326416\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047051429748535\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039984703063965\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030500411987305\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.79934692382812\n",
            "||∇_X meta|| = 0.0016571276355534792\n",
            "ΔX norm: 1.6571302694501355e-05\n",
            "Stage 1/10:  62%|█████████████████▉           | 185/300 [04:32<03:15,  1.70s/it]T Loss=2.3039135932922363\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304363489151001\n",
            "g_norm = tensor(0.0898, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303173065185547\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036446571350098\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304574728012085\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8626251220703\n",
            "||∇_X meta|| = 0.0015716286143288016\n",
            "ΔX norm: 1.571625762153417e-05\n",
            "Stage 1/10:  62%|█████████████████▉           | 186/300 [04:33<03:07,  1.65s/it]T Loss=2.303973913192749\n",
            "g_norm = tensor(0.0829, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025662899017334\n",
            "g_norm = tensor(0.0817, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024230003356934\n",
            "g_norm = tensor(0.0813, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303621768951416\n",
            "g_norm = tensor(0.0834, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303600788116455\n",
            "g_norm = tensor(0.0763, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.02212524414062\n",
            "||∇_X meta|| = 0.0016381633467972279\n",
            "ΔX norm: 1.6381631212425418e-05\n",
            "Stage 1/10:  62%|██████████████████           | 187/300 [04:35<02:59,  1.59s/it]T Loss=2.304682731628418\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036370277404785\n",
            "g_norm = tensor(0.1347, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035309314727783\n",
            "g_norm = tensor(0.1414, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055734634399414\n",
            "g_norm = tensor(0.1340, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054065704345703\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.09205627441406\n",
            "||∇_X meta|| = 0.0016925352392718196\n",
            "ΔX norm: 1.6925414456636645e-05\n",
            "Stage 1/10:  63%|██████████████████▏          | 188/300 [04:36<02:51,  1.53s/it]T Loss=2.303704023361206\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033318519592285\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302978038787842\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302227020263672\n",
            "g_norm = tensor(0.1331, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304563045501709\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.97779846191406\n",
            "||∇_X meta|| = 0.0014473984483629465\n",
            "ΔX norm: 1.4474002455244772e-05\n",
            "Stage 1/10:  63%|██████████████████▎          | 189/300 [04:38<02:45,  1.50s/it]T Loss=2.3034560680389404\n",
            "g_norm = tensor(0.0818, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027169704437256\n",
            "g_norm = tensor(0.0861, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303725481033325\n",
            "g_norm = tensor(0.0898, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304119110107422\n",
            "g_norm = tensor(0.0814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302529811859131\n",
            "g_norm = tensor(0.0759, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.42481994628906\n",
            "||∇_X meta|| = 0.0015651893336325884\n",
            "ΔX norm: 1.5651905414415523e-05\n",
            "Stage 1/10:  63%|██████████████████▎          | 190/300 [04:39<02:40,  1.46s/it]T Loss=2.305081605911255\n",
            "g_norm = tensor(0.1461, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033933639526367\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30440616607666\n",
            "g_norm = tensor(0.1449, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031630516052246\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043761253356934\n",
            "g_norm = tensor(0.1415, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.89495849609375\n",
            "||∇_X meta|| = 0.001598954084329307\n",
            "ΔX norm: 1.5989526218618266e-05\n",
            "Stage 1/10:  64%|██████████████████▍          | 191/300 [04:41<02:39,  1.47s/it]T Loss=2.304440498352051\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046176433563232\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304384231567383\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035731315612793\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040919303894043\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.5269775390625\n",
            "||∇_X meta|| = 0.001564167207106948\n",
            "ΔX norm: 1.5641739082639106e-05\n",
            "Stage 1/10:  64%|██████████████████▌          | 192/300 [04:42<02:36,  1.45s/it]T Loss=2.3031880855560303\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028690814971924\n",
            "g_norm = tensor(0.0902, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304473400115967\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304701328277588\n",
            "g_norm = tensor(0.0854, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040034770965576\n",
            "g_norm = tensor(0.0922, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.49594116210938\n",
            "||∇_X meta|| = 0.0014588481280952692\n",
            "ΔX norm: 1.4588463272957597e-05\n",
            "Stage 1/10:  64%|██████████████████▋          | 193/300 [04:43<02:34,  1.44s/it]T Loss=2.3024582862854004\n",
            "g_norm = tensor(0.1316, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017730712890625\n",
            "g_norm = tensor(0.1397, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039443492889404\n",
            "g_norm = tensor(0.1184, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303619623184204\n",
            "g_norm = tensor(0.1532, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303671360015869\n",
            "g_norm = tensor(0.1370, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.44442749023438\n",
            "||∇_X meta|| = 0.001368365017697215\n",
            "ΔX norm: 1.3683646102435887e-05\n",
            "Stage 1/10:  65%|██████████████████▊          | 194/300 [04:45<02:35,  1.46s/it]T Loss=2.3033447265625\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302488088607788\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304128646850586\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303586483001709\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026721477508545\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.0446319580078\n",
            "||∇_X meta|| = 0.0016345783369615674\n",
            "ΔX norm: 1.6345766198355705e-05\n",
            "Stage 1/10:  65%|██████████████████▊          | 195/300 [04:46<02:32,  1.45s/it]T Loss=2.304577589035034\n",
            "g_norm = tensor(0.1271, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047103881835938\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039538860321045\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053696155548096\n",
            "g_norm = tensor(0.1326, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3068912029266357\n",
            "g_norm = tensor(0.1425, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.70460510253906\n",
            "||∇_X meta|| = 0.0016065039671957493\n",
            "ΔX norm: 1.606508158147335e-05\n",
            "Stage 1/10:  65%|██████████████████▉          | 196/300 [04:48<02:43,  1.58s/it]T Loss=2.303002119064331\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032894134521484\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028154373168945\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302767276763916\n",
            "g_norm = tensor(0.0983, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303771495819092\n",
            "g_norm = tensor(0.0847, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.25234985351562\n",
            "||∇_X meta|| = 0.0015165430959314108\n",
            "ΔX norm: 1.5165438526310027e-05\n",
            "Stage 1/10:  66%|███████████████████          | 197/300 [04:50<02:41,  1.57s/it]T Loss=2.303579807281494\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3004608154296875\n",
            "g_norm = tensor(0.1814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046343326568604\n",
            "g_norm = tensor(0.1397, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032097816467285\n",
            "g_norm = tensor(0.1488, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303394317626953\n",
            "g_norm = tensor(0.1765, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4824676513672\n",
            "||∇_X meta|| = 0.0016504722880199552\n",
            "ΔX norm: 1.6504865925526246e-05\n",
            "Stage 1/10:  66%|███████████████████▏         | 198/300 [04:51<02:40,  1.57s/it]T Loss=2.303650379180908\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023133277893066\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304617404937744\n",
            "g_norm = tensor(0.0931, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304906129837036\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050057888031006\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7353057861328\n",
            "||∇_X meta|| = 0.0017085910076275468\n",
            "ΔX norm: 1.7085887520806864e-05\n",
            "Stage 1/10:  66%|███████████████████▏         | 199/300 [04:53<02:34,  1.53s/it]T Loss=2.3037829399108887\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029541969299316\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037309646606445\n",
            "g_norm = tensor(0.0849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046271800994873\n",
            "g_norm = tensor(0.0814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040738105773926\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.7005615234375\n",
            "||∇_X meta|| = 0.0015364930732175708\n",
            "ΔX norm: 1.5364919818239287e-05\n",
            "Stage 1/10:  67%|███████████████████▎         | 200/300 [04:54<02:28,  1.49s/it]T Loss=2.304614305496216\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304503917694092\n",
            "g_norm = tensor(0.1289, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044028282165527\n",
            "g_norm = tensor(0.1368, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304368495941162\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052873611450195\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.89991760253906\n",
            "||∇_X meta|| = 0.001631110324524343\n",
            "ΔX norm: 1.631109626032412e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/10:  67%|███████████████████▍         | 201/300 [04:56<02:24,  1.46s/it]T Loss=2.3049659729003906\n",
            "g_norm = tensor(0.1356, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042187690734863\n",
            "g_norm = tensor(0.1360, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304184913635254\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041205406188965\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040452003479004\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.51504516601562\n",
            "||∇_X meta|| = 0.0017234134720638394\n",
            "ΔX norm: 1.7234086044481955e-05\n",
            "Stage 1/10:  67%|███████████████████▌         | 202/300 [04:57<02:32,  1.56s/it]T Loss=2.304067850112915\n",
            "g_norm = tensor(0.0922, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033409118652344\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035929203033447\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043129444122314\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303454637527466\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.19105529785156\n",
            "||∇_X meta|| = 0.0016728655900806189\n",
            "ΔX norm: 1.672869075264316e-05\n",
            "Stage 1/10:  68%|███████████████████▌         | 203/300 [04:59<02:28,  1.53s/it]T Loss=2.3047759532928467\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042125701904297\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045811653137207\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029704093933105\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305736780166626\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.6646270751953\n",
            "||∇_X meta|| = 0.001562722958624363\n",
            "ΔX norm: 1.56272690219339e-05\n",
            "Stage 1/10:  68%|███████████████████▋         | 204/300 [05:00<02:25,  1.52s/it]T Loss=2.3050174713134766\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30499529838562\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304710865020752\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037819862365723\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304378032684326\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.48155212402344\n",
            "||∇_X meta|| = 0.0014716943260282278\n",
            "ΔX norm: 1.471692758059362e-05\n",
            "Stage 1/10:  68%|███████████████████▊         | 205/300 [05:02<02:33,  1.61s/it]T Loss=2.303699016571045\n",
            "g_norm = tensor(0.1678, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3059284687042236\n",
            "g_norm = tensor(0.1285, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025660514831543\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303166627883911\n",
            "g_norm = tensor(0.1520, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040151596069336\n",
            "g_norm = tensor(0.1594, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.95445251464844\n",
            "||∇_X meta|| = 0.0015998341841623187\n",
            "ΔX norm: 1.5998344679246657e-05\n",
            "Stage 1/10:  69%|███████████████████▉         | 206/300 [05:04<02:36,  1.67s/it]T Loss=2.3041460514068604\n",
            "g_norm = tensor(0.0650, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041012287139893\n",
            "g_norm = tensor(0.0650, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304523229598999\n",
            "g_norm = tensor(0.0599, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040690422058105\n",
            "g_norm = tensor(0.0662, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038361072540283\n",
            "g_norm = tensor(0.0553, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7606964111328\n",
            "||∇_X meta|| = 0.001640257891267538\n",
            "ΔX norm: 1.640258233237546e-05\n",
            "Stage 1/10:  69%|████████████████████         | 207/300 [05:05<02:28,  1.60s/it]T Loss=2.3038322925567627\n",
            "g_norm = tensor(0.0885, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042502403259277\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029839992523193\n",
            "g_norm = tensor(0.1157, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033032417297363\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302997350692749\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.96311950683594\n",
            "||∇_X meta|| = 0.0014938667882233858\n",
            "ΔX norm: 1.4938766071281862e-05\n",
            "Stage 1/10:  69%|████████████████████         | 208/300 [05:07<02:21,  1.54s/it]T Loss=2.303964614868164\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050591945648193\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041892051696777\n",
            "g_norm = tensor(0.0908, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303926467895508\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039233684539795\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.23341369628906\n",
            "||∇_X meta|| = 0.0016284429002553225\n",
            "ΔX norm: 1.6284448065562174e-05\n",
            "Stage 1/10:  70%|████████████████████▏        | 209/300 [05:08<02:15,  1.49s/it]T Loss=2.3039891719818115\n",
            "g_norm = tensor(0.1380, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048243522644043\n",
            "g_norm = tensor(0.1594, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047726154327393\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040874004364014\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303614377975464\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3690643310547\n",
            "||∇_X meta|| = 0.0014957876410335302\n",
            "ΔX norm: 1.4957878192944918e-05\n",
            "Stage 1/10:  70%|████████████████████▎        | 210/300 [05:10<02:16,  1.51s/it]T Loss=2.304797649383545\n",
            "g_norm = tensor(0.1314, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024749755859375\n",
            "g_norm = tensor(0.1374, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042075634002686\n",
            "g_norm = tensor(0.1273, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045315742492676\n",
            "g_norm = tensor(0.1493, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303274631500244\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.03097534179688\n",
            "||∇_X meta|| = 0.001584303448908031\n",
            "ΔX norm: 1.5843041182961315e-05\n",
            "Stage 1/10:  70%|████████████████████▍        | 211/300 [05:11<02:11,  1.48s/it]T Loss=2.3041563034057617\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045451641082764\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036937713623047\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303781032562256\n",
            "g_norm = tensor(0.1330, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034212589263916\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.40184020996094\n",
            "||∇_X meta|| = 0.0014801870565861464\n",
            "ΔX norm: 1.4801901670580264e-05\n",
            "Stage 1/10:  71%|████████████████████▍        | 212/300 [05:13<02:08,  1.46s/it]T Loss=2.303375720977783\n",
            "g_norm = tensor(0.0794, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304140567779541\n",
            "g_norm = tensor(0.0815, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303924798965454\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304187536239624\n",
            "g_norm = tensor(0.0751, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039095401763916\n",
            "g_norm = tensor(0.0772, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.45814514160156\n",
            "||∇_X meta|| = 0.0016547972336411476\n",
            "ΔX norm: 1.65479850693373e-05\n",
            "Stage 1/10:  71%|████████████████████▌        | 213/300 [05:14<02:06,  1.45s/it]T Loss=2.303248882293701\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303924560546875\n",
            "g_norm = tensor(0.0767, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303279399871826\n",
            "g_norm = tensor(0.0730, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030803203582764\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034794330596924\n",
            "g_norm = tensor(0.0799, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.29864501953125\n",
            "||∇_X meta|| = 0.001578634837642312\n",
            "ΔX norm: 1.578638330101967e-05\n",
            "Stage 1/10:  71%|████████████████████▋        | 214/300 [05:16<02:12,  1.54s/it]T Loss=2.3040637969970703\n",
            "g_norm = tensor(0.1021, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036422729492188\n",
            "g_norm = tensor(0.0980, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035218715667725\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303560733795166\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304046630859375\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.20223999023438\n",
            "||∇_X meta|| = 0.0014570830389857292\n",
            "ΔX norm: 1.4570840903616045e-05\n",
            "Stage 1/10:  72%|████████████████████▊        | 215/300 [05:17<02:13,  1.57s/it]T Loss=2.302598237991333\n",
            "g_norm = tensor(0.1348, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041484355926514\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036386966705322\n",
            "g_norm = tensor(0.1573, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303504467010498\n",
            "g_norm = tensor(0.1302, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302546977996826\n",
            "g_norm = tensor(0.1530, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.39840698242188\n",
            "||∇_X meta|| = 0.0015899388818070292\n",
            "ΔX norm: 1.5899413483566605e-05\n",
            "Stage 1/10:  72%|████████████████████▉        | 216/300 [05:19<02:07,  1.52s/it]T Loss=2.3041560649871826\n",
            "g_norm = tensor(0.1243, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303507089614868\n",
            "g_norm = tensor(0.1442, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048768043518066\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303635597229004\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051459789276123\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.40921020507812\n",
            "||∇_X meta|| = 0.001465603825636208\n",
            "ΔX norm: 1.4656036910309922e-05\n",
            "Stage 1/10:  72%|████████████████████▉        | 217/300 [05:20<02:03,  1.49s/it]T Loss=2.3050484657287598\n",
            "g_norm = tensor(0.1248, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304018497467041\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305388927459717\n",
            "g_norm = tensor(0.1278, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304354190826416\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303647756576538\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.6155548095703\n",
            "||∇_X meta|| = 0.001580574898980558\n",
            "ΔX norm: 1.5805746443220414e-05\n",
            "Stage 1/10:  73%|█████████████████████        | 218/300 [05:22<02:10,  1.60s/it]T Loss=2.3038253784179688\n",
            "g_norm = tensor(0.1410, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304543972015381\n",
            "g_norm = tensor(0.1327, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302976369857788\n",
            "g_norm = tensor(0.1389, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030412197113037\n",
            "g_norm = tensor(0.1645, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302555561065674\n",
            "g_norm = tensor(0.1548, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.44204711914062\n",
            "||∇_X meta|| = 0.0016069782432168722\n",
            "ΔX norm: 1.606969817657955e-05\n",
            "Stage 1/10:  73%|█████████████████████▏       | 219/300 [05:23<02:05,  1.55s/it]T Loss=2.303497076034546\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304039716720581\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040852546691895\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303577423095703\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041577339172363\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.54937744140625\n",
            "||∇_X meta|| = 0.0015390877379104495\n",
            "ΔX norm: 1.5390922271762975e-05\n",
            "Stage 1/10:  73%|█████████████████████▎       | 220/300 [05:25<02:01,  1.52s/it]T Loss=2.3031938076019287\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033840656280518\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302672863006592\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302574634552002\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032455444335938\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.92599487304688\n",
            "||∇_X meta|| = 0.001566677587106824\n",
            "ΔX norm: 1.5666842955397442e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/10:  74%|█████████████████████▎       | 221/300 [05:26<01:58,  1.50s/it]T Loss=2.3036749362945557\n",
            "g_norm = tensor(0.1360, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304985523223877\n",
            "g_norm = tensor(0.1471, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030457496643066\n",
            "g_norm = tensor(0.1652, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029885292053223\n",
            "g_norm = tensor(0.1573, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303445816040039\n",
            "g_norm = tensor(0.1507, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.2467803955078\n",
            "||∇_X meta|| = 0.001493031857535243\n",
            "ΔX norm: 1.4930365068721585e-05\n",
            "Stage 1/10:  74%|█████████████████████▍       | 222/300 [05:28<02:07,  1.63s/it]T Loss=2.303760051727295\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302952527999878\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304720163345337\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034327030181885\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303539276123047\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.40576171875\n",
            "||∇_X meta|| = 0.001527964835986495\n",
            "ΔX norm: 1.5279656508937478e-05\n",
            "Stage 1/10:  74%|█████████████████████▌       | 223/300 [05:30<02:10,  1.69s/it]T Loss=2.303496837615967\n",
            "g_norm = tensor(0.1422, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30438494682312\n",
            "g_norm = tensor(0.1529, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305327892303467\n",
            "g_norm = tensor(0.1285, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043975830078125\n",
            "g_norm = tensor(0.1262, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303645610809326\n",
            "g_norm = tensor(0.1258, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.08123779296875\n",
            "||∇_X meta|| = 0.0016660192050039768\n",
            "ΔX norm: 1.6660167602822185e-05\n",
            "Stage 1/10:  75%|█████████████████████▋       | 224/300 [05:32<02:04,  1.64s/it]T Loss=2.3051979541778564\n",
            "g_norm = tensor(0.1555, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056998252868652\n",
            "g_norm = tensor(0.1336, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304013252258301\n",
            "g_norm = tensor(0.1391, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046698570251465\n",
            "g_norm = tensor(0.1335, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30376935005188\n",
            "g_norm = tensor(0.1546, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.00299072265625\n",
            "||∇_X meta|| = 0.0015737414360046387\n",
            "ΔX norm: 1.573745066707488e-05\n",
            "Stage 1/10:  75%|█████████████████████▊       | 225/300 [05:34<02:10,  1.75s/it]T Loss=2.3037381172180176\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030707836151123\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304100513458252\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043909072875977\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040122985839844\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0057830810547\n",
            "||∇_X meta|| = 0.0014493369963020086\n",
            "ΔX norm: 1.4493336493615061e-05\n",
            "Stage 1/10:  75%|█████████████████████▊       | 226/300 [05:36<02:16,  1.84s/it]T Loss=2.304095506668091\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304420232772827\n",
            "g_norm = tensor(0.0804, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042104244232178\n",
            "g_norm = tensor(0.0760, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043923377990723\n",
            "g_norm = tensor(0.0833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304541826248169\n",
            "g_norm = tensor(0.0770, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.26470947265625\n",
            "||∇_X meta|| = 0.0016055763699114323\n",
            "ΔX norm: 1.6055793821578845e-05\n",
            "Stage 1/10:  76%|█████████████████████▉       | 227/300 [05:37<02:07,  1.75s/it]T Loss=2.3032984733581543\n",
            "g_norm = tensor(0.0993, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038296699523926\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030946254730225\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304025650024414\n",
            "g_norm = tensor(0.0757, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024215698242188\n",
            "g_norm = tensor(0.0782, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0951385498047\n",
            "||∇_X meta|| = 0.0017110536573454738\n",
            "ΔX norm: 1.7110494809458032e-05\n",
            "Stage 1/10:  76%|██████████████████████       | 228/300 [05:39<02:02,  1.70s/it]T Loss=2.3030827045440674\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303600788116455\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038463592529297\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031859397888184\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302797317504883\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.52423095703125\n",
            "||∇_X meta|| = 0.0015044676838442683\n",
            "ΔX norm: 1.5044681276776828e-05\n",
            "Stage 1/10:  76%|██████████████████████▏      | 229/300 [05:40<01:57,  1.65s/it]T Loss=2.303344488143921\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042244911193848\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038017749786377\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033013343811035\n",
            "g_norm = tensor(0.1022, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304270029067993\n",
            "g_norm = tensor(0.0902, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.87423706054688\n",
            "||∇_X meta|| = 0.0014481740072369576\n",
            "ΔX norm: 1.4481704056379385e-05\n",
            "Stage 1/10:  77%|██████████████████████▏      | 230/300 [05:42<01:52,  1.60s/it]T Loss=2.304401397705078\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304323196411133\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304750680923462\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039402961730957\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039183616638184\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.04119873046875\n",
            "||∇_X meta|| = 0.0015199611661955714\n",
            "ΔX norm: 1.5199599147308618e-05\n",
            "Stage 1/10:  77%|██████████████████████▎      | 231/300 [05:43<01:45,  1.53s/it]T Loss=2.3031022548675537\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303061008453369\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047943115234375\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029046058654785\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303584575653076\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.79220581054688\n",
            "||∇_X meta|| = 0.0014423856046050787\n",
            "ΔX norm: 1.4423858374357224e-05\n",
            "Stage 1/10:  77%|██████████████████████▍      | 232/300 [05:45<01:44,  1.54s/it]T Loss=2.304128646850586\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304379940032959\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037848472595215\n",
            "g_norm = tensor(0.0820, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044440746307373\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041818141937256\n",
            "g_norm = tensor(0.0884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.29335021972656\n",
            "||∇_X meta|| = 0.0015238381456583738\n",
            "ΔX norm: 1.5238369996950496e-05\n",
            "Stage 1/10:  78%|██████████████████████▌      | 233/300 [05:46<01:40,  1.50s/it]T Loss=2.3036551475524902\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028900623321533\n",
            "g_norm = tensor(0.1457, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303316593170166\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037922382354736\n",
            "g_norm = tensor(0.1516, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026585578918457\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.17613220214844\n",
            "||∇_X meta|| = 0.001609223778359592\n",
            "ΔX norm: 1.6092237274278887e-05\n",
            "Stage 1/10:  78%|██████████████████████▌      | 234/300 [05:48<01:37,  1.48s/it]T Loss=2.3032424449920654\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043675422668457\n",
            "g_norm = tensor(0.1356, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027350902557373\n",
            "g_norm = tensor(0.1477, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302428722381592\n",
            "g_norm = tensor(0.1307, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302914619445801\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.39315795898438\n",
            "||∇_X meta|| = 0.0015790710458531976\n",
            "ΔX norm: 1.5790725228725933e-05\n",
            "Stage 1/10:  78%|██████████████████████▋      | 235/300 [05:49<01:36,  1.49s/it]T Loss=2.3033173084259033\n",
            "g_norm = tensor(0.1353, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304722309112549\n",
            "g_norm = tensor(0.1629, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305729627609253\n",
            "g_norm = tensor(0.1667, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302607297897339\n",
            "g_norm = tensor(0.1580, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305337429046631\n",
            "g_norm = tensor(0.1488, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.86474609375\n",
            "||∇_X meta|| = 0.001661698566749692\n",
            "ΔX norm: 1.6616942957625724e-05\n",
            "Stage 1/10:  79%|██████████████████████▊      | 236/300 [05:51<01:38,  1.55s/it]T Loss=2.3021159172058105\n",
            "g_norm = tensor(0.1338, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035314083099365\n",
            "g_norm = tensor(0.1378, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031609058380127\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043360710144043\n",
            "g_norm = tensor(0.1381, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022043704986572\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.10018920898438\n",
            "||∇_X meta|| = 0.0014557798858731985\n",
            "ΔX norm: 1.4557778740709182e-05\n",
            "Stage 1/10:  79%|██████████████████████▉      | 237/300 [05:52<01:36,  1.53s/it]T Loss=2.303129196166992\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044140338897705\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032877445220947\n",
            "g_norm = tensor(0.1319, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302381992340088\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303710460662842\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.58056640625\n",
            "||∇_X meta|| = 0.001647862489335239\n",
            "ΔX norm: 1.6478577890666202e-05\n",
            "Stage 1/10:  79%|███████████████████████      | 238/300 [05:54<01:34,  1.52s/it]T Loss=2.302633762359619\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038859367370605\n",
            "g_norm = tensor(0.1350, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031184673309326\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024516105651855\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036599159240723\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8665313720703\n",
            "||∇_X meta|| = 0.0016707552131265402\n",
            "ΔX norm: 1.6707557733752765e-05\n",
            "Stage 1/10:  80%|███████████████████████      | 239/300 [05:56<01:43,  1.70s/it]T Loss=2.3042523860931396\n",
            "g_norm = tensor(0.0835, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037657737731934\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304108142852783\n",
            "g_norm = tensor(0.0761, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045225143432617\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038041591644287\n",
            "g_norm = tensor(0.0740, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.667724609375\n",
            "||∇_X meta|| = 0.0015642972430214286\n",
            "ΔX norm: 1.5642950529581867e-05\n",
            "Stage 1/10:  80%|███████████████████████▏     | 240/300 [05:58<01:41,  1.69s/it]T Loss=2.304208278656006\n",
            "g_norm = tensor(0.0931, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303255796432495\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304724931716919\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039565086364746\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030264377593994\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.30381774902344\n",
            "||∇_X meta|| = 0.0015408446779474616\n",
            "ΔX norm: 1.540847370051779e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/10:  80%|███████████████████████▎     | 241/300 [05:59<01:36,  1.63s/it]T Loss=2.3039298057556152\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045895099639893\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303969383239746\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304749011993408\n",
            "g_norm = tensor(0.0847, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044400215148926\n",
            "g_norm = tensor(0.0829, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =227.63963317871094\n",
            "||∇_X meta|| = 0.0014956864761188626\n",
            "ΔX norm: 1.4956888662709389e-05\n",
            "Stage 1/10:  81%|███████████████████████▍     | 242/300 [06:01<01:42,  1.76s/it]T Loss=2.3029634952545166\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032376766204834\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301685333251953\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020970821380615\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034121990203857\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1267547607422\n",
            "||∇_X meta|| = 0.0015828597825020552\n",
            "ΔX norm: 1.582860386406537e-05\n",
            "Stage 1/10:  81%|███████████████████████▍     | 243/300 [06:03<01:40,  1.76s/it]T Loss=2.303832769393921\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024251461029053\n",
            "g_norm = tensor(0.1410, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304837703704834\n",
            "g_norm = tensor(0.1213, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304992437362671\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044750690460205\n",
            "g_norm = tensor(0.1467, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.89605712890625\n",
            "||∇_X meta|| = 0.0014770369743928313\n",
            "ΔX norm: 1.4770329471502919e-05\n",
            "Stage 1/10:  81%|███████████████████████▌     | 244/300 [06:04<01:33,  1.67s/it]T Loss=2.3041019439697266\n",
            "g_norm = tensor(0.0712, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30373215675354\n",
            "g_norm = tensor(0.0681, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031418323516846\n",
            "g_norm = tensor(0.0720, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304300308227539\n",
            "g_norm = tensor(0.0677, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303938627243042\n",
            "g_norm = tensor(0.0640, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.60659790039062\n",
            "||∇_X meta|| = 0.0015120218740776181\n",
            "ΔX norm: 1.5120202988327947e-05\n",
            "Stage 1/10:  82%|███████████████████████▋     | 245/300 [06:06<01:29,  1.63s/it]T Loss=2.3021016120910645\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3006529808044434\n",
            "g_norm = tensor(0.1118, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028452396392822\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030219078063965\n",
            "g_norm = tensor(0.1409, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036131858825684\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.23617553710938\n",
            "||∇_X meta|| = 0.0015479138819500804\n",
            "ΔX norm: 1.5479094145121053e-05\n",
            "Stage 1/10:  82%|███████████████████████▊     | 246/300 [06:07<01:26,  1.60s/it]T Loss=2.304975986480713\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044776916503906\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038198947906494\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304208993911743\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053531646728516\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.00686645507812\n",
            "||∇_X meta|| = 0.0016602725954726338\n",
            "ΔX norm: 1.6602753021288663e-05\n",
            "Stage 1/10:  82%|███████████████████████▉     | 247/300 [06:09<01:22,  1.55s/it]T Loss=2.3029465675354004\n",
            "g_norm = tensor(0.1210, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302546262741089\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303981065750122\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024299144744873\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034348487854004\n",
            "g_norm = tensor(0.0922, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.94662475585938\n",
            "||∇_X meta|| = 0.0016116081969812512\n",
            "ΔX norm: 1.6116158803924918e-05\n",
            "Stage 1/10:  83%|███████████████████████▉     | 248/300 [06:10<01:21,  1.57s/it]T Loss=2.3041088581085205\n",
            "g_norm = tensor(0.1360, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052284717559814\n",
            "g_norm = tensor(0.1567, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041763305664062\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30442476272583\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049628734588623\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.29519653320312\n",
            "||∇_X meta|| = 0.0014775899471715093\n",
            "ΔX norm: 1.4775919225940015e-05\n",
            "Stage 1/10:  83%|████████████████████████     | 249/300 [06:12<01:19,  1.56s/it]T Loss=2.3044447898864746\n",
            "g_norm = tensor(0.1423, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303910493850708\n",
            "g_norm = tensor(0.1163, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303584098815918\n",
            "g_norm = tensor(0.1534, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304880142211914\n",
            "g_norm = tensor(0.1216, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3010778427124023\n",
            "g_norm = tensor(0.1334, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9447479248047\n",
            "||∇_X meta|| = 0.0013574587646871805\n",
            "ΔX norm: 1.3574569493357558e-05\n",
            "Stage 1/10:  83%|████████████████████████▏    | 250/300 [06:14<01:17,  1.56s/it]T Loss=2.3030714988708496\n",
            "g_norm = tensor(0.0849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303921699523926\n",
            "g_norm = tensor(0.0719, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034820556640625\n",
            "g_norm = tensor(0.0815, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304001569747925\n",
            "g_norm = tensor(0.0704, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035852909088135\n",
            "g_norm = tensor(0.0810, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.49378967285156\n",
            "||∇_X meta|| = 0.001607132377102971\n",
            "ΔX norm: 1.6071307982201688e-05\n",
            "Stage 1/10:  84%|████████████████████████▎    | 251/300 [06:15<01:14,  1.52s/it]T Loss=2.3038899898529053\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30435848236084\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026695251464844\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303776264190674\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304381847381592\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.10528564453125\n",
            "||∇_X meta|| = 0.0016325199976563454\n",
            "ΔX norm: 1.632521343708504e-05\n",
            "Stage 1/10:  84%|████████████████████████▎    | 252/300 [06:16<01:12,  1.51s/it]T Loss=2.3034756183624268\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032171726226807\n",
            "g_norm = tensor(0.0933, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039729595184326\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039355278015137\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046820163726807\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7297821044922\n",
            "||∇_X meta|| = 0.0016821966273710132\n",
            "ΔX norm: 1.6821953977341764e-05\n",
            "Stage 1/10:  84%|████████████████████████▍    | 253/300 [06:18<01:09,  1.49s/it]T Loss=2.3042657375335693\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035168647766113\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042519092559814\n",
            "g_norm = tensor(0.1358, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303997039794922\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303677797317505\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.5537567138672\n",
            "||∇_X meta|| = 0.001634934451431036\n",
            "ΔX norm: 1.6349378711311147e-05\n",
            "Stage 1/10:  85%|████████████████████████▌    | 254/300 [06:19<01:09,  1.51s/it]T Loss=2.3037283420562744\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038573265075684\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034539222717285\n",
            "g_norm = tensor(0.1458, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031017780303955\n",
            "g_norm = tensor(0.1263, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039023876190186\n",
            "g_norm = tensor(0.1392, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.73175048828125\n",
            "||∇_X meta|| = 0.0015374342910945415\n",
            "ΔX norm: 1.5374351278296672e-05\n",
            "Stage 1/10:  85%|████████████████████████▋    | 255/300 [06:21<01:12,  1.61s/it]T Loss=2.3039839267730713\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045501708984375\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036928176879883\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030636310577393\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039629459381104\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.80072021484375\n",
            "||∇_X meta|| = 0.0014900590758770704\n",
            "ΔX norm: 1.4900584574206732e-05\n",
            "Stage 1/10:  85%|████████████████████████▋    | 256/300 [06:23<01:09,  1.59s/it]T Loss=2.302258014678955\n",
            "g_norm = tensor(0.1835, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030788898468018\n",
            "g_norm = tensor(0.1320, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302656650543213\n",
            "g_norm = tensor(0.1552, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302302837371826\n",
            "g_norm = tensor(0.1634, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028030395507812\n",
            "g_norm = tensor(0.1517, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.10243225097656\n",
            "||∇_X meta|| = 0.0016923417570069432\n",
            "ΔX norm: 1.6923404473345727e-05\n",
            "Stage 1/10:  86%|████████████████████████▊    | 257/300 [06:25<01:09,  1.61s/it]T Loss=2.303523063659668\n",
            "g_norm = tensor(0.1340, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304356336593628\n",
            "g_norm = tensor(0.1276, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305225133895874\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305725336074829\n",
            "g_norm = tensor(0.1517, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043248653411865\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.26644897460938\n",
            "||∇_X meta|| = 0.001407237141393125\n",
            "ΔX norm: 1.4072439626033884e-05\n",
            "Stage 1/10:  86%|████████████████████████▉    | 258/300 [06:26<01:07,  1.60s/it]T Loss=2.3036859035491943\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303311824798584\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026175498962402\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046040534973145\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035101890563965\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.26312255859375\n",
            "||∇_X meta|| = 0.0014744974905624986\n",
            "ΔX norm: 1.4744960026291665e-05\n",
            "Stage 1/10:  86%|█████████████████████████    | 259/300 [06:28<01:04,  1.58s/it]T Loss=2.3035354614257812\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046672344207764\n",
            "g_norm = tensor(0.0828, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044114112854004\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304215908050537\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304257869720459\n",
            "g_norm = tensor(0.0928, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.17877197265625\n",
            "||∇_X meta|| = 0.0014065797440707684\n",
            "ΔX norm: 1.4065827599551994e-05\n",
            "Stage 1/10:  87%|█████████████████████████▏   | 260/300 [06:30<01:12,  1.81s/it]T Loss=2.3034329414367676\n",
            "g_norm = tensor(0.1268, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304849147796631\n",
            "g_norm = tensor(0.1447, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025386333465576\n",
            "g_norm = tensor(0.1380, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301698684692383\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023552894592285\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.81861877441406\n",
            "||∇_X meta|| = 0.001539920805953443\n",
            "ΔX norm: 1.539932236482855e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/10:  87%|█████████████████████████▏   | 261/300 [06:32<01:12,  1.86s/it]T Loss=2.302145481109619\n",
            "g_norm = tensor(0.1585, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303501605987549\n",
            "g_norm = tensor(0.1304, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303912401199341\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302065372467041\n",
            "g_norm = tensor(0.1470, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302518129348755\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.66526794433594\n",
            "||∇_X meta|| = 0.001636889879591763\n",
            "ΔX norm: 1.6368885553674772e-05\n",
            "Stage 1/10:  87%|█████████████████████████▎   | 262/300 [06:34<01:17,  2.03s/it]T Loss=2.3029046058654785\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302736759185791\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033337593078613\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304004430770874\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302712917327881\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.83714294433594\n",
            "||∇_X meta|| = 0.0016567441634833813\n",
            "ΔX norm: 1.6567419152124785e-05\n",
            "Stage 1/10:  88%|█████████████████████████▍   | 263/300 [06:36<01:13,  1.99s/it]T Loss=2.3019299507141113\n",
            "g_norm = tensor(0.1390, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303081512451172\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040199279785156\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036370277404785\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018527030944824\n",
            "g_norm = tensor(0.1363, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.13153076171875\n",
            "||∇_X meta|| = 0.0015594580909237266\n",
            "ΔX norm: 1.5594554497511126e-05\n",
            "Stage 1/10:  88%|█████████████████████████▌   | 264/300 [06:39<01:15,  2.10s/it]T Loss=2.302354335784912\n",
            "g_norm = tensor(0.1103, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035190105438232\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038461208343506\n",
            "g_norm = tensor(0.1336, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019444942474365\n",
            "g_norm = tensor(0.1387, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023722171783447\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.23033142089844\n",
            "||∇_X meta|| = 0.001500902813859284\n",
            "ΔX norm: 1.5009007256594487e-05\n",
            "Stage 1/10:  88%|█████████████████████████▌   | 265/300 [06:40<01:09,  1.99s/it]T Loss=2.3031623363494873\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036446571350098\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031840324401855\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304147720336914\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303610324859619\n",
            "g_norm = tensor(0.0848, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5299835205078\n",
            "||∇_X meta|| = 0.0015691251028329134\n",
            "ΔX norm: 1.5691257431171834e-05\n",
            "Stage 1/10:  89%|█████████████████████████▋   | 266/300 [06:42<01:07,  1.97s/it]T Loss=2.3035500049591064\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304088830947876\n",
            "g_norm = tensor(0.1327, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303919792175293\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035340309143066\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303223133087158\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =233.0701446533203\n",
            "||∇_X meta|| = 0.0015141051262617111\n",
            "ΔX norm: 1.5141122275963426e-05\n",
            "Stage 1/10:  89%|█████████████████████████▊   | 267/300 [06:44<01:01,  1.86s/it]T Loss=2.3034114837646484\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302241802215576\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031113147735596\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039097785949707\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041560649871826\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5801239013672\n",
            "||∇_X meta|| = 0.0016009273240342736\n",
            "ΔX norm: 1.6009258615667932e-05\n",
            "Stage 1/10:  89%|█████████████████████████▉   | 268/300 [06:45<00:56,  1.78s/it]T Loss=2.303332567214966\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042240142822266\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303786039352417\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030734062194824\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305208444595337\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.77330017089844\n",
            "||∇_X meta|| = 0.0015779994428157806\n",
            "ΔX norm: 1.577998227730859e-05\n",
            "Stage 1/10:  90%|██████████████████████████   | 269/300 [06:47<00:53,  1.72s/it]T Loss=2.3046042919158936\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038039207458496\n",
            "g_norm = tensor(0.0834, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032097816467285\n",
            "g_norm = tensor(0.0825, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033041954040527\n",
            "g_norm = tensor(0.0876, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040988445281982\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5282440185547\n",
            "||∇_X meta|| = 0.0015798916574567556\n",
            "ΔX norm: 1.5798905224073678e-05\n",
            "Stage 1/10:  90%|██████████████████████████   | 270/300 [06:49<00:56,  1.88s/it]T Loss=2.3039772510528564\n",
            "g_norm = tensor(0.1449, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304098129272461\n",
            "g_norm = tensor(0.1243, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303619146347046\n",
            "g_norm = tensor(0.1632, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031535148620605\n",
            "g_norm = tensor(0.1302, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302696704864502\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.97555541992188\n",
            "||∇_X meta|| = 0.0017471768660470843\n",
            "ΔX norm: 1.7471702449256554e-05\n",
            "Stage 1/10:  90%|██████████████████████████▏  | 271/300 [06:52<00:57,  1.99s/it]T Loss=2.30424165725708\n",
            "g_norm = tensor(0.1292, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038289546966553\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039169311523438\n",
            "g_norm = tensor(0.0933, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30315899848938\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303122043609619\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.96620178222656\n",
            "||∇_X meta|| = 0.0018845699960365891\n",
            "ΔX norm: 1.884566154330969e-05\n",
            "Stage 1/10:  91%|██████████████████████████▎  | 272/300 [06:54<01:01,  2.19s/it]T Loss=2.305013418197632\n",
            "g_norm = tensor(0.1301, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30385684967041\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040919303894043\n",
            "g_norm = tensor(0.1320, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050742149353027\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058342933654785\n",
            "g_norm = tensor(0.1222, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.62820434570312\n",
            "||∇_X meta|| = 0.0015431572683155537\n",
            "ΔX norm: 1.5431627616635524e-05\n",
            "Stage 1/10:  91%|██████████████████████████▍  | 273/300 [06:56<00:58,  2.16s/it]T Loss=2.3032917976379395\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304276704788208\n",
            "g_norm = tensor(0.1249, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302032947540283\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048417568206787\n",
            "g_norm = tensor(0.1295, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304936170578003\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4080810546875\n",
            "||∇_X meta|| = 0.0015441069845110178\n",
            "ΔX norm: 1.5441009963979013e-05\n",
            "Stage 1/10:  91%|██████████████████████████▍  | 274/300 [06:58<00:51,  1.96s/it]T Loss=2.3034915924072266\n",
            "g_norm = tensor(0.1259, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302903890609741\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303424835205078\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024182319641113\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027853965759277\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0733184814453\n",
            "||∇_X meta|| = 0.0014687414513900876\n",
            "ΔX norm: 1.4687421753478702e-05\n",
            "Stage 1/10:  92%|██████████████████████████▌  | 275/300 [07:00<00:52,  2.10s/it]T Loss=2.303530216217041\n",
            "g_norm = tensor(0.1578, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302661657333374\n",
            "g_norm = tensor(0.1783, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038251399993896\n",
            "g_norm = tensor(0.1381, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028764724731445\n",
            "g_norm = tensor(0.1620, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036086559295654\n",
            "g_norm = tensor(0.1516, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.243896484375\n",
            "||∇_X meta|| = 0.0015579067403450608\n",
            "ΔX norm: 1.5579113096464425e-05\n",
            "Stage 1/10:  92%|██████████████████████████▋  | 276/300 [07:02<00:50,  2.12s/it]T Loss=2.303982973098755\n",
            "g_norm = tensor(0.1184, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304267168045044\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304877758026123\n",
            "g_norm = tensor(0.1323, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037097454071045\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026082515716553\n",
            "g_norm = tensor(0.1283, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.44384765625\n",
            "||∇_X meta|| = 0.0017558879917487502\n",
            "ΔX norm: 1.7558859326527454e-05\n",
            "Stage 1/10:  92%|██████████████████████████▊  | 277/300 [07:04<00:45,  1.99s/it]T Loss=2.303103446960449\n",
            "g_norm = tensor(0.0850, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034846782684326\n",
            "g_norm = tensor(0.0714, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029592037200928\n",
            "g_norm = tensor(0.0751, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304103374481201\n",
            "g_norm = tensor(0.0768, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027396202087402\n",
            "g_norm = tensor(0.0802, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.35113525390625\n",
            "||∇_X meta|| = 0.001517156488262117\n",
            "ΔX norm: 1.5171572158578783e-05\n",
            "Stage 1/10:  93%|██████████████████████████▊  | 278/300 [07:06<00:41,  1.90s/it]T Loss=2.30389666557312\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039515018463135\n",
            "g_norm = tensor(0.1243, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043618202209473\n",
            "g_norm = tensor(0.0917, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031527996063232\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303508996963501\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7325439453125\n",
            "||∇_X meta|| = 0.0016270336927846074\n",
            "ΔX norm: 1.6270372725557536e-05\n",
            "Stage 1/10:  93%|██████████████████████████▉  | 279/300 [07:08<00:40,  1.92s/it]T Loss=2.303185224533081\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303549289703369\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042197227478027\n",
            "g_norm = tensor(0.1291, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049495220184326\n",
            "g_norm = tensor(0.1388, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050456047058105\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.77252197265625\n",
            "||∇_X meta|| = 0.0016780068399384618\n",
            "ΔX norm: 1.6780018995632418e-05\n",
            "Stage 1/10:  93%|███████████████████████████  | 280/300 [07:10<00:38,  1.94s/it]T Loss=2.3033690452575684\n",
            "g_norm = tensor(0.1488, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037233352661133\n",
            "g_norm = tensor(0.1305, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304672956466675\n",
            "g_norm = tensor(0.1392, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3010001182556152\n",
            "g_norm = tensor(0.1453, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037593364715576\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.4757080078125\n",
            "||∇_X meta|| = 0.0015302329557016492\n",
            "ΔX norm: 1.5302342944778502e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/10:  94%|███████████████████████████▏ | 281/300 [07:11<00:34,  1.84s/it]T Loss=2.3048110008239746\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304537773132324\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039422035217285\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049368858337402\n",
            "g_norm = tensor(0.1369, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040292263031006\n",
            "g_norm = tensor(0.1529, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.31387329101562\n",
            "||∇_X meta|| = 0.001517161843366921\n",
            "ΔX norm: 1.5171578525041696e-05\n",
            "Stage 1/10:  94%|███████████████████████████▎ | 282/300 [07:13<00:34,  1.93s/it]T Loss=2.303284168243408\n",
            "g_norm = tensor(0.0942, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303213119506836\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304175615310669\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303615093231201\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022620677948\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7682342529297\n",
            "||∇_X meta|| = 0.0015950108645483851\n",
            "ΔX norm: 1.5950146917020902e-05\n",
            "Stage 1/10:  94%|███████████████████████████▎ | 283/300 [07:15<00:31,  1.84s/it]T Loss=2.303992509841919\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303946018218994\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304260730743408\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033900260925293\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036625385284424\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.3762664794922\n",
            "||∇_X meta|| = 0.0016094824532046914\n",
            "ΔX norm: 1.6094822058221325e-05\n",
            "Stage 1/10:  95%|███████████████████████████▍ | 284/300 [07:17<00:28,  1.75s/it]T Loss=2.304811954498291\n",
            "g_norm = tensor(0.0845, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037467002868652\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303631067276001\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304826021194458\n",
            "g_norm = tensor(0.0840, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044674396514893\n",
            "g_norm = tensor(0.0849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.92791748046875\n",
            "||∇_X meta|| = 0.0016082412330433726\n",
            "ΔX norm: 1.6082401998573914e-05\n",
            "Stage 1/10:  95%|███████████████████████████▌ | 285/300 [07:18<00:26,  1.74s/it]T Loss=2.303675651550293\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304900646209717\n",
            "g_norm = tensor(0.1334, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038671016693115\n",
            "g_norm = tensor(0.1336, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302424907684326\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303443193435669\n",
            "g_norm = tensor(0.1348, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.7411651611328\n",
            "||∇_X meta|| = 0.0014634404797106981\n",
            "ΔX norm: 1.4634411854785867e-05\n",
            "Stage 1/10:  95%|███████████████████████████▋ | 286/300 [07:20<00:24,  1.74s/it]T Loss=2.304279327392578\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305710554122925\n",
            "g_norm = tensor(0.0980, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304478883743286\n",
            "g_norm = tensor(0.0862, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305027723312378\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051981925964355\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.6025848388672\n",
            "||∇_X meta|| = 0.0015616780146956444\n",
            "ΔX norm: 1.561677891004365e-05\n",
            "Stage 1/10:  96%|███████████████████████████▋ | 287/300 [07:22<00:24,  1.88s/it]T Loss=2.3037264347076416\n",
            "g_norm = tensor(0.0857, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038523197174072\n",
            "g_norm = tensor(0.0754, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033273220062256\n",
            "g_norm = tensor(0.0758, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027126789093018\n",
            "g_norm = tensor(0.0860, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038840293884277\n",
            "g_norm = tensor(0.0836, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.82839965820312\n",
            "||∇_X meta|| = 0.0015585902146995068\n",
            "ΔX norm: 1.558595795358997e-05\n",
            "Stage 1/10:  96%|███████████████████████████▊ | 288/300 [07:24<00:22,  1.84s/it]T Loss=2.304049015045166\n",
            "g_norm = tensor(0.0763, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037195205688477\n",
            "g_norm = tensor(0.0713, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304760456085205\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035030364990234\n",
            "g_norm = tensor(0.0852, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045401573181152\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.49411010742188\n",
            "||∇_X meta|| = 0.0015375500079244375\n",
            "ΔX norm: 1.537545904284343e-05\n",
            "Stage 1/10:  96%|███████████████████████████▉ | 289/300 [07:26<00:19,  1.74s/it]T Loss=2.3038108348846436\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303741931915283\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303896427154541\n",
            "g_norm = tensor(0.0767, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032798767089844\n",
            "g_norm = tensor(0.0947, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304368257522583\n",
            "g_norm = tensor(0.0897, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.89361572265625\n",
            "||∇_X meta|| = 0.0014865261036902666\n",
            "ΔX norm: 1.486524888605345e-05\n",
            "Stage 1/10:  97%|████████████████████████████ | 290/300 [07:27<00:16,  1.68s/it]T Loss=2.305135726928711\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303048610687256\n",
            "g_norm = tensor(0.1496, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056161403656006\n",
            "g_norm = tensor(0.1712, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3059136867523193\n",
            "g_norm = tensor(0.1248, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040568828582764\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.30372619628906\n",
            "||∇_X meta|| = 0.0016635083593428135\n",
            "ΔX norm: 1.6635098290862516e-05\n",
            "Stage 1/10:  97%|████████████████████████████▏| 291/300 [07:29<00:14,  1.62s/it]T Loss=2.3059704303741455\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303004741668701\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303877830505371\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304490804672241\n",
            "g_norm = tensor(0.1302, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303689479827881\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.71661376953125\n",
            "||∇_X meta|| = 0.0015175462467595935\n",
            "ΔX norm: 1.5175477528828196e-05\n",
            "Stage 1/10:  97%|████████████████████████████▏| 292/300 [07:30<00:12,  1.59s/it]T Loss=2.3033223152160645\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039488792419434\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303459405899048\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303804874420166\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303375244140625\n",
            "g_norm = tensor(0.0980, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.70272827148438\n",
            "||∇_X meta|| = 0.0015848020557314157\n",
            "ΔX norm: 1.5848023394937627e-05\n",
            "Stage 1/10:  98%|████████████████████████████▎| 293/300 [07:32<00:11,  1.60s/it]T Loss=2.304050922393799\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050878047943115\n",
            "g_norm = tensor(0.1262, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30422043800354\n",
            "g_norm = tensor(0.1222, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044381141662598\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303109884262085\n",
            "g_norm = tensor(0.1442, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0566864013672\n",
            "||∇_X meta|| = 0.0016825152561068535\n",
            "ΔX norm: 1.6825131751829758e-05\n",
            "Stage 1/10:  98%|████████████████████████████▍| 294/300 [07:33<00:09,  1.62s/it]T Loss=2.303485870361328\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302035331726074\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303959369659424\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026978969573975\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033246994018555\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.84500122070312\n",
            "||∇_X meta|| = 0.0015232183504849672\n",
            "ΔX norm: 1.5232219084282406e-05\n",
            "Stage 1/10:  98%|████████████████████████████▌| 295/300 [07:35<00:08,  1.63s/it]T Loss=2.3036093711853027\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304926872253418\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045027256011963\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028552532196045\n",
            "g_norm = tensor(0.1270, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040151596069336\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.93084716796875\n",
            "||∇_X meta|| = 0.0014500062679871917\n",
            "ΔX norm: 1.4500017641694285e-05\n",
            "Stage 1/10:  99%|████████████████████████████▌| 296/300 [07:37<00:06,  1.66s/it]T Loss=2.3043856620788574\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303534507751465\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032679557800293\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303833484649658\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303961992263794\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8761444091797\n",
            "||∇_X meta|| = 0.001476587844081223\n",
            "ΔX norm: 1.4765910236747004e-05\n",
            "Stage 1/10:  99%|████████████████████████████▋| 297/300 [07:38<00:04,  1.64s/it]T Loss=2.304070234298706\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049144744873047\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304138660430908\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049991130828857\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304494857788086\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.52108764648438\n",
            "||∇_X meta|| = 0.0014974315417930484\n",
            "ΔX norm: 1.4974332771089394e-05\n",
            "Stage 1/10:  99%|████████████████████████████▊| 298/300 [07:40<00:03,  1.75s/it]T Loss=2.304368495941162\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304884195327759\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304781436920166\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304738998413086\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042173385620117\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.47412109375\n",
            "||∇_X meta|| = 0.001415687962435186\n",
            "ΔX norm: 1.4156890756567009e-05\n",
            "Stage 1/10: 100%|████████████████████████████▉| 299/300 [07:42<00:01,  1.72s/it]T Loss=2.303072452545166\n",
            "g_norm = tensor(0.1099, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30332088470459\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037006855010986\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027117252349854\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034961223602295\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.02456665039062\n",
            "||∇_X meta|| = 0.0016467329114675522\n",
            "ΔX norm: 1.646730197535362e-05\n",
            "Stage 0, class 0, loss 2.209                                                    \n",
            "Stage 0, class 1, loss 2.268\n",
            "Stage 0, class 2, loss 2.342\n",
            "Stage 0, class 3, loss 2.361\n",
            "Stage 0, class 4, loss 2.303\n",
            "Stage 0, class 5, loss 2.323\n",
            "Stage 0, class 6, loss 2.385\n",
            "Stage 0, class 7, loss 2.218\n",
            "Stage 0, class 8, loss 2.383\n",
            "Stage 0, class 9, loss 2.259\n",
            "Stage 2/10:   0%|                                       | 0/300 [00:00<?, ?it/s]T Loss=2.3044819831848145\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304779529571533\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302610158920288\n",
            "g_norm = tensor(0.1354, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035659790039062\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303368091583252\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4735107421875\n",
            "||∇_X meta|| = 0.003919420298188925\n",
            "ΔX norm: 3.9194183045765385e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 2/10:   0%|                               | 1/300 [00:01<08:11,  1.64s/it]T Loss=2.303950548171997\n",
            "g_norm = tensor(0.0808, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304966688156128\n",
            "g_norm = tensor(0.0872, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303441047668457\n",
            "g_norm = tensor(0.0748, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304166316986084\n",
            "g_norm = tensor(0.0741, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041043281555176\n",
            "g_norm = tensor(0.0736, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.10467529296875\n",
            "||∇_X meta|| = 0.004012470133602619\n",
            "ΔX norm: 4.012471254100092e-05\n",
            "Stage 2/10:   1%|▏                              | 2/300 [00:03<09:05,  1.83s/it]T Loss=2.304579257965088\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302894115447998\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032491207122803\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036749362945557\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038735389709473\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.07839965820312\n",
            "||∇_X meta|| = 0.003866232233121991\n",
            "ΔX norm: 3.866228144033812e-05\n",
            "Stage 2/10:   1%|▎                              | 3/300 [00:05<09:20,  1.89s/it]T Loss=2.303955554962158\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302586793899536\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303507089614868\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031792640686035\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303269624710083\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.52200317382812\n",
            "||∇_X meta|| = 0.0036198669113218784\n",
            "ΔX norm: 3.6198689485900104e-05\n",
            "Stage 2/10:   1%|▍                              | 4/300 [00:07<08:31,  1.73s/it]T Loss=2.3037033081054688\n",
            "g_norm = tensor(0.0695, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038525581359863\n",
            "g_norm = tensor(0.0757, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035728931427\n",
            "g_norm = tensor(0.0820, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039183616638184\n",
            "g_norm = tensor(0.0832, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303119421005249\n",
            "g_norm = tensor(0.0815, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.22215270996094\n",
            "||∇_X meta|| = 0.0035675871185958385\n",
            "ΔX norm: 3.567586827557534e-05\n",
            "Stage 2/10:   2%|▌                              | 5/300 [00:08<07:59,  1.62s/it]T Loss=2.304668426513672\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057780265808105\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035635948181152\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303823947906494\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044118881225586\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.58277893066406\n",
            "||∇_X meta|| = 0.0038039847277104855\n",
            "ΔX norm: 3.803989238804206e-05\n",
            "Stage 2/10:   2%|▌                              | 6/300 [00:09<07:36,  1.55s/it]T Loss=2.3037526607513428\n",
            "g_norm = tensor(0.1350, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304619312286377\n",
            "g_norm = tensor(0.1367, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3006460666656494\n",
            "g_norm = tensor(0.1493, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302595376968384\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033089637756348\n",
            "g_norm = tensor(0.1363, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1161346435547\n",
            "||∇_X meta|| = 0.0035882305819541216\n",
            "ΔX norm: 3.588233812479302e-05\n",
            "Stage 2/10:   2%|▋                              | 7/300 [00:11<07:25,  1.52s/it]T Loss=2.30379056930542\n",
            "g_norm = tensor(0.0691, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047595024108887\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049025535583496\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304330348968506\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047611713409424\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.46896362304688\n",
            "||∇_X meta|| = 0.003786301240324974\n",
            "ΔX norm: 3.7863010220462456e-05\n",
            "Stage 2/10:   3%|▊                              | 8/300 [00:13<07:54,  1.63s/it]T Loss=2.303558349609375\n",
            "g_norm = tensor(0.1464, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303361415863037\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302351474761963\n",
            "g_norm = tensor(0.1389, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042497634887695\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041863441467285\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.04319763183594\n",
            "||∇_X meta|| = 0.003909342456609011\n",
            "ΔX norm: 3.909330553142354e-05\n",
            "Stage 2/10:   3%|▉                              | 9/300 [00:14<07:44,  1.60s/it]T Loss=2.303649425506592\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304013729095459\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032119274139404\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303523302078247\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303776979446411\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.80491638183594\n",
            "||∇_X meta|| = 0.0034759703557938337\n",
            "ΔX norm: 3.475971971056424e-05\n",
            "Stage 2/10:   3%|█                             | 10/300 [00:16<07:38,  1.58s/it]T Loss=2.3015811443328857\n",
            "g_norm = tensor(0.1625, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303189277648926\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301229476928711\n",
            "g_norm = tensor(0.1413, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039774894714355\n",
            "g_norm = tensor(0.1532, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304514169692993\n",
            "g_norm = tensor(0.1586, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6924285888672\n",
            "||∇_X meta|| = 0.0033382137771695852\n",
            "ΔX norm: 3.338211899972521e-05\n",
            "Stage 2/10:   4%|█                             | 11/300 [00:17<07:31,  1.56s/it]T Loss=2.304262161254883\n",
            "g_norm = tensor(0.0726, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035125732421875\n",
            "g_norm = tensor(0.0710, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304103374481201\n",
            "g_norm = tensor(0.0784, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303739070892334\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037924766540527\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.46218872070312\n",
            "||∇_X meta|| = 0.003432958386838436\n",
            "ΔX norm: 3.432959783822298e-05\n",
            "Stage 2/10:   4%|█▏                            | 12/300 [00:19<07:22,  1.54s/it]T Loss=2.3044466972351074\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30471134185791\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034427165985107\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037467002868652\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303767204284668\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.28103637695312\n",
            "||∇_X meta|| = 0.0036311752628535032\n",
            "ΔX norm: 3.6311757867224514e-05\n",
            "Stage 2/10:   4%|█▎                            | 13/300 [00:20<07:32,  1.58s/it]T Loss=2.3053390979766846\n",
            "g_norm = tensor(0.1413, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023788928985596\n",
            "g_norm = tensor(0.1498, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039557933807373\n",
            "g_norm = tensor(0.1382, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037235736846924\n",
            "g_norm = tensor(0.1454, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303612470626831\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3500213623047\n",
            "||∇_X meta|| = 0.0031231632456183434\n",
            "ΔX norm: 3.123161877738312e-05\n",
            "Stage 2/10:   5%|█▍                            | 14/300 [00:23<08:24,  1.76s/it]T Loss=2.304147243499756\n",
            "g_norm = tensor(0.1373, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303473472595215\n",
            "g_norm = tensor(0.1416, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304704189300537\n",
            "g_norm = tensor(0.1739, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031656742095947\n",
            "g_norm = tensor(0.1570, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042492866516113\n",
            "g_norm = tensor(0.1545, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4633331298828\n",
            "||∇_X meta|| = 0.003910647239536047\n",
            "ΔX norm: 3.910644954885356e-05\n",
            "Stage 2/10:   5%|█▌                            | 15/300 [00:24<08:14,  1.73s/it]T Loss=2.3034918308258057\n",
            "g_norm = tensor(0.1443, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30375337600708\n",
            "g_norm = tensor(0.1627, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304724931716919\n",
            "g_norm = tensor(0.1377, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305586338043213\n",
            "g_norm = tensor(0.1369, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048222064971924\n",
            "g_norm = tensor(0.1356, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.63644409179688\n",
            "||∇_X meta|| = 0.0034348967019468546\n",
            "ΔX norm: 3.434893369558267e-05\n",
            "Stage 2/10:   5%|█▌                            | 16/300 [00:26<07:52,  1.66s/it]T Loss=2.304079055786133\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046460151672363\n",
            "g_norm = tensor(0.1475, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043227195739746\n",
            "g_norm = tensor(0.1350, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041884899139404\n",
            "g_norm = tensor(0.1472, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044545650482178\n",
            "g_norm = tensor(0.1534, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.18589782714844\n",
            "||∇_X meta|| = 0.003656883956864476\n",
            "ΔX norm: 3.656884655356407e-05\n",
            "Stage 2/10:   6%|█▋                            | 17/300 [00:27<07:36,  1.61s/it]T Loss=2.304095506668091\n",
            "g_norm = tensor(0.1139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30305814743042\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303931713104248\n",
            "g_norm = tensor(0.0980, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034074306488037\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036208152770996\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.97625732421875\n",
            "||∇_X meta|| = 0.00308073777705431\n",
            "ΔX norm: 3.080738679273054e-05\n",
            "Stage 2/10:   6%|█▊                            | 18/300 [00:29<07:19,  1.56s/it]T Loss=2.3033108711242676\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304288625717163\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034844398498535\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046927452087402\n",
            "g_norm = tensor(0.1269, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040709495544434\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.17152404785156\n",
            "||∇_X meta|| = 0.0032804091461002827\n",
            "ΔX norm: 3.280408418504521e-05\n",
            "Stage 2/10:   6%|█▉                            | 19/300 [00:30<07:07,  1.52s/it]T Loss=2.30224347114563\n",
            "g_norm = tensor(0.1505, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303057909011841\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038394451141357\n",
            "g_norm = tensor(0.1389, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305150270462036\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303093671798706\n",
            "g_norm = tensor(0.1523, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.27626037597656\n",
            "||∇_X meta|| = 0.003767169313505292\n",
            "ΔX norm: 3.767165617318824e-05\n",
            "Stage 2/10:   7%|██                            | 20/300 [00:32<07:19,  1.57s/it]T Loss=2.303438663482666\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305691957473755\n",
            "g_norm = tensor(0.1324, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304105520248413\n",
            "g_norm = tensor(0.1345, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30350399017334\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304109811782837\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.27764892578125\n",
            "||∇_X meta|| = 0.0033879135735332966\n",
            "ΔX norm: 3.3879106922540814e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 2/10:   7%|██                            | 21/300 [00:33<07:14,  1.56s/it]T Loss=2.3043551445007324\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303659439086914\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303504467010498\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032078742980957\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303670883178711\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.86837768554688\n",
            "||∇_X meta|| = 0.0032393531873822212\n",
            "ΔX norm: 3.239354555262253e-05\n",
            "Stage 2/10:   7%|██▏                           | 22/300 [00:35<07:42,  1.66s/it]T Loss=2.303323745727539\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034844398498535\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036961555480957\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303314685821533\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040313720703125\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4340362548828\n",
            "||∇_X meta|| = 0.0032826492097228765\n",
            "ΔX norm: 3.2826497772475705e-05\n",
            "Stage 2/10:   8%|██▎                           | 23/300 [00:37<07:34,  1.64s/it]T Loss=2.3033242225646973\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304152727127075\n",
            "g_norm = tensor(0.0854, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303429365158081\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304307699203491\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303839683532715\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.91514587402344\n",
            "||∇_X meta|| = 0.0031527841929346323\n",
            "ΔX norm: 3.152782664983533e-05\n",
            "Stage 2/10:   8%|██▍                           | 24/300 [00:38<07:23,  1.61s/it]T Loss=2.3045125007629395\n",
            "g_norm = tensor(0.1525, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038151264190674\n",
            "g_norm = tensor(0.1103, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034355640411377\n",
            "g_norm = tensor(0.1527, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045318126678467\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031301498413086\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8870391845703\n",
            "||∇_X meta|| = 0.0031039013992995024\n",
            "ΔX norm: 3.103898779954761e-05\n",
            "Stage 2/10:   8%|██▌                           | 25/300 [00:40<07:37,  1.66s/it]T Loss=2.303166151046753\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032760620117188\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301858425140381\n",
            "g_norm = tensor(0.1253, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028855323791504\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303476333618164\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.71694946289062\n",
            "||∇_X meta|| = 0.0036124172620475292\n",
            "ΔX norm: 3.612412911024876e-05\n",
            "Stage 2/10:   9%|██▌                           | 26/300 [00:42<07:43,  1.69s/it]T Loss=2.302753448486328\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042149543762207\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039121627807617\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303379535675049\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302950620651245\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.27818298339844\n",
            "||∇_X meta|| = 0.003187892958521843\n",
            "ΔX norm: 3.187893526046537e-05\n",
            "Stage 2/10:   9%|██▋                           | 27/300 [00:44<07:34,  1.67s/it]T Loss=2.305231809616089\n",
            "g_norm = tensor(0.1693, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031554222106934\n",
            "g_norm = tensor(0.1637, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305389881134033\n",
            "g_norm = tensor(0.1630, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304210901260376\n",
            "g_norm = tensor(0.1677, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050713539123535\n",
            "g_norm = tensor(0.1363, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9958038330078\n",
            "||∇_X meta|| = 0.0032395594753324986\n",
            "ΔX norm: 3.2395560992881656e-05\n",
            "Stage 2/10:   9%|██▊                           | 28/300 [00:45<07:19,  1.62s/it]T Loss=2.3031864166259766\n",
            "g_norm = tensor(0.1255, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303402900695801\n",
            "g_norm = tensor(0.0942, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303321599960327\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303374767303467\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3014256954193115\n",
            "g_norm = tensor(0.1553, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5540771484375\n",
            "||∇_X meta|| = 0.0030691069550812244\n",
            "ΔX norm: 3.0691073334310204e-05\n",
            "Stage 2/10:  10%|██▉                           | 29/300 [00:47<07:08,  1.58s/it]T Loss=2.3036751747131348\n",
            "g_norm = tensor(0.1997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3009233474731445\n",
            "g_norm = tensor(0.2034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046960830688477\n",
            "g_norm = tensor(0.1993, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303988218307495\n",
            "g_norm = tensor(0.1908, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304924488067627\n",
            "g_norm = tensor(0.1757, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.58872985839844\n",
            "||∇_X meta|| = 0.0031908710952848196\n",
            "ΔX norm: 3.190874485881068e-05\n",
            "Stage 2/10:  10%|███                           | 30/300 [00:48<07:01,  1.56s/it]T Loss=2.304141044616699\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303333282470703\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303558826446533\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041768074035645\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304609775543213\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2532196044922\n",
            "||∇_X meta|| = 0.0028276429511606693\n",
            "ΔX norm: 2.8276410375838168e-05\n",
            "Stage 2/10:  10%|███                           | 31/300 [00:50<07:01,  1.57s/it]T Loss=2.30326509475708\n",
            "g_norm = tensor(0.1525, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302372455596924\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034372329711914\n",
            "g_norm = tensor(0.1500, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30369234085083\n",
            "g_norm = tensor(0.1248, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304529905319214\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9371795654297\n",
            "||∇_X meta|| = 0.003141201101243496\n",
            "ΔX norm: 3.141208435408771e-05\n",
            "Stage 2/10:  11%|███▏                          | 32/300 [00:51<06:54,  1.55s/it]T Loss=2.3043901920318604\n",
            "g_norm = tensor(0.0682, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029911518096924\n",
            "g_norm = tensor(0.0737, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303976535797119\n",
            "g_norm = tensor(0.0634, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038177490234375\n",
            "g_norm = tensor(0.0672, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303269624710083\n",
            "g_norm = tensor(0.0684, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6085968017578\n",
            "||∇_X meta|| = 0.0032149208709597588\n",
            "ΔX norm: 3.214923708583228e-05\n",
            "Stage 2/10:  11%|███▎                          | 33/300 [00:53<06:53,  1.55s/it]T Loss=2.304443836212158\n",
            "g_norm = tensor(0.1367, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041586875915527\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303412914276123\n",
            "g_norm = tensor(0.1218, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048348426818848\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303682804107666\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2131805419922\n",
            "||∇_X meta|| = 0.002872537588700652\n",
            "ΔX norm: 2.8725333322654478e-05\n",
            "Stage 2/10:  11%|███▍                          | 34/300 [00:54<06:55,  1.56s/it]T Loss=2.302903413772583\n",
            "g_norm = tensor(0.1384, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303955554962158\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035972118377686\n",
            "g_norm = tensor(0.0846, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302968978881836\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303131580352783\n",
            "g_norm = tensor(0.1107, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.04660034179688\n",
            "||∇_X meta|| = 0.0028851106762886047\n",
            "ΔX norm: 2.8851136448793113e-05\n",
            "Stage 2/10:  12%|███▌                          | 35/300 [00:56<06:55,  1.57s/it]T Loss=2.3033127784729004\n",
            "g_norm = tensor(0.1630, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054585456848145\n",
            "g_norm = tensor(0.1352, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305453062057495\n",
            "g_norm = tensor(0.1461, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301980495452881\n",
            "g_norm = tensor(0.1887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303218364715576\n",
            "g_norm = tensor(0.1321, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.33203125\n",
            "||∇_X meta|| = 0.002891041338443756\n",
            "ΔX norm: 2.8910424589412287e-05\n",
            "Stage 2/10:  12%|███▌                          | 36/300 [00:58<07:03,  1.60s/it]T Loss=2.306717872619629\n",
            "g_norm = tensor(0.1516, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305449962615967\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305386781692505\n",
            "g_norm = tensor(0.1268, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048839569091797\n",
            "g_norm = tensor(0.1630, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053038120269775\n",
            "g_norm = tensor(0.1431, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.43348693847656\n",
            "||∇_X meta|| = 0.0024828307796269655\n",
            "ΔX norm: 2.4828288587741554e-05\n",
            "Stage 2/10:  12%|███▋                          | 37/300 [00:59<06:59,  1.59s/it]T Loss=2.3033447265625\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047986030578613\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30377459526062\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038182258605957\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303313732147217\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.48194885253906\n",
            "||∇_X meta|| = 0.002542081754654646\n",
            "ΔX norm: 2.542080073908437e-05\n",
            "Stage 2/10:  13%|███▊                          | 38/300 [01:01<06:56,  1.59s/it]T Loss=2.3033664226531982\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303830862045288\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303410291671753\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042349815368652\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029017448425293\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.99398803710938\n",
            "||∇_X meta|| = 0.002981086727231741\n",
            "ΔX norm: 2.9810875275870785e-05\n",
            "Stage 2/10:  13%|███▉                          | 39/300 [01:02<06:49,  1.57s/it]T Loss=2.305419683456421\n",
            "g_norm = tensor(0.1442, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045475482940674\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035011291503906\n",
            "g_norm = tensor(0.1107, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304682493209839\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3060495853424072\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.81405639648438\n",
            "||∇_X meta|| = 0.002676771255210042\n",
            "ΔX norm: 2.6767685994855128e-05\n",
            "Stage 2/10:  13%|████                          | 40/300 [01:04<07:05,  1.64s/it]T Loss=2.303872585296631\n",
            "g_norm = tensor(0.1270, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303769111633301\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046200275421143\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047683238983154\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044190406799316\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.997802734375\n",
            "||∇_X meta|| = 0.003096278989687562\n",
            "ΔX norm: 3.096278669545427e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 2/10:  14%|████                          | 41/300 [01:06<06:59,  1.62s/it]T Loss=2.3041832447052\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.300938129425049\n",
            "g_norm = tensor(0.1465, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029677867889404\n",
            "g_norm = tensor(0.1385, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030755519866943\n",
            "g_norm = tensor(0.1356, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028149604797363\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6736602783203\n",
            "||∇_X meta|| = 0.0024522540625184774\n",
            "ΔX norm: 2.452254011586774e-05\n",
            "Stage 2/10:  14%|████▏                         | 42/300 [01:08<07:24,  1.72s/it]T Loss=2.304635763168335\n",
            "g_norm = tensor(0.1342, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046059608459473\n",
            "g_norm = tensor(0.1410, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302900552749634\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304281234741211\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047244548797607\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2861328125\n",
            "||∇_X meta|| = 0.0027227404061704874\n",
            "ΔX norm: 2.7227384634898044e-05\n",
            "Stage 2/10:  14%|████▎                         | 43/300 [01:09<07:15,  1.70s/it]T Loss=2.303762912750244\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037400245666504\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3063015937805176\n",
            "g_norm = tensor(0.1408, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044841289520264\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041939735412598\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.98287963867188\n",
            "||∇_X meta|| = 0.002623687731102109\n",
            "ΔX norm: 2.6236863050144166e-05\n",
            "Stage 2/10:  15%|████▍                         | 44/300 [01:11<07:02,  1.65s/it]T Loss=2.303252935409546\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030102252960205\n",
            "g_norm = tensor(0.0810, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029797077178955\n",
            "g_norm = tensor(0.0821, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303286075592041\n",
            "g_norm = tensor(0.0890, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036069869995117\n",
            "g_norm = tensor(0.0865, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.22341918945312\n",
            "||∇_X meta|| = 0.002518497873097658\n",
            "ΔX norm: 2.51849942287663e-05\n",
            "Stage 2/10:  15%|████▌                         | 45/300 [01:13<07:25,  1.75s/it]T Loss=2.3029227256774902\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033394813537598\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304351329803467\n",
            "g_norm = tensor(0.0833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303515911102295\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035550117492676\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4765625\n",
            "||∇_X meta|| = 0.0025864061899483204\n",
            "ΔX norm: 2.586402843007818e-05\n",
            "Stage 2/10:  15%|████▌                         | 46/300 [01:14<07:16,  1.72s/it]T Loss=2.304161310195923\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036625385284424\n",
            "g_norm = tensor(0.1466, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051273822784424\n",
            "g_norm = tensor(0.1467, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303957462310791\n",
            "g_norm = tensor(0.1496, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029327392578125\n",
            "g_norm = tensor(0.1484, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.04318237304688\n",
            "||∇_X meta|| = 0.0024298299103975296\n",
            "ΔX norm: 2.429832602501847e-05\n",
            "Stage 2/10:  16%|████▋                         | 47/300 [01:16<07:06,  1.69s/it]T Loss=2.304187297821045\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304832935333252\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045551776885986\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040547370910645\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303934335708618\n",
            "g_norm = tensor(0.0993, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1326904296875\n",
            "||∇_X meta|| = 0.0026588295586407185\n",
            "ΔX norm: 2.6588333639665507e-05\n",
            "Stage 2/10:  16%|████▊                         | 48/300 [01:18<06:51,  1.63s/it]T Loss=2.304832935333252\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023784160614014\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036227226257324\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026950359344482\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304154396057129\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.89874267578125\n",
            "||∇_X meta|| = 0.002796521410346031\n",
            "ΔX norm: 2.79651958408067e-05\n",
            "Stage 2/10:  16%|████▉                         | 49/300 [01:19<06:43,  1.61s/it]T Loss=2.3040823936462402\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30454158782959\n",
            "g_norm = tensor(0.1269, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052215576171875\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303375720977783\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048946857452393\n",
            "g_norm = tensor(0.1154, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7561798095703\n",
            "||∇_X meta|| = 0.002561515662819147\n",
            "ΔX norm: 2.5615134291001596e-05\n",
            "Stage 2/10:  17%|█████                         | 50/300 [01:21<06:38,  1.59s/it]T Loss=2.303605794906616\n",
            "g_norm = tensor(0.1522, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304445266723633\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305147409439087\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045406341552734\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047213554382324\n",
            "g_norm = tensor(0.1363, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.87405395507812\n",
            "||∇_X meta|| = 0.002423723228275776\n",
            "ΔX norm: 2.423722435196396e-05\n",
            "Stage 2/10:  17%|█████                         | 51/300 [01:22<06:45,  1.63s/it]T Loss=2.3061788082122803\n",
            "g_norm = tensor(0.1283, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30389666557312\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050925731658936\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303128242492676\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304198741912842\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.8644561767578\n",
            "||∇_X meta|| = 0.002527147065848112\n",
            "ΔX norm: 2.527144897612743e-05\n",
            "Stage 2/10:  17%|█████▏                        | 52/300 [01:24<06:42,  1.62s/it]T Loss=2.303697109222412\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021798133850098\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024673461914062\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302135467529297\n",
            "g_norm = tensor(0.0980, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30336594581604\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.79859924316406\n",
            "||∇_X meta|| = 0.0025741616263985634\n",
            "ΔX norm: 2.5741584977367893e-05\n",
            "Stage 2/10:  18%|█████▎                        | 53/300 [01:26<06:42,  1.63s/it]T Loss=2.3058528900146484\n",
            "g_norm = tensor(0.1673, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053839206695557\n",
            "g_norm = tensor(0.1549, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041677474975586\n",
            "g_norm = tensor(0.1779, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305053949356079\n",
            "g_norm = tensor(0.1251, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303908109664917\n",
            "g_norm = tensor(0.1906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.78738403320312\n",
            "||∇_X meta|| = 0.002471962943673134\n",
            "ΔX norm: 2.4719534849282354e-05\n",
            "Stage 2/10:  18%|█████▍                        | 54/300 [01:27<06:56,  1.69s/it]T Loss=2.3042032718658447\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043665885925293\n",
            "g_norm = tensor(0.1292, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026013374328613\n",
            "g_norm = tensor(0.1349, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041911125183105\n",
            "g_norm = tensor(0.1357, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039767742156982\n",
            "g_norm = tensor(0.1302, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.78158569335938\n",
            "||∇_X meta|| = 0.0024735769256949425\n",
            "ΔX norm: 2.4735823899391107e-05\n",
            "Stage 2/10:  18%|█████▌                        | 55/300 [01:30<07:28,  1.83s/it]T Loss=2.3044753074645996\n",
            "g_norm = tensor(0.1525, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303630828857422\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032925128936768\n",
            "g_norm = tensor(0.0960, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030717372894287\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303718090057373\n",
            "g_norm = tensor(0.1259, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.08934020996094\n",
            "||∇_X meta|| = 0.002342421095818281\n",
            "ΔX norm: 2.34242070291657e-05\n",
            "Stage 2/10:  19%|█████▌                        | 56/300 [01:31<07:21,  1.81s/it]T Loss=2.3036293983459473\n",
            "g_norm = tensor(0.0917, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302696943283081\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030710220336914\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303006410598755\n",
            "g_norm = tensor(0.1011, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029391765594482\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.09083557128906\n",
            "||∇_X meta|| = 0.0024073536042124033\n",
            "ΔX norm: 2.4073553504422307e-05\n",
            "Stage 2/10:  19%|█████▋                        | 57/300 [01:33<07:05,  1.75s/it]T Loss=2.30307674407959\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302215814590454\n",
            "g_norm = tensor(0.1357, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303680658340454\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303034543991089\n",
            "g_norm = tensor(0.1367, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304381847381592\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.11367797851562\n",
            "||∇_X meta|| = 0.002833436941727996\n",
            "ΔX norm: 2.833438884408679e-05\n",
            "Stage 2/10:  19%|█████▊                        | 58/300 [01:35<06:54,  1.71s/it]T Loss=2.3047947883605957\n",
            "g_norm = tensor(0.1153, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043227195739746\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056015968322754\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303946018218994\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303316354751587\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8572235107422\n",
            "||∇_X meta|| = 0.0026010959409177303\n",
            "ΔX norm: 2.60109081864357e-05\n",
            "Stage 2/10:  20%|█████▉                        | 59/300 [01:36<06:52,  1.71s/it]T Loss=2.3036303520202637\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304111957550049\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043909072875977\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045036792755127\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043277263641357\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.09791564941406\n",
            "||∇_X meta|| = 0.0028937342576682568\n",
            "ΔX norm: 2.89373638224788e-05\n",
            "Stage 2/10:  20%|██████                        | 60/300 [01:38<06:43,  1.68s/it]T Loss=2.3038761615753174\n",
            "g_norm = tensor(0.0960, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304914951324463\n",
            "g_norm = tensor(0.0878, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036997318267822\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040719032287598\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304708957672119\n",
            "g_norm = tensor(0.0808, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.00570678710938\n",
            "||∇_X meta|| = 0.0022272442001849413\n",
            "ΔX norm: 2.2272455680649728e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 2/10:  20%|██████                        | 61/300 [01:40<07:02,  1.77s/it]T Loss=2.3035056591033936\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043012619018555\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305353879928589\n",
            "g_norm = tensor(0.1103, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035125732421875\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043086528778076\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.13877868652344\n",
            "||∇_X meta|| = 0.0021536352578550577\n",
            "ΔX norm: 2.1536352505791e-05\n",
            "Stage 2/10:  21%|██████▏                       | 62/300 [01:42<07:33,  1.90s/it]T Loss=2.3048582077026367\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044180870056152\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304185628890991\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040592670440674\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043053150177\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.89816284179688\n",
            "||∇_X meta|| = 0.0024726754054427147\n",
            "ΔX norm: 2.472674532327801e-05\n",
            "Stage 2/10:  21%|██████▎                       | 63/300 [01:44<07:19,  1.85s/it]T Loss=2.303159236907959\n",
            "g_norm = tensor(0.0821, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035244941711426\n",
            "g_norm = tensor(0.0853, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028693199157715\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038740158081055\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032784461975098\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.42315673828125\n",
            "||∇_X meta|| = 0.0026257080025970936\n",
            "ΔX norm: 2.62570410995977e-05\n",
            "Stage 2/10:  21%|██████▍                       | 64/300 [01:45<06:51,  1.74s/it]T Loss=2.3060600757598877\n",
            "g_norm = tensor(0.1717, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033907413482666\n",
            "g_norm = tensor(0.1348, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039402961730957\n",
            "g_norm = tensor(0.1325, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038647174835205\n",
            "g_norm = tensor(0.1431, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048593997955322\n",
            "g_norm = tensor(0.1845, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.59718322753906\n",
            "||∇_X meta|| = 0.0023424122482538223\n",
            "ΔX norm: 2.3424141545547172e-05\n",
            "Stage 2/10:  22%|██████▌                       | 65/300 [01:47<07:09,  1.83s/it]T Loss=2.302384853363037\n",
            "g_norm = tensor(0.1392, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303494453430176\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030240535736084\n",
            "g_norm = tensor(0.1187, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032612800598145\n",
            "g_norm = tensor(0.1317, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026599884033203\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.25840759277344\n",
            "||∇_X meta|| = 0.002398270647972822\n",
            "ΔX norm: 2.3982707716641016e-05\n",
            "Stage 2/10:  22%|██████▌                       | 66/300 [01:49<07:14,  1.86s/it]T Loss=2.3034892082214355\n",
            "g_norm = tensor(0.0861, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055615425109863\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042378425598145\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037235736846924\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304048776626587\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.25775146484375\n",
            "||∇_X meta|| = 0.0024064339231699705\n",
            "ΔX norm: 2.4064345780061558e-05\n",
            "Stage 2/10:  22%|██████▋                       | 67/300 [01:51<07:24,  1.91s/it]T Loss=2.3035120964050293\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302347183227539\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026325702667236\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30353045463562\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304285764694214\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.64767456054688\n",
            "||∇_X meta|| = 0.002331802388653159\n",
            "ΔX norm: 2.331803261768073e-05\n",
            "Stage 2/10:  23%|██████▊                       | 68/300 [01:53<07:03,  1.83s/it]T Loss=2.3035035133361816\n",
            "g_norm = tensor(0.0843, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302069902420044\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035635948181152\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030052185058594\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303417682647705\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4291534423828\n",
            "||∇_X meta|| = 0.002154969610273838\n",
            "ΔX norm: 2.1549765733652748e-05\n",
            "Stage 2/10:  23%|██████▉                       | 69/300 [01:55<07:01,  1.82s/it]T Loss=2.301849365234375\n",
            "g_norm = tensor(0.1459, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305924654006958\n",
            "g_norm = tensor(0.1709, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304609775543213\n",
            "g_norm = tensor(0.1549, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3067290782928467\n",
            "g_norm = tensor(0.1804, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305309534072876\n",
            "g_norm = tensor(0.1658, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2755889892578\n",
            "||∇_X meta|| = 0.0023137936368584633\n",
            "ΔX norm: 2.3137967218644917e-05\n",
            "Stage 2/10:  23%|███████                       | 70/300 [01:56<06:44,  1.76s/it]T Loss=2.303837776184082\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302978038787842\n",
            "g_norm = tensor(0.1652, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304042339324951\n",
            "g_norm = tensor(0.0956, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035192489624023\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046212196350098\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.6650390625\n",
            "||∇_X meta|| = 0.0024773285258561373\n",
            "ΔX norm: 2.4773271434241906e-05\n",
            "Stage 2/10:  24%|███████                       | 71/300 [01:58<06:25,  1.69s/it]T Loss=2.304481029510498\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305250883102417\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045167922973633\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.307143211364746\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052165508270264\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.21896362304688\n",
            "||∇_X meta|| = 0.0018925843760371208\n",
            "ΔX norm: 1.8925864424090832e-05\n",
            "Stage 2/10:  24%|███████▏                      | 72/300 [01:59<06:17,  1.65s/it]T Loss=2.304215908050537\n",
            "g_norm = tensor(0.1522, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045287132263184\n",
            "g_norm = tensor(0.1269, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037948608398438\n",
            "g_norm = tensor(0.1542, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305586576461792\n",
            "g_norm = tensor(0.1299, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303682327270508\n",
            "g_norm = tensor(0.1392, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.44544982910156\n",
            "||∇_X meta|| = 0.002061983337625861\n",
            "ΔX norm: 2.0619852875825018e-05\n",
            "Stage 2/10:  24%|███████▎                      | 73/300 [02:01<06:08,  1.62s/it]T Loss=2.301860809326172\n",
            "g_norm = tensor(0.1583, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30306339263916\n",
            "g_norm = tensor(0.1326, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046088218688965\n",
            "g_norm = tensor(0.1685, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304953098297119\n",
            "g_norm = tensor(0.1377, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038673400878906\n",
            "g_norm = tensor(0.1358, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3523712158203\n",
            "||∇_X meta|| = 0.0021838739048689604\n",
            "ΔX norm: 2.1838774046045728e-05\n",
            "Stage 2/10:  25%|███████▍                      | 74/300 [02:03<06:00,  1.59s/it]T Loss=2.305262804031372\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048670291900635\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304811477661133\n",
            "g_norm = tensor(0.0744, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049001693725586\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304208993911743\n",
            "g_norm = tensor(0.0850, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6028289794922\n",
            "||∇_X meta|| = 0.0021223649382591248\n",
            "ΔX norm: 2.1223620933596976e-05\n",
            "Stage 2/10:  25%|███████▌                      | 75/300 [02:04<05:52,  1.57s/it]T Loss=2.3034496307373047\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302839517593384\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30401349067688\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30374813079834\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304185152053833\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9248504638672\n",
            "||∇_X meta|| = 0.0020219741854816675\n",
            "ΔX norm: 2.0219724319758825e-05\n",
            "Stage 2/10:  25%|███████▌                      | 76/300 [02:06<05:50,  1.56s/it]T Loss=2.3022396564483643\n",
            "g_norm = tensor(0.0931, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303645610809326\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303077220916748\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022260665893555\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037168979644775\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.50564575195312\n",
            "||∇_X meta|| = 0.0021876883693039417\n",
            "ΔX norm: 2.1876889150007628e-05\n",
            "Stage 2/10:  26%|███████▋                      | 77/300 [02:07<05:45,  1.55s/it]T Loss=2.3040060997009277\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303696393966675\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025333881378174\n",
            "g_norm = tensor(0.1187, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3060312271118164\n",
            "g_norm = tensor(0.1230, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025670051574707\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.95654296875\n",
            "||∇_X meta|| = 0.001993869198486209\n",
            "ΔX norm: 1.9938668629038148e-05\n",
            "Stage 2/10:  26%|███████▊                      | 78/300 [02:09<05:43,  1.55s/it]T Loss=2.303558111190796\n",
            "g_norm = tensor(0.0956, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026206493377686\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022472858428955\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303746461868286\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026719093322754\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.39068603515625\n",
            "||∇_X meta|| = 0.002170395338907838\n",
            "ΔX norm: 2.1703988750232384e-05\n",
            "Stage 2/10:  26%|███████▉                      | 79/300 [02:10<05:39,  1.54s/it]T Loss=2.303370952606201\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303415060043335\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303061008453369\n",
            "g_norm = tensor(0.0847, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035686016082764\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033783435821533\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2404327392578\n",
            "||∇_X meta|| = 0.0024126768112182617\n",
            "ΔX norm: 2.412679350527469e-05\n",
            "Stage 2/10:  27%|████████                      | 80/300 [02:12<05:59,  1.64s/it]T Loss=2.304816246032715\n",
            "g_norm = tensor(0.1157, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305509090423584\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304328441619873\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028461933135986\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030123710632324\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1246795654297\n",
            "||∇_X meta|| = 0.002370300702750683\n",
            "ΔX norm: 2.370299080212135e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 2/10:  27%|████████                      | 81/300 [02:14<06:51,  1.88s/it]T Loss=2.304145336151123\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036208152770996\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302626132965088\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033859729766846\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303805112838745\n",
            "g_norm = tensor(0.0917, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.33151245117188\n",
            "||∇_X meta|| = 0.0021266601979732513\n",
            "ΔX norm: 2.1266589101287536e-05\n",
            "Stage 2/10:  27%|████████▏                     | 82/300 [02:17<07:58,  2.19s/it]T Loss=2.303011894226074\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301942825317383\n",
            "g_norm = tensor(0.1398, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021137714385986\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046250343322754\n",
            "g_norm = tensor(0.1347, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303062915802002\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.06495666503906\n",
            "||∇_X meta|| = 0.001995752565562725\n",
            "ΔX norm: 1.9957535187131725e-05\n",
            "Stage 2/10:  28%|████████▎                     | 83/300 [02:20<08:10,  2.26s/it]T Loss=2.3027005195617676\n",
            "g_norm = tensor(0.1323, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304499864578247\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036015033721924\n",
            "g_norm = tensor(0.1270, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048386573791504\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036575317382812\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7775115966797\n",
            "||∇_X meta|| = 0.0019144348334521055\n",
            "ΔX norm: 1.9144334146403708e-05\n",
            "Stage 2/10:  28%|████████▍                     | 84/300 [02:22<07:53,  2.19s/it]T Loss=2.30483341217041\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033854961395264\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033759593963623\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303842067718506\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033671379089355\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.86227416992188\n",
            "||∇_X meta|| = 0.002207034733146429\n",
            "ΔX norm: 2.2070325940148905e-05\n",
            "Stage 2/10:  28%|████████▌                     | 85/300 [02:24<07:38,  2.13s/it]T Loss=2.3005566596984863\n",
            "g_norm = tensor(0.1440, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018012046813965\n",
            "g_norm = tensor(0.1450, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028225898742676\n",
            "g_norm = tensor(0.1268, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302800178527832\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303319215774536\n",
            "g_norm = tensor(0.1309, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6412353515625\n",
            "||∇_X meta|| = 0.0022204441484063864\n",
            "ΔX norm: 2.2204405468073674e-05\n",
            "Stage 2/10:  29%|████████▌                     | 86/300 [02:26<07:32,  2.11s/it]T Loss=2.3046231269836426\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304382801055908\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049747943878174\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303945302963257\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034067153930664\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.31423950195312\n",
            "||∇_X meta|| = 0.0021297805942595005\n",
            "ΔX norm: 2.1297810235409997e-05\n",
            "Stage 2/10:  29%|████████▋                     | 87/300 [02:28<07:15,  2.04s/it]T Loss=2.3035693168640137\n",
            "g_norm = tensor(0.1360, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042290210723877\n",
            "g_norm = tensor(0.1337, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305018663406372\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053295612335205\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038251399993896\n",
            "g_norm = tensor(0.1341, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.90359497070312\n",
            "||∇_X meta|| = 0.00204847427085042\n",
            "ΔX norm: 2.0484709239099175e-05\n",
            "Stage 2/10:  29%|████████▊                     | 88/300 [02:30<07:00,  1.98s/it]T Loss=2.304342269897461\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302704334259033\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303831100463867\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302734613418579\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304563045501709\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.71234130859375\n",
            "||∇_X meta|| = 0.002047278918325901\n",
            "ΔX norm: 2.0472767573664896e-05\n",
            "Stage 2/10:  30%|████████▉                     | 89/300 [02:31<06:48,  1.93s/it]T Loss=2.3031609058380127\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302746057510376\n",
            "g_norm = tensor(0.1251, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043806552886963\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035359382629395\n",
            "g_norm = tensor(0.0810, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024609088897705\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1956329345703\n",
            "||∇_X meta|| = 0.001881201402284205\n",
            "ΔX norm: 1.881199932540767e-05\n",
            "Stage 2/10:  30%|█████████                     | 90/300 [02:33<06:38,  1.90s/it]T Loss=2.303325653076172\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037145137786865\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304696559906006\n",
            "g_norm = tensor(0.1187, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304563045501709\n",
            "g_norm = tensor(0.1011, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026211261749268\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5054473876953\n",
            "||∇_X meta|| = 0.0021330288145691156\n",
            "ΔX norm: 2.133028829121031e-05\n",
            "Stage 2/10:  30%|█████████                     | 91/300 [02:35<06:31,  1.87s/it]T Loss=2.304844379425049\n",
            "g_norm = tensor(0.1454, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303633451461792\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303471088409424\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036653995513916\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053624629974365\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.06265258789062\n",
            "||∇_X meta|| = 0.0022226544097065926\n",
            "ΔX norm: 2.2226557121030055e-05\n",
            "Stage 2/10:  31%|█████████▏                    | 92/300 [02:37<06:21,  1.83s/it]T Loss=2.303889036178589\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303313732147217\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304555892944336\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304717540740967\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045103549957275\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.30812072753906\n",
            "||∇_X meta|| = 0.001858385861851275\n",
            "ΔX norm: 1.8583865312393755e-05\n",
            "Stage 2/10:  31%|█████████▎                    | 93/300 [02:39<06:14,  1.81s/it]T Loss=2.302745819091797\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305070400238037\n",
            "g_norm = tensor(0.1450, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304067611694336\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018507957458496\n",
            "g_norm = tensor(0.1299, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303986072540283\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8843231201172\n",
            "||∇_X meta|| = 0.001969031523913145\n",
            "ΔX norm: 1.9690307453856803e-05\n",
            "Stage 2/10:  31%|█████████▍                    | 94/300 [02:40<06:04,  1.77s/it]T Loss=2.3026554584503174\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028228282928467\n",
            "g_norm = tensor(0.0890, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302879571914673\n",
            "g_norm = tensor(0.0744, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304539203643799\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028125762939453\n",
            "g_norm = tensor(0.0817, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.7747039794922\n",
            "||∇_X meta|| = 0.0020151648204773664\n",
            "ΔX norm: 2.0151697754045017e-05\n",
            "Stage 2/10:  32%|█████████▌                    | 95/300 [02:42<06:01,  1.76s/it]T Loss=2.303447723388672\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303262233734131\n",
            "g_norm = tensor(0.0835, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037562370300293\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037571907043457\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037028312683105\n",
            "g_norm = tensor(0.0709, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.40469360351562\n",
            "||∇_X meta|| = 0.0018907898338511586\n",
            "ΔX norm: 1.8907905541709624e-05\n",
            "Stage 2/10:  32%|█████████▌                    | 96/300 [02:44<06:04,  1.79s/it]T Loss=2.303187131881714\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303708791732788\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3015685081481934\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30319881439209\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302548885345459\n",
            "g_norm = tensor(0.1218, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.48355102539062\n",
            "||∇_X meta|| = 0.002168224658817053\n",
            "ΔX norm: 2.168228274967987e-05\n",
            "Stage 2/10:  32%|█████████▋                    | 97/300 [02:46<05:55,  1.75s/it]T Loss=2.303825855255127\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304457187652588\n",
            "g_norm = tensor(0.1358, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030903339385986\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031442165374756\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303508996963501\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.04725646972656\n",
            "||∇_X meta|| = 0.0016492665745317936\n",
            "ΔX norm: 1.64926332217874e-05\n",
            "Stage 2/10:  33%|█████████▊                    | 98/300 [02:47<05:49,  1.73s/it]T Loss=2.303203821182251\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302133560180664\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303633213043213\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301619529724121\n",
            "g_norm = tensor(0.1378, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302794933319092\n",
            "g_norm = tensor(0.1107, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.50161743164062\n",
            "||∇_X meta|| = 0.0019506544340401888\n",
            "ΔX norm: 1.950654768734239e-05\n",
            "Stage 2/10:  33%|█████████▉                    | 99/300 [02:49<05:45,  1.72s/it]T Loss=2.3041954040527344\n",
            "g_norm = tensor(0.1527, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039841651916504\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302870750427246\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30332612991333\n",
            "g_norm = tensor(0.1352, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037173748016357\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.16732788085938\n",
            "||∇_X meta|| = 0.0019152575405314565\n",
            "ΔX norm: 1.915259417728521e-05\n",
            "Stage 2/10:  33%|█████████▋                   | 100/300 [02:51<05:50,  1.75s/it]T Loss=2.3049700260162354\n",
            "g_norm = tensor(0.0771, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304238796234131\n",
            "g_norm = tensor(0.0706, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051552772521973\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053841590881348\n",
            "g_norm = tensor(0.0897, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304579973220825\n",
            "g_norm = tensor(0.0667, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.40274047851562\n",
            "||∇_X meta|| = 0.0021320225205272436\n",
            "ΔX norm: 2.1320245650713332e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 2/10:  34%|█████████▊                   | 101/300 [02:52<05:44,  1.73s/it]T Loss=2.3027355670928955\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046207427978516\n",
            "g_norm = tensor(0.0802, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034894466400146\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304426431655884\n",
            "g_norm = tensor(0.0767, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034965991973877\n",
            "g_norm = tensor(0.0821, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0236053466797\n",
            "||∇_X meta|| = 0.0018886433681473136\n",
            "ΔX norm: 1.8886417819885537e-05\n",
            "Stage 2/10:  34%|█████████▊                   | 102/300 [02:55<06:13,  1.89s/it]T Loss=2.3037009239196777\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30423641204834\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305079221725464\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303028106689453\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303394317626953\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.45977783203125\n",
            "||∇_X meta|| = 0.0021591545082628727\n",
            "ΔX norm: 2.1591567929135635e-05\n",
            "Stage 2/10:  34%|█████████▉                   | 103/300 [02:57<06:23,  1.95s/it]T Loss=2.305096387863159\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038675785064697\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305135488510132\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038687705993652\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037960529327393\n",
            "g_norm = tensor(0.1358, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.69235229492188\n",
            "||∇_X meta|| = 0.0018565048230811954\n",
            "ΔX norm: 1.85650096682366e-05\n",
            "Stage 2/10:  35%|██████████                   | 104/300 [02:59<06:31,  2.00s/it]T Loss=2.303333044052124\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040382862091064\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047566413879395\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031318187713623\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036484718322754\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5474853515625\n",
            "||∇_X meta|| = 0.0016224469291046262\n",
            "ΔX norm: 1.6224437786149792e-05\n",
            "Stage 2/10:  35%|██████████▏                  | 105/300 [03:01<06:40,  2.05s/it]T Loss=2.3033506870269775\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021817207336426\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301687002182007\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038740158081055\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034470081329346\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.89376831054688\n",
            "||∇_X meta|| = 0.002233547857031226\n",
            "ΔX norm: 2.2335469111567363e-05\n",
            "Stage 2/10:  35%|██████████▏                  | 106/300 [03:03<06:28,  2.00s/it]T Loss=2.3044793605804443\n",
            "g_norm = tensor(0.1234, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027305603027344\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023629188537598\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025569915771484\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023784160614014\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.93894958496094\n",
            "||∇_X meta|| = 0.00198897416703403\n",
            "ΔX norm: 1.9889746909029782e-05\n",
            "Stage 2/10:  36%|██████████▎                  | 107/300 [03:05<06:09,  1.91s/it]T Loss=2.303814649581909\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304866313934326\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045456409454346\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30448842048645\n",
            "g_norm = tensor(0.1375, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052501678466797\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.94464111328125\n",
            "||∇_X meta|| = 0.0018383546266704798\n",
            "ΔX norm: 1.8383536371402442e-05\n",
            "Stage 2/10:  36%|██████████▍                  | 108/300 [03:06<06:00,  1.88s/it]T Loss=2.304032802581787\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041863441467285\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026175498962402\n",
            "g_norm = tensor(0.1351, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054873943328857\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3016343116760254\n",
            "g_norm = tensor(0.1053, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.82064819335938\n",
            "||∇_X meta|| = 0.0019171742023900151\n",
            "ΔX norm: 1.9171720850863494e-05\n",
            "Stage 2/10:  36%|██████████▌                  | 109/300 [03:08<05:50,  1.84s/it]T Loss=2.3040566444396973\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303866147994995\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038439750671387\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035151958465576\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036491870880127\n",
            "g_norm = tensor(0.1258, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4730987548828\n",
            "||∇_X meta|| = 0.0017779908375814557\n",
            "ΔX norm: 1.7779851987143047e-05\n",
            "Stage 2/10:  37%|██████████▋                  | 110/300 [03:10<05:41,  1.80s/it]T Loss=2.30344820022583\n",
            "g_norm = tensor(0.0752, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035266399383545\n",
            "g_norm = tensor(0.0669, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303971767425537\n",
            "g_norm = tensor(0.0702, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042657375335693\n",
            "g_norm = tensor(0.0792, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029091358184814\n",
            "g_norm = tensor(0.0804, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.6659698486328\n",
            "||∇_X meta|| = 0.0018169903196394444\n",
            "ΔX norm: 1.816991607483942e-05\n",
            "Stage 2/10:  37%|██████████▋                  | 111/300 [03:12<05:55,  1.88s/it]T Loss=2.304413318634033\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052077293395996\n",
            "g_norm = tensor(0.1308, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038406372070312\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30391001701355\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30218768119812\n",
            "g_norm = tensor(0.1157, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.00045776367188\n",
            "||∇_X meta|| = 0.001652657170780003\n",
            "ΔX norm: 1.6526537365280092e-05\n",
            "Stage 2/10:  37%|██████████▊                  | 112/300 [03:14<06:01,  1.92s/it]T Loss=2.3043081760406494\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037238121032715\n",
            "g_norm = tensor(0.1549, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035221099853516\n",
            "g_norm = tensor(0.1323, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040802478790283\n",
            "g_norm = tensor(0.1374, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038439750671387\n",
            "g_norm = tensor(0.1349, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.830810546875\n",
            "||∇_X meta|| = 0.0018361372640356421\n",
            "ΔX norm: 1.8361361071583815e-05\n",
            "Stage 2/10:  38%|██████████▉                  | 113/300 [03:16<05:51,  1.88s/it]T Loss=2.302933931350708\n",
            "g_norm = tensor(0.0733, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302271604537964\n",
            "g_norm = tensor(0.0852, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033018112182617\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303091049194336\n",
            "g_norm = tensor(0.0838, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303438186645508\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.32473754882812\n",
            "||∇_X meta|| = 0.0017880636733025312\n",
            "ΔX norm: 1.788065674190875e-05\n",
            "Stage 2/10:  38%|███████████                  | 114/300 [03:18<05:52,  1.89s/it]T Loss=2.303734302520752\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046910762786865\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044214248657227\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048183917999268\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305081844329834\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.38343811035156\n",
            "||∇_X meta|| = 0.0016095901373773813\n",
            "ΔX norm: 1.6095909813884646e-05\n",
            "Stage 2/10:  38%|███████████                  | 115/300 [03:19<05:44,  1.86s/it]T Loss=2.3038957118988037\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302745819091797\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028829097747803\n",
            "g_norm = tensor(0.0945, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021888732910156\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302659273147583\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.76976013183594\n",
            "||∇_X meta|| = 0.0018676635809242725\n",
            "ΔX norm: 1.8676610125112347e-05\n",
            "Stage 2/10:  39%|███████████▏                 | 116/300 [03:21<05:50,  1.91s/it]T Loss=2.3032307624816895\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040072917938232\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303049325942993\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303516387939453\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036649227142334\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.32115173339844\n",
            "||∇_X meta|| = 0.0017994932131841779\n",
            "ΔX norm: 1.799491474230308e-05\n",
            "Stage 2/10:  39%|███████████▎                 | 117/300 [03:24<05:57,  1.95s/it]T Loss=2.3021788597106934\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302260398864746\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303082227706909\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303283929824829\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302826404571533\n",
            "g_norm = tensor(0.0790, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.29360961914062\n",
            "||∇_X meta|| = 0.0019618836231529713\n",
            "ΔX norm: 1.9618808437371626e-05\n",
            "Stage 2/10:  39%|███████████▍                 | 118/300 [03:25<05:45,  1.90s/it]T Loss=2.305065155029297\n",
            "g_norm = tensor(0.1566, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302633285522461\n",
            "g_norm = tensor(0.1656, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024420738220215\n",
            "g_norm = tensor(0.1434, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041932582855225\n",
            "g_norm = tensor(0.1338, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022167682647705\n",
            "g_norm = tensor(0.1545, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.23831176757812\n",
            "||∇_X meta|| = 0.0018849584739655256\n",
            "ΔX norm: 1.8849552361643873e-05\n",
            "Stage 2/10:  40%|███████████▌                 | 119/300 [03:27<05:38,  1.87s/it]T Loss=2.300908327102661\n",
            "g_norm = tensor(0.1269, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303936004638672\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035061359405518\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026230335235596\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301218032836914\n",
            "g_norm = tensor(0.1510, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4466552734375\n",
            "||∇_X meta|| = 0.0018971014069393277\n",
            "ΔX norm: 1.8971009922097437e-05\n",
            "Stage 2/10:  40%|███████████▌                 | 120/300 [03:29<05:28,  1.83s/it]T Loss=2.304879665374756\n",
            "g_norm = tensor(0.1447, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039302825927734\n",
            "g_norm = tensor(0.1263, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054287433624268\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042213916778564\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302839756011963\n",
            "g_norm = tensor(0.1453, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.56671142578125\n",
            "||∇_X meta|| = 0.0017044852720573545\n",
            "ΔX norm: 1.704484566289466e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 2/10:  40%|███████████▋                 | 121/300 [03:31<05:24,  1.81s/it]T Loss=2.3040900230407715\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040976524353027\n",
            "g_norm = tensor(0.0876, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303346633911133\n",
            "g_norm = tensor(0.0850, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303957462310791\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303445339202881\n",
            "g_norm = tensor(0.0836, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.01953125\n",
            "||∇_X meta|| = 0.0017938937526196241\n",
            "ΔX norm: 1.7938944438355975e-05\n",
            "Stage 2/10:  41%|███████████▊                 | 122/300 [03:33<05:36,  1.89s/it]T Loss=2.3031744956970215\n",
            "g_norm = tensor(0.0850, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303493022918701\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033604621887207\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030753135681152\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30389666557312\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.05848693847656\n",
            "||∇_X meta|| = 0.001765553024597466\n",
            "ΔX norm: 1.7655498595559038e-05\n",
            "Stage 2/10:  41%|███████████▉                 | 123/300 [03:35<05:34,  1.89s/it]T Loss=2.302927017211914\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304187297821045\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037283420562744\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304133892059326\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303590774536133\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.17404174804688\n",
            "||∇_X meta|| = 0.0018020181450992823\n",
            "ΔX norm: 1.8020180505118333e-05\n",
            "Stage 2/10:  41%|███████████▉                 | 124/300 [03:36<05:27,  1.86s/it]T Loss=2.3038783073425293\n",
            "g_norm = tensor(0.1075, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037922382354736\n",
            "g_norm = tensor(0.0928, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303821325302124\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040642738342285\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040096759796143\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.67816162109375\n",
            "||∇_X meta|| = 0.001816850039176643\n",
            "ΔX norm: 1.8168493625125848e-05\n",
            "Stage 2/10:  42%|████████████                 | 125/300 [03:38<05:19,  1.83s/it]T Loss=2.3038330078125\n",
            "g_norm = tensor(0.0843, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303602695465088\n",
            "g_norm = tensor(0.0709, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304546356201172\n",
            "g_norm = tensor(0.0767, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035526275634766\n",
            "g_norm = tensor(0.0847, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030295372009277\n",
            "g_norm = tensor(0.0816, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.97726440429688\n",
            "||∇_X meta|| = 0.0017864214023575187\n",
            "ΔX norm: 1.786422035365831e-05\n",
            "Stage 2/10:  42%|████████████▏                | 126/300 [03:40<05:27,  1.88s/it]T Loss=2.3038125038146973\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037736415863037\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305572032928467\n",
            "g_norm = tensor(0.1075, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040900230407715\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304018020629883\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.5894317626953\n",
            "||∇_X meta|| = 0.001664404640905559\n",
            "ΔX norm: 1.664402589085512e-05\n",
            "Stage 2/10:  42%|████████████▎                | 127/300 [03:42<05:26,  1.88s/it]T Loss=2.3033504486083984\n",
            "g_norm = tensor(0.1099, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036391735076904\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040289878845215\n",
            "g_norm = tensor(0.1357, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040242195129395\n",
            "g_norm = tensor(0.1322, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303968906402588\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.62142944335938\n",
            "||∇_X meta|| = 0.0017662246245890856\n",
            "ΔX norm: 1.7662261598161422e-05\n",
            "Stage 2/10:  43%|████████████▎                | 128/300 [03:44<05:25,  1.89s/it]T Loss=2.303635835647583\n",
            "g_norm = tensor(0.0818, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031787872314453\n",
            "g_norm = tensor(0.0878, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053231239318848\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030543327331543\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304143190383911\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.3029327392578\n",
            "||∇_X meta|| = 0.0017260690219700336\n",
            "ΔX norm: 1.726068694551941e-05\n",
            "Stage 2/10:  43%|████████████▍                | 129/300 [03:46<05:15,  1.84s/it]T Loss=2.304410457611084\n",
            "g_norm = tensor(0.1372, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302971601486206\n",
            "g_norm = tensor(0.1285, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303701639175415\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302948236465454\n",
            "g_norm = tensor(0.1235, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033053874969482\n",
            "g_norm = tensor(0.1364, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.15750122070312\n",
            "||∇_X meta|| = 0.0017131827771663666\n",
            "ΔX norm: 1.71318188222358e-05\n",
            "Stage 2/10:  43%|████████████▌                | 130/300 [03:47<05:09,  1.82s/it]T Loss=2.302778482437134\n",
            "g_norm = tensor(0.1472, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042941093444824\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035106658935547\n",
            "g_norm = tensor(0.1266, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303464412689209\n",
            "g_norm = tensor(0.1243, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033156394958496\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0169677734375\n",
            "||∇_X meta|| = 0.001681002089753747\n",
            "ΔX norm: 1.6810054148663767e-05\n",
            "Stage 2/10:  44%|████████████▋                | 131/300 [03:49<05:03,  1.79s/it]T Loss=2.303804874420166\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045284748077393\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043460845947266\n",
            "g_norm = tensor(0.0858, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040683269500732\n",
            "g_norm = tensor(0.0736, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304267406463623\n",
            "g_norm = tensor(0.0815, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.27224731445312\n",
            "||∇_X meta|| = 0.0016535354079678655\n",
            "ΔX norm: 1.6535368558834307e-05\n",
            "Stage 2/10:  44%|████████████▊                | 132/300 [03:51<05:04,  1.81s/it]T Loss=2.3034985065460205\n",
            "g_norm = tensor(0.0808, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304035186767578\n",
            "g_norm = tensor(0.0795, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036513328552246\n",
            "g_norm = tensor(0.0851, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036580085754395\n",
            "g_norm = tensor(0.0756, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30414080619812\n",
            "g_norm = tensor(0.0798, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3550567626953\n",
            "||∇_X meta|| = 0.001752888667397201\n",
            "ΔX norm: 1.7528900571051054e-05\n",
            "Stage 2/10:  44%|████████████▊                | 133/300 [03:53<05:03,  1.82s/it]T Loss=2.3032774925231934\n",
            "g_norm = tensor(0.0922, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304201126098633\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30413818359375\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303870677947998\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039116859436035\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2933349609375\n",
            "||∇_X meta|| = 0.0018540803575888276\n",
            "ΔX norm: 1.8540804376243614e-05\n",
            "Stage 2/10:  45%|████████████▉                | 134/300 [03:55<05:05,  1.84s/it]T Loss=2.30458402633667\n",
            "g_norm = tensor(0.1443, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033480644226074\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035454750061035\n",
            "g_norm = tensor(0.1618, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046011924743652\n",
            "g_norm = tensor(0.1255, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302356719970703\n",
            "g_norm = tensor(0.1440, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7266845703125\n",
            "||∇_X meta|| = 0.001592810032889247\n",
            "ΔX norm: 1.5928075299598277e-05\n",
            "Stage 2/10:  45%|█████████████                | 135/300 [03:57<05:03,  1.84s/it]T Loss=2.3033101558685303\n",
            "g_norm = tensor(0.1268, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303619384765625\n",
            "g_norm = tensor(0.1243, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038759231567383\n",
            "g_norm = tensor(0.1461, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040385246276855\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305007219314575\n",
            "g_norm = tensor(0.1361, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.839599609375\n",
            "||∇_X meta|| = 0.0018602479249238968\n",
            "ΔX norm: 1.8602451746119186e-05\n",
            "Stage 2/10:  45%|█████████████▏               | 136/300 [03:58<04:59,  1.83s/it]T Loss=2.3039731979370117\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049631118774414\n",
            "g_norm = tensor(0.1210, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046629428863525\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046300411224365\n",
            "g_norm = tensor(0.1392, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044495582580566\n",
            "g_norm = tensor(0.1269, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2178955078125\n",
            "||∇_X meta|| = 0.0015904668252915144\n",
            "ΔX norm: 1.5904686733847484e-05\n",
            "Stage 2/10:  46%|█████████████▏               | 137/300 [04:00<05:03,  1.86s/it]T Loss=2.301236391067505\n",
            "g_norm = tensor(0.1655, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304611921310425\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040385246276855\n",
            "g_norm = tensor(0.1504, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033366203308105\n",
            "g_norm = tensor(0.1371, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303161382675171\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.93482971191406\n",
            "||∇_X meta|| = 0.0017771219136193395\n",
            "ΔX norm: 1.7771222701412626e-05\n",
            "Stage 2/10:  46%|█████████████▎               | 138/300 [04:02<04:57,  1.84s/it]T Loss=2.3034756183624268\n",
            "g_norm = tensor(0.1214, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045406341552734\n",
            "g_norm = tensor(0.0866, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038628101348877\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303086042404175\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304030179977417\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.11289978027344\n",
            "||∇_X meta|| = 0.0015467737102881074\n",
            "ΔX norm: 1.546776002214756e-05\n",
            "Stage 2/10:  46%|█████████████▍               | 139/300 [04:04<04:53,  1.82s/it]T Loss=2.3042826652526855\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302158832550049\n",
            "g_norm = tensor(0.1259, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041324615478516\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035812377929688\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302276134490967\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.73175048828125\n",
            "||∇_X meta|| = 0.0017021747771650553\n",
            "ΔX norm: 1.7021748135448433e-05\n",
            "Stage 2/10:  47%|█████████████▌               | 140/300 [04:06<04:48,  1.80s/it]T Loss=2.3032805919647217\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033223152160645\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3015637397766113\n",
            "g_norm = tensor(0.1222, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302586793899536\n",
            "g_norm = tensor(0.1080, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027865886688232\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.90036010742188\n",
            "||∇_X meta|| = 0.0015014787204563618\n",
            "ΔX norm: 1.5014823475212324e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 2/10:  47%|█████████████▋               | 141/300 [04:07<04:45,  1.80s/it]T Loss=2.3043100833892822\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30356502532959\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30326247215271\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304204225540161\n",
            "g_norm = tensor(0.0942, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032288551330566\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.85740661621094\n",
            "||∇_X meta|| = 0.0016981260851025581\n",
            "ΔX norm: 1.6981299268081784e-05\n",
            "Stage 2/10:  47%|█████████████▋               | 142/300 [04:09<04:47,  1.82s/it]T Loss=2.3025104999542236\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036484718322754\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049864768981934\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302948474884033\n",
            "g_norm = tensor(0.1437, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303375720977783\n",
            "g_norm = tensor(0.1353, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.91160583496094\n",
            "||∇_X meta|| = 0.0016525865066796541\n",
            "ΔX norm: 1.6525847968296148e-05\n",
            "Stage 2/10:  48%|█████████████▊               | 143/300 [04:11<04:57,  1.90s/it]T Loss=2.3051466941833496\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303737163543701\n",
            "g_norm = tensor(0.1371, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026633262634277\n",
            "g_norm = tensor(0.1327, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025143146514893\n",
            "g_norm = tensor(0.1395, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047988414764404\n",
            "g_norm = tensor(0.1319, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.65272521972656\n",
            "||∇_X meta|| = 0.0017545056762173772\n",
            "ΔX norm: 1.7545024093124084e-05\n",
            "Stage 2/10:  48%|█████████████▉               | 144/300 [04:14<05:20,  2.06s/it]T Loss=2.304394245147705\n",
            "g_norm = tensor(0.1347, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303976058959961\n",
            "g_norm = tensor(0.0766, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039820194244385\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305100202560425\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304741144180298\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.583740234375\n",
            "||∇_X meta|| = 0.0016551496228203177\n",
            "ΔX norm: 1.655148298596032e-05\n",
            "Stage 2/10:  48%|██████████████               | 145/300 [04:16<05:10,  2.01s/it]T Loss=2.3027377128601074\n",
            "g_norm = tensor(0.0879, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021843433380127\n",
            "g_norm = tensor(0.0820, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304370403289795\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032422065734863\n",
            "g_norm = tensor(0.0860, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302604913711548\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.53890991210938\n",
            "||∇_X meta|| = 0.0017462882678955793\n",
            "ΔX norm: 1.7462863979744725e-05\n",
            "Stage 2/10:  49%|██████████████               | 146/300 [04:18<05:04,  1.98s/it]T Loss=2.303169012069702\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028457164764404\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304370164871216\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304983615875244\n",
            "g_norm = tensor(0.1381, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028576374053955\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.38577270507812\n",
            "||∇_X meta|| = 0.0017638716381043196\n",
            "ΔX norm: 1.7638651115703396e-05\n",
            "Stage 2/10:  49%|██████████████▏              | 147/300 [04:20<05:02,  1.97s/it]T Loss=2.3033251762390137\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304112672805786\n",
            "g_norm = tensor(0.0862, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035287857055664\n",
            "g_norm = tensor(0.0872, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303711414337158\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304232358932495\n",
            "g_norm = tensor(0.0836, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.27728271484375\n",
            "||∇_X meta|| = 0.0015239081112667918\n",
            "ΔX norm: 1.523906939837616e-05\n",
            "Stage 2/10:  49%|██████████████▎              | 148/300 [04:22<04:59,  1.97s/it]T Loss=2.3043324947357178\n",
            "g_norm = tensor(0.1350, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051211833953857\n",
            "g_norm = tensor(0.1365, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038055896759033\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305068016052246\n",
            "g_norm = tensor(0.1539, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043103218078613\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.40097045898438\n",
            "||∇_X meta|| = 0.0016818001167848706\n",
            "ΔX norm: 1.6817988580442034e-05\n",
            "Stage 2/10:  50%|██████████████▍              | 149/300 [04:23<04:56,  1.97s/it]T Loss=2.3038153648376465\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050642013549805\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031516075134277\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303929567337036\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051884174346924\n",
            "g_norm = tensor(0.1268, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.38645935058594\n",
            "||∇_X meta|| = 0.0015322138788178563\n",
            "ΔX norm: 1.532212809252087e-05\n",
            "Stage 2/10:  50%|██████████████▌              | 150/300 [04:25<04:49,  1.93s/it]T Loss=2.3041672706604004\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303981304168701\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304264545440674\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049044609069824\n",
            "g_norm = tensor(0.1216, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043928146362305\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.2243194580078\n",
            "||∇_X meta|| = 0.0014986442402005196\n",
            "ΔX norm: 1.4986449059506413e-05\n",
            "Stage 2/10:  50%|██████████████▌              | 151/300 [04:27<04:43,  1.90s/it]T Loss=2.3048477172851562\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305471897125244\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051095008850098\n",
            "g_norm = tensor(0.0883, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046443462371826\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304689884185791\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.0552215576172\n",
            "||∇_X meta|| = 0.0016924096271395683\n",
            "ΔX norm: 1.692407386144623e-05\n",
            "Stage 2/10:  51%|██████████████▋              | 152/300 [04:29<04:38,  1.88s/it]T Loss=2.3029115200042725\n",
            "g_norm = tensor(0.1187, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030126094818115\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303133010864258\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302677869796753\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301949977874756\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3797149658203\n",
            "||∇_X meta|| = 0.001494131749495864\n",
            "ΔX norm: 1.4941329027351458e-05\n",
            "Stage 2/10:  51%|██████████████▊              | 153/300 [04:31<04:32,  1.86s/it]T Loss=2.302687406539917\n",
            "g_norm = tensor(0.0848, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302581310272217\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304202079772949\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028953075408936\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302306652069092\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.85743713378906\n",
            "||∇_X meta|| = 0.0017383533995598555\n",
            "ΔX norm: 1.7383521480951458e-05\n",
            "Stage 2/10:  51%|██████████████▉              | 154/300 [04:33<04:36,  1.90s/it]T Loss=2.30460786819458\n",
            "g_norm = tensor(0.0941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306135654449463\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033359050750732\n",
            "g_norm = tensor(0.0937, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304046869277954\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036909103393555\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.12637329101562\n",
            "||∇_X meta|| = 0.0014839343493804336\n",
            "ΔX norm: 1.4839331925031729e-05\n",
            "Stage 2/10:  52%|██████████████▉              | 155/300 [04:35<04:31,  1.87s/it]T Loss=2.302370548248291\n",
            "g_norm = tensor(0.1595, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303358793258667\n",
            "g_norm = tensor(0.1437, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304354190826416\n",
            "g_norm = tensor(0.1646, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042101860046387\n",
            "g_norm = tensor(0.1519, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301877498626709\n",
            "g_norm = tensor(0.1766, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.60105895996094\n",
            "||∇_X meta|| = 0.001820070086978376\n",
            "ΔX norm: 1.8200691556558013e-05\n",
            "Stage 2/10:  52%|███████████████              | 156/300 [04:36<04:27,  1.86s/it]T Loss=2.303513765335083\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304813861846924\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039207458496094\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305418014526367\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040122985839844\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.79237365722656\n",
            "||∇_X meta|| = 0.0016427517402917147\n",
            "ΔX norm: 1.6427495211246423e-05\n",
            "Stage 2/10:  52%|███████████████▏             | 157/300 [04:38<04:20,  1.82s/it]T Loss=2.3020219802856445\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303591251373291\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034744262695312\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029346466064453\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036599159240723\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.68710327148438\n",
            "||∇_X meta|| = 0.0015767253935337067\n",
            "ΔX norm: 1.5767222066642717e-05\n",
            "Stage 2/10:  53%|███████████████▎             | 158/300 [04:40<04:17,  1.81s/it]T Loss=2.3039231300354004\n",
            "g_norm = tensor(0.1570, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032264709472656\n",
            "g_norm = tensor(0.1342, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304443597793579\n",
            "g_norm = tensor(0.1258, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304058790206909\n",
            "g_norm = tensor(0.1537, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305178165435791\n",
            "g_norm = tensor(0.1374, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.41746520996094\n",
            "||∇_X meta|| = 0.0015176450833678246\n",
            "ΔX norm: 1.5176497072388884e-05\n",
            "Stage 2/10:  53%|███████████████▎             | 159/300 [04:42<04:23,  1.87s/it]T Loss=2.30228328704834\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022208213806152\n",
            "g_norm = tensor(0.1235, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031742572784424\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304744005203247\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304952621459961\n",
            "g_norm = tensor(0.1296, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1806640625\n",
            "||∇_X meta|| = 0.0015453501837328076\n",
            "ΔX norm: 1.5453495507244952e-05\n",
            "Stage 2/10:  53%|███████████████▍             | 160/300 [04:44<04:22,  1.87s/it]T Loss=2.3032546043395996\n",
            "g_norm = tensor(0.1576, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30427885055542\n",
            "g_norm = tensor(0.1354, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305198907852173\n",
            "g_norm = tensor(0.1526, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303713083267212\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041610717773438\n",
            "g_norm = tensor(0.1163, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.28079223632812\n",
            "||∇_X meta|| = 0.0017689672531560063\n",
            "ΔX norm: 1.7689673768472858e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 2/10:  54%|███████████████▌             | 161/300 [04:46<04:19,  1.87s/it]T Loss=2.3041369915008545\n",
            "g_norm = tensor(0.0787, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304021120071411\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037734031677246\n",
            "g_norm = tensor(0.0827, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303739070892334\n",
            "g_norm = tensor(0.0683, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039016723632812\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.72955322265625\n",
            "||∇_X meta|| = 0.0015539668966084719\n",
            "ΔX norm: 1.5539695596089587e-05\n",
            "Stage 2/10:  54%|███████████████▋             | 162/300 [04:48<04:22,  1.91s/it]T Loss=2.3032984733581543\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30397367477417\n",
            "g_norm = tensor(0.1258, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302553176879883\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3014976978302\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033406734466553\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0439453125\n",
            "||∇_X meta|| = 0.0015921273734420538\n",
            "ΔX norm: 1.5921266822260804e-05\n",
            "Stage 2/10:  54%|███████████████▊             | 163/300 [04:50<04:19,  1.90s/it]T Loss=2.30403208732605\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031115531921387\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304217576980591\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035311698913574\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304626941680908\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.45089721679688\n",
            "||∇_X meta|| = 0.0017328771064057946\n",
            "ΔX norm: 1.7328764442936517e-05\n",
            "Stage 2/10:  55%|███████████████▊             | 164/300 [04:51<04:14,  1.87s/it]T Loss=2.3021929264068604\n",
            "g_norm = tensor(0.1706, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030338287353516\n",
            "g_norm = tensor(0.1139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030009269714355\n",
            "g_norm = tensor(0.1597, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303936719894409\n",
            "g_norm = tensor(0.1486, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034250736236572\n",
            "g_norm = tensor(0.1545, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.88571166992188\n",
            "||∇_X meta|| = 0.0014604609459638596\n",
            "ΔX norm: 1.4604584976041224e-05\n",
            "Stage 2/10:  55%|███████████████▉             | 165/300 [04:53<04:09,  1.85s/it]T Loss=2.304831027984619\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036491870880127\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037819862365723\n",
            "g_norm = tensor(0.1153, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304431200027466\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038432598114014\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2761688232422\n",
            "||∇_X meta|| = 0.0015678320778533816\n",
            "ΔX norm: 1.567832805449143e-05\n",
            "Stage 2/10:  55%|████████████████             | 166/300 [04:55<04:11,  1.88s/it]T Loss=2.3029699325561523\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033230304718018\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036367893218994\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303776502609253\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30299711227417\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.52667236328125\n",
            "||∇_X meta|| = 0.0015081919264048338\n",
            "ΔX norm: 1.5081923265825026e-05\n",
            "Stage 2/10:  56%|████████████████▏            | 167/300 [04:57<04:06,  1.85s/it]T Loss=2.3058547973632812\n",
            "g_norm = tensor(0.1561, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304413318634033\n",
            "g_norm = tensor(0.1336, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304086208343506\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038718700408936\n",
            "g_norm = tensor(0.1671, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037381172180176\n",
            "g_norm = tensor(0.1422, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.06117248535156\n",
            "||∇_X meta|| = 0.0016498935874551535\n",
            "ΔX norm: 1.649890145927202e-05\n",
            "Stage 2/10:  56%|████████████████▏            | 168/300 [04:59<04:12,  1.92s/it]T Loss=2.3034448623657227\n",
            "g_norm = tensor(0.1387, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035309314727783\n",
            "g_norm = tensor(0.1321, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033838272094727\n",
            "g_norm = tensor(0.1441, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303835391998291\n",
            "g_norm = tensor(0.1370, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035225868225098\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.72579956054688\n",
            "||∇_X meta|| = 0.0016306393081322312\n",
            "ΔX norm: 1.630642327654641e-05\n",
            "Stage 2/10:  56%|████████████████▎            | 169/300 [05:01<04:12,  1.93s/it]T Loss=2.3032097816467285\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303589344024658\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035454750061035\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302855968475342\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303908348083496\n",
            "g_norm = tensor(0.0867, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.66140747070312\n",
            "||∇_X meta|| = 0.0015984271885827184\n",
            "ΔX norm: 1.5984292986104265e-05\n",
            "Stage 2/10:  57%|████████████████▍            | 170/300 [05:03<04:07,  1.90s/it]T Loss=2.3018035888671875\n",
            "g_norm = tensor(0.0856, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034846782684326\n",
            "g_norm = tensor(0.0699, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040480613708496\n",
            "g_norm = tensor(0.0731, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037235736846924\n",
            "g_norm = tensor(0.0732, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304049253463745\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.92718505859375\n",
            "||∇_X meta|| = 0.0016245373990386724\n",
            "ΔX norm: 1.6245379811152816e-05\n",
            "Stage 2/10:  57%|████████████████▌            | 171/300 [05:05<04:00,  1.86s/it]T Loss=2.304370403289795\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304218053817749\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048596382141113\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305415391921997\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30438494682312\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.240478515625\n",
            "||∇_X meta|| = 0.00172877823933959\n",
            "ΔX norm: 1.728773713693954e-05\n",
            "Stage 2/10:  57%|████████████████▋            | 172/300 [05:06<03:57,  1.86s/it]T Loss=2.3040614128112793\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303609609603882\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021156787872314\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026270866394043\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302065372467041\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.6114959716797\n",
            "||∇_X meta|| = 0.0015742034884169698\n",
            "ΔX norm: 1.5741992683615535e-05\n",
            "Stage 2/10:  58%|████████████████▋            | 173/300 [05:08<03:56,  1.86s/it]T Loss=2.3014743328094482\n",
            "g_norm = tensor(0.1510, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049209117889404\n",
            "g_norm = tensor(0.1472, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042235374450684\n",
            "g_norm = tensor(0.1463, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036460876464844\n",
            "g_norm = tensor(0.1400, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046841621398926\n",
            "g_norm = tensor(0.1425, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.33238220214844\n",
            "||∇_X meta|| = 0.0014732489362359047\n",
            "ΔX norm: 1.4732546333107166e-05\n",
            "Stage 2/10:  58%|████████████████▊            | 174/300 [05:10<03:53,  1.85s/it]T Loss=2.304353713989258\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023228645324707\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030591011047363\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301427125930786\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037171363830566\n",
            "g_norm = tensor(0.0931, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =227.70184326171875\n",
            "||∇_X meta|| = 0.0014286842197179794\n",
            "ΔX norm: 1.4286833902588114e-05\n",
            "Stage 2/10:  58%|████████████████▉            | 175/300 [05:12<04:06,  1.98s/it]T Loss=2.3036744594573975\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042664527893066\n",
            "g_norm = tensor(0.1350, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044161796569824\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304220676422119\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043999671936035\n",
            "g_norm = tensor(0.1305, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.9095001220703\n",
            "||∇_X meta|| = 0.0014547336613759398\n",
            "ΔX norm: 1.4547337741532829e-05\n",
            "Stage 2/10:  59%|█████████████████            | 176/300 [05:14<04:04,  1.97s/it]T Loss=2.303056478500366\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302955150604248\n",
            "g_norm = tensor(0.1255, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041276931762695\n",
            "g_norm = tensor(0.1353, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302802562713623\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302075147628784\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3833770751953\n",
            "||∇_X meta|| = 0.0014985824236646295\n",
            "ΔX norm: 1.4985803318268154e-05\n",
            "Stage 2/10:  59%|█████████████████            | 177/300 [05:16<03:59,  1.95s/it]T Loss=2.3035600185394287\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302521228790283\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304349899291992\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036715984344482\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044285774230957\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.93765258789062\n",
            "||∇_X meta|| = 0.0016067461110651493\n",
            "ΔX norm: 1.6067480828496628e-05\n",
            "Stage 2/10:  59%|█████████████████▏           | 178/300 [05:18<03:53,  1.91s/it]T Loss=2.3036916255950928\n",
            "g_norm = tensor(0.1469, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057777881622314\n",
            "g_norm = tensor(0.1453, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304304599761963\n",
            "g_norm = tensor(0.1720, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054213523864746\n",
            "g_norm = tensor(0.1602, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040902614593506\n",
            "g_norm = tensor(0.1776, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2256622314453\n",
            "||∇_X meta|| = 0.0015377937816083431\n",
            "ΔX norm: 1.537792013550643e-05\n",
            "Stage 2/10:  60%|█████████████████▎           | 179/300 [05:20<03:50,  1.90s/it]T Loss=2.303942918777466\n",
            "g_norm = tensor(0.1381, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303539752960205\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304589033126831\n",
            "g_norm = tensor(0.1326, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043429851531982\n",
            "g_norm = tensor(0.1302, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304436445236206\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.36538696289062\n",
            "||∇_X meta|| = 0.001717221806757152\n",
            "ΔX norm: 1.71721912920475e-05\n",
            "Stage 2/10:  60%|█████████████████▍           | 180/300 [05:22<03:50,  1.92s/it]T Loss=2.304457187652588\n",
            "g_norm = tensor(0.0811, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047070503234863\n",
            "g_norm = tensor(0.0854, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30397891998291\n",
            "g_norm = tensor(0.0763, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304708957672119\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044681549072266\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.61685180664062\n",
            "||∇_X meta|| = 0.0014936680672690272\n",
            "ΔX norm: 1.4936693332856521e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 2/10:  60%|█████████████████▍           | 181/300 [05:24<03:51,  1.94s/it]T Loss=2.305133104324341\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303187131881714\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040688037872314\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033323287963867\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303675413131714\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.57891845703125\n",
            "||∇_X meta|| = 0.0015859404811635613\n",
            "ΔX norm: 1.585938298376277e-05\n",
            "Stage 2/10:  61%|█████████████████▌           | 182/300 [05:26<03:57,  2.01s/it]T Loss=2.303208112716675\n",
            "g_norm = tensor(0.1021, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044867515563965\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303485631942749\n",
            "g_norm = tensor(0.0798, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303875684738159\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044543266296387\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1490478515625\n",
            "||∇_X meta|| = 0.0014730809489265084\n",
            "ΔX norm: 1.473079919378506e-05\n",
            "Stage 2/10:  61%|█████████████████▋           | 183/300 [05:28<03:50,  1.97s/it]T Loss=2.3034229278564453\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302938461303711\n",
            "g_norm = tensor(0.0928, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029420375823975\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030717372894287\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303802251815796\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.64239501953125\n",
            "||∇_X meta|| = 0.001706899725832045\n",
            "ΔX norm: 1.7068970919353887e-05\n",
            "Stage 2/10:  61%|█████████████████▊           | 184/300 [05:30<03:42,  1.92s/it]T Loss=2.3045573234558105\n",
            "g_norm = tensor(0.1484, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303387403488159\n",
            "g_norm = tensor(0.1379, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302826404571533\n",
            "g_norm = tensor(0.1397, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038296699523926\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024814128875732\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.15126037597656\n",
            "||∇_X meta|| = 0.0016636501532047987\n",
            "ΔX norm: 1.6636493455735035e-05\n",
            "Stage 2/10:  62%|█████████████████▉           | 185/300 [05:32<03:38,  1.90s/it]T Loss=2.304457664489746\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036270141601562\n",
            "g_norm = tensor(0.1178, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048198223114014\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041305541992188\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038694858551025\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.26943969726562\n",
            "||∇_X meta|| = 0.0014030627207830548\n",
            "ΔX norm: 1.403067562932847e-05\n",
            "Stage 2/10:  62%|█████████████████▉           | 186/300 [05:34<03:45,  1.97s/it]T Loss=2.305553913116455\n",
            "g_norm = tensor(0.1324, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30253267288208\n",
            "g_norm = tensor(0.1323, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305050849914551\n",
            "g_norm = tensor(0.1509, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034300804138184\n",
            "g_norm = tensor(0.1385, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304034471511841\n",
            "g_norm = tensor(0.1514, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5813751220703\n",
            "||∇_X meta|| = 0.001600626390427351\n",
            "ΔX norm: 1.6006259102141485e-05\n",
            "Stage 2/10:  62%|██████████████████           | 187/300 [05:36<03:43,  1.98s/it]T Loss=2.3033509254455566\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303571939468384\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036601543426514\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304823160171509\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304727554321289\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0872344970703\n",
            "||∇_X meta|| = 0.0015105981146916747\n",
            "ΔX norm: 1.510597485321341e-05\n",
            "Stage 2/10:  63%|██████████████████▏          | 188/300 [05:37<03:35,  1.93s/it]T Loss=2.3050317764282227\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058385848999023\n",
            "g_norm = tensor(0.1346, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057072162628174\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304713726043701\n",
            "g_norm = tensor(0.1304, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046722412109375\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.64952087402344\n",
            "||∇_X meta|| = 0.0018388198222965002\n",
            "ΔX norm: 1.838817843236029e-05\n",
            "Stage 2/10:  63%|██████████████████▎          | 189/300 [05:39<03:33,  1.93s/it]T Loss=2.304288387298584\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303745746612549\n",
            "g_norm = tensor(0.1283, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041698932647705\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304727077484131\n",
            "g_norm = tensor(0.1483, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303617238998413\n",
            "g_norm = tensor(0.1366, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.51885986328125\n",
            "||∇_X meta|| = 0.0014761058846488595\n",
            "ΔX norm: 1.4761062629986554e-05\n",
            "Stage 2/10:  63%|██████████████████▎          | 190/300 [05:41<03:26,  1.88s/it]T Loss=2.3037447929382324\n",
            "g_norm = tensor(0.0802, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303117036819458\n",
            "g_norm = tensor(0.0791, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034677505493164\n",
            "g_norm = tensor(0.0747, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037984371185303\n",
            "g_norm = tensor(0.0706, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038337230682373\n",
            "g_norm = tensor(0.0804, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.71859741210938\n",
            "||∇_X meta|| = 0.0016437459271401167\n",
            "ΔX norm: 1.6437452359241433e-05\n",
            "Stage 2/10:  64%|██████████████████▍          | 191/300 [05:43<03:25,  1.89s/it]T Loss=2.3029768466949463\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042850494384766\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303006887435913\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038594722747803\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033556938171387\n",
            "g_norm = tensor(0.0897, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.85162353515625\n",
            "||∇_X meta|| = 0.0017183874733746052\n",
            "ΔX norm: 1.7183891031891108e-05\n",
            "Stage 2/10:  64%|██████████████████▌          | 192/300 [05:45<03:27,  1.92s/it]T Loss=2.3051156997680664\n",
            "g_norm = tensor(0.1455, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055777549743652\n",
            "g_norm = tensor(0.1473, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3063247203826904\n",
            "g_norm = tensor(0.1567, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305161952972412\n",
            "g_norm = tensor(0.1609, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045814037323\n",
            "g_norm = tensor(0.1724, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2999725341797\n",
            "||∇_X meta|| = 0.0017214423278346658\n",
            "ΔX norm: 1.7214453691849485e-05\n",
            "Stage 2/10:  64%|██████████████████▋          | 193/300 [05:47<03:27,  1.94s/it]T Loss=2.302234172821045\n",
            "g_norm = tensor(0.1500, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041024208068848\n",
            "g_norm = tensor(0.1361, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303631067276001\n",
            "g_norm = tensor(0.1398, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302717685699463\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303166627883911\n",
            "g_norm = tensor(0.1439, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4773406982422\n",
            "||∇_X meta|| = 0.0016659032553434372\n",
            "ΔX norm: 1.6659023458487354e-05\n",
            "Stage 2/10:  65%|██████████████████▊          | 194/300 [05:49<03:27,  1.96s/it]T Loss=2.302870750427246\n",
            "g_norm = tensor(0.1416, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302283763885498\n",
            "g_norm = tensor(0.1414, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028311729431152\n",
            "g_norm = tensor(0.1446, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042547702789307\n",
            "g_norm = tensor(0.1614, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033430576324463\n",
            "g_norm = tensor(0.1248, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.69448852539062\n",
            "||∇_X meta|| = 0.0017916822107508779\n",
            "ΔX norm: 1.7916814613272436e-05\n",
            "Stage 2/10:  65%|██████████████████▊          | 195/300 [05:51<03:24,  1.95s/it]T Loss=2.3040366172790527\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029942512512207\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038032054901123\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303042411804199\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303593158721924\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.42056274414062\n",
            "||∇_X meta|| = 0.001658216817304492\n",
            "ΔX norm: 1.658216569921933e-05\n",
            "Stage 2/10:  65%|██████████████████▉          | 196/300 [05:53<03:17,  1.90s/it]T Loss=2.3037710189819336\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048834800720215\n",
            "g_norm = tensor(0.0865, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304431676864624\n",
            "g_norm = tensor(0.0739, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304719924926758\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304051637649536\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.77874755859375\n",
            "||∇_X meta|| = 0.001496697310358286\n",
            "ΔX norm: 1.4966958588047419e-05\n",
            "Stage 2/10:  66%|███████████████████          | 197/300 [05:55<03:15,  1.90s/it]T Loss=2.3047738075256348\n",
            "g_norm = tensor(0.0884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052783012390137\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054070472717285\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304826259613037\n",
            "g_norm = tensor(0.0862, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052830696105957\n",
            "g_norm = tensor(0.0831, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.44363403320312\n",
            "||∇_X meta|| = 0.0016190498135983944\n",
            "ΔX norm: 1.6190495443879627e-05\n",
            "Stage 2/10:  66%|███████████████████▏         | 198/300 [05:57<03:12,  1.88s/it]T Loss=2.303709030151367\n",
            "g_norm = tensor(0.1444, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302280902862549\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035919666290283\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037381172180176\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051917552948\n",
            "g_norm = tensor(0.1397, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.0473175048828\n",
            "||∇_X meta|| = 0.001504745101556182\n",
            "ΔX norm: 1.5047479791974183e-05\n",
            "Stage 2/10:  66%|███████████████████▏         | 199/300 [05:58<03:08,  1.86s/it]T Loss=2.3029472827911377\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302795886993408\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030858039855957\n",
            "g_norm = tensor(0.1405, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037281036376953\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040738105773926\n",
            "g_norm = tensor(0.1312, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7271728515625\n",
            "||∇_X meta|| = 0.0016528434352949262\n",
            "ΔX norm: 1.6528436390217394e-05\n",
            "Stage 2/10:  67%|███████████████████▎         | 200/300 [06:00<03:04,  1.84s/it]T Loss=2.3051998615264893\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304429292678833\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303597927093506\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034324645996094\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303459644317627\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.02476501464844\n",
            "||∇_X meta|| = 0.0015850490890443325\n",
            "ΔX norm: 1.5850511772441678e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 2/10:  67%|███████████████████▍         | 201/300 [06:02<03:00,  1.82s/it]T Loss=2.3042426109313965\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30456805229187\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305830478668213\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304490566253662\n",
            "g_norm = tensor(0.1250, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041000366210938\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.50611877441406\n",
            "||∇_X meta|| = 0.0016193365445360541\n",
            "ΔX norm: 1.6193371266126633e-05\n",
            "Stage 2/10:  67%|███████████████████▌         | 202/300 [06:04<03:12,  1.97s/it]T Loss=2.3041152954101562\n",
            "g_norm = tensor(0.1500, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304517984390259\n",
            "g_norm = tensor(0.1417, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041892051696777\n",
            "g_norm = tensor(0.1433, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305436611175537\n",
            "g_norm = tensor(0.1593, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052685260772705\n",
            "g_norm = tensor(0.1334, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.91734313964844\n",
            "||∇_X meta|| = 0.0015801030676811934\n",
            "ΔX norm: 1.580106072651688e-05\n",
            "Stage 2/10:  68%|███████████████████▌         | 203/300 [06:07<03:26,  2.13s/it]T Loss=2.3043510913848877\n",
            "g_norm = tensor(0.0802, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304206132888794\n",
            "g_norm = tensor(0.0770, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048095703125\n",
            "g_norm = tensor(0.0823, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30492901802063\n",
            "g_norm = tensor(0.0843, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039815425872803\n",
            "g_norm = tensor(0.0851, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.69288635253906\n",
            "||∇_X meta|| = 0.0014722943305969238\n",
            "ΔX norm: 1.4722938431077637e-05\n",
            "Stage 2/10:  68%|███████████████████▋         | 204/300 [06:08<03:13,  2.02s/it]T Loss=2.3046839237213135\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303966522216797\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043503761291504\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050429821014404\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30450439453125\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.6641845703125\n",
            "||∇_X meta|| = 0.0014952578349038959\n",
            "ΔX norm: 1.4952585843275301e-05\n",
            "Stage 2/10:  68%|███████████████████▊         | 205/300 [06:10<03:06,  1.97s/it]T Loss=2.3037941455841064\n",
            "g_norm = tensor(0.0748, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038623332977295\n",
            "g_norm = tensor(0.0838, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037257194519043\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037822246551514\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039352893829346\n",
            "g_norm = tensor(0.0794, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.17494201660156\n",
            "||∇_X meta|| = 0.0015894296811893582\n",
            "ΔX norm: 1.5894305761321448e-05\n",
            "Stage 2/10:  69%|███████████████████▉         | 206/300 [06:13<03:20,  2.14s/it]T Loss=2.3039963245391846\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053698539733887\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035590648651123\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041553497314453\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039674758911133\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.79803466796875\n",
            "||∇_X meta|| = 0.0015314711490646005\n",
            "ΔX norm: 1.5314695701817982e-05\n",
            "Stage 2/10:  69%|████████████████████         | 207/300 [06:15<03:15,  2.10s/it]T Loss=2.3025519847869873\n",
            "g_norm = tensor(0.1364, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036389350891113\n",
            "g_norm = tensor(0.1687, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035006523132324\n",
            "g_norm = tensor(0.1480, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303067684173584\n",
            "g_norm = tensor(0.1412, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023681640625\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.98519897460938\n",
            "||∇_X meta|| = 0.001464001601561904\n",
            "ΔX norm: 1.4640028894064017e-05\n",
            "Stage 2/10:  69%|████████████████████         | 208/300 [06:17<03:03,  2.00s/it]T Loss=2.3039731979370117\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033487796783447\n",
            "g_norm = tensor(0.1021, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304792642593384\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032374382019043\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029420375823975\n",
            "g_norm = tensor(0.1318, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.70281982421875\n",
            "||∇_X meta|| = 0.0015891010407358408\n",
            "ΔX norm: 1.58909988385858e-05\n",
            "Stage 2/10:  70%|████████████████████▏        | 209/300 [06:18<02:52,  1.90s/it]T Loss=2.303737163543701\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303864002227783\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046462535858154\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304853916168213\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042311668395996\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.47889709472656\n",
            "||∇_X meta|| = 0.0014754963340237737\n",
            "ΔX norm: 1.475496628700057e-05\n",
            "Stage 2/10:  70%|████████████████████▎        | 210/300 [06:20<02:44,  1.82s/it]T Loss=2.304427146911621\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303985118865967\n",
            "g_norm = tensor(0.1299, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040430545806885\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304948329925537\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047871589660645\n",
            "g_norm = tensor(0.1107, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9622039794922\n",
            "||∇_X meta|| = 0.0016126077389344573\n",
            "ΔX norm: 1.6126079572131857e-05\n",
            "Stage 2/10:  70%|████████████████████▍        | 211/300 [06:22<02:45,  1.86s/it]T Loss=2.304558038711548\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034520149230957\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034884929656982\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037235736846924\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303475856781006\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.06228637695312\n",
            "||∇_X meta|| = 0.0016286082100123167\n",
            "ΔX norm: 1.6286096069961786e-05\n",
            "Stage 2/10:  71%|████████████████████▍        | 212/300 [06:24<02:47,  1.90s/it]T Loss=2.30198335647583\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302455186843872\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303649663925171\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017733097076416\n",
            "g_norm = tensor(0.0928, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302155017852783\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.81800842285156\n",
            "||∇_X meta|| = 0.0014868407743051648\n",
            "ΔX norm: 1.486841938458383e-05\n",
            "Stage 2/10:  71%|████████████████████▌        | 213/300 [06:26<02:39,  1.83s/it]T Loss=2.304757595062256\n",
            "g_norm = tensor(0.1234, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039937019348145\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30440616607666\n",
            "g_norm = tensor(0.1440, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038907051086426\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031036853790283\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.84751892089844\n",
            "||∇_X meta|| = 0.0015483885072171688\n",
            "ΔX norm: 1.5483892639167607e-05\n",
            "Stage 2/10:  71%|████████████████████▋        | 214/300 [06:27<02:34,  1.79s/it]T Loss=2.3037495613098145\n",
            "g_norm = tensor(0.1597, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303760051727295\n",
            "g_norm = tensor(0.1530, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032686710357666\n",
            "g_norm = tensor(0.1470, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302823066711426\n",
            "g_norm = tensor(0.1832, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3016819953918457\n",
            "g_norm = tensor(0.1561, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.18983459472656\n",
            "||∇_X meta|| = 0.0016117676859721541\n",
            "ΔX norm: 1.611767220310867e-05\n",
            "Stage 2/10:  72%|████████████████████▊        | 215/300 [06:29<02:30,  1.77s/it]T Loss=2.304704427719116\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039748668670654\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039815425872803\n",
            "g_norm = tensor(0.1250, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305077075958252\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304048538208008\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3836212158203\n",
            "||∇_X meta|| = 0.0015723721589893103\n",
            "ΔX norm: 1.5723766409792006e-05\n",
            "Stage 2/10:  72%|████████████████████▉        | 216/300 [06:31<02:24,  1.72s/it]T Loss=2.3036322593688965\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040378093719482\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040544986724854\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303008556365967\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040499687194824\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.38633728027344\n",
            "||∇_X meta|| = 0.0015443488955497742\n",
            "ΔX norm: 1.544348015158903e-05\n",
            "Stage 2/10:  72%|████████████████████▉        | 217/300 [06:32<02:22,  1.72s/it]T Loss=2.304637908935547\n",
            "g_norm = tensor(0.1498, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303647518157959\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303380250930786\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303755283355713\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304002046585083\n",
            "g_norm = tensor(0.1376, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.67636108398438\n",
            "||∇_X meta|| = 0.0015787096926942468\n",
            "ΔX norm: 1.5787099982844666e-05\n",
            "Stage 2/10:  73%|█████████████████████        | 218/300 [06:34<02:18,  1.69s/it]T Loss=2.3042550086975098\n",
            "g_norm = tensor(0.0851, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304111957550049\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304525852203369\n",
            "g_norm = tensor(0.0852, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039863109588623\n",
            "g_norm = tensor(0.0716, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034045696258545\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.05450439453125\n",
            "||∇_X meta|| = 0.0013835832942277193\n",
            "ΔX norm: 1.3835831850883551e-05\n",
            "Stage 2/10:  73%|█████████████████████▏       | 219/300 [06:36<02:16,  1.68s/it]T Loss=2.3045918941497803\n",
            "g_norm = tensor(0.1377, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302076578140259\n",
            "g_norm = tensor(0.1335, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303816318511963\n",
            "g_norm = tensor(0.1301, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302694797515869\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017995357513428\n",
            "g_norm = tensor(0.1424, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.62210083007812\n",
            "||∇_X meta|| = 0.0016524409875273705\n",
            "ΔX norm: 1.6524374586879276e-05\n",
            "Stage 2/10:  73%|█████████████████████▎       | 220/300 [06:37<02:12,  1.65s/it]T Loss=2.3032917976379395\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303297281265259\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041489124298096\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031489849090576\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022024631500244\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.07594299316406\n",
            "||∇_X meta|| = 0.0014905674615874887\n",
            "ΔX norm: 1.4905640455253888e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 2/10:  74%|█████████████████████▎       | 221/300 [06:39<02:11,  1.67s/it]T Loss=2.3044309616088867\n",
            "g_norm = tensor(0.1474, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045284748077393\n",
            "g_norm = tensor(0.1373, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3059754371643066\n",
            "g_norm = tensor(0.1551, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058221340179443\n",
            "g_norm = tensor(0.1927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047022819519043\n",
            "g_norm = tensor(0.1494, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =227.7660369873047\n",
            "||∇_X meta|| = 0.0016050990670919418\n",
            "ΔX norm: 1.605099532753229e-05\n",
            "Stage 2/10:  74%|█████████████████████▍       | 222/300 [06:41<02:23,  1.84s/it]T Loss=2.3044562339782715\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304924249649048\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035240173339844\n",
            "g_norm = tensor(0.0827, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30326771736145\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028619289398193\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.49447631835938\n",
            "||∇_X meta|| = 0.0015678592026233673\n",
            "ΔX norm: 1.5678569980082102e-05\n",
            "Stage 2/10:  74%|█████████████████████▌       | 223/300 [06:43<02:19,  1.81s/it]T Loss=2.3042593002319336\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036675453186035\n",
            "g_norm = tensor(0.0857, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302921772003174\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040380477905273\n",
            "g_norm = tensor(0.0837, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040082454681396\n",
            "g_norm = tensor(0.0807, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.7458038330078\n",
            "||∇_X meta|| = 0.0016823384212329984\n",
            "ΔX norm: 1.682341462583281e-05\n",
            "Stage 2/10:  75%|█████████████████████▋       | 224/300 [06:44<02:12,  1.74s/it]T Loss=2.303292751312256\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047027587890625\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304116725921631\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040671348571777\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034350872039795\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.64117431640625\n",
            "||∇_X meta|| = 0.0013722711009904742\n",
            "ΔX norm: 1.3722674339078367e-05\n",
            "Stage 2/10:  75%|█████████████████████▊       | 225/300 [06:46<02:10,  1.74s/it]T Loss=2.3043251037597656\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304258346557617\n",
            "g_norm = tensor(0.0739, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304084062576294\n",
            "g_norm = tensor(0.0748, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039166927337646\n",
            "g_norm = tensor(0.0718, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30342698097229\n",
            "g_norm = tensor(0.0846, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.98495483398438\n",
            "||∇_X meta|| = 0.0016072873258963227\n",
            "ΔX norm: 1.6072875951067545e-05\n",
            "Stage 2/10:  75%|█████████████████████▊       | 226/300 [06:48<02:04,  1.68s/it]T Loss=2.3044357299804688\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032121658325195\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303071975708008\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033580780029297\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030166625976562\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.33364868164062\n",
            "||∇_X meta|| = 0.0014765176456421614\n",
            "ΔX norm: 1.4765204468858428e-05\n",
            "Stage 2/10:  76%|█████████████████████▉       | 227/300 [06:49<01:58,  1.63s/it]T Loss=2.304511547088623\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055260181427\n",
            "g_norm = tensor(0.1299, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027448654174805\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045990467071533\n",
            "g_norm = tensor(0.1424, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034651279449463\n",
            "g_norm = tensor(0.1361, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.24549865722656\n",
            "||∇_X meta|| = 0.0015265109250321984\n",
            "ΔX norm: 1.5265115507645532e-05\n",
            "Stage 2/10:  76%|██████████████████████       | 228/300 [06:51<01:55,  1.60s/it]T Loss=2.3027255535125732\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303203582763672\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039989471435547\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032305240631104\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029370307922363\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.50662231445312\n",
            "||∇_X meta|| = 0.0015286060515791178\n",
            "ΔX norm: 1.5286052075680345e-05\n",
            "Stage 2/10:  76%|██████████████████████▏      | 229/300 [06:52<01:50,  1.56s/it]T Loss=2.303206205368042\n",
            "g_norm = tensor(0.0888, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031041622161865\n",
            "g_norm = tensor(0.0778, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035178184509277\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303382635116577\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303337335586548\n",
            "g_norm = tensor(0.0818, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.83102416992188\n",
            "||∇_X meta|| = 0.0015158021124079823\n",
            "ΔX norm: 1.5158003407123033e-05\n",
            "Stage 2/10:  77%|██████████████████████▏      | 230/300 [06:54<01:53,  1.62s/it]T Loss=2.3031373023986816\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046116828918457\n",
            "g_norm = tensor(0.1739, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303027391433716\n",
            "g_norm = tensor(0.1439, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033227920532227\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028552532196045\n",
            "g_norm = tensor(0.1368, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.39073181152344\n",
            "||∇_X meta|| = 0.001466659945435822\n",
            "ΔX norm: 1.466659796278691e-05\n",
            "Stage 2/10:  77%|██████████████████████▎      | 231/300 [06:56<01:52,  1.63s/it]T Loss=2.3046677112579346\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041865825653076\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048737049102783\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304482936859131\n",
            "g_norm = tensor(0.0864, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303220510482788\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.30921936035156\n",
            "||∇_X meta|| = 0.0016497723991051316\n",
            "ΔX norm: 1.6497720935149118e-05\n",
            "Stage 2/10:  77%|██████████████████████▍      | 232/300 [06:57<01:50,  1.62s/it]T Loss=2.303619146347046\n",
            "g_norm = tensor(0.0821, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304429292678833\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303891658782959\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304053783416748\n",
            "g_norm = tensor(0.0794, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304866313934326\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7409210205078\n",
            "||∇_X meta|| = 0.0013633997878059745\n",
            "ΔX norm: 1.3633987691719085e-05\n",
            "Stage 2/10:  78%|██████████████████████▌      | 233/300 [06:59<01:46,  1.59s/it]T Loss=2.302199363708496\n",
            "g_norm = tensor(0.1283, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303255319595337\n",
            "g_norm = tensor(0.1380, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033251762390137\n",
            "g_norm = tensor(0.1591, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025240898132324\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303499221801758\n",
            "g_norm = tensor(0.1417, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.28445434570312\n",
            "||∇_X meta|| = 0.001540858531370759\n",
            "ΔX norm: 1.5408590115839615e-05\n",
            "Stage 2/10:  78%|██████████████████████▌      | 234/300 [07:00<01:44,  1.59s/it]T Loss=2.3042163848876953\n",
            "g_norm = tensor(0.0756, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304055690765381\n",
            "g_norm = tensor(0.0734, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047351837158203\n",
            "g_norm = tensor(0.0771, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034918308258057\n",
            "g_norm = tensor(0.0753, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303926467895508\n",
            "g_norm = tensor(0.0641, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.96612548828125\n",
            "||∇_X meta|| = 0.0016889793332666159\n",
            "ΔX norm: 1.688977499725297e-05\n",
            "Stage 2/10:  78%|██████████████████████▋      | 235/300 [07:02<01:41,  1.56s/it]T Loss=2.303530216217041\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037428855895996\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038525581359863\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304213047027588\n",
            "g_norm = tensor(0.1289, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033969402313232\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.21156311035156\n",
            "||∇_X meta|| = 0.001563675352372229\n",
            "ΔX norm: 1.563674413773697e-05\n",
            "Stage 2/10:  79%|██████████████████████▊      | 236/300 [07:04<01:46,  1.66s/it]T Loss=2.3045482635498047\n",
            "g_norm = tensor(0.1022, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303502321243286\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303816556930542\n",
            "g_norm = tensor(0.1489, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304961681365967\n",
            "g_norm = tensor(0.1249, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303311347961426\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.16009521484375\n",
            "||∇_X meta|| = 0.001551654888316989\n",
            "ΔX norm: 1.5516523490077816e-05\n",
            "Stage 2/10:  79%|██████████████████████▉      | 237/300 [07:05<01:43,  1.64s/it]T Loss=2.3037142753601074\n",
            "g_norm = tensor(0.1383, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028550148010254\n",
            "g_norm = tensor(0.1502, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041908740997314\n",
            "g_norm = tensor(0.1396, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029441833496094\n",
            "g_norm = tensor(0.1658, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304807662963867\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7490234375\n",
            "||∇_X meta|| = 0.001748228445649147\n",
            "ΔX norm: 1.748231443343684e-05\n",
            "Stage 2/10:  79%|███████████████████████      | 238/300 [07:07<01:47,  1.73s/it]T Loss=2.304576873779297\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046579360961914\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047657012939453\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30430269241333\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305619955062866\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.0372314453125\n",
            "||∇_X meta|| = 0.0015283398097380996\n",
            "ΔX norm: 1.5283429092960432e-05\n",
            "Stage 2/10:  80%|███████████████████████      | 239/300 [07:09<01:44,  1.71s/it]T Loss=2.3060495853424072\n",
            "g_norm = tensor(0.1463, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045966625213623\n",
            "g_norm = tensor(0.1336, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303611993789673\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058433532714844\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304497718811035\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.0538787841797\n",
            "||∇_X meta|| = 0.0015781306428834796\n",
            "ΔX norm: 1.5781337424414232e-05\n",
            "Stage 2/10:  80%|███████████████████████▏     | 240/300 [07:10<01:39,  1.66s/it]T Loss=2.3011422157287598\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305189847946167\n",
            "g_norm = tensor(0.1243, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043243885040283\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051578998565674\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027591705322266\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9794921875\n",
            "||∇_X meta|| = 0.0014462930848821998\n",
            "ΔX norm: 1.4462937542703003e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 2/10:  80%|███████████████████████▎     | 241/300 [07:12<01:43,  1.76s/it]T Loss=2.304657220840454\n",
            "g_norm = tensor(0.1316, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304046154022217\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018643856048584\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034586906433105\n",
            "g_norm = tensor(0.1291, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039908409118652\n",
            "g_norm = tensor(0.1397, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2032012939453\n",
            "||∇_X meta|| = 0.001369331730529666\n",
            "ΔX norm: 1.3693310393136926e-05\n",
            "Stage 2/10:  81%|███████████████████████▍     | 242/300 [07:15<01:46,  1.84s/it]T Loss=2.3039493560791016\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304058074951172\n",
            "g_norm = tensor(0.1309, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039073944091797\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041532039642334\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304436206817627\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.65382385253906\n",
            "||∇_X meta|| = 0.001671668840572238\n",
            "ΔX norm: 1.671668724156916e-05\n",
            "Stage 2/10:  81%|███████████████████████▍     | 243/300 [07:16<01:43,  1.81s/it]T Loss=2.3038330078125\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035144805908203\n",
            "g_norm = tensor(0.1183, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039145469665527\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043570518493652\n",
            "g_norm = tensor(0.0821, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037962913513184\n",
            "g_norm = tensor(0.0868, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.00778198242188\n",
            "||∇_X meta|| = 0.0014765512896701694\n",
            "ΔX norm: 1.4765529158466961e-05\n",
            "Stage 2/10:  81%|███████████████████████▌     | 244/300 [07:18<01:37,  1.74s/it]T Loss=2.303849458694458\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029143810272217\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025901317596436\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304187774658203\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025283813476562\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1043701171875\n",
            "||∇_X meta|| = 0.0017061653779819608\n",
            "ΔX norm: 1.7061644030036405e-05\n",
            "Stage 2/10:  82%|███████████████████████▋     | 245/300 [07:19<01:32,  1.68s/it]T Loss=2.3026552200317383\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302888870239258\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303701877593994\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30357027053833\n",
            "g_norm = tensor(0.1218, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304725170135498\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.08163452148438\n",
            "||∇_X meta|| = 0.001672806334681809\n",
            "ΔX norm: 1.6728057744330727e-05\n",
            "Stage 2/10:  82%|███████████████████████▊     | 246/300 [07:21<01:32,  1.71s/it]T Loss=2.304593086242676\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049988746643066\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304015636444092\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045828342437744\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305600166320801\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.14273071289062\n",
            "||∇_X meta|| = 0.0016425387002527714\n",
            "ΔX norm: 1.6425412468379363e-05\n",
            "Stage 2/10:  82%|███████████████████████▉     | 247/300 [07:23<01:30,  1.70s/it]T Loss=2.3028688430786133\n",
            "g_norm = tensor(0.1420, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037824630737305\n",
            "g_norm = tensor(0.1219, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041324615478516\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304011583328247\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304840087890625\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.05758666992188\n",
            "||∇_X meta|| = 0.0014108477625995874\n",
            "ΔX norm: 1.4108467439655215e-05\n",
            "Stage 2/10:  83%|███████████████████████▉     | 248/300 [07:24<01:27,  1.68s/it]T Loss=2.301764965057373\n",
            "g_norm = tensor(0.1184, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021645545959473\n",
            "g_norm = tensor(0.1424, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038077354431152\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035290241241455\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028931617736816\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9584197998047\n",
            "||∇_X meta|| = 0.0015274353791028261\n",
            "ΔX norm: 1.5274355973815545e-05\n",
            "Stage 2/10:  83%|████████████████████████     | 249/300 [07:26<01:23,  1.65s/it]T Loss=2.30356764793396\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035435676574707\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303962230682373\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044936656951904\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30363392829895\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.1228790283203\n",
            "||∇_X meta|| = 0.0015300208469852805\n",
            "ΔX norm: 1.5300194718292914e-05\n",
            "Stage 2/10:  83%|████████████████████████▏    | 250/300 [07:28<01:21,  1.62s/it]T Loss=2.3033576011657715\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043041229248047\n",
            "g_norm = tensor(0.0852, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041863441467285\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028781414031982\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303326368331909\n",
            "g_norm = tensor(0.0849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.67575073242188\n",
            "||∇_X meta|| = 0.0015763718402013183\n",
            "ΔX norm: 1.5763705960125662e-05\n",
            "Stage 2/10:  84%|████████████████████████▎    | 251/300 [07:29<01:20,  1.65s/it]T Loss=2.304062843322754\n",
            "g_norm = tensor(0.0851, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039114475250244\n",
            "g_norm = tensor(0.0869, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30405855178833\n",
            "g_norm = tensor(0.0872, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303725481033325\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049912452697754\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.7655029296875\n",
            "||∇_X meta|| = 0.0015762835973873734\n",
            "ΔX norm: 1.576288923388347e-05\n",
            "Stage 2/10:  84%|████████████████████████▎    | 252/300 [07:31<01:19,  1.66s/it]T Loss=2.3061115741729736\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034164905548096\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041186332702637\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3061747550964355\n",
            "g_norm = tensor(0.1273, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040671348571777\n",
            "g_norm = tensor(0.1557, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.59674072265625\n",
            "||∇_X meta|| = 0.001550986897200346\n",
            "ΔX norm: 1.5509855074924417e-05\n",
            "Stage 2/10:  84%|████████████████████████▍    | 253/300 [07:33<01:21,  1.74s/it]T Loss=2.3036255836486816\n",
            "g_norm = tensor(0.1107, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30427885055542\n",
            "g_norm = tensor(0.1103, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302738666534424\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304431915283203\n",
            "g_norm = tensor(0.1206, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303753614425659\n",
            "g_norm = tensor(0.1276, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3151397705078\n",
            "||∇_X meta|| = 0.0016473530558869243\n",
            "ΔX norm: 1.6473552022944205e-05\n",
            "Stage 2/10:  85%|████████████████████████▌    | 254/300 [07:35<01:24,  1.83s/it]T Loss=2.301743984222412\n",
            "g_norm = tensor(0.1444, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303487539291382\n",
            "g_norm = tensor(0.1475, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302990674972534\n",
            "g_norm = tensor(0.1330, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303144931793213\n",
            "g_norm = tensor(0.1333, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302135705947876\n",
            "g_norm = tensor(0.1499, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8541717529297\n",
            "||∇_X meta|| = 0.0014684356283396482\n",
            "ΔX norm: 1.4684403140563518e-05\n",
            "Stage 2/10:  85%|████████████████████████▋    | 255/300 [07:37<01:21,  1.80s/it]T Loss=2.304490566253662\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045175075531006\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305084466934204\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051109313964844\n",
            "g_norm = tensor(0.1314, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304018497467041\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.82159423828125\n",
            "||∇_X meta|| = 0.0015811072662472725\n",
            "ΔX norm: 1.5811121556907892e-05\n",
            "Stage 2/10:  85%|████████████████████████▋    | 256/300 [07:38<01:18,  1.78s/it]T Loss=2.3032352924346924\n",
            "g_norm = tensor(0.1364, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304840087890625\n",
            "g_norm = tensor(0.1416, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305950880050659\n",
            "g_norm = tensor(0.1472, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304774045944214\n",
            "g_norm = tensor(0.1610, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302703380584717\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.71681213378906\n",
            "||∇_X meta|| = 0.0017662672325968742\n",
            "ΔX norm: 1.7662699974607676e-05\n",
            "Stage 2/10:  86%|████████████████████████▊    | 257/300 [07:40<01:14,  1.73s/it]T Loss=2.3036608695983887\n",
            "g_norm = tensor(0.0825, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051419258117676\n",
            "g_norm = tensor(0.0861, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042938709259033\n",
            "g_norm = tensor(0.0960, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303865432739258\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043770790100098\n",
            "g_norm = tensor(0.0806, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9434051513672\n",
            "||∇_X meta|| = 0.001592932385392487\n",
            "ΔX norm: 1.5929341316223145e-05\n",
            "Stage 2/10:  86%|████████████████████████▉    | 258/300 [07:42<01:10,  1.68s/it]T Loss=2.304649591445923\n",
            "g_norm = tensor(0.1210, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304603099822998\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303194522857666\n",
            "g_norm = tensor(0.1316, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046295642852783\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040695190429688\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.75433349609375\n",
            "||∇_X meta|| = 0.001414865255355835\n",
            "ΔX norm: 1.414865801052656e-05\n",
            "Stage 2/10:  86%|█████████████████████████    | 259/300 [07:43<01:08,  1.68s/it]T Loss=2.3037590980529785\n",
            "g_norm = tensor(0.1299, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304532051086426\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305436372756958\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038477897644043\n",
            "g_norm = tensor(0.1221, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056862354278564\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.2425537109375\n",
            "||∇_X meta|| = 0.0015786791918799281\n",
            "ΔX norm: 1.5786807125550695e-05\n",
            "Stage 2/10:  87%|█████████████████████████▏   | 260/300 [07:45<01:06,  1.65s/it]T Loss=2.30436372756958\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304001808166504\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305126667022705\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035495281219482\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304281234741211\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.33856201171875\n",
            "||∇_X meta|| = 0.001636024215258658\n",
            "ΔX norm: 1.6360241716029122e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 2/10:  87%|█████████████████████████▏   | 261/300 [07:46<01:03,  1.63s/it]T Loss=2.3032631874084473\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027114868164062\n",
            "g_norm = tensor(0.1053, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022751808166504\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303037166595459\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030142784118652\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.82565307617188\n",
            "||∇_X meta|| = 0.0015727793797850609\n",
            "ΔX norm: 1.5727842765045352e-05\n",
            "Stage 2/10:  87%|█████████████████████████▎   | 262/300 [07:49<01:09,  1.83s/it]T Loss=2.303569793701172\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304664134979248\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047995567321777\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046061992645264\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034608364105225\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.56588745117188\n",
            "||∇_X meta|| = 0.0015589313115924597\n",
            "ΔX norm: 1.558933945489116e-05\n",
            "Stage 2/10:  88%|█████████████████████████▍   | 263/300 [07:51<01:07,  1.82s/it]T Loss=2.3039238452911377\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303694248199463\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039064407348633\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303394079208374\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045172691345215\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.94207763671875\n",
            "||∇_X meta|| = 0.001610316103324294\n",
            "ΔX norm: 1.610313483979553e-05\n",
            "Stage 2/10:  88%|█████████████████████████▌   | 264/300 [07:52<01:02,  1.75s/it]T Loss=2.302952289581299\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036351203918457\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019702434539795\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304478883743286\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032748699188232\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.0043182373047\n",
            "||∇_X meta|| = 0.001613824744708836\n",
            "ΔX norm: 1.6138241335283965e-05\n",
            "Stage 2/10:  88%|█████████████████████████▌   | 265/300 [07:54<01:01,  1.76s/it]T Loss=2.304551839828491\n",
            "g_norm = tensor(0.1258, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302792549133301\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302339792251587\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040051460266113\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302482843399048\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.07501220703125\n",
            "||∇_X meta|| = 0.001547168823890388\n",
            "ΔX norm: 1.5471681763301603e-05\n",
            "Stage 2/10:  89%|█████████████████████████▋   | 266/300 [07:56<00:59,  1.74s/it]T Loss=2.3042080402374268\n",
            "g_norm = tensor(0.1206, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304919958114624\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043293952941895\n",
            "g_norm = tensor(0.1391, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044402599334717\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303774356842041\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7994842529297\n",
            "||∇_X meta|| = 0.0015287571586668491\n",
            "ΔX norm: 1.528763459646143e-05\n",
            "Stage 2/10:  89%|█████████████████████████▊   | 267/300 [07:57<00:55,  1.67s/it]T Loss=2.3023414611816406\n",
            "g_norm = tensor(0.1844, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049323558807373\n",
            "g_norm = tensor(0.2030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302544355392456\n",
            "g_norm = tensor(0.1914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030922412872314\n",
            "g_norm = tensor(0.1849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30542254447937\n",
            "g_norm = tensor(0.1654, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.84188842773438\n",
            "||∇_X meta|| = 0.0017222326714545488\n",
            "ΔX norm: 1.722230445011519e-05\n",
            "Stage 2/10:  89%|█████████████████████████▉   | 268/300 [07:59<00:52,  1.64s/it]T Loss=2.3036434650421143\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303931713104248\n",
            "g_norm = tensor(0.1297, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047409057617188\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037943840026855\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044087886810303\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.385498046875\n",
            "||∇_X meta|| = 0.0015349478926509619\n",
            "ΔX norm: 1.5349538443842903e-05\n",
            "Stage 2/10:  90%|██████████████████████████   | 269/300 [08:00<00:49,  1.59s/it]T Loss=2.304837465286255\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304438829421997\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303535223007202\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039698600769043\n",
            "g_norm = tensor(0.1218, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303600788116455\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.69349670410156\n",
            "||∇_X meta|| = 0.001630751765333116\n",
            "ΔX norm: 1.630753104109317e-05\n",
            "Stage 2/10:  90%|██████████████████████████   | 270/300 [08:02<00:47,  1.57s/it]T Loss=2.30378794670105\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030312061309814\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040406703948975\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029017448425293\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030776977539062\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5075225830078\n",
            "||∇_X meta|| = 0.001670621451921761\n",
            "ΔX norm: 1.670618621574249e-05\n",
            "Stage 2/10:  90%|██████████████████████████▏  | 271/300 [08:03<00:44,  1.55s/it]T Loss=2.3033251762390137\n",
            "g_norm = tensor(0.1337, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030195236206055\n",
            "g_norm = tensor(0.1282, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303917407989502\n",
            "g_norm = tensor(0.1341, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035364151000977\n",
            "g_norm = tensor(0.1258, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028581142425537\n",
            "g_norm = tensor(0.1295, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.16964721679688\n",
            "||∇_X meta|| = 0.0017918063094839454\n",
            "ΔX norm: 1.7918020603246987e-05\n",
            "Stage 2/10:  91%|██████████████████████████▎  | 272/300 [08:05<00:42,  1.53s/it]T Loss=2.3039727210998535\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018171787261963\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043296337127686\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303150177001953\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044352531433105\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.12489318847656\n",
            "||∇_X meta|| = 0.0018019606359302998\n",
            "ΔX norm: 1.8019592971540987e-05\n",
            "Stage 2/10:  91%|██████████████████████████▍  | 273/300 [08:06<00:41,  1.55s/it]T Loss=2.3048932552337646\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305107593536377\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304579257965088\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051624298095703\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303899049758911\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5596923828125\n",
            "||∇_X meta|| = 0.0015559479361400008\n",
            "ΔX norm: 1.5559477105853148e-05\n",
            "Stage 2/10:  91%|██████████████████████████▍  | 274/300 [08:08<00:40,  1.57s/it]T Loss=2.3047280311584473\n",
            "g_norm = tensor(0.1394, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304049491882324\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031973838806152\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049590587615967\n",
            "g_norm = tensor(0.0983, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30462384223938\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.926513671875\n",
            "||∇_X meta|| = 0.001535507501102984\n",
            "ΔX norm: 1.535506635264028e-05\n",
            "Stage 2/10:  92%|██████████████████████████▌  | 275/300 [08:09<00:39,  1.58s/it]T Loss=2.303974151611328\n",
            "g_norm = tensor(0.0682, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042192459106445\n",
            "g_norm = tensor(0.0715, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041443824768066\n",
            "g_norm = tensor(0.0651, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048818111419678\n",
            "g_norm = tensor(0.0777, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304180860519409\n",
            "g_norm = tensor(0.0776, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.04843139648438\n",
            "||∇_X meta|| = 0.001586606726050377\n",
            "ΔX norm: 1.5866064131841995e-05\n",
            "Stage 2/10:  92%|██████████████████████████▋  | 276/300 [08:11<00:37,  1.58s/it]T Loss=2.3036856651306152\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303205728530884\n",
            "g_norm = tensor(0.0792, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303102493286133\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042030334472656\n",
            "g_norm = tensor(0.0820, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030412197113037\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.79937744140625\n",
            "||∇_X meta|| = 0.0015112350229173899\n",
            "ΔX norm: 1.5112368600966875e-05\n",
            "Stage 2/10:  92%|██████████████████████████▊  | 277/300 [08:13<00:39,  1.72s/it]T Loss=2.3012185096740723\n",
            "g_norm = tensor(0.1556, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303271770477295\n",
            "g_norm = tensor(0.1392, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3015058040618896\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035075664520264\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023791313171387\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.52383422851562\n",
            "||∇_X meta|| = 0.0014997320249676704\n",
            "ΔX norm: 1.4997368452895898e-05\n",
            "Stage 2/10:  93%|██████████████████████████▊  | 278/300 [08:15<00:36,  1.68s/it]T Loss=2.3030917644500732\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304250717163086\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039445877075195\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051557540893555\n",
            "g_norm = tensor(0.1266, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040478229522705\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.99388122558594\n",
            "||∇_X meta|| = 0.0015605844091624022\n",
            "ΔX norm: 1.5605848602717742e-05\n",
            "Stage 2/10:  93%|██████████████████████████▉  | 279/300 [08:16<00:34,  1.63s/it]T Loss=2.3032519817352295\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028111457824707\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303271770477295\n",
            "g_norm = tensor(0.0871, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303769588470459\n",
            "g_norm = tensor(0.0822, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032443523406982\n",
            "g_norm = tensor(0.0816, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.56138610839844\n",
            "||∇_X meta|| = 0.0014262690674513578\n",
            "ΔX norm: 1.426270591764478e-05\n",
            "Stage 2/10:  93%|███████████████████████████  | 280/300 [08:18<00:32,  1.64s/it]T Loss=2.30338716506958\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034889698028564\n",
            "g_norm = tensor(0.1328, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029496669769287\n",
            "g_norm = tensor(0.0993, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025574684143066\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042831420898438\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1525115966797\n",
            "||∇_X meta|| = 0.0014498945092782378\n",
            "ΔX norm: 1.4498965356324334e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 2/10:  94%|███████████████████████████▏ | 281/300 [08:20<00:32,  1.69s/it]T Loss=2.3020901679992676\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017454147338867\n",
            "g_norm = tensor(0.1430, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3016724586486816\n",
            "g_norm = tensor(0.1389, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301630973815918\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30255389213562\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.7412109375\n",
            "||∇_X meta|| = 0.0015995233552530408\n",
            "ΔX norm: 1.599522693140898e-05\n",
            "Stage 2/10:  94%|███████████████████████████▎ | 282/300 [08:22<00:34,  1.91s/it]T Loss=2.3043811321258545\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047146797180176\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304060697555542\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039066791534424\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304598093032837\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.92298889160156\n",
            "||∇_X meta|| = 0.0016713368240743876\n",
            "ΔX norm: 1.6713389413780533e-05\n",
            "Stage 2/10:  94%|███████████████████████████▎ | 283/300 [08:24<00:31,  1.87s/it]T Loss=2.304936170578003\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303611993789673\n",
            "g_norm = tensor(0.1360, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051040172576904\n",
            "g_norm = tensor(0.1408, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034443855285645\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041815757751465\n",
            "g_norm = tensor(0.1482, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.96408081054688\n",
            "||∇_X meta|| = 0.001568690757267177\n",
            "ΔX norm: 1.568694096931722e-05\n",
            "Stage 2/10:  95%|███████████████████████████▍ | 284/300 [08:25<00:28,  1.79s/it]T Loss=2.303358554840088\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303410768508911\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046326637268066\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052663803100586\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039498329162598\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0042266845703\n",
            "||∇_X meta|| = 0.0015900207217782736\n",
            "ΔX norm: 1.5900204743957147e-05\n",
            "Stage 2/10:  95%|███████████████████████████▌ | 285/300 [08:27<00:25,  1.72s/it]T Loss=2.3021979331970215\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304626703262329\n",
            "g_norm = tensor(0.1561, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017354011535645\n",
            "g_norm = tensor(0.1348, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019309043884277\n",
            "g_norm = tensor(0.1443, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30367112159729\n",
            "g_norm = tensor(0.1607, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.01165771484375\n",
            "||∇_X meta|| = 0.001584670739248395\n",
            "ΔX norm: 1.5846684618736617e-05\n",
            "Stage 2/10:  95%|███████████████████████████▋ | 286/300 [08:29<00:23,  1.68s/it]T Loss=2.3048477172851562\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021655082702637\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302738904953003\n",
            "g_norm = tensor(0.1307, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30279803276062\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304262161254883\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.98184204101562\n",
            "||∇_X meta|| = 0.0015703151002526283\n",
            "ΔX norm: 1.5703137250966392e-05\n",
            "Stage 2/10:  96%|███████████████████████████▋ | 287/300 [08:30<00:21,  1.64s/it]T Loss=2.301340341567993\n",
            "g_norm = tensor(0.1711, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026115894317627\n",
            "g_norm = tensor(0.1471, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034136295318604\n",
            "g_norm = tensor(0.1720, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027138710021973\n",
            "g_norm = tensor(0.1301, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3006181716918945\n",
            "g_norm = tensor(0.1468, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.03054809570312\n",
            "||∇_X meta|| = 0.001629966078326106\n",
            "ΔX norm: 1.6299711205647327e-05\n",
            "Stage 2/10:  96%|███████████████████████████▊ | 288/300 [08:32<00:19,  1.64s/it]T Loss=2.302542209625244\n",
            "g_norm = tensor(0.0705, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303168773651123\n",
            "g_norm = tensor(0.0746, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030498027801514\n",
            "g_norm = tensor(0.0763, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029537200927734\n",
            "g_norm = tensor(0.0793, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303061008453369\n",
            "g_norm = tensor(0.0651, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.41531372070312\n",
            "||∇_X meta|| = 0.0016218656674027443\n",
            "ΔX norm: 1.6218653399846517e-05\n",
            "Stage 2/10:  96%|███████████████████████████▉ | 289/300 [08:33<00:17,  1.62s/it]T Loss=2.3026890754699707\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30212140083313\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018031120300293\n",
            "g_norm = tensor(0.1422, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302584171295166\n",
            "g_norm = tensor(0.1278, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302553653717041\n",
            "g_norm = tensor(0.1466, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0977783203125\n",
            "||∇_X meta|| = 0.0015183623181656003\n",
            "ΔX norm: 1.5183649338723626e-05\n",
            "Stage 2/10:  97%|████████████████████████████ | 290/300 [08:35<00:16,  1.60s/it]T Loss=2.3017663955688477\n",
            "g_norm = tensor(0.1491, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303689956665039\n",
            "g_norm = tensor(0.1372, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302811861038208\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304393768310547\n",
            "g_norm = tensor(0.1666, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026137351989746\n",
            "g_norm = tensor(0.1282, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9964599609375\n",
            "||∇_X meta|| = 0.0014462464023381472\n",
            "ΔX norm: 1.446246460545808e-05\n",
            "Stage 2/10:  97%|████████████████████████████▏| 291/300 [08:37<00:14,  1.61s/it]T Loss=2.3035240173339844\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027470111846924\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032279014587402\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303719997406006\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021602630615234\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.80563354492188\n",
            "||∇_X meta|| = 0.0015501598827540874\n",
            "ΔX norm: 1.5501609595958143e-05\n",
            "Stage 2/10:  97%|████████████████████████████▏| 292/300 [08:38<00:12,  1.59s/it]T Loss=2.3042683601379395\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303380250930786\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302579164505005\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036694526672363\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038229942321777\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.79144287109375\n",
            "||∇_X meta|| = 0.0015498785069212317\n",
            "ΔX norm: 1.5498793800361454e-05\n",
            "Stage 2/10:  98%|████████████████████████████▎| 293/300 [08:40<00:11,  1.63s/it]T Loss=2.302398681640625\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040008544921875\n",
            "g_norm = tensor(0.0841, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033182621002197\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303359031677246\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302471399307251\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.06924438476562\n",
            "||∇_X meta|| = 0.0015048319473862648\n",
            "ΔX norm: 1.5048323803057428e-05\n",
            "Stage 2/10:  98%|████████████████████████████▍| 294/300 [08:41<00:09,  1.62s/it]T Loss=2.3022727966308594\n",
            "g_norm = tensor(0.1278, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303679943084717\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302401065826416\n",
            "g_norm = tensor(0.1673, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024916648864746\n",
            "g_norm = tensor(0.1366, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039517402648926\n",
            "g_norm = tensor(0.1251, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.54751586914062\n",
            "||∇_X meta|| = 0.0014187187189236283\n",
            "ΔX norm: 1.4187156011757907e-05\n",
            "Stage 2/10:  98%|████████████████████████████▌| 295/300 [08:43<00:08,  1.65s/it]T Loss=2.3027303218841553\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304184913635254\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032708168029785\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040409088134766\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304253101348877\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.96763610839844\n",
            "||∇_X meta|| = 0.001662746537476778\n",
            "ΔX norm: 1.6627460354357027e-05\n",
            "Stage 2/10:  99%|████████████████████████████▌| 296/300 [08:45<00:06,  1.62s/it]T Loss=2.305443286895752\n",
            "g_norm = tensor(0.1327, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030974864959717\n",
            "g_norm = tensor(0.1218, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304917812347412\n",
            "g_norm = tensor(0.1518, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049511909484863\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039557933807373\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.44552612304688\n",
            "||∇_X meta|| = 0.001563692232593894\n",
            "ΔX norm: 1.5636936950613745e-05\n",
            "Stage 2/10:  99%|████████████████████████████▋| 297/300 [08:47<00:05,  1.68s/it]T Loss=2.303194522857666\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303210496902466\n",
            "g_norm = tensor(0.0869, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025097846984863\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031301498413086\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303267240524292\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.07823181152344\n",
            "||∇_X meta|| = 0.0015806459123268723\n",
            "ΔX norm: 1.580645221110899e-05\n",
            "Stage 2/10:  99%|████████████████████████████▊| 298/300 [08:48<00:03,  1.65s/it]T Loss=2.3046154975891113\n",
            "g_norm = tensor(0.1140, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037285804748535\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043060302734375\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304525852203369\n",
            "g_norm = tensor(0.1379, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302921772003174\n",
            "g_norm = tensor(0.1118, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.93325805664062\n",
            "||∇_X meta|| = 0.0015893387608230114\n",
            "ΔX norm: 1.5893438103375956e-05\n",
            "Stage 2/10: 100%|████████████████████████████▉| 299/300 [08:50<00:01,  1.64s/it]T Loss=2.3034324645996094\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303673505783081\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304755687713623\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040735721588135\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039352893829346\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.51132202148438\n",
            "||∇_X meta|| = 0.0015912095550447702\n",
            "ΔX norm: 1.591209729667753e-05\n",
            "Stage 1, class 0, loss 2.209                                                    \n",
            "Stage 1, class 1, loss 2.267\n",
            "Stage 1, class 2, loss 2.341\n",
            "Stage 1, class 3, loss 2.362\n",
            "Stage 1, class 4, loss 2.304\n",
            "Stage 1, class 5, loss 2.325\n",
            "Stage 1, class 6, loss 2.384\n",
            "Stage 1, class 7, loss 2.220\n",
            "Stage 1, class 8, loss 2.382\n",
            "Stage 1, class 9, loss 2.259\n",
            "Stage 3/10:   0%|                                       | 0/300 [00:00<?, ?it/s]T Loss=2.3045949935913086\n",
            "g_norm = tensor(0.1679, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3005361557006836\n",
            "g_norm = tensor(0.1842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028666973114014\n",
            "g_norm = tensor(0.1496, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019142150878906\n",
            "g_norm = tensor(0.1465, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303917646408081\n",
            "g_norm = tensor(0.1600, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.84231567382812\n",
            "||∇_X meta|| = 0.004194281529635191\n",
            "ΔX norm: 4.194283246761188e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 3/10:   0%|                               | 1/300 [00:01<09:01,  1.81s/it]T Loss=2.3026089668273926\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054118156433105\n",
            "g_norm = tensor(0.1548, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304431915283203\n",
            "g_norm = tensor(0.1258, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046069145202637\n",
            "g_norm = tensor(0.1464, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046491146087646\n",
            "g_norm = tensor(0.1725, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7859649658203\n",
            "||∇_X meta|| = 0.003725003218278289\n",
            "ΔX norm: 3.72500107914675e-05\n",
            "Stage 3/10:   1%|▏                              | 2/300 [00:04<11:25,  2.30s/it]T Loss=2.3041656017303467\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043136596679688\n",
            "g_norm = tensor(0.0835, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057780265808105\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304920196533203\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305478572845459\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.00462341308594\n",
            "||∇_X meta|| = 0.003526685293763876\n",
            "ΔX norm: 3.5266853956272826e-05\n",
            "Stage 3/10:   1%|▎                              | 3/300 [00:06<10:27,  2.11s/it]T Loss=2.3043181896209717\n",
            "g_norm = tensor(0.1328, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30470871925354\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036084175109863\n",
            "g_norm = tensor(0.1099, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304884433746338\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033549785614014\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.69493103027344\n",
            "||∇_X meta|| = 0.003930332604795694\n",
            "ΔX norm: 3.9303311496041715e-05\n",
            "Stage 3/10:   1%|▍                              | 4/300 [00:07<09:27,  1.92s/it]T Loss=2.303934097290039\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053910732269287\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050289154052734\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304352283477783\n",
            "g_norm = tensor(0.0822, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304649829864502\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.7458953857422\n",
            "||∇_X meta|| = 0.0036042556166648865\n",
            "ΔX norm: 3.604259836720303e-05\n",
            "Stage 3/10:   2%|▌                              | 5/300 [00:09<09:06,  1.85s/it]T Loss=2.3043951988220215\n",
            "g_norm = tensor(0.1558, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052210807800293\n",
            "g_norm = tensor(0.1696, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304332733154297\n",
            "g_norm = tensor(0.1626, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304466962814331\n",
            "g_norm = tensor(0.1436, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050200939178467\n",
            "g_norm = tensor(0.1599, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.92909240722656\n",
            "||∇_X meta|| = 0.0037249645683914423\n",
            "ΔX norm: 3.724962880369276e-05\n",
            "Stage 3/10:   2%|▌                              | 6/300 [00:11<08:50,  1.80s/it]T Loss=2.3044896125793457\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305328607559204\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304542064666748\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304607391357422\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30454158782959\n",
            "g_norm = tensor(0.1250, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5911407470703\n",
            "||∇_X meta|| = 0.003361344337463379\n",
            "ΔX norm: 3.361351991770789e-05\n",
            "Stage 3/10:   2%|▋                              | 7/300 [00:14<10:22,  2.13s/it]T Loss=2.3055076599121094\n",
            "g_norm = tensor(0.1251, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057162761688232\n",
            "g_norm = tensor(0.1499, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045575618743896\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302351474761963\n",
            "g_norm = tensor(0.1567, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058884143829346\n",
            "g_norm = tensor(0.1304, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.54869079589844\n",
            "||∇_X meta|| = 0.003768616821616888\n",
            "ΔX norm: 3.768609167309478e-05\n",
            "Stage 3/10:   3%|▊                              | 8/300 [00:16<10:21,  2.13s/it]T Loss=2.303872585296631\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303875684738159\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303840398788452\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043160438537598\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303279161453247\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3937530517578\n",
            "||∇_X meta|| = 0.0037386431358754635\n",
            "ΔX norm: 3.7386456824606284e-05\n",
            "Stage 3/10:   3%|▉                              | 9/300 [00:18<09:57,  2.05s/it]T Loss=2.304062843322754\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304097890853882\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304656744003296\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304790496826172\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040897846221924\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.0277862548828\n",
            "||∇_X meta|| = 0.003558364463970065\n",
            "ΔX norm: 3.558361640898511e-05\n",
            "Stage 3/10:   3%|█                             | 10/300 [00:20<10:34,  2.19s/it]T Loss=2.30348539352417\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302558422088623\n",
            "g_norm = tensor(0.1325, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057796955108643\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303737163543701\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032608032226562\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.41534423828125\n",
            "||∇_X meta|| = 0.0033891224302351475\n",
            "ΔX norm: 3.389119592611678e-05\n",
            "Stage 3/10:   4%|█                             | 11/300 [00:22<10:18,  2.14s/it]T Loss=2.3037068843841553\n",
            "g_norm = tensor(0.1253, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021740913391113\n",
            "g_norm = tensor(0.1317, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303799867630005\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041932582855225\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031320571899414\n",
            "g_norm = tensor(0.1348, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5580291748047\n",
            "||∇_X meta|| = 0.0033819263335317373\n",
            "ΔX norm: 3.381925853318535e-05\n",
            "Stage 3/10:   4%|█▏                            | 12/300 [00:24<09:48,  2.04s/it]T Loss=2.302354574203491\n",
            "g_norm = tensor(0.1362, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303248167037964\n",
            "g_norm = tensor(0.1430, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050568103790283\n",
            "g_norm = tensor(0.1404, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054075241088867\n",
            "g_norm = tensor(0.1352, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303457736968994\n",
            "g_norm = tensor(0.1412, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.43138122558594\n",
            "||∇_X meta|| = 0.0031591958831995726\n",
            "ΔX norm: 3.159194966428913e-05\n",
            "Stage 3/10:   4%|█▎                            | 13/300 [00:26<09:09,  1.91s/it]T Loss=2.303363800048828\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030285835266113\n",
            "g_norm = tensor(0.1257, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304680824279785\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303994655609131\n",
            "g_norm = tensor(0.1352, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030052185058594\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.84799194335938\n",
            "||∇_X meta|| = 0.0035153422504663467\n",
            "ΔX norm: 3.5153396311216056e-05\n",
            "Stage 3/10:   5%|█▍                            | 14/300 [00:27<08:36,  1.81s/it]T Loss=2.3026065826416016\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035244941711426\n",
            "g_norm = tensor(0.0848, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30367112159729\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033087253570557\n",
            "g_norm = tensor(0.0830, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303886890411377\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.76231384277344\n",
            "||∇_X meta|| = 0.0036486804019659758\n",
            "ΔX norm: 3.648682832135819e-05\n",
            "Stage 3/10:   5%|█▌                            | 15/300 [00:29<08:15,  1.74s/it]T Loss=2.3026299476623535\n",
            "g_norm = tensor(0.0693, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040990829467773\n",
            "g_norm = tensor(0.0739, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037075996398926\n",
            "g_norm = tensor(0.0767, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033361434936523\n",
            "g_norm = tensor(0.0847, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030219078063965\n",
            "g_norm = tensor(0.0737, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.62881469726562\n",
            "||∇_X meta|| = 0.003186258487403393\n",
            "ΔX norm: 3.186257163179107e-05\n",
            "Stage 3/10:   5%|█▌                            | 16/300 [00:30<08:03,  1.70s/it]T Loss=2.303602695465088\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043229579925537\n",
            "g_norm = tensor(0.1387, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304530382156372\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021445274353027\n",
            "g_norm = tensor(0.1413, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035964965820312\n",
            "g_norm = tensor(0.1323, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7950897216797\n",
            "||∇_X meta|| = 0.0033422557171434164\n",
            "ΔX norm: 3.342253330629319e-05\n",
            "Stage 3/10:   6%|█▋                            | 17/300 [00:32<07:53,  1.67s/it]T Loss=2.3041958808898926\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303558349609375\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037261962890625\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034260272979736\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044419288635254\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.17442321777344\n",
            "||∇_X meta|| = 0.003355150343850255\n",
            "ΔX norm: 3.355148510308936e-05\n",
            "Stage 3/10:   6%|█▊                            | 18/300 [00:34<07:59,  1.70s/it]T Loss=2.302361249923706\n",
            "g_norm = tensor(0.1359, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302241325378418\n",
            "g_norm = tensor(0.1327, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039710521698\n",
            "g_norm = tensor(0.1206, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304673910140991\n",
            "g_norm = tensor(0.1518, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034956455230713\n",
            "g_norm = tensor(0.1547, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.55328369140625\n",
            "||∇_X meta|| = 0.0031231979373842478\n",
            "ΔX norm: 3.123197166132741e-05\n",
            "Stage 3/10:   6%|█▉                            | 19/300 [00:36<07:58,  1.70s/it]T Loss=2.303694248199463\n",
            "g_norm = tensor(0.1420, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036086559295654\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305238723754883\n",
            "g_norm = tensor(0.1372, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30289888381958\n",
            "g_norm = tensor(0.1322, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3061575889587402\n",
            "g_norm = tensor(0.1553, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.05810546875\n",
            "||∇_X meta|| = 0.0036123436875641346\n",
            "ΔX norm: 3.6123445170233026e-05\n",
            "Stage 3/10:   7%|██                            | 20/300 [00:37<07:47,  1.67s/it]T Loss=2.3043551445007324\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044586181640625\n",
            "g_norm = tensor(0.1243, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045992851257324\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045272827148438\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043053150177\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.82078552246094\n",
            "||∇_X meta|| = 0.003179091028869152\n",
            "ΔX norm: 3.179090708727017e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 3/10:   7%|██                            | 21/300 [00:39<08:14,  1.77s/it]T Loss=2.303332805633545\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034191131591797\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029465675354004\n",
            "g_norm = tensor(0.1214, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034396171569824\n",
            "g_norm = tensor(0.1216, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021466732025146\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.46141052246094\n",
            "||∇_X meta|| = 0.0032030774746090174\n",
            "ΔX norm: 3.2030799047788605e-05\n",
            "Stage 3/10:   7%|██▏                           | 22/300 [00:41<08:47,  1.90s/it]T Loss=2.302699089050293\n",
            "g_norm = tensor(0.1394, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023464679718018\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045802116394043\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034868240356445\n",
            "g_norm = tensor(0.1334, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041954040527344\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6327667236328\n",
            "||∇_X meta|| = 0.0033299680799245834\n",
            "ΔX norm: 3.3299711503786966e-05\n",
            "Stage 3/10:   8%|██▎                           | 23/300 [00:43<08:30,  1.84s/it]T Loss=2.3031020164489746\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304327964782715\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302586317062378\n",
            "g_norm = tensor(0.1335, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019094467163086\n",
            "g_norm = tensor(0.1299, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032240867614746\n",
            "g_norm = tensor(0.1388, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.8486785888672\n",
            "||∇_X meta|| = 0.0032556867226958275\n",
            "ΔX norm: 3.255685078329407e-05\n",
            "Stage 3/10:   8%|██▍                           | 24/300 [00:45<08:02,  1.75s/it]T Loss=2.3040809631347656\n",
            "g_norm = tensor(0.0698, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303985118865967\n",
            "g_norm = tensor(0.0880, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033156394958496\n",
            "g_norm = tensor(0.0787, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303818702697754\n",
            "g_norm = tensor(0.0665, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044114112854004\n",
            "g_norm = tensor(0.0663, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.87757873535156\n",
            "||∇_X meta|| = 0.003051450941711664\n",
            "ΔX norm: 3.051449493796099e-05\n",
            "Stage 3/10:   8%|██▌                           | 25/300 [00:46<07:49,  1.71s/it]T Loss=2.3035025596618652\n",
            "g_norm = tensor(0.1540, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039638996124268\n",
            "g_norm = tensor(0.1316, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304617404937744\n",
            "g_norm = tensor(0.1427, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026814460754395\n",
            "g_norm = tensor(0.1413, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047852516174316\n",
            "g_norm = tensor(0.1206, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2145538330078\n",
            "||∇_X meta|| = 0.0031908147502690554\n",
            "ΔX norm: 3.1908199161989614e-05\n",
            "Stage 3/10:   9%|██▌                           | 26/300 [00:48<07:38,  1.67s/it]T Loss=2.303880214691162\n",
            "g_norm = tensor(0.0783, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045525550842285\n",
            "g_norm = tensor(0.0711, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039207458496094\n",
            "g_norm = tensor(0.0791, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034045696258545\n",
            "g_norm = tensor(0.0757, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303506374359131\n",
            "g_norm = tensor(0.0824, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.04493713378906\n",
            "||∇_X meta|| = 0.0029943794943392277\n",
            "ΔX norm: 2.9943765184725635e-05\n",
            "Stage 3/10:   9%|██▋                           | 27/300 [00:49<07:26,  1.64s/it]T Loss=2.3037540912628174\n",
            "g_norm = tensor(0.1436, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032991886138916\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039045333862305\n",
            "g_norm = tensor(0.1648, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045101165771484\n",
            "g_norm = tensor(0.1408, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303657054901123\n",
            "g_norm = tensor(0.1505, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.99371337890625\n",
            "||∇_X meta|| = 0.0029477758798748255\n",
            "ΔX norm: 2.9477751013473608e-05\n",
            "Stage 3/10:   9%|██▊                           | 28/300 [00:52<08:14,  1.82s/it]T Loss=2.3033456802368164\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304069995880127\n",
            "g_norm = tensor(0.1140, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304582118988037\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303666353225708\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304532766342163\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.72621154785156\n",
            "||∇_X meta|| = 0.0029236546251922846\n",
            "ΔX norm: 2.923652937170118e-05\n",
            "Stage 3/10:  10%|██▉                           | 29/300 [00:54<08:54,  1.97s/it]T Loss=2.3028995990753174\n",
            "g_norm = tensor(0.0755, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303189754486084\n",
            "g_norm = tensor(0.0687, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029093742370605\n",
            "g_norm = tensor(0.0705, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30352783203125\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302626132965088\n",
            "g_norm = tensor(0.0727, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.971923828125\n",
            "||∇_X meta|| = 0.0034717852249741554\n",
            "ΔX norm: 3.471784293651581e-05\n",
            "Stage 3/10:  10%|███                           | 30/300 [00:56<08:33,  1.90s/it]T Loss=2.304561138153076\n",
            "g_norm = tensor(0.1605, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304971694946289\n",
            "g_norm = tensor(0.1706, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304509401321411\n",
            "g_norm = tensor(0.1877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303581953048706\n",
            "g_norm = tensor(0.1412, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040335178375244\n",
            "g_norm = tensor(0.1600, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.06472778320312\n",
            "||∇_X meta|| = 0.0031054546125233173\n",
            "ΔX norm: 3.1054558348841965e-05\n",
            "Stage 3/10:  10%|███                           | 31/300 [00:57<08:22,  1.87s/it]T Loss=2.304640054702759\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305320978164673\n",
            "g_norm = tensor(0.1351, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053369522094727\n",
            "g_norm = tensor(0.1286, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304133176803589\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303083896636963\n",
            "g_norm = tensor(0.1318, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.27542114257812\n",
            "||∇_X meta|| = 0.002820417517796159\n",
            "ΔX norm: 2.8204234695294872e-05\n",
            "Stage 3/10:  11%|███▏                          | 32/300 [00:59<08:08,  1.82s/it]T Loss=2.3051514625549316\n",
            "g_norm = tensor(0.1702, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038082122802734\n",
            "g_norm = tensor(0.1603, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301257610321045\n",
            "g_norm = tensor(0.1817, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018226623535156\n",
            "g_norm = tensor(0.1491, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031983375549316\n",
            "g_norm = tensor(0.1471, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.99560546875\n",
            "||∇_X meta|| = 0.0030932801309973\n",
            "ΔX norm: 3.093276245635934e-05\n",
            "Stage 3/10:  11%|███▎                          | 33/300 [01:01<07:58,  1.79s/it]T Loss=2.304114580154419\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026840686798096\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022396564483643\n",
            "g_norm = tensor(0.1328, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303563356399536\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302711009979248\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5375518798828\n",
            "||∇_X meta|| = 0.0028617586940526962\n",
            "ΔX norm: 2.8617538191610947e-05\n",
            "Stage 3/10:  11%|███▍                          | 34/300 [01:03<07:54,  1.78s/it]T Loss=2.3033008575439453\n",
            "g_norm = tensor(0.0829, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303152561187744\n",
            "g_norm = tensor(0.0908, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026576042175293\n",
            "g_norm = tensor(0.0836, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044095039367676\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303755283355713\n",
            "g_norm = tensor(0.0816, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.41676330566406\n",
            "||∇_X meta|| = 0.002697157207876444\n",
            "ΔX norm: 2.6971576517098583e-05\n",
            "Stage 3/10:  12%|███▌                          | 35/300 [01:04<07:57,  1.80s/it]T Loss=2.3049561977386475\n",
            "g_norm = tensor(0.0699, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041884899139404\n",
            "g_norm = tensor(0.0593, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036341667175293\n",
            "g_norm = tensor(0.0704, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041698932647705\n",
            "g_norm = tensor(0.0785, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041744232177734\n",
            "g_norm = tensor(0.0679, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1414337158203\n",
            "||∇_X meta|| = 0.0027826842851936817\n",
            "ΔX norm: 2.7826828954857774e-05\n",
            "Stage 3/10:  12%|███▌                          | 36/300 [01:06<07:47,  1.77s/it]T Loss=2.303946018218994\n",
            "g_norm = tensor(0.1572, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035645484924316\n",
            "g_norm = tensor(0.1258, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304509401321411\n",
            "g_norm = tensor(0.1319, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036201000213623\n",
            "g_norm = tensor(0.1565, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304980516433716\n",
            "g_norm = tensor(0.1402, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7403564453125\n",
            "||∇_X meta|| = 0.0030316507909446955\n",
            "ΔX norm: 3.03164852084592e-05\n",
            "Stage 3/10:  12%|███▋                          | 37/300 [01:08<08:02,  1.83s/it]T Loss=2.3036739826202393\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033294677734375\n",
            "g_norm = tensor(0.0732, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028225898742676\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032774925231934\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304414987564087\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6973114013672\n",
            "||∇_X meta|| = 0.002739118877798319\n",
            "ΔX norm: 2.739117553574033e-05\n",
            "Stage 3/10:  13%|███▊                          | 38/300 [01:10<07:53,  1.81s/it]T Loss=2.3036370277404785\n",
            "g_norm = tensor(0.0742, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034849166870117\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302595615386963\n",
            "g_norm = tensor(0.0760, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031744956970215\n",
            "g_norm = tensor(0.0759, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033666610717773\n",
            "g_norm = tensor(0.0762, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.53768920898438\n",
            "||∇_X meta|| = 0.002541883150115609\n",
            "ΔX norm: 2.5418818040634505e-05\n",
            "Stage 3/10:  13%|███▉                          | 39/300 [01:12<07:43,  1.78s/it]T Loss=2.3036282062530518\n",
            "g_norm = tensor(0.0879, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043782711029053\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304131031036377\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041393756866455\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042235374450684\n",
            "g_norm = tensor(0.0846, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2739715576172\n",
            "||∇_X meta|| = 0.00250120647251606\n",
            "ΔX norm: 2.501205563021358e-05\n",
            "Stage 3/10:  13%|████                          | 40/300 [01:13<07:37,  1.76s/it]T Loss=2.3037917613983154\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304847002029419\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043549060821533\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303635835647583\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303061008453369\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3990478515625\n",
            "||∇_X meta|| = 0.0027426001615822315\n",
            "ΔX norm: 2.742601282079704e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 3/10:  14%|████                          | 41/300 [01:15<07:31,  1.74s/it]T Loss=2.3037166595458984\n",
            "g_norm = tensor(0.0803, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303335189819336\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034586906433105\n",
            "g_norm = tensor(0.0731, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302980661392212\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036537170410156\n",
            "g_norm = tensor(0.0853, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3645477294922\n",
            "||∇_X meta|| = 0.002579024061560631\n",
            "ΔX norm: 2.579027568572201e-05\n",
            "Stage 3/10:  14%|████▏                         | 42/300 [01:17<08:06,  1.88s/it]T Loss=2.3034987449645996\n",
            "g_norm = tensor(0.1533, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025522232055664\n",
            "g_norm = tensor(0.1402, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056390285491943\n",
            "g_norm = tensor(0.1734, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023228645324707\n",
            "g_norm = tensor(0.1454, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036551475524902\n",
            "g_norm = tensor(0.1807, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0619354248047\n",
            "||∇_X meta|| = 0.0026695686392486095\n",
            "ΔX norm: 2.6695655833464116e-05\n",
            "Stage 3/10:  14%|████▎                         | 43/300 [01:19<07:59,  1.87s/it]T Loss=2.3036062717437744\n",
            "g_norm = tensor(0.0696, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303095817565918\n",
            "g_norm = tensor(0.0798, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033440113067627\n",
            "g_norm = tensor(0.0704, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032116889953613\n",
            "g_norm = tensor(0.0643, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304656744003296\n",
            "g_norm = tensor(0.0688, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.72361755371094\n",
            "||∇_X meta|| = 0.0028726549353450537\n",
            "ΔX norm: 2.872655022656545e-05\n",
            "Stage 3/10:  15%|████▍                         | 44/300 [01:21<07:39,  1.80s/it]T Loss=2.3039908409118652\n",
            "g_norm = tensor(0.1427, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036465644836426\n",
            "g_norm = tensor(0.1535, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036065101623535\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042101860046387\n",
            "g_norm = tensor(0.1307, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040974140167236\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.05067443847656\n",
            "||∇_X meta|| = 0.0024614387657493353\n",
            "ΔX norm: 2.4614402718725614e-05\n",
            "Stage 3/10:  15%|████▌                         | 45/300 [01:22<07:19,  1.72s/it]T Loss=2.302165985107422\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036770820617676\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030829429626465\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039088249206543\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027985095977783\n",
            "g_norm = tensor(0.0683, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.94410705566406\n",
            "||∇_X meta|| = 0.0027286014519631863\n",
            "ΔX norm: 2.7285988835501485e-05\n",
            "Stage 3/10:  15%|████▌                         | 46/300 [01:24<07:08,  1.69s/it]T Loss=2.303663969039917\n",
            "g_norm = tensor(0.1788, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027286529541016\n",
            "g_norm = tensor(0.1467, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028628826141357\n",
            "g_norm = tensor(0.1541, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036911487579346\n",
            "g_norm = tensor(0.1364, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036763668060303\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.03843688964844\n",
            "||∇_X meta|| = 0.0023489741142839193\n",
            "ΔX norm: 2.3489707018597983e-05\n",
            "Stage 3/10:  16%|████▋                         | 47/300 [01:25<07:01,  1.67s/it]T Loss=2.303703546524048\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304330587387085\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303737163543701\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302659511566162\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303457736968994\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7958221435547\n",
            "||∇_X meta|| = 0.0029501081444323063\n",
            "ΔX norm: 2.9501105018425733e-05\n",
            "Stage 3/10:  16%|████▊                         | 48/300 [01:27<06:59,  1.66s/it]T Loss=2.3037147521972656\n",
            "g_norm = tensor(0.0853, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038744926452637\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036646842956543\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050386905670166\n",
            "g_norm = tensor(0.1011, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303997039794922\n",
            "g_norm = tensor(0.0873, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.04344177246094\n",
            "||∇_X meta|| = 0.0022710973862558603\n",
            "ΔX norm: 2.271097582706716e-05\n",
            "Stage 3/10:  16%|████▉                         | 49/300 [01:29<06:56,  1.66s/it]T Loss=2.306621551513672\n",
            "g_norm = tensor(0.1296, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028440475463867\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038406372070312\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043229579925537\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304555654525757\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.1194610595703\n",
            "||∇_X meta|| = 0.0026761835906654596\n",
            "ΔX norm: 2.6761785193230025e-05\n",
            "Stage 3/10:  17%|█████                         | 50/300 [01:31<07:01,  1.69s/it]T Loss=2.304486036300659\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304802417755127\n",
            "g_norm = tensor(0.1263, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303618907928467\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303877353668213\n",
            "g_norm = tensor(0.0941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033623695373535\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.34710693359375\n",
            "||∇_X meta|| = 0.002461562165990472\n",
            "ΔX norm: 2.4615654183435254e-05\n",
            "Stage 3/10:  17%|█████                         | 51/300 [01:32<06:55,  1.67s/it]T Loss=2.3028435707092285\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303785800933838\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032124042510986\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303689479827881\n",
            "g_norm = tensor(0.1385, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303565502166748\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4040985107422\n",
            "||∇_X meta|| = 0.0024896683171391487\n",
            "ΔX norm: 2.489668804628309e-05\n",
            "Stage 3/10:  17%|█████▏                        | 52/300 [01:34<07:06,  1.72s/it]T Loss=2.3020026683807373\n",
            "g_norm = tensor(0.1392, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026607036590576\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028616905212402\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032803535461426\n",
            "g_norm = tensor(0.1345, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026857376098633\n",
            "g_norm = tensor(0.1263, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.09893798828125\n",
            "||∇_X meta|| = 0.0023844344541430473\n",
            "ΔX norm: 2.384430990787223e-05\n",
            "Stage 3/10:  18%|█████▎                        | 53/300 [01:36<07:17,  1.77s/it]T Loss=2.304595470428467\n",
            "g_norm = tensor(0.1099, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052477836608887\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042445182800293\n",
            "g_norm = tensor(0.0956, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041412830352783\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043293952941895\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0701446533203\n",
            "||∇_X meta|| = 0.002615425270050764\n",
            "ΔX norm: 2.6154291845159605e-05\n",
            "Stage 3/10:  18%|█████▍                        | 54/300 [01:38<07:05,  1.73s/it]T Loss=2.3034861087799072\n",
            "g_norm = tensor(0.0829, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035261631011963\n",
            "g_norm = tensor(0.0797, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029184341430664\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303464412689209\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039448261260986\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.12901306152344\n",
            "||∇_X meta|| = 0.0021990088280290365\n",
            "ΔX norm: 2.199005575675983e-05\n",
            "Stage 3/10:  18%|█████▌                        | 55/300 [01:39<07:01,  1.72s/it]T Loss=2.305408000946045\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036112785339355\n",
            "g_norm = tensor(0.1206, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040828704833984\n",
            "g_norm = tensor(0.1379, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038547039031982\n",
            "g_norm = tensor(0.1376, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303910493850708\n",
            "g_norm = tensor(0.1230, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7531280517578\n",
            "||∇_X meta|| = 0.0025278187822550535\n",
            "ΔX norm: 2.5278182874899358e-05\n",
            "Stage 3/10:  19%|█████▌                        | 56/300 [01:41<07:01,  1.73s/it]T Loss=2.302062511444092\n",
            "g_norm = tensor(0.1234, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035800457000732\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040175437927246\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032383918762207\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303891658782959\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.80711364746094\n",
            "||∇_X meta|| = 0.002408702624961734\n",
            "ΔX norm: 2.4087048586807214e-05\n",
            "Stage 3/10:  19%|█████▋                        | 57/300 [01:43<06:58,  1.72s/it]T Loss=2.3039305210113525\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037493228912354\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048601150512695\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303403377532959\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304046154022217\n",
            "g_norm = tensor(0.0781, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.17901611328125\n",
            "||∇_X meta|| = 0.002510983729735017\n",
            "ΔX norm: 2.510984631953761e-05\n",
            "Stage 3/10:  19%|█████▊                        | 58/300 [01:44<06:46,  1.68s/it]T Loss=2.3044967651367188\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035380840301514\n",
            "g_norm = tensor(0.1364, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030378818511963\n",
            "g_norm = tensor(0.1316, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038182258605957\n",
            "g_norm = tensor(0.1452, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304708957672119\n",
            "g_norm = tensor(0.1670, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.23880004882812\n",
            "||∇_X meta|| = 0.002828488126397133\n",
            "ΔX norm: 2.8284925065236166e-05\n",
            "Stage 3/10:  20%|█████▉                        | 59/300 [01:46<06:37,  1.65s/it]T Loss=2.303229331970215\n",
            "g_norm = tensor(0.1410, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303096055984497\n",
            "g_norm = tensor(0.1139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306246280670166\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040273189544678\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3061861991882324\n",
            "g_norm = tensor(0.1292, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.83116149902344\n",
            "||∇_X meta|| = 0.00243859039619565\n",
            "ΔX norm: 2.4385908545809798e-05\n",
            "Stage 3/10:  20%|██████                        | 60/300 [01:47<06:29,  1.62s/it]T Loss=2.3027732372283936\n",
            "g_norm = tensor(0.1546, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050174713134766\n",
            "g_norm = tensor(0.1620, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303062915802002\n",
            "g_norm = tensor(0.1471, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302816390991211\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303680419921875\n",
            "g_norm = tensor(0.1206, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.12811279296875\n",
            "||∇_X meta|| = 0.002155429683625698\n",
            "ΔX norm: 2.155433685402386e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 3/10:  20%|██████                        | 61/300 [01:49<06:29,  1.63s/it]T Loss=2.304145336151123\n",
            "g_norm = tensor(0.0714, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30293869972229\n",
            "g_norm = tensor(0.0801, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031067848205566\n",
            "g_norm = tensor(0.0752, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304065227508545\n",
            "g_norm = tensor(0.0796, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303558111190796\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.89974975585938\n",
            "||∇_X meta|| = 0.0021522254683077335\n",
            "ΔX norm: 2.152225533791352e-05\n",
            "Stage 3/10:  21%|██████▏                       | 62/300 [01:51<07:05,  1.79s/it]T Loss=2.303039789199829\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032195568084717\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030126094818115\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303678035736084\n",
            "g_norm = tensor(0.1295, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034353256225586\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.05328369140625\n",
            "||∇_X meta|| = 0.0024682774674147367\n",
            "ΔX norm: 2.46827767114155e-05\n",
            "Stage 3/10:  21%|██████▎                       | 63/300 [01:54<08:10,  2.07s/it]T Loss=2.304471254348755\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047266006469727\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038618564605713\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301953077316284\n",
            "g_norm = tensor(0.1345, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043007850646973\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.93971252441406\n",
            "||∇_X meta|| = 0.0024197108577936888\n",
            "ΔX norm: 2.419710835965816e-05\n",
            "Stage 3/10:  21%|██████▍                       | 64/300 [01:56<07:53,  2.01s/it]T Loss=2.3031976222991943\n",
            "g_norm = tensor(0.1263, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026034832000732\n",
            "g_norm = tensor(0.1497, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303204298019409\n",
            "g_norm = tensor(0.1619, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304192066192627\n",
            "g_norm = tensor(0.1282, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302616596221924\n",
            "g_norm = tensor(0.1397, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.32240295410156\n",
            "||∇_X meta|| = 0.002287094248458743\n",
            "ΔX norm: 2.287099414388649e-05\n",
            "Stage 3/10:  22%|██████▌                       | 65/300 [01:58<07:48,  1.99s/it]T Loss=2.303851366043091\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040120601654053\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037524223327637\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032515048980713\n",
            "g_norm = tensor(0.1357, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039631843566895\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.91366577148438\n",
            "||∇_X meta|| = 0.0021968374494463205\n",
            "ΔX norm: 2.196840796386823e-05\n",
            "Stage 3/10:  22%|██████▌                       | 66/300 [01:59<07:27,  1.91s/it]T Loss=2.303405284881592\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041958808898926\n",
            "g_norm = tensor(0.1419, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036208152770996\n",
            "g_norm = tensor(0.1289, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035521507263184\n",
            "g_norm = tensor(0.1630, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303187608718872\n",
            "g_norm = tensor(0.1396, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.755615234375\n",
            "||∇_X meta|| = 0.0026175568345934153\n",
            "ΔX norm: 2.6175554012297653e-05\n",
            "Stage 3/10:  22%|██████▋                       | 67/300 [02:01<07:10,  1.85s/it]T Loss=2.305515766143799\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303633451461792\n",
            "g_norm = tensor(0.0923, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305614948272705\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303982734680176\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304746150970459\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.02720642089844\n",
            "||∇_X meta|| = 0.002258329652249813\n",
            "ΔX norm: 2.258324639115017e-05\n",
            "Stage 3/10:  23%|██████▊                       | 68/300 [02:03<06:57,  1.80s/it]T Loss=2.3029892444610596\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031005859375\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30159330368042\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303915500640869\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304969549179077\n",
            "g_norm = tensor(0.1459, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.59854125976562\n",
            "||∇_X meta|| = 0.002436690963804722\n",
            "ΔX norm: 2.4366885554627515e-05\n",
            "Stage 3/10:  23%|██████▉                       | 69/300 [02:04<06:43,  1.75s/it]T Loss=2.3038432598114014\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303783416748047\n",
            "g_norm = tensor(0.1400, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035871982574463\n",
            "g_norm = tensor(0.1382, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302773952484131\n",
            "g_norm = tensor(0.1405, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038668632507324\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4916534423828\n",
            "||∇_X meta|| = 0.002619176171720028\n",
            "ΔX norm: 2.6191790311713703e-05\n",
            "Stage 3/10:  23%|███████                       | 70/300 [02:06<06:37,  1.73s/it]T Loss=2.303474187850952\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303774356842041\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032898902893066\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303586959838867\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028531074523926\n",
            "g_norm = tensor(0.1409, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.46270751953125\n",
            "||∇_X meta|| = 0.0026495608035475016\n",
            "ΔX norm: 2.6495559723116457e-05\n",
            "Stage 3/10:  24%|███████                       | 71/300 [02:08<06:35,  1.73s/it]T Loss=2.3042359352111816\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304563522338867\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304778575897217\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044254779815674\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038151264190674\n",
            "g_norm = tensor(0.0793, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4530029296875\n",
            "||∇_X meta|| = 0.0020623498130589724\n",
            "ΔX norm: 2.0623509044526145e-05\n",
            "Stage 3/10:  24%|███████▏                      | 72/300 [02:09<06:26,  1.69s/it]T Loss=2.303968667984009\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303821563720703\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040709495544434\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304263114929199\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035852909088135\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.32626342773438\n",
            "||∇_X meta|| = 0.0021290385629981756\n",
            "ΔX norm: 2.12903723877389e-05\n",
            "Stage 3/10:  24%|███████▎                      | 73/300 [02:11<06:24,  1.69s/it]T Loss=2.304919719696045\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046038150787354\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046765327453613\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045365810394287\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304175853729248\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.19168090820312\n",
            "||∇_X meta|| = 0.0020596671383827925\n",
            "ΔX norm: 2.059667713183444e-05\n",
            "Stage 3/10:  25%|███████▍                      | 74/300 [02:13<06:25,  1.71s/it]T Loss=2.3037004470825195\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038182258605957\n",
            "g_norm = tensor(0.0960, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304370403289795\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304455280303955\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303117275238037\n",
            "g_norm = tensor(0.1118, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4894561767578\n",
            "||∇_X meta|| = 0.0021186054218560457\n",
            "ΔX norm: 2.1186069716350175e-05\n",
            "Stage 3/10:  25%|███████▌                      | 75/300 [02:15<06:51,  1.83s/it]T Loss=2.3026487827301025\n",
            "g_norm = tensor(0.0778, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031115531921387\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034920692443848\n",
            "g_norm = tensor(0.0755, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031134605407715\n",
            "g_norm = tensor(0.0849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302093505859375\n",
            "g_norm = tensor(0.1110, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.0147247314453\n",
            "||∇_X meta|| = 0.0026425784453749657\n",
            "ΔX norm: 2.6425761461723596e-05\n",
            "Stage 3/10:  25%|███████▌                      | 76/300 [02:17<06:51,  1.84s/it]T Loss=2.3019840717315674\n",
            "g_norm = tensor(0.1350, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034451007843018\n",
            "g_norm = tensor(0.1359, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304206371307373\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037400245666504\n",
            "g_norm = tensor(0.1531, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301919460296631\n",
            "g_norm = tensor(0.1324, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8763427734375\n",
            "||∇_X meta|| = 0.0021624562796205282\n",
            "ΔX norm: 2.1624546207021922e-05\n",
            "Stage 3/10:  26%|███████▋                      | 77/300 [02:19<06:40,  1.80s/it]T Loss=2.305335521697998\n",
            "g_norm = tensor(0.1153, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305037260055542\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043644428253174\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048105239868164\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044686317443848\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.21604919433594\n",
            "||∇_X meta|| = 0.0019462024793028831\n",
            "ΔX norm: 1.9462026102701202e-05\n",
            "Stage 3/10:  26%|███████▊                      | 78/300 [02:20<06:38,  1.79s/it]T Loss=2.304741382598877\n",
            "g_norm = tensor(0.1353, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305138349533081\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303828716278076\n",
            "g_norm = tensor(0.1327, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051018714904785\n",
            "g_norm = tensor(0.1423, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304431438446045\n",
            "g_norm = tensor(0.1318, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.21926879882812\n",
            "||∇_X meta|| = 0.002026523696258664\n",
            "ΔX norm: 2.0265266357455403e-05\n",
            "Stage 3/10:  26%|███████▉                      | 79/300 [02:22<06:26,  1.75s/it]T Loss=2.3026211261749268\n",
            "g_norm = tensor(0.0789, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029656410217285\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030178546905518\n",
            "g_norm = tensor(0.0804, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303205966949463\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037185668945312\n",
            "g_norm = tensor(0.0833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.61233520507812\n",
            "||∇_X meta|| = 0.0020287525840103626\n",
            "ΔX norm: 2.028752351179719e-05\n",
            "Stage 3/10:  27%|████████                      | 80/300 [02:24<06:26,  1.76s/it]T Loss=2.3042988777160645\n",
            "g_norm = tensor(0.0652, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044662475585938\n",
            "g_norm = tensor(0.0856, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036386966705322\n",
            "g_norm = tensor(0.0791, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304560661315918\n",
            "g_norm = tensor(0.0865, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047919273376465\n",
            "g_norm = tensor(0.0801, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9093780517578\n",
            "||∇_X meta|| = 0.0018702966626733541\n",
            "ΔX norm: 1.870292726380285e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 3/10:  27%|████████                      | 81/300 [02:26<06:32,  1.79s/it]T Loss=2.3045551776885986\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029189109802246\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029487133026123\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303576707839966\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303481340408325\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1517333984375\n",
            "||∇_X meta|| = 0.0021195814479142427\n",
            "ΔX norm: 2.119579767168034e-05\n",
            "Stage 3/10:  27%|████████▏                     | 82/300 [02:28<06:57,  1.92s/it]T Loss=2.3044180870056152\n",
            "g_norm = tensor(0.0829, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304541826248169\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033924102783203\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043036460876465\n",
            "g_norm = tensor(0.0844, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044273853302\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.94923400878906\n",
            "||∇_X meta|| = 0.0021336646750569344\n",
            "ΔX norm: 2.1336669306037948e-05\n",
            "Stage 3/10:  28%|████████▎                     | 83/300 [02:30<06:59,  1.93s/it]T Loss=2.3044402599334717\n",
            "g_norm = tensor(0.0822, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304443120956421\n",
            "g_norm = tensor(0.0798, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046467304229736\n",
            "g_norm = tensor(0.0799, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304241180419922\n",
            "g_norm = tensor(0.0858, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057000637054443\n",
            "g_norm = tensor(0.0784, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.15699768066406\n",
            "||∇_X meta|| = 0.0019397605210542679\n",
            "ΔX norm: 1.9397595679038204e-05\n",
            "Stage 3/10:  28%|████████▍                     | 84/300 [02:32<06:40,  1.85s/it]T Loss=2.3033697605133057\n",
            "g_norm = tensor(0.1453, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302370548248291\n",
            "g_norm = tensor(0.1218, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303152561187744\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040947914123535\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020215034484863\n",
            "g_norm = tensor(0.1436, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0986785888672\n",
            "||∇_X meta|| = 0.002059456193819642\n",
            "ΔX norm: 2.059454891423229e-05\n",
            "Stage 3/10:  28%|████████▌                     | 85/300 [02:33<06:34,  1.83s/it]T Loss=2.3032193183898926\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304462194442749\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020339012145996\n",
            "g_norm = tensor(0.1103, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304333448410034\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303942918777466\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9397735595703\n",
            "||∇_X meta|| = 0.002314790850505233\n",
            "ΔX norm: 2.3147886167862453e-05\n",
            "Stage 3/10:  29%|████████▌                     | 86/300 [02:35<06:18,  1.77s/it]T Loss=2.302696466445923\n",
            "g_norm = tensor(0.0841, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031811714172363\n",
            "g_norm = tensor(0.0686, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030810356140137\n",
            "g_norm = tensor(0.0752, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026480674743652\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028371334075928\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3911590576172\n",
            "||∇_X meta|| = 0.0021784924902021885\n",
            "ΔX norm: 2.1784942873637192e-05\n",
            "Stage 3/10:  29%|████████▋                     | 87/300 [02:37<06:46,  1.91s/it]T Loss=2.303778886795044\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043782711029053\n",
            "g_norm = tensor(0.1295, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045554161071777\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305197238922119\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049354553222656\n",
            "g_norm = tensor(0.1465, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.58250427246094\n",
            "||∇_X meta|| = 0.0019273514626547694\n",
            "ΔX norm: 1.927348057506606e-05\n",
            "Stage 3/10:  29%|████████▊                     | 88/300 [02:39<06:32,  1.85s/it]T Loss=2.3028316497802734\n",
            "g_norm = tensor(0.1562, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303239345550537\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030288219451904\n",
            "g_norm = tensor(0.1372, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304248332977295\n",
            "g_norm = tensor(0.1282, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037030696868896\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.06861877441406\n",
            "||∇_X meta|| = 0.0021419052500277758\n",
            "ΔX norm: 2.1419018594315276e-05\n",
            "Stage 3/10:  30%|████████▉                     | 89/300 [02:40<06:14,  1.77s/it]T Loss=2.303978443145752\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047165870666504\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037681579589844\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050119876861572\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304570198059082\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.93951416015625\n",
            "||∇_X meta|| = 0.0020369833800941706\n",
            "ΔX norm: 2.0369845515233465e-05\n",
            "Stage 3/10:  30%|█████████                     | 90/300 [02:42<06:05,  1.74s/it]T Loss=2.303866147994995\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302987575531006\n",
            "g_norm = tensor(0.0908, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302999973297119\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303039073944092\n",
            "g_norm = tensor(0.1216, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303096055984497\n",
            "g_norm = tensor(0.0980, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.88331604003906\n",
            "||∇_X meta|| = 0.0019269533222541213\n",
            "ΔX norm: 1.9269506083219312e-05\n",
            "Stage 3/10:  30%|█████████                     | 91/300 [02:44<06:01,  1.73s/it]T Loss=2.304474353790283\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047804832458496\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043301105499268\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304884910583496\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043324947357178\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.58717346191406\n",
            "||∇_X meta|| = 0.0020964890718460083\n",
            "ΔX norm: 2.0964893337804824e-05\n",
            "Stage 3/10:  31%|█████████▏                    | 92/300 [02:46<05:59,  1.73s/it]T Loss=2.302370548248291\n",
            "g_norm = tensor(0.1510, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045811653137207\n",
            "g_norm = tensor(0.1409, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304398775100708\n",
            "g_norm = tensor(0.1538, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304137706756592\n",
            "g_norm = tensor(0.1583, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043506145477295\n",
            "g_norm = tensor(0.1614, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.738525390625\n",
            "||∇_X meta|| = 0.001822062418796122\n",
            "ΔX norm: 1.822060403355863e-05\n",
            "Stage 3/10:  31%|█████████▎                    | 93/300 [02:48<06:34,  1.91s/it]T Loss=2.305215358734131\n",
            "g_norm = tensor(0.1804, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046412467956543\n",
            "g_norm = tensor(0.1380, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046348094940186\n",
            "g_norm = tensor(0.1322, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303591728210449\n",
            "g_norm = tensor(0.1522, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30564022064209\n",
            "g_norm = tensor(0.1623, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.78195190429688\n",
            "||∇_X meta|| = 0.0019465357763692737\n",
            "ΔX norm: 1.946529846463818e-05\n",
            "Stage 3/10:  31%|█████████▍                    | 94/300 [02:51<07:26,  2.17s/it]T Loss=2.3033738136291504\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303924322128296\n",
            "g_norm = tensor(0.0890, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041861057281494\n",
            "g_norm = tensor(0.0767, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30370831489563\n",
            "g_norm = tensor(0.0858, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30387282371521\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4742431640625\n",
            "||∇_X meta|| = 0.0020034753251820803\n",
            "ΔX norm: 2.003474764933344e-05\n",
            "Stage 3/10:  32%|█████████▌                    | 95/300 [02:54<08:20,  2.44s/it]T Loss=2.303382396697998\n",
            "g_norm = tensor(0.0760, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037142753601074\n",
            "g_norm = tensor(0.0777, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045272827148438\n",
            "g_norm = tensor(0.0845, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050739765167236\n",
            "g_norm = tensor(0.0758, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045177459716797\n",
            "g_norm = tensor(0.0718, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.61325073242188\n",
            "||∇_X meta|| = 0.0019049023976549506\n",
            "ΔX norm: 1.9049022739636712e-05\n",
            "Stage 3/10:  32%|█████████▌                    | 96/300 [02:57<09:05,  2.67s/it]T Loss=2.3055129051208496\n",
            "g_norm = tensor(0.1764, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040976524353027\n",
            "g_norm = tensor(0.1531, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305040121078491\n",
            "g_norm = tensor(0.1773, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304356336593628\n",
            "g_norm = tensor(0.1435, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30605149269104\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =233.04368591308594\n",
            "||∇_X meta|| = 0.0020518151577562094\n",
            "ΔX norm: 2.0518147721304558e-05\n",
            "Stage 3/10:  32%|█████████▋                    | 97/300 [02:59<08:29,  2.51s/it]T Loss=2.3055741786956787\n",
            "g_norm = tensor(0.1377, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3063955307006836\n",
            "g_norm = tensor(0.1458, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030991554260254\n",
            "g_norm = tensor(0.1316, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304142951965332\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032829761505127\n",
            "g_norm = tensor(0.1560, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.47149658203125\n",
            "||∇_X meta|| = 0.0018019845010712743\n",
            "ΔX norm: 1.8019800336332992e-05\n",
            "Stage 3/10:  33%|█████████▊                    | 98/300 [03:01<07:42,  2.29s/it]T Loss=2.304137706756592\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304483413696289\n",
            "g_norm = tensor(0.0746, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041887283325195\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038711547851562\n",
            "g_norm = tensor(0.0856, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304232597351074\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.8070526123047\n",
            "||∇_X meta|| = 0.0018826257437467575\n",
            "ΔX norm: 1.8826243831426837e-05\n",
            "Stage 3/10:  33%|█████████▉                    | 99/300 [03:03<07:06,  2.12s/it]T Loss=2.304035186767578\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304503917694092\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044002056121826\n",
            "g_norm = tensor(0.1345, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052875995635986\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304173231124878\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5446014404297\n",
            "||∇_X meta|| = 0.002100848825648427\n",
            "ΔX norm: 2.1008452677051537e-05\n",
            "Stage 3/10:  33%|█████████▋                   | 100/300 [03:05<07:28,  2.24s/it]T Loss=2.302602529525757\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032774925231934\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303318500518799\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029773235321045\n",
            "g_norm = tensor(0.1118, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302520751953125\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.89187622070312\n",
            "||∇_X meta|| = 0.0018128525698557496\n",
            "ΔX norm: 1.8128524970961735e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 3/10:  34%|█████████▊                   | 101/300 [03:07<07:32,  2.28s/it]T Loss=2.3024744987487793\n",
            "g_norm = tensor(0.1446, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031163215637207\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303295135498047\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3010659217834473\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303325653076172\n",
            "g_norm = tensor(0.1273, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9474639892578\n",
            "||∇_X meta|| = 0.0020948597230017185\n",
            "ΔX norm: 2.0948564269929193e-05\n",
            "Stage 3/10:  34%|█████████▊                   | 102/300 [03:10<07:45,  2.35s/it]T Loss=2.3041164875030518\n",
            "g_norm = tensor(0.1312, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305882215499878\n",
            "g_norm = tensor(0.1347, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051438331604004\n",
            "g_norm = tensor(0.1670, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053805828094482\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304353952407837\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.80393981933594\n",
            "||∇_X meta|| = 0.0021428330801427364\n",
            "ΔX norm: 2.1428417312563397e-05\n",
            "Stage 3/10:  34%|█████████▉                   | 103/300 [03:12<07:15,  2.21s/it]T Loss=2.3030030727386475\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304206371307373\n",
            "g_norm = tensor(0.0983, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304548740386963\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304609775543213\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036484718322754\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1503143310547\n",
            "||∇_X meta|| = 0.0018128841184079647\n",
            "ΔX norm: 1.8128863302990794e-05\n",
            "Stage 3/10:  35%|██████████                   | 104/300 [03:14<07:10,  2.20s/it]T Loss=2.303619861602783\n",
            "g_norm = tensor(0.1348, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304530620574951\n",
            "g_norm = tensor(0.1374, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30383038520813\n",
            "g_norm = tensor(0.1585, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039722442626953\n",
            "g_norm = tensor(0.1367, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035407066345215\n",
            "g_norm = tensor(0.1567, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2811737060547\n",
            "||∇_X meta|| = 0.001872562919743359\n",
            "ΔX norm: 1.8725631889537908e-05\n",
            "Stage 3/10:  35%|██████████▏                  | 105/300 [03:16<06:41,  2.06s/it]T Loss=2.303992986679077\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303652048110962\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039207458496094\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303809642791748\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037946224212646\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.896484375\n",
            "||∇_X meta|| = 0.001942461240105331\n",
            "ΔX norm: 1.9424605852691457e-05\n",
            "Stage 3/10:  35%|██████████▏                  | 106/300 [03:18<06:21,  1.97s/it]T Loss=2.304595470428467\n",
            "g_norm = tensor(0.1157, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042914867401123\n",
            "g_norm = tensor(0.1110, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303593158721924\n",
            "g_norm = tensor(0.1021, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303428888320923\n",
            "g_norm = tensor(0.0831, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303260326385498\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.16079711914062\n",
            "||∇_X meta|| = 0.0019894959405064583\n",
            "ΔX norm: 1.989489101106301e-05\n",
            "Stage 3/10:  36%|██████████▎                  | 107/300 [03:19<06:03,  1.88s/it]T Loss=2.3052611351013184\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048348426818848\n",
            "g_norm = tensor(0.1370, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040342330932617\n",
            "g_norm = tensor(0.1110, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304495334625244\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303468704223633\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.69281005859375\n",
            "||∇_X meta|| = 0.0018320349045097828\n",
            "ΔX norm: 1.8320373783353716e-05\n",
            "Stage 3/10:  36%|██████████▍                  | 108/300 [03:21<05:54,  1.85s/it]T Loss=2.3039634227752686\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039355278015137\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303624391555786\n",
            "g_norm = tensor(0.0941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049089908599854\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043558597564697\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.52685546875\n",
            "||∇_X meta|| = 0.0017813830636441708\n",
            "ΔX norm: 1.781384889909532e-05\n",
            "Stage 3/10:  36%|██████████▌                  | 109/300 [03:23<05:44,  1.80s/it]T Loss=2.304349660873413\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046040534973145\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023874759674072\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032662868499756\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035964965820312\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.43423461914062\n",
            "||∇_X meta|| = 0.001866222359240055\n",
            "ΔX norm: 1.8662249203771353e-05\n",
            "Stage 3/10:  37%|██████████▋                  | 110/300 [03:24<05:35,  1.76s/it]T Loss=2.3048882484436035\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050289154052734\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305696964263916\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038487434387207\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049087524414062\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.59226989746094\n",
            "||∇_X meta|| = 0.0018946261843666434\n",
            "ΔX norm: 1.8946240743389353e-05\n",
            "Stage 3/10:  37%|██████████▋                  | 111/300 [03:26<05:32,  1.76s/it]T Loss=2.302814483642578\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035709857940674\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035552501678467\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034861087799072\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304588794708252\n",
            "g_norm = tensor(0.1210, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.18878173828125\n",
            "||∇_X meta|| = 0.001730190240778029\n",
            "ΔX norm: 1.730189978843555e-05\n",
            "Stage 3/10:  37%|██████████▊                  | 112/300 [03:28<05:26,  1.73s/it]T Loss=2.3029768466949463\n",
            "g_norm = tensor(0.0753, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303269386291504\n",
            "g_norm = tensor(0.0831, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303579807281494\n",
            "g_norm = tensor(0.0766, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302720069885254\n",
            "g_norm = tensor(0.0698, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302999973297119\n",
            "g_norm = tensor(0.0757, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4129180908203\n",
            "||∇_X meta|| = 0.0017237537540495396\n",
            "ΔX norm: 1.7237538486369886e-05\n",
            "Stage 3/10:  38%|██████████▉                  | 113/300 [03:29<05:21,  1.72s/it]T Loss=2.3028621673583984\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303408145904541\n",
            "g_norm = tensor(0.0738, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303511142730713\n",
            "g_norm = tensor(0.0692, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303196907043457\n",
            "g_norm = tensor(0.0708, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035290241241455\n",
            "g_norm = tensor(0.0846, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.81820678710938\n",
            "||∇_X meta|| = 0.0018352029146626592\n",
            "ΔX norm: 1.8352013285038993e-05\n",
            "Stage 3/10:  38%|███████████                  | 114/300 [03:31<05:13,  1.69s/it]T Loss=2.30403995513916\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047919273376465\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302359104156494\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303025245666504\n",
            "g_norm = tensor(0.1219, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043227195739746\n",
            "g_norm = tensor(0.1440, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.02455139160156\n",
            "||∇_X meta|| = 0.001732097240164876\n",
            "ΔX norm: 1.7320955521427095e-05\n",
            "Stage 3/10:  38%|███████████                  | 115/300 [03:33<05:12,  1.69s/it]T Loss=2.304065465927124\n",
            "g_norm = tensor(0.1522, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304624080657959\n",
            "g_norm = tensor(0.1713, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303194999694824\n",
            "g_norm = tensor(0.1457, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039028644561768\n",
            "g_norm = tensor(0.1234, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303323745727539\n",
            "g_norm = tensor(0.1374, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.91497802734375\n",
            "||∇_X meta|| = 0.0016001741169020534\n",
            "ΔX norm: 1.600174255145248e-05\n",
            "Stage 3/10:  39%|███████████▏                 | 116/300 [03:35<06:04,  1.98s/it]T Loss=2.303612232208252\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038265705108643\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041446208953857\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304387331008911\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033344745635986\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.71278381347656\n",
            "||∇_X meta|| = 0.001762263011187315\n",
            "ΔX norm: 1.7622649465920404e-05\n",
            "Stage 3/10:  39%|███████████▎                 | 117/300 [03:37<06:02,  1.98s/it]T Loss=2.3030872344970703\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027987480163574\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019466400146484\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036208152770996\n",
            "g_norm = tensor(0.1216, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030755519866943\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3031768798828\n",
            "||∇_X meta|| = 0.0017524372087791562\n",
            "ΔX norm: 1.752436946844682e-05\n",
            "Stage 3/10:  39%|███████████▍                 | 118/300 [03:39<05:53,  1.94s/it]T Loss=2.307839870452881\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054585456848145\n",
            "g_norm = tensor(0.1378, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304316520690918\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047595024108887\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057944774627686\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.24630737304688\n",
            "||∇_X meta|| = 0.002019578358158469\n",
            "ΔX norm: 2.0195779143250547e-05\n",
            "Stage 3/10:  40%|███████████▌                 | 119/300 [03:41<05:43,  1.90s/it]T Loss=2.3062243461608887\n",
            "g_norm = tensor(0.1411, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042969703674316\n",
            "g_norm = tensor(0.1305, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303452253341675\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304475784301758\n",
            "g_norm = tensor(0.1528, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054542541503906\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.0029296875\n",
            "||∇_X meta|| = 0.0015198896871879697\n",
            "ΔX norm: 1.5198963410512079e-05\n",
            "Stage 3/10:  40%|███████████▌                 | 120/300 [03:43<05:35,  1.86s/it]T Loss=2.3042221069335938\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040997982025146\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036880493164062\n",
            "g_norm = tensor(0.0902, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302938938140869\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303743362426758\n",
            "g_norm = tensor(0.0768, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.05218505859375\n",
            "||∇_X meta|| = 0.001959369517862797\n",
            "ΔX norm: 1.9593688193708658e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 3/10:  40%|███████████▋                 | 121/300 [03:45<05:36,  1.88s/it]T Loss=2.3028011322021484\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034608364105225\n",
            "g_norm = tensor(0.1262, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304408550262451\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055529594421387\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051414489746094\n",
            "g_norm = tensor(0.1302, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.84217834472656\n",
            "||∇_X meta|| = 0.0017914432100951672\n",
            "ΔX norm: 1.7914411728270352e-05\n",
            "Stage 3/10:  41%|███████████▊                 | 122/300 [03:47<05:46,  1.95s/it]T Loss=2.304889678955078\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303298234939575\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056018352508545\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040969371795654\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304077625274658\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6578369140625\n",
            "||∇_X meta|| = 0.0017408132553100586\n",
            "ΔX norm: 1.740815059747547e-05\n",
            "Stage 3/10:  41%|███████████▉                 | 123/300 [03:49<05:41,  1.93s/it]T Loss=2.3032822608947754\n",
            "g_norm = tensor(0.0865, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304377794265747\n",
            "g_norm = tensor(0.0865, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038384914398193\n",
            "g_norm = tensor(0.0879, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303992748260498\n",
            "g_norm = tensor(0.0582, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036389350891113\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.36839294433594\n",
            "||∇_X meta|| = 0.0015580441104248166\n",
            "ΔX norm: 1.558045005367603e-05\n",
            "Stage 3/10:  41%|███████████▉                 | 124/300 [03:50<05:29,  1.87s/it]T Loss=2.3041164875030518\n",
            "g_norm = tensor(0.0947, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302934169769287\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303162097930908\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036227226257324\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303025722503662\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3731689453125\n",
            "||∇_X meta|| = 0.0015315357595682144\n",
            "ΔX norm: 1.531535053800326e-05\n",
            "Stage 3/10:  42%|████████████                 | 125/300 [03:52<05:15,  1.81s/it]T Loss=2.3028030395507812\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029959201812744\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3011672496795654\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037877082824707\n",
            "g_norm = tensor(0.0850, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026669025421143\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5792694091797\n",
            "||∇_X meta|| = 0.001706623355858028\n",
            "ΔX norm: 1.7066218788386323e-05\n",
            "Stage 3/10:  42%|████████████▏                | 126/300 [03:54<05:34,  1.92s/it]T Loss=2.3033828735351562\n",
            "g_norm = tensor(0.0922, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031065464019775\n",
            "g_norm = tensor(0.0737, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302915096282959\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304243326187134\n",
            "g_norm = tensor(0.0885, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302525043487549\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.73138427734375\n",
            "||∇_X meta|| = 0.0016075798776000738\n",
            "ΔX norm: 1.607579179108143e-05\n",
            "Stage 3/10:  42%|████████████▎                | 127/300 [03:56<05:35,  1.94s/it]T Loss=2.3033900260925293\n",
            "g_norm = tensor(0.1364, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037030696868896\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027193546295166\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302455425262451\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049111366271973\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.17283630371094\n",
            "||∇_X meta|| = 0.0017741256160661578\n",
            "ΔX norm: 1.774124575604219e-05\n",
            "Stage 3/10:  43%|████████████▎                | 128/300 [03:58<05:22,  1.88s/it]T Loss=2.306565761566162\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306408405303955\n",
            "g_norm = tensor(0.1305, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30438232421875\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038840293884277\n",
            "g_norm = tensor(0.1309, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050637245178223\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.49853515625\n",
            "||∇_X meta|| = 0.0017460646340623498\n",
            "ΔX norm: 1.7460615708841942e-05\n",
            "Stage 3/10:  43%|████████████▍                | 129/300 [04:00<05:16,  1.85s/it]T Loss=2.304410696029663\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30267333984375\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036720752716064\n",
            "g_norm = tensor(0.0850, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30387282371521\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030238151550293\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7225799560547\n",
            "||∇_X meta|| = 0.0017401865916326642\n",
            "ΔX norm: 1.7401849618181586e-05\n",
            "Stage 3/10:  43%|████████████▌                | 130/300 [04:01<05:06,  1.80s/it]T Loss=2.3031678199768066\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302995443344116\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302809476852417\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029775619506836\n",
            "g_norm = tensor(0.1269, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024020195007324\n",
            "g_norm = tensor(0.1382, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6356964111328\n",
            "||∇_X meta|| = 0.001412997837178409\n",
            "ΔX norm: 1.4129992450762074e-05\n",
            "Stage 3/10:  44%|████████████▋                | 131/300 [04:03<05:03,  1.80s/it]T Loss=2.303881883621216\n",
            "g_norm = tensor(0.0856, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304152488708496\n",
            "g_norm = tensor(0.1319, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033790588378906\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303706407546997\n",
            "g_norm = tensor(0.0860, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043508529663086\n",
            "g_norm = tensor(0.1332, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.00198364257812\n",
            "||∇_X meta|| = 0.001605733297765255\n",
            "ΔX norm: 1.6057341781561263e-05\n",
            "Stage 3/10:  44%|████████████▊                | 132/300 [04:05<05:02,  1.80s/it]T Loss=2.302886724472046\n",
            "g_norm = tensor(0.1655, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3009583950042725\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301703691482544\n",
            "g_norm = tensor(0.1651, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3008711338043213\n",
            "g_norm = tensor(0.1581, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304983615875244\n",
            "g_norm = tensor(0.1733, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.38226318359375\n",
            "||∇_X meta|| = 0.0015966023784130812\n",
            "ΔX norm: 1.5966019418556243e-05\n",
            "Stage 3/10:  44%|████████████▊                | 133/300 [04:07<04:54,  1.76s/it]T Loss=2.3045990467071533\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037238121032715\n",
            "g_norm = tensor(0.1335, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053877353668213\n",
            "g_norm = tensor(0.1384, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050293922424316\n",
            "g_norm = tensor(0.1617, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038206100463867\n",
            "g_norm = tensor(0.1358, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.24171447753906\n",
            "||∇_X meta|| = 0.00163843494374305\n",
            "ΔX norm: 1.638437606743537e-05\n",
            "Stage 3/10:  45%|████████████▉                | 134/300 [04:08<04:51,  1.76s/it]T Loss=2.3039565086364746\n",
            "g_norm = tensor(0.0723, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041696548461914\n",
            "g_norm = tensor(0.0690, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043951988220215\n",
            "g_norm = tensor(0.0866, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30403470993042\n",
            "g_norm = tensor(0.0707, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304594039916992\n",
            "g_norm = tensor(0.0648, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.7320556640625\n",
            "||∇_X meta|| = 0.0016293295193463564\n",
            "ΔX norm: 1.6293281078105792e-05\n",
            "Stage 3/10:  45%|█████████████                | 135/300 [04:11<05:02,  1.83s/it]T Loss=2.303419589996338\n",
            "g_norm = tensor(0.1291, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029024600982666\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303097724914551\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029563426971436\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027703762054443\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.96102905273438\n",
            "||∇_X meta|| = 0.0014885382261127234\n",
            "ΔX norm: 1.4885376003803685e-05\n",
            "Stage 3/10:  45%|█████████████▏               | 136/300 [04:12<05:01,  1.84s/it]T Loss=2.304356813430786\n",
            "g_norm = tensor(0.1333, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304267406463623\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3059792518615723\n",
            "g_norm = tensor(0.1457, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303773880004883\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043062686920166\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.589111328125\n",
            "||∇_X meta|| = 0.0015444211894646287\n",
            "ΔX norm: 1.5444236851180904e-05\n",
            "Stage 3/10:  46%|█████████████▏               | 137/300 [04:14<05:03,  1.86s/it]T Loss=2.304084062576294\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043227195739746\n",
            "g_norm = tensor(0.0778, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043785095214844\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045828342437744\n",
            "g_norm = tensor(0.0867, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041787147521973\n",
            "g_norm = tensor(0.0888, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.64883422851562\n",
            "||∇_X meta|| = 0.0016511025605723262\n",
            "ΔX norm: 1.651101774768904e-05\n",
            "Stage 3/10:  46%|█████████████▎               | 138/300 [04:16<05:09,  1.91s/it]T Loss=2.303723096847534\n",
            "g_norm = tensor(0.1021, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035097122192383\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034121990203857\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041887283325195\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038718700408936\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.57749938964844\n",
            "||∇_X meta|| = 0.001539636985398829\n",
            "ΔX norm: 1.5396353774121962e-05\n",
            "Stage 3/10:  46%|█████████████▍               | 139/300 [04:18<05:01,  1.87s/it]T Loss=2.3030171394348145\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038299083709717\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304687261581421\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302502155303955\n",
            "g_norm = tensor(0.1110, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303853988647461\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.13156127929688\n",
            "||∇_X meta|| = 0.0015672059962525964\n",
            "ΔX norm: 1.5672057998017408e-05\n",
            "Stage 3/10:  47%|█████████████▌               | 140/300 [04:20<04:49,  1.81s/it]T Loss=2.304030179977417\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037495613098145\n",
            "g_norm = tensor(0.0788, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040192127227783\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043880462646484\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043136596679688\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9801483154297\n",
            "||∇_X meta|| = 0.00165185471996665\n",
            "ΔX norm: 1.651853381190449e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 3/10:  47%|█████████████▋               | 141/300 [04:21<04:44,  1.79s/it]T Loss=2.3052520751953125\n",
            "g_norm = tensor(0.1370, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037984371185303\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029823303222656\n",
            "g_norm = tensor(0.1461, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303288221359253\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043391704559326\n",
            "g_norm = tensor(0.1362, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1898651123047\n",
            "||∇_X meta|| = 0.0016326509648934007\n",
            "ΔX norm: 1.6326504919561557e-05\n",
            "Stage 3/10:  47%|█████████████▋               | 142/300 [04:24<05:12,  1.98s/it]T Loss=2.304765462875366\n",
            "g_norm = tensor(0.1626, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039066791534424\n",
            "g_norm = tensor(0.1632, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305140972137451\n",
            "g_norm = tensor(0.1597, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042569160461426\n",
            "g_norm = tensor(0.1483, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033299446105957\n",
            "g_norm = tensor(0.1542, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.65350341796875\n",
            "||∇_X meta|| = 0.0017708624945953488\n",
            "ΔX norm: 1.770864582795184e-05\n",
            "Stage 3/10:  48%|█████████████▊               | 143/300 [04:26<05:10,  1.97s/it]T Loss=2.3029303550720215\n",
            "g_norm = tensor(0.1157, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035337924957275\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303581714630127\n",
            "g_norm = tensor(0.1380, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303823947906494\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302896499633789\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0980682373047\n",
            "||∇_X meta|| = 0.0015618245815858245\n",
            "ΔX norm: 1.5618243196513504e-05\n",
            "Stage 3/10:  48%|█████████████▉               | 144/300 [04:28<04:57,  1.91s/it]T Loss=2.303358554840088\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026938438415527\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031251430511475\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032243251800537\n",
            "g_norm = tensor(0.1359, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302692413330078\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.40147399902344\n",
            "||∇_X meta|| = 0.0017124449368566275\n",
            "ΔX norm: 1.7124433725257404e-05\n",
            "Stage 3/10:  48%|██████████████               | 145/300 [04:29<04:44,  1.84s/it]T Loss=2.3048737049102783\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303088426589966\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303088665008545\n",
            "g_norm = tensor(0.1163, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037285804748535\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040013313293457\n",
            "g_norm = tensor(0.1324, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.3955535888672\n",
            "||∇_X meta|| = 0.0014045553980395198\n",
            "ΔX norm: 1.4045548596186563e-05\n",
            "Stage 3/10:  49%|██████████████               | 146/300 [04:31<04:45,  1.85s/it]T Loss=2.303025722503662\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301704168319702\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303253173828125\n",
            "g_norm = tensor(0.1178, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046493530273438\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020071983337402\n",
            "g_norm = tensor(0.0861, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.81370544433594\n",
            "||∇_X meta|| = 0.0015653286827728152\n",
            "ΔX norm: 1.565325874253176e-05\n",
            "Stage 3/10:  49%|██████████████▏              | 147/300 [04:33<04:41,  1.84s/it]T Loss=2.3037314414978027\n",
            "g_norm = tensor(0.1374, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304778575897217\n",
            "g_norm = tensor(0.1417, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042819499969482\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045456409454346\n",
            "g_norm = tensor(0.1250, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304511547088623\n",
            "g_norm = tensor(0.1504, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9624786376953\n",
            "||∇_X meta|| = 0.0015625490341335535\n",
            "ΔX norm: 1.5625480955350213e-05\n",
            "Stage 3/10:  49%|██████████████▎              | 148/300 [04:35<04:34,  1.80s/it]T Loss=2.3039708137512207\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035149574279785\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305082321166992\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304027557373047\n",
            "g_norm = tensor(0.0847, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032939434051514\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.18666076660156\n",
            "||∇_X meta|| = 0.001776576740667224\n",
            "ΔX norm: 1.776575118128676e-05\n",
            "Stage 3/10:  50%|██████████████▍              | 149/300 [04:37<04:36,  1.83s/it]T Loss=2.304393768310547\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043618202209473\n",
            "g_norm = tensor(0.1285, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304941415786743\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304267168045044\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304323196411133\n",
            "g_norm = tensor(0.0941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.37005615234375\n",
            "||∇_X meta|| = 0.001511812792159617\n",
            "ΔX norm: 1.5118149349291343e-05\n",
            "Stage 3/10:  50%|██████████████▌              | 150/300 [04:38<04:33,  1.82s/it]T Loss=2.303816556930542\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046774864196777\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037121295928955\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303037405014038\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303853750228882\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.83154296875\n",
            "||∇_X meta|| = 0.0016565228579565883\n",
            "ΔX norm: 1.656521635595709e-05\n",
            "Stage 3/10:  50%|██████████████▌              | 151/300 [04:40<04:28,  1.80s/it]T Loss=2.3012313842773438\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034934997558594\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3014392852783203\n",
            "g_norm = tensor(0.0849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303584575653076\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303995132446289\n",
            "g_norm = tensor(0.0800, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.47390747070312\n",
            "||∇_X meta|| = 0.0016791089437901974\n",
            "ΔX norm: 1.6791076632216573e-05\n",
            "Stage 3/10:  51%|██████████████▋              | 152/300 [04:42<04:29,  1.82s/it]T Loss=2.3035502433776855\n",
            "g_norm = tensor(0.1282, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044114112854004\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028674125671387\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303781270980835\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039116859436035\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.15184020996094\n",
            "||∇_X meta|| = 0.001719021238386631\n",
            "ΔX norm: 1.719024294288829e-05\n",
            "Stage 3/10:  51%|██████████████▊              | 153/300 [04:44<04:25,  1.81s/it]T Loss=2.3051364421844482\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054890632629395\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306159734725952\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306082248687744\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304783344268799\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.85670471191406\n",
            "||∇_X meta|| = 0.0015007726615294814\n",
            "ΔX norm: 1.5007753972895443e-05\n",
            "Stage 3/10:  51%|██████████████▉              | 154/300 [04:46<04:21,  1.79s/it]T Loss=2.3027007579803467\n",
            "g_norm = tensor(0.1301, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303159713745117\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036048412323\n",
            "g_norm = tensor(0.1263, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025686740875244\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303359270095825\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.06185913085938\n",
            "||∇_X meta|| = 0.0014880539383739233\n",
            "ΔX norm: 1.4880558410368394e-05\n",
            "Stage 3/10:  52%|██████████████▉              | 155/300 [04:47<04:13,  1.74s/it]T Loss=2.3045709133148193\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040618896484375\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305044412612915\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024981021881104\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303696632385254\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.427490234375\n",
            "||∇_X meta|| = 0.0017556232633069158\n",
            "ΔX norm: 1.7556239981786348e-05\n",
            "Stage 3/10:  52%|███████████████              | 156/300 [04:49<04:11,  1.75s/it]T Loss=2.3047571182250977\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046462535858154\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054680824279785\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304410934448242\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30548357963562\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4503631591797\n",
            "||∇_X meta|| = 0.0015190753620117903\n",
            "ΔX norm: 1.5190755220828578e-05\n",
            "Stage 3/10:  52%|███████████████▏             | 157/300 [04:51<04:20,  1.82s/it]T Loss=2.3032753467559814\n",
            "g_norm = tensor(0.1401, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302319288253784\n",
            "g_norm = tensor(0.1557, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3011724948883057\n",
            "g_norm = tensor(0.1439, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302494764328003\n",
            "g_norm = tensor(0.1479, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302051305770874\n",
            "g_norm = tensor(0.1412, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.57464599609375\n",
            "||∇_X meta|| = 0.0017192848026752472\n",
            "ΔX norm: 1.7192816812894307e-05\n",
            "Stage 3/10:  53%|███████████████▎             | 158/300 [04:53<04:31,  1.91s/it]T Loss=2.303452968597412\n",
            "g_norm = tensor(0.0567, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035364151000977\n",
            "g_norm = tensor(0.0628, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039770126342773\n",
            "g_norm = tensor(0.0585, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303652286529541\n",
            "g_norm = tensor(0.0597, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303412675857544\n",
            "g_norm = tensor(0.0557, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.89599609375\n",
            "||∇_X meta|| = 0.0016812748508527875\n",
            "ΔX norm: 1.6812735339044593e-05\n",
            "Stage 3/10:  53%|███████████████▎             | 159/300 [04:55<04:35,  1.95s/it]T Loss=2.305272340774536\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304636001586914\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052024841308594\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039278984069824\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029561042785645\n",
            "g_norm = tensor(0.1053, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7165985107422\n",
            "||∇_X meta|| = 0.0015994616551324725\n",
            "ΔX norm: 1.5994639397831634e-05\n",
            "Stage 3/10:  53%|███████████████▍             | 160/300 [04:57<04:31,  1.94s/it]T Loss=2.3031468391418457\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303896188735962\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026163578033447\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302706241607666\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025858402252197\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.58126831054688\n",
            "||∇_X meta|| = 0.0015700538642704487\n",
            "ΔX norm: 1.570053063915111e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 3/10:  54%|███████████████▌             | 161/300 [04:59<04:29,  1.94s/it]T Loss=2.3029680252075195\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042662143707275\n",
            "g_norm = tensor(0.0942, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303762912750244\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049588203430176\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303696870803833\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.39601135253906\n",
            "||∇_X meta|| = 0.0016415473073720932\n",
            "ΔX norm: 1.6415480786236003e-05\n",
            "Stage 3/10:  54%|███████████████▋             | 162/300 [05:01<04:44,  2.06s/it]T Loss=2.3020856380462646\n",
            "g_norm = tensor(0.1380, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036751747131348\n",
            "g_norm = tensor(0.1154, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303818941116333\n",
            "g_norm = tensor(0.1258, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30362606048584\n",
            "g_norm = tensor(0.1270, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302586555480957\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.798095703125\n",
            "||∇_X meta|| = 0.0015872973017394543\n",
            "ΔX norm: 1.587297629157547e-05\n",
            "Stage 3/10:  54%|███████████████▊             | 163/300 [05:03<04:37,  2.02s/it]T Loss=2.3044700622558594\n",
            "g_norm = tensor(0.0748, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30238938331604\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303677797317505\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30362606048584\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302887201309204\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4754638671875\n",
            "||∇_X meta|| = 0.001651490107178688\n",
            "ΔX norm: 1.651493221288547e-05\n",
            "Stage 3/10:  55%|███████████████▊             | 164/300 [05:05<04:26,  1.96s/it]T Loss=2.303830862045288\n",
            "g_norm = tensor(0.1338, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303126811981201\n",
            "g_norm = tensor(0.1302, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030166625976562\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040268421173096\n",
            "g_norm = tensor(0.1359, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039534091949463\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.68350219726562\n",
            "||∇_X meta|| = 0.0016193599440157413\n",
            "ΔX norm: 1.619360591575969e-05\n",
            "Stage 3/10:  55%|███████████████▉             | 165/300 [05:07<04:17,  1.91s/it]T Loss=2.304051637649536\n",
            "g_norm = tensor(0.1451, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038601875305176\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035624027252197\n",
            "g_norm = tensor(0.1268, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303834915161133\n",
            "g_norm = tensor(0.1334, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028974533081055\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.46185302734375\n",
            "||∇_X meta|| = 0.0017071189358830452\n",
            "ΔX norm: 1.707121919025667e-05\n",
            "Stage 3/10:  55%|████████████████             | 166/300 [05:09<04:07,  1.85s/it]T Loss=2.3048460483551025\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046481609344482\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053359985351562\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046469688415527\n",
            "g_norm = tensor(0.0980, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303520679473877\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.62936401367188\n",
            "||∇_X meta|| = 0.0017889700829982758\n",
            "ΔX norm: 1.7889682567329146e-05\n",
            "Stage 3/10:  56%|████████████████▏            | 167/300 [05:10<04:09,  1.87s/it]T Loss=2.304459571838379\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303986072540283\n",
            "g_norm = tensor(0.1269, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304398536682129\n",
            "g_norm = tensor(0.1285, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045690059661865\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041372299194336\n",
            "g_norm = tensor(0.1348, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.3162384033203\n",
            "||∇_X meta|| = 0.0016463125357404351\n",
            "ΔX norm: 1.646307464397978e-05\n",
            "Stage 3/10:  56%|████████████████▏            | 168/300 [05:12<04:04,  1.85s/it]T Loss=2.3041467666625977\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030483722686768\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303100109100342\n",
            "g_norm = tensor(0.1355, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040549755096436\n",
            "g_norm = tensor(0.1528, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032801151275635\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.52426147460938\n",
            "||∇_X meta|| = 0.0015451246872544289\n",
            "ΔX norm: 1.5451256331289187e-05\n",
            "Stage 3/10:  56%|████████████████▎            | 169/300 [05:14<04:11,  1.92s/it]T Loss=2.3047118186950684\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303612470626831\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049936294555664\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304994821548462\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039841651916504\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.99940490722656\n",
            "||∇_X meta|| = 0.0016193402698263526\n",
            "ΔX norm: 1.619338581804186e-05\n",
            "Stage 3/10:  57%|████████████████▍            | 170/300 [05:17<04:21,  2.01s/it]T Loss=2.3032991886138916\n",
            "g_norm = tensor(0.1140, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024673461914062\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034164905548096\n",
            "g_norm = tensor(0.0852, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302366018295288\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030428886413574\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1597137451172\n",
            "||∇_X meta|| = 0.0014944067224860191\n",
            "ΔX norm: 1.4944054782972671e-05\n",
            "Stage 3/10:  57%|████████████████▌            | 171/300 [05:19<04:20,  2.02s/it]T Loss=2.3011462688446045\n",
            "g_norm = tensor(0.1541, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032593727111816\n",
            "g_norm = tensor(0.1899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302180528640747\n",
            "g_norm = tensor(0.1503, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027281761169434\n",
            "g_norm = tensor(0.1402, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029799461364746\n",
            "g_norm = tensor(0.1275, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.66696166992188\n",
            "||∇_X meta|| = 0.0016754069365561008\n",
            "ΔX norm: 1.675409293966368e-05\n",
            "Stage 3/10:  57%|████████████████▋            | 172/300 [05:21<04:13,  1.98s/it]T Loss=2.305985927581787\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057851791381836\n",
            "g_norm = tensor(0.1314, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035659790039062\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055851459503174\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045566082000732\n",
            "g_norm = tensor(0.1255, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.2480926513672\n",
            "||∇_X meta|| = 0.001727786846458912\n",
            "ΔX norm: 1.727785638649948e-05\n",
            "Stage 3/10:  58%|████████████████▋            | 173/300 [05:22<04:11,  1.98s/it]T Loss=2.3040902614593506\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035457134246826\n",
            "g_norm = tensor(0.1154, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302894353866577\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304189682006836\n",
            "g_norm = tensor(0.1373, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303138256072998\n",
            "g_norm = tensor(0.1471, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9695587158203\n",
            "||∇_X meta|| = 0.001554985879920423\n",
            "ΔX norm: 1.5549871022813022e-05\n",
            "Stage 3/10:  58%|████████████████▊            | 174/300 [05:24<04:08,  1.97s/it]T Loss=2.3032140731811523\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30306339263916\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304948091506958\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036017417907715\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034019470214844\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.96707153320312\n",
            "||∇_X meta|| = 0.001640273374505341\n",
            "ΔX norm: 1.6402755136368796e-05\n",
            "Stage 3/10:  58%|████████████████▉            | 175/300 [05:26<04:03,  1.95s/it]T Loss=2.303292751312256\n",
            "g_norm = tensor(0.1397, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041515350341797\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304093837738037\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038341999053955\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30269718170166\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.69981384277344\n",
            "||∇_X meta|| = 0.0016352453967556357\n",
            "ΔX norm: 1.6352472812286578e-05\n",
            "Stage 3/10:  59%|█████████████████            | 176/300 [05:28<04:03,  1.97s/it]T Loss=2.302894115447998\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025662899017334\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303334951400757\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30249285697937\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303452730178833\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.13461303710938\n",
            "||∇_X meta|| = 0.0017664283514022827\n",
            "ΔX norm: 1.7664293409325182e-05\n",
            "Stage 3/10:  59%|█████████████████            | 177/300 [05:30<03:57,  1.93s/it]T Loss=2.3028321266174316\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3014535903930664\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302900791168213\n",
            "g_norm = tensor(0.0993, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027637004852295\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023979663848877\n",
            "g_norm = tensor(0.0923, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.30296325683594\n",
            "||∇_X meta|| = 0.0016535278409719467\n",
            "ΔX norm: 1.6535270333406515e-05\n",
            "Stage 3/10:  59%|█████████████████▏           | 178/300 [05:32<03:56,  1.94s/it]T Loss=2.3043971061706543\n",
            "g_norm = tensor(0.0695, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036041259765625\n",
            "g_norm = tensor(0.0839, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043341636657715\n",
            "g_norm = tensor(0.0756, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039135932922363\n",
            "g_norm = tensor(0.0779, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303391695022583\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9456787109375\n",
            "||∇_X meta|| = 0.001507158624008298\n",
            "ΔX norm: 1.5071559573698323e-05\n",
            "Stage 3/10:  60%|█████████████████▎           | 179/300 [05:34<03:52,  1.92s/it]T Loss=2.304131031036377\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043644428253174\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045501708984375\n",
            "g_norm = tensor(0.0883, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30348801612854\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303565502166748\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.26588439941406\n",
            "||∇_X meta|| = 0.0016313388478010893\n",
            "ΔX norm: 1.63133936439408e-05\n",
            "Stage 3/10:  60%|█████████████████▍           | 180/300 [05:36<03:44,  1.87s/it]T Loss=2.303115129470825\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303452968597412\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302173137664795\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304025173187256\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303209066390991\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.39324951171875\n",
            "||∇_X meta|| = 0.001659489469602704\n",
            "ΔX norm: 1.6594878616160713e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 3/10:  60%|█████████████████▍           | 181/300 [05:38<03:46,  1.90s/it]T Loss=2.3030378818511963\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303295373916626\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303454875946045\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303494930267334\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048484325408936\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.39678955078125\n",
            "||∇_X meta|| = 0.001582433353178203\n",
            "ΔX norm: 1.5824343790882267e-05\n",
            "Stage 3/10:  61%|█████████████████▌           | 182/300 [05:40<04:00,  2.04s/it]T Loss=2.304809093475342\n",
            "g_norm = tensor(0.1477, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055741786956787\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304409980773926\n",
            "g_norm = tensor(0.1438, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040525913238525\n",
            "g_norm = tensor(0.1591, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036694526672363\n",
            "g_norm = tensor(0.1338, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0045928955078\n",
            "||∇_X meta|| = 0.00154010986443609\n",
            "ΔX norm: 1.5401095879497007e-05\n",
            "Stage 3/10:  61%|█████████████████▋           | 183/300 [05:42<03:57,  2.03s/it]T Loss=2.303030014038086\n",
            "g_norm = tensor(0.0840, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304187297821045\n",
            "g_norm = tensor(0.0854, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303664207458496\n",
            "g_norm = tensor(0.0825, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303455352783203\n",
            "g_norm = tensor(0.0677, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027801513671875\n",
            "g_norm = tensor(0.0880, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8603515625\n",
            "||∇_X meta|| = 0.0016741326544433832\n",
            "ΔX norm: 1.674135637586005e-05\n",
            "Stage 3/10:  61%|█████████████████▊           | 184/300 [05:44<03:49,  1.98s/it]T Loss=2.3046152591705322\n",
            "g_norm = tensor(0.1011, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037383556365967\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304811954498291\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044657707214355\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303931713104248\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3280487060547\n",
            "||∇_X meta|| = 0.0016969087300822139\n",
            "ΔX norm: 1.696911385806743e-05\n",
            "Stage 3/10:  62%|█████████████████▉           | 185/300 [05:46<03:39,  1.91s/it]T Loss=2.303192615509033\n",
            "g_norm = tensor(0.0855, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305182933807373\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303673267364502\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033623695373535\n",
            "g_norm = tensor(0.0878, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032169342041016\n",
            "g_norm = tensor(0.0823, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.479736328125\n",
            "||∇_X meta|| = 0.0016685548471286893\n",
            "ΔX norm: 1.668553704803344e-05\n",
            "Stage 3/10:  62%|█████████████████▉           | 186/300 [05:48<03:40,  1.93s/it]T Loss=2.3036224842071533\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043086528778076\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031058311462402\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304675579071045\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304170846939087\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.03392028808594\n",
            "||∇_X meta|| = 0.0016123931854963303\n",
            "ΔX norm: 1.6123927707667463e-05\n",
            "Stage 3/10:  62%|██████████████████           | 187/300 [05:50<03:33,  1.89s/it]T Loss=2.304598331451416\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302607774734497\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047995567321777\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029322624206543\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303305149078369\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7322235107422\n",
            "||∇_X meta|| = 0.0014203591272234917\n",
            "ΔX norm: 1.4203579667082522e-05\n",
            "Stage 3/10:  63%|██████████████████▏          | 188/300 [05:51<03:25,  1.84s/it]T Loss=2.303004741668701\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304652452468872\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037757873535156\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032846450805664\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040599822998047\n",
            "g_norm = tensor(0.1230, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.79722595214844\n",
            "||∇_X meta|| = 0.0014685610076412559\n",
            "ΔX norm: 1.4685610949527472e-05\n",
            "Stage 3/10:  63%|██████████████████▎          | 189/300 [05:53<03:33,  1.92s/it]T Loss=2.3031673431396484\n",
            "g_norm = tensor(0.1178, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037893772125244\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040270805358887\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032495975494385\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057212829589844\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.06468200683594\n",
            "||∇_X meta|| = 0.0016098212217912078\n",
            "ΔX norm: 1.6098209016490728e-05\n",
            "Stage 3/10:  63%|██████████████████▎          | 190/300 [05:55<03:34,  1.95s/it]T Loss=2.303652286529541\n",
            "g_norm = tensor(0.0933, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303501605987549\n",
            "g_norm = tensor(0.0740, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033785820007324\n",
            "g_norm = tensor(0.0878, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303544521331787\n",
            "g_norm = tensor(0.0867, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038742542266846\n",
            "g_norm = tensor(0.0682, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.40904235839844\n",
            "||∇_X meta|| = 0.0015012755757197738\n",
            "ΔX norm: 1.5012729818408843e-05\n",
            "Stage 3/10:  64%|██████████████████▍          | 191/300 [05:57<03:25,  1.89s/it]T Loss=2.303675413131714\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026363849639893\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030171394348145\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303605556488037\n",
            "g_norm = tensor(0.1249, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304163932800293\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8920440673828\n",
            "||∇_X meta|| = 0.0015630670823156834\n",
            "ΔX norm: 1.5630688722012565e-05\n",
            "Stage 3/10:  64%|██████████████████▌          | 192/300 [05:59<03:24,  1.89s/it]T Loss=2.3041672706604004\n",
            "g_norm = tensor(0.1441, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046205043792725\n",
            "g_norm = tensor(0.1248, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040568828582764\n",
            "g_norm = tensor(0.1349, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305238962173462\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050718307495117\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.25405883789062\n",
            "||∇_X meta|| = 0.0017001015366986394\n",
            "ΔX norm: 1.7001035303110257e-05\n",
            "Stage 3/10:  64%|██████████████████▋          | 193/300 [06:02<03:45,  2.11s/it]T Loss=2.304316282272339\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304523468017578\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052194118499756\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303694486618042\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037827014923096\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.96395874023438\n",
            "||∇_X meta|| = 0.001621218747459352\n",
            "ΔX norm: 1.6212188711506315e-05\n",
            "Stage 3/10:  65%|██████████████████▊          | 194/300 [06:03<03:35,  2.04s/it]T Loss=2.3029873371124268\n",
            "g_norm = tensor(0.1375, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302485704421997\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038601875305176\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022561073303223\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303481101989746\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.87765502929688\n",
            "||∇_X meta|| = 0.0016428858507424593\n",
            "ΔX norm: 1.6428839444415644e-05\n",
            "Stage 3/10:  65%|██████████████████▊          | 195/300 [06:06<03:44,  2.14s/it]T Loss=2.3048787117004395\n",
            "g_norm = tensor(0.1467, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041205406188965\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045783042907715\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052754402160645\n",
            "g_norm = tensor(0.1368, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30525541305542\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4424591064453\n",
            "||∇_X meta|| = 0.00145002081990242\n",
            "ΔX norm: 1.4500201359624043e-05\n",
            "Stage 3/10:  65%|██████████████████▉          | 196/300 [06:08<03:40,  2.12s/it]T Loss=2.303128957748413\n",
            "g_norm = tensor(0.0759, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039820194244385\n",
            "g_norm = tensor(0.0732, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029839992523193\n",
            "g_norm = tensor(0.0749, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303553819656372\n",
            "g_norm = tensor(0.0673, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034863471984863\n",
            "g_norm = tensor(0.0651, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.86898803710938\n",
            "||∇_X meta|| = 0.0015203870134428144\n",
            "ΔX norm: 1.5203854673018213e-05\n",
            "Stage 3/10:  66%|███████████████████          | 197/300 [06:10<03:30,  2.05s/it]T Loss=2.3026435375213623\n",
            "g_norm = tensor(0.1163, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304241895675659\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044421672821045\n",
            "g_norm = tensor(0.0885, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304354667663574\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041768074035645\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.46328735351562\n",
            "||∇_X meta|| = 0.001513221301138401\n",
            "ΔX norm: 1.5132230146264192e-05\n",
            "Stage 3/10:  66%|███████████████████▏         | 198/300 [06:12<03:19,  1.95s/it]T Loss=2.303579330444336\n",
            "g_norm = tensor(0.1219, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304530620574951\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034560680389404\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304203510284424\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304302215576172\n",
            "g_norm = tensor(0.0885, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.475341796875\n",
            "||∇_X meta|| = 0.0016864169156178832\n",
            "ΔX norm: 1.6864149074535817e-05\n",
            "Stage 3/10:  66%|███████████████████▏         | 199/300 [06:14<03:21,  2.00s/it]T Loss=2.3031201362609863\n",
            "g_norm = tensor(0.1671, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046014308929443\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051064014434814\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036322593688965\n",
            "g_norm = tensor(0.1296, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30466365814209\n",
            "g_norm = tensor(0.0945, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.06541442871094\n",
            "||∇_X meta|| = 0.0015010288916528225\n",
            "ΔX norm: 1.5010279639682267e-05\n",
            "Stage 3/10:  67%|███████████████████▎         | 200/300 [06:15<03:14,  1.95s/it]T Loss=2.303358793258667\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303159236907959\n",
            "g_norm = tensor(0.0942, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303028106689453\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30350923538208\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303327798843384\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.76431274414062\n",
            "||∇_X meta|| = 0.001538734184578061\n",
            "ΔX norm: 1.5387335224659182e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 3/10:  67%|███████████████████▍         | 201/300 [06:17<03:09,  1.92s/it]T Loss=2.301659107208252\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301729440689087\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041818141937256\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3013501167297363\n",
            "g_norm = tensor(0.1184, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020968437194824\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.45701599121094\n",
            "||∇_X meta|| = 0.001664872164838016\n",
            "ΔX norm: 1.6648711607558653e-05\n",
            "Stage 3/10:  67%|███████████████████▌         | 202/300 [06:20<03:21,  2.05s/it]T Loss=2.303983211517334\n",
            "g_norm = tensor(0.0867, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047587871551514\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031067848205566\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303712844848633\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302626609802246\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.89108276367188\n",
            "||∇_X meta|| = 0.0015851991483941674\n",
            "ΔX norm: 1.585203062859364e-05\n",
            "Stage 3/10:  68%|███████████████████▌         | 203/300 [06:22<03:22,  2.08s/it]T Loss=2.3036117553710938\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041043281555176\n",
            "g_norm = tensor(0.1302, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028879165649414\n",
            "g_norm = tensor(0.1342, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047006130218506\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042643070220947\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.64430236816406\n",
            "||∇_X meta|| = 0.0017274622805416584\n",
            "ΔX norm: 1.727461494738236e-05\n",
            "Stage 3/10:  68%|███████████████████▋         | 204/300 [06:24<03:13,  2.01s/it]T Loss=2.3041694164276123\n",
            "g_norm = tensor(0.0814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302738904953003\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303629159927368\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032479286193848\n",
            "g_norm = tensor(0.0798, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034324645996094\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.63525390625\n",
            "||∇_X meta|| = 0.0015122760087251663\n",
            "ΔX norm: 1.5122753211471718e-05\n",
            "Stage 3/10:  68%|███████████████████▊         | 205/300 [06:26<03:07,  1.98s/it]T Loss=2.302884340286255\n",
            "g_norm = tensor(0.1259, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043458461761475\n",
            "g_norm = tensor(0.1157, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042922019958496\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302823305130005\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036293983459473\n",
            "g_norm = tensor(0.1143, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.52783203125\n",
            "||∇_X meta|| = 0.001636118395254016\n",
            "ΔX norm: 1.636120032344479e-05\n",
            "Stage 3/10:  69%|███████████████████▉         | 206/300 [06:27<02:56,  1.88s/it]T Loss=2.303382158279419\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303352117538452\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304499387741089\n",
            "g_norm = tensor(0.0856, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304619312286377\n",
            "g_norm = tensor(0.0840, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046011924743652\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.70314025878906\n",
            "||∇_X meta|| = 0.0015046634944155812\n",
            "ΔX norm: 1.5046620319481008e-05\n",
            "Stage 3/10:  69%|████████████████████         | 207/300 [06:29<02:51,  1.85s/it]T Loss=2.30415940284729\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039674758911133\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304246425628662\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036108016967773\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303549289703369\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.28936767578125\n",
            "||∇_X meta|| = 0.001565952436067164\n",
            "ΔX norm: 1.5659545169910416e-05\n",
            "Stage 3/10:  69%|████████████████████         | 208/300 [06:31<02:57,  1.93s/it]T Loss=2.3036675453186035\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054816722869873\n",
            "g_norm = tensor(0.1578, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031513690948486\n",
            "g_norm = tensor(0.1498, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049960136413574\n",
            "g_norm = tensor(0.1531, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304431676864624\n",
            "g_norm = tensor(0.1558, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7283935546875\n",
            "||∇_X meta|| = 0.0014896559296175838\n",
            "ΔX norm: 1.4896578250045422e-05\n",
            "Stage 3/10:  70%|████████████████████▏        | 209/300 [06:33<02:53,  1.90s/it]T Loss=2.303607940673828\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304473400115967\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302807569503784\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304805278778076\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041203022003174\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.38482666015625\n",
            "||∇_X meta|| = 0.0017399726202711463\n",
            "ΔX norm: 1.739973777148407e-05\n",
            "Stage 3/10:  70%|████████████████████▎        | 210/300 [06:35<02:44,  1.83s/it]T Loss=2.30560040473938\n",
            "g_norm = tensor(0.1757, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037664890289307\n",
            "g_norm = tensor(0.1385, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052868843078613\n",
            "g_norm = tensor(0.1393, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046839237213135\n",
            "g_norm = tensor(0.1370, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304917335510254\n",
            "g_norm = tensor(0.1830, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.74685668945312\n",
            "||∇_X meta|| = 0.001617788104340434\n",
            "ΔX norm: 1.6177875295397826e-05\n",
            "Stage 3/10:  70%|████████████████████▍        | 211/300 [06:36<02:43,  1.84s/it]T Loss=2.3037848472595215\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041014671325684\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302706241607666\n",
            "g_norm = tensor(0.0765, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303274631500244\n",
            "g_norm = tensor(0.0824, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041441440582275\n",
            "g_norm = tensor(0.0852, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4732208251953\n",
            "||∇_X meta|| = 0.0015747530851513147\n",
            "ΔX norm: 1.5747538782306947e-05\n",
            "Stage 3/10:  71%|████████████████████▍        | 212/300 [06:38<02:41,  1.84s/it]T Loss=2.303924798965454\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031294345855713\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302884340286255\n",
            "g_norm = tensor(0.0956, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029236793518066\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302985668182373\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9591827392578\n",
            "||∇_X meta|| = 0.001580924610607326\n",
            "ΔX norm: 1.5809277101652697e-05\n",
            "Stage 3/10:  71%|████████████████████▌        | 213/300 [06:40<02:38,  1.82s/it]T Loss=2.304098606109619\n",
            "g_norm = tensor(0.0945, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302216053009033\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028857707977295\n",
            "g_norm = tensor(0.0794, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034048080444336\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023531436920166\n",
            "g_norm = tensor(0.0878, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.24954223632812\n",
            "||∇_X meta|| = 0.0016550127184018493\n",
            "ΔX norm: 1.655014966672752e-05\n",
            "Stage 3/10:  71%|████████████████████▋        | 214/300 [06:42<02:37,  1.83s/it]T Loss=2.3037734031677246\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302382469177246\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040661811828613\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036341667175293\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026692867279053\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.14584350585938\n",
            "||∇_X meta|| = 0.0015259173233062029\n",
            "ΔX norm: 1.525916377431713e-05\n",
            "Stage 3/10:  72%|████████████████████▊        | 215/300 [06:44<02:32,  1.79s/it]T Loss=2.3032774925231934\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303967237472534\n",
            "g_norm = tensor(0.1342, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303025960922241\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303631544113159\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30418062210083\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.46629333496094\n",
            "||∇_X meta|| = 0.0016761256847530603\n",
            "ΔX norm: 1.6761263395892456e-05\n",
            "Stage 3/10:  72%|████████████████████▉        | 216/300 [06:45<02:30,  1.79s/it]T Loss=2.3038010597229004\n",
            "g_norm = tensor(0.0851, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048207759857178\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041770458221436\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033008575439453\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035285472869873\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4630584716797\n",
            "||∇_X meta|| = 0.0015921093290671706\n",
            "ΔX norm: 1.5921094018267468e-05\n",
            "Stage 3/10:  72%|████████████████████▉        | 217/300 [06:47<02:29,  1.80s/it]T Loss=2.3035614490509033\n",
            "g_norm = tensor(0.0695, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303840398788452\n",
            "g_norm = tensor(0.0764, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035101890563965\n",
            "g_norm = tensor(0.0689, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034284114837646\n",
            "g_norm = tensor(0.0725, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303826093673706\n",
            "g_norm = tensor(0.0814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.08665466308594\n",
            "||∇_X meta|| = 0.0016787091735750437\n",
            "ΔX norm: 1.6787113054306246e-05\n",
            "Stage 3/10:  73%|█████████████████████        | 218/300 [06:49<02:27,  1.80s/it]T Loss=2.304802417755127\n",
            "g_norm = tensor(0.1415, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050150871276855\n",
            "g_norm = tensor(0.1371, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041117191314697\n",
            "g_norm = tensor(0.1436, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304593563079834\n",
            "g_norm = tensor(0.1230, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039393424987793\n",
            "g_norm = tensor(0.1637, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3144989013672\n",
            "||∇_X meta|| = 0.0015056137926876545\n",
            "ΔX norm: 1.5056131815072149e-05\n",
            "Stage 3/10:  73%|█████████████████████▏       | 219/300 [06:51<02:27,  1.82s/it]T Loss=2.3052780628204346\n",
            "g_norm = tensor(0.1292, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304025650024414\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305138111114502\n",
            "g_norm = tensor(0.1408, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052265644073486\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053641319274902\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.022216796875\n",
            "||∇_X meta|| = 0.0015973267145454884\n",
            "ΔX norm: 1.597326081537176e-05\n",
            "Stage 3/10:  73%|█████████████████████▎       | 220/300 [06:54<02:53,  2.16s/it]T Loss=2.3050224781036377\n",
            "g_norm = tensor(0.0956, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302873134613037\n",
            "g_norm = tensor(0.0830, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033132553100586\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036673069000244\n",
            "g_norm = tensor(0.0933, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036646842956543\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.54493713378906\n",
            "||∇_X meta|| = 0.001658296794630587\n",
            "ΔX norm: 1.6582956959609874e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 3/10:  74%|█████████████████████▎       | 221/300 [06:56<02:50,  2.16s/it]T Loss=2.304163694381714\n",
            "g_norm = tensor(0.1270, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031296730041504\n",
            "g_norm = tensor(0.0838, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038716316223145\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040080070495605\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303459882736206\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1248016357422\n",
            "||∇_X meta|| = 0.0015911703230813146\n",
            "ΔX norm: 1.591169711900875e-05\n",
            "Stage 3/10:  74%|█████████████████████▍       | 222/300 [06:59<03:00,  2.32s/it]T Loss=2.3034002780914307\n",
            "g_norm = tensor(0.1307, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303222894668579\n",
            "g_norm = tensor(0.1210, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303330183029175\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030569553375244\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034510612487793\n",
            "g_norm = tensor(0.1331, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.6643524169922\n",
            "||∇_X meta|| = 0.0014735881704837084\n",
            "ΔX norm: 1.4735896911588497e-05\n",
            "Stage 3/10:  74%|█████████████████████▌       | 223/300 [07:01<02:48,  2.19s/it]T Loss=2.305096387863159\n",
            "g_norm = tensor(0.0800, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049349784851074\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044724464416504\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039798736572266\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041181564331055\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.41305541992188\n",
            "||∇_X meta|| = 0.0015747344586998224\n",
            "ΔX norm: 1.5747358702355996e-05\n",
            "Stage 3/10:  75%|█████████████████████▋       | 224/300 [07:03<02:41,  2.13s/it]T Loss=2.3027546405792236\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302947759628296\n",
            "g_norm = tensor(0.1292, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302072525024414\n",
            "g_norm = tensor(0.1301, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029091358184814\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042709827423096\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3978271484375\n",
            "||∇_X meta|| = 0.001575422240421176\n",
            "ΔX norm: 1.575420901644975e-05\n",
            "Stage 3/10:  75%|█████████████████████▊       | 225/300 [07:04<02:32,  2.04s/it]T Loss=2.3039965629577637\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30433988571167\n",
            "g_norm = tensor(0.0851, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304219961166382\n",
            "g_norm = tensor(0.1349, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304718017578125\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304858684539795\n",
            "g_norm = tensor(0.1075, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.79791259765625\n",
            "||∇_X meta|| = 0.0015571920666843653\n",
            "ΔX norm: 1.557191353640519e-05\n",
            "Stage 3/10:  75%|█████████████████████▊       | 226/300 [07:06<02:26,  1.98s/it]T Loss=2.3032515048980713\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302948474884033\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041656017303467\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044421672821045\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303396701812744\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.83267211914062\n",
            "||∇_X meta|| = 0.0014979355037212372\n",
            "ΔX norm: 1.4979376828705426e-05\n",
            "Stage 3/10:  76%|█████████████████████▉       | 227/300 [07:08<02:24,  1.98s/it]T Loss=2.3030459880828857\n",
            "g_norm = tensor(0.1449, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036160469055176\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304651975631714\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040857315063477\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045318126678467\n",
            "g_norm = tensor(0.1417, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9453887939453\n",
            "||∇_X meta|| = 0.0015295729972422123\n",
            "ΔX norm: 1.5295752746169455e-05\n",
            "Stage 3/10:  76%|██████████████████████       | 228/300 [07:10<02:21,  1.97s/it]T Loss=2.3025031089782715\n",
            "g_norm = tensor(0.1330, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028564453125\n",
            "g_norm = tensor(0.1338, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034796714782715\n",
            "g_norm = tensor(0.1140, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305063247680664\n",
            "g_norm = tensor(0.1286, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035922050476074\n",
            "g_norm = tensor(0.1273, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.92959594726562\n",
            "||∇_X meta|| = 0.0015604682266712189\n",
            "ΔX norm: 1.560469354444649e-05\n",
            "Stage 3/10:  76%|██████████████████████▏      | 229/300 [07:12<02:23,  2.03s/it]T Loss=2.3033180236816406\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046324253082275\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305332660675049\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053197860717773\n",
            "g_norm = tensor(0.1304, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042609691619873\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.2406005859375\n",
            "||∇_X meta|| = 0.001563390833325684\n",
            "ΔX norm: 1.5633899238309823e-05\n",
            "Stage 3/10:  77%|██████████████████████▏      | 230/300 [07:14<02:19,  1.99s/it]T Loss=2.3043789863586426\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034400939941406\n",
            "g_norm = tensor(0.1391, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051974773406982\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304093837738037\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305112838745117\n",
            "g_norm = tensor(0.1384, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.02674865722656\n",
            "||∇_X meta|| = 0.001431743148714304\n",
            "ΔX norm: 1.4317429304355755e-05\n",
            "Stage 3/10:  77%|██████████████████████▎      | 231/300 [07:16<02:14,  1.95s/it]T Loss=2.303231716156006\n",
            "g_norm = tensor(0.1314, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043503761291504\n",
            "g_norm = tensor(0.1698, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048336505889893\n",
            "g_norm = tensor(0.1637, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030996322631836\n",
            "g_norm = tensor(0.1485, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021743297576904\n",
            "g_norm = tensor(0.1477, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.95321655273438\n",
            "||∇_X meta|| = 0.001511351321823895\n",
            "ΔX norm: 1.5113572771952022e-05\n",
            "Stage 3/10:  77%|██████████████████████▍      | 232/300 [07:18<02:08,  1.90s/it]T Loss=2.3035426139831543\n",
            "g_norm = tensor(0.1529, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029849529266357\n",
            "g_norm = tensor(0.1384, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029582500457764\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303022623062134\n",
            "g_norm = tensor(0.1266, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029308319091797\n",
            "g_norm = tensor(0.1524, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4980926513672\n",
            "||∇_X meta|| = 0.0015104352496564388\n",
            "ΔX norm: 1.5104385965969414e-05\n",
            "Stage 3/10:  78%|██████████████████████▌      | 233/300 [07:20<02:08,  1.91s/it]T Loss=2.303497076034546\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035261631011963\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039705753326416\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043785095214844\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046936988830566\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.17820739746094\n",
            "||∇_X meta|| = 0.0016018275637179613\n",
            "ΔX norm: 1.6018264432204887e-05\n",
            "Stage 3/10:  78%|██████████████████████▌      | 234/300 [07:22<02:04,  1.88s/it]T Loss=2.3044285774230957\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304136276245117\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304321765899658\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303577423095703\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303790807723999\n",
            "g_norm = tensor(0.0897, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.30625915527344\n",
            "||∇_X meta|| = 0.0015518143773078918\n",
            "ΔX norm: 1.5518147847615182e-05\n",
            "Stage 3/10:  78%|██████████████████████▋      | 235/300 [07:24<02:04,  1.92s/it]T Loss=2.3022706508636475\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033607006073\n",
            "g_norm = tensor(0.0811, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022608757019043\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30308198928833\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303396701812744\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2680206298828\n",
            "||∇_X meta|| = 0.00174619909375906\n",
            "ΔX norm: 1.7462018149672076e-05\n",
            "Stage 3/10:  79%|██████████████████████▊      | 236/300 [07:26<02:05,  1.96s/it]T Loss=2.3030617237091064\n",
            "g_norm = tensor(0.1318, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024649620056152\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303929328918457\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303715229034424\n",
            "g_norm = tensor(0.1183, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050475120544434\n",
            "g_norm = tensor(0.1407, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.88388061523438\n",
            "||∇_X meta|| = 0.0014884679112583399\n",
            "ΔX norm: 1.4884700249240268e-05\n",
            "Stage 3/10:  79%|██████████████████████▉      | 237/300 [07:28<02:00,  1.91s/it]T Loss=2.304084300994873\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304643392562866\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303706169128418\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045506477355957\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042147159576416\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9893341064453\n",
            "||∇_X meta|| = 0.0017058408120647073\n",
            "ΔX norm: 1.70584098668769e-05\n",
            "Stage 3/10:  79%|███████████████████████      | 238/300 [07:29<01:55,  1.87s/it]T Loss=2.305842876434326\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306149959564209\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050742149353027\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051295280456543\n",
            "g_norm = tensor(0.1378, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049569129943848\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.3990478515625\n",
            "||∇_X meta|| = 0.0015348544111475348\n",
            "ΔX norm: 1.5348565284512006e-05\n",
            "Stage 3/10:  80%|███████████████████████      | 239/300 [07:31<01:51,  1.83s/it]T Loss=2.3049943447113037\n",
            "g_norm = tensor(0.1435, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037450313568115\n",
            "g_norm = tensor(0.1382, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040289878845215\n",
            "g_norm = tensor(0.1520, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058290481567383\n",
            "g_norm = tensor(0.1549, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039746284484863\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.88613891601562\n",
            "||∇_X meta|| = 0.0016114411409944296\n",
            "ΔX norm: 1.6114403479150496e-05\n",
            "Stage 3/10:  80%|███████████████████████▏     | 240/300 [07:33<01:47,  1.79s/it]T Loss=2.303107738494873\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033671379089355\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045854568481445\n",
            "g_norm = tensor(0.1022, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303861141204834\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038859367370605\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.61265563964844\n",
            "||∇_X meta|| = 0.0018262342782691121\n",
            "ΔX norm: 1.826232073653955e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 3/10:  80%|███████████████████████▎     | 241/300 [07:35<01:45,  1.79s/it]T Loss=2.304047107696533\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302550792694092\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303635835647583\n",
            "g_norm = tensor(0.0931, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302701711654663\n",
            "g_norm = tensor(0.1430, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302976608276367\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9994659423828\n",
            "||∇_X meta|| = 0.0015781940892338753\n",
            "ΔX norm: 1.578195224283263e-05\n",
            "Stage 3/10:  81%|███████████████████████▍     | 242/300 [07:37<01:53,  1.95s/it]T Loss=2.3029558658599854\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30302095413208\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033151626586914\n",
            "g_norm = tensor(0.1143, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036136627197266\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303880453109741\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.0128936767578\n",
            "||∇_X meta|| = 0.0016653139609843493\n",
            "ΔX norm: 1.665314266574569e-05\n",
            "Stage 3/10:  81%|███████████████████████▍     | 243/300 [07:39<01:55,  2.03s/it]T Loss=2.303461790084839\n",
            "g_norm = tensor(0.0758, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303677558898926\n",
            "g_norm = tensor(0.0807, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303903818130493\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044815063476562\n",
            "g_norm = tensor(0.0814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304116725921631\n",
            "g_norm = tensor(0.0883, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =227.72508239746094\n",
            "||∇_X meta|| = 0.0017761894268915057\n",
            "ΔX norm: 1.7761880371836014e-05\n",
            "Stage 3/10:  81%|███████████████████████▌     | 244/300 [07:41<01:50,  1.98s/it]T Loss=2.3043174743652344\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304050922393799\n",
            "g_norm = tensor(0.1307, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048253059387207\n",
            "g_norm = tensor(0.1444, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305185317993164\n",
            "g_norm = tensor(0.1776, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041300773620605\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.52188110351562\n",
            "||∇_X meta|| = 0.0016014168504625559\n",
            "ΔX norm: 1.6014184438972734e-05\n",
            "Stage 3/10:  82%|███████████████████████▋     | 245/300 [07:43<01:44,  1.90s/it]T Loss=2.3042685985565186\n",
            "g_norm = tensor(0.0794, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304309129714966\n",
            "g_norm = tensor(0.0712, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035900592803955\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303931713104248\n",
            "g_norm = tensor(0.0858, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031506538391113\n",
            "g_norm = tensor(0.0752, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.47996520996094\n",
            "||∇_X meta|| = 0.0016228969907388091\n",
            "ΔX norm: 1.6228994354605675e-05\n",
            "Stage 3/10:  82%|███████████████████████▊     | 246/300 [07:44<01:38,  1.83s/it]T Loss=2.30387806892395\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304508924484253\n",
            "g_norm = tensor(0.0980, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035311698913574\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036460876464844\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034720420837402\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.53887939453125\n",
            "||∇_X meta|| = 0.0015604393556714058\n",
            "ΔX norm: 1.560440614412073e-05\n",
            "Stage 3/10:  82%|███████████████████████▉     | 247/300 [07:46<01:35,  1.81s/it]T Loss=2.304405689239502\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304278612136841\n",
            "g_norm = tensor(0.1371, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038172721862793\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304211139678955\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304361581802368\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.89413452148438\n",
            "||∇_X meta|| = 0.0015602022176608443\n",
            "ΔX norm: 1.560200507810805e-05\n",
            "Stage 3/10:  83%|███████████████████████▉     | 248/300 [07:48<01:41,  1.95s/it]T Loss=2.303478717803955\n",
            "g_norm = tensor(0.0928, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303785800933838\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031702041625977\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027281761169434\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303332805633545\n",
            "g_norm = tensor(0.1022, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.25335693359375\n",
            "||∇_X meta|| = 0.001790288952179253\n",
            "ΔX norm: 1.7902872059494257e-05\n",
            "Stage 3/10:  83%|████████████████████████     | 249/300 [07:50<01:38,  1.93s/it]T Loss=2.303743839263916\n",
            "g_norm = tensor(0.0782, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030314445495605\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30263090133667\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030612468719482\n",
            "g_norm = tensor(0.0937, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304077625274658\n",
            "g_norm = tensor(0.0857, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.79122924804688\n",
            "||∇_X meta|| = 0.00159131467808038\n",
            "ΔX norm: 1.5913130482658744e-05\n",
            "Stage 3/10:  83%|████████████████████████▏    | 250/300 [07:52<01:37,  1.95s/it]T Loss=2.303633213043213\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303288698196411\n",
            "g_norm = tensor(0.1262, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304048776626587\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303182363510132\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304271697998047\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.79367065429688\n",
            "||∇_X meta|| = 0.0013894086005166173\n",
            "ΔX norm: 1.3894072253606282e-05\n",
            "Stage 3/10:  84%|████████████████████████▎    | 251/300 [07:55<01:41,  2.07s/it]T Loss=2.3022704124450684\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302745819091797\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302736759185791\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022701740264893\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303626537322998\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.80096435546875\n",
            "||∇_X meta|| = 0.0014796070754528046\n",
            "ΔX norm: 1.4796107279835269e-05\n",
            "Stage 3/10:  84%|████████████████████████▎    | 252/300 [07:56<01:34,  1.98s/it]T Loss=2.3034329414367676\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30300235748291\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304370403289795\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026270866394043\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040266036987305\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1361846923828\n",
            "||∇_X meta|| = 0.001690436969511211\n",
            "ΔX norm: 1.690436874923762e-05\n",
            "Stage 3/10:  84%|████████████████████████▍    | 253/300 [07:58<01:29,  1.91s/it]T Loss=2.304600954055786\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303150177001953\n",
            "g_norm = tensor(0.0937, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303542137145996\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036842346191406\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049869537353516\n",
            "g_norm = tensor(0.0871, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.60787963867188\n",
            "||∇_X meta|| = 0.0014624671312049031\n",
            "ΔX norm: 1.4624664800066967e-05\n",
            "Stage 3/10:  85%|████████████████████████▌    | 254/300 [08:00<01:33,  2.02s/it]T Loss=2.3032543659210205\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036210536956787\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302919864654541\n",
            "g_norm = tensor(0.0713, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303128719329834\n",
            "g_norm = tensor(0.0885, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030922412872314\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.59434509277344\n",
            "||∇_X meta|| = 0.0013746835757046938\n",
            "ΔX norm: 1.3746833246841561e-05\n",
            "Stage 3/10:  85%|████████████████████████▋    | 255/300 [08:02<01:32,  2.05s/it]T Loss=2.3041064739227295\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031117916107178\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045578002929688\n",
            "g_norm = tensor(0.0888, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046817779541016\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036186695098877\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.95326232910156\n",
            "||∇_X meta|| = 0.0015503211179748178\n",
            "ΔX norm: 1.5503181202802807e-05\n",
            "Stage 3/10:  85%|████████████████████████▋    | 256/300 [08:04<01:27,  2.00s/it]T Loss=2.303952693939209\n",
            "g_norm = tensor(0.0857, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034956455230713\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304652690887451\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305189371109009\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303863048553467\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4193878173828\n",
            "||∇_X meta|| = 0.001591587089933455\n",
            "ΔX norm: 1.5915869880700484e-05\n",
            "Stage 3/10:  86%|████████████████████████▊    | 257/300 [08:06<01:24,  1.97s/it]T Loss=2.304250955581665\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034310340881348\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034908771514893\n",
            "g_norm = tensor(0.1153, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037257194519043\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302363395690918\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.79156494140625\n",
            "||∇_X meta|| = 0.0015100551536306739\n",
            "ΔX norm: 1.5100551536306739e-05\n",
            "Stage 3/10:  86%|████████████████████████▉    | 258/300 [08:08<01:20,  1.92s/it]T Loss=2.3034934997558594\n",
            "g_norm = tensor(0.1400, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303586006164551\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035359382629395\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032174110412598\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040804862976074\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.30873107910156\n",
            "||∇_X meta|| = 0.0015350545290857553\n",
            "ΔX norm: 1.5350549801951274e-05\n",
            "Stage 3/10:  86%|█████████████████████████    | 259/300 [08:10<01:20,  1.96s/it]T Loss=2.304170608520508\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026421070098877\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031108379364014\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037421703338623\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041293621063232\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6083984375\n",
            "||∇_X meta|| = 0.0016379787120968103\n",
            "ΔX norm: 1.6379757653339766e-05\n",
            "Stage 3/10:  87%|█████████████████████████▏   | 260/300 [08:12<01:18,  1.96s/it]T Loss=2.30413556098938\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040804862976074\n",
            "g_norm = tensor(0.0858, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042826652526855\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045105934143066\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303882598876953\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5721893310547\n",
            "||∇_X meta|| = 0.001504919957369566\n",
            "ΔX norm: 1.5049223293317482e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 3/10:  87%|█████████████████████████▏   | 261/300 [08:14<01:15,  1.93s/it]T Loss=2.302574872970581\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036460876464844\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047327995300293\n",
            "g_norm = tensor(0.1396, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035285472869873\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048863410949707\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.91929626464844\n",
            "||∇_X meta|| = 0.001566146849654615\n",
            "ΔX norm: 1.566148057463579e-05\n",
            "Stage 3/10:  87%|█████████████████████████▎   | 262/300 [08:16<01:19,  2.09s/it]T Loss=2.3039047718048096\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047900199890137\n",
            "g_norm = tensor(0.1371, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049118518829346\n",
            "g_norm = tensor(0.1324, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30420184135437\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30461049079895\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.91384887695312\n",
            "||∇_X meta|| = 0.0015415566740557551\n",
            "ΔX norm: 1.541556957818102e-05\n",
            "Stage 3/10:  88%|█████████████████████████▍   | 263/300 [08:18<01:16,  2.06s/it]T Loss=2.3029568195343018\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303567886352539\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302469253540039\n",
            "g_norm = tensor(0.1312, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304919719696045\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022255897521973\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.89846801757812\n",
            "||∇_X meta|| = 0.0015258877538144588\n",
            "ΔX norm: 1.525890183984302e-05\n",
            "Stage 3/10:  88%|█████████████████████████▌   | 264/300 [08:20<01:11,  1.99s/it]T Loss=2.3025832176208496\n",
            "g_norm = tensor(0.0816, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303168773651123\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032584190368652\n",
            "g_norm = tensor(0.0825, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303213596343994\n",
            "g_norm = tensor(0.0723, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303065061569214\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.43948364257812\n",
            "||∇_X meta|| = 0.0014506387524306774\n",
            "ΔX norm: 1.4506384104606695e-05\n",
            "Stage 3/10:  88%|█████████████████████████▌   | 265/300 [08:22<01:07,  1.92s/it]T Loss=2.30189847946167\n",
            "g_norm = tensor(0.1253, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034675121307373\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030948638916016\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302703857421875\n",
            "g_norm = tensor(0.1213, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302701473236084\n",
            "g_norm = tensor(0.1411, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2794647216797\n",
            "||∇_X meta|| = 0.0015810005133971572\n",
            "ΔX norm: 1.5810001059435308e-05\n",
            "Stage 3/10:  89%|█████████████████████████▋   | 266/300 [08:24<01:03,  1.86s/it]T Loss=2.303668975830078\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305851459503174\n",
            "g_norm = tensor(0.1452, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045125007629395\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303893566131592\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037917613983154\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.43801879882812\n",
            "||∇_X meta|| = 0.001591591048054397\n",
            "ΔX norm: 1.5915911717456765e-05\n",
            "Stage 3/10:  89%|█████████████████████████▊   | 267/300 [08:25<00:59,  1.81s/it]T Loss=2.304617404937744\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035435676574707\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302915573120117\n",
            "g_norm = tensor(0.0980, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033804893493652\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303370952606201\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.17880249023438\n",
            "||∇_X meta|| = 0.0014449203154072165\n",
            "ΔX norm: 1.4449233276536688e-05\n",
            "Stage 3/10:  89%|█████████████████████████▉   | 268/300 [08:27<00:56,  1.77s/it]T Loss=2.304664134979248\n",
            "g_norm = tensor(0.0854, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048768043518066\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039677143096924\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304914951324463\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305098295211792\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.8939971923828\n",
            "||∇_X meta|| = 0.0013980097137391567\n",
            "ΔX norm: 1.39801095428993e-05\n",
            "Stage 3/10:  90%|██████████████████████████   | 269/300 [08:29<00:54,  1.75s/it]T Loss=2.3026466369628906\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302766799926758\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045849800109863\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304325580596924\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30305814743042\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.51519775390625\n",
            "||∇_X meta|| = 0.0014481812249869108\n",
            "ΔX norm: 1.4481825019174721e-05\n",
            "Stage 3/10:  90%|██████████████████████████   | 270/300 [08:30<00:51,  1.73s/it]T Loss=2.3040950298309326\n",
            "g_norm = tensor(0.0794, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303697109222412\n",
            "g_norm = tensor(0.0796, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303943634033203\n",
            "g_norm = tensor(0.0752, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039793968200684\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038814067840576\n",
            "g_norm = tensor(0.0852, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9361114501953\n",
            "||∇_X meta|| = 0.0017067979788407683\n",
            "ΔX norm: 1.706795592326671e-05\n",
            "Stage 3/10:  90%|██████████████████████████▏  | 271/300 [08:33<00:58,  2.01s/it]T Loss=2.3046863079071045\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304410457611084\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302652597427368\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303489923477173\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303616523742676\n",
            "g_norm = tensor(0.0829, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0582275390625\n",
            "||∇_X meta|| = 0.0016562858363613486\n",
            "ΔX norm: 1.6562862583668903e-05\n",
            "Stage 3/10:  91%|██████████████████████████▎  | 272/300 [08:35<00:57,  2.07s/it]T Loss=2.303872585296631\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305023670196533\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048856258392334\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047423362731934\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304915428161621\n",
            "g_norm = tensor(0.1330, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.88116455078125\n",
            "||∇_X meta|| = 0.0015920759178698063\n",
            "ΔX norm: 1.592077205714304e-05\n",
            "Stage 3/10:  91%|██████████████████████████▍  | 273/300 [08:37<00:54,  2.01s/it]T Loss=2.3047447204589844\n",
            "g_norm = tensor(0.1362, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026986122131348\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039774894714355\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303288459777832\n",
            "g_norm = tensor(0.1273, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304245948791504\n",
            "g_norm = tensor(0.1249, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.05621337890625\n",
            "||∇_X meta|| = 0.0016198940575122833\n",
            "ΔX norm: 1.6198922821786255e-05\n",
            "Stage 3/10:  91%|██████████████████████████▍  | 274/300 [08:39<00:50,  1.94s/it]T Loss=2.3051178455352783\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051860332489014\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305178642272949\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303514003753662\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304821252822876\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.87831115722656\n",
            "||∇_X meta|| = 0.0016013984568417072\n",
            "ΔX norm: 1.6014004359021783e-05\n",
            "Stage 3/10:  92%|██████████████████████████▌  | 275/300 [08:41<00:47,  1.88s/it]T Loss=2.303501605987549\n",
            "g_norm = tensor(0.1285, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046555519104004\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027939796447754\n",
            "g_norm = tensor(0.1259, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027851581573486\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301103115081787\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.85032653808594\n",
            "||∇_X meta|| = 0.0015463404124602675\n",
            "ΔX norm: 1.546339080960024e-05\n",
            "Stage 3/10:  92%|██████████████████████████▋  | 276/300 [08:42<00:44,  1.84s/it]T Loss=2.3045718669891357\n",
            "g_norm = tensor(0.0816, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046457767486572\n",
            "g_norm = tensor(0.0947, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304863452911377\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30433988571167\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303784132003784\n",
            "g_norm = tensor(0.0811, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.6783447265625\n",
            "||∇_X meta|| = 0.0015881475992500782\n",
            "ΔX norm: 1.5881460058153607e-05\n",
            "Stage 3/10:  92%|██████████████████████████▊  | 277/300 [08:44<00:41,  1.81s/it]T Loss=2.304288864135742\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033275604248047\n",
            "g_norm = tensor(0.1485, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304529905319214\n",
            "g_norm = tensor(0.1493, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302708387374878\n",
            "g_norm = tensor(0.1509, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304551601409912\n",
            "g_norm = tensor(0.1327, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.64315795898438\n",
            "||∇_X meta|| = 0.0017998504918068647\n",
            "ΔX norm: 1.7998512703343295e-05\n",
            "Stage 3/10:  93%|██████████████████████████▊  | 278/300 [08:46<00:39,  1.77s/it]T Loss=2.303487777709961\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036389350891113\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036797046661377\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303823947906494\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035762310028076\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.415283203125\n",
            "||∇_X meta|| = 0.0015570935793220997\n",
            "ΔX norm: 1.5570965842925943e-05\n",
            "Stage 3/10:  93%|██████████████████████████▉  | 279/300 [08:48<00:36,  1.76s/it]T Loss=2.303041934967041\n",
            "g_norm = tensor(0.1011, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035120964050293\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038620948791504\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030428886413574\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303279161453247\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.60450744628906\n",
            "||∇_X meta|| = 0.0017572304932400584\n",
            "ΔX norm: 1.7572290744283237e-05\n",
            "Stage 3/10:  93%|███████████████████████████  | 280/300 [08:49<00:35,  1.80s/it]T Loss=2.3049492835998535\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302643060684204\n",
            "g_norm = tensor(0.1389, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052520751953125\n",
            "g_norm = tensor(0.1326, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049988746643066\n",
            "g_norm = tensor(0.1455, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055739402770996\n",
            "g_norm = tensor(0.1413, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.71922302246094\n",
            "||∇_X meta|| = 0.0015802759444341063\n",
            "ΔX norm: 1.580278512847144e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 3/10:  94%|███████████████████████████▏ | 281/300 [08:51<00:34,  1.81s/it]T Loss=2.304908275604248\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030033111572266\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027119636535645\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303370952606201\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302462339401245\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.80430603027344\n",
            "||∇_X meta|| = 0.0016073297010734677\n",
            "ΔX norm: 1.607327430974692e-05\n",
            "Stage 3/10:  94%|███████████████████████████▎ | 282/300 [08:54<00:37,  2.06s/it]T Loss=2.3048195838928223\n",
            "g_norm = tensor(0.1367, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302527904510498\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057422637939453\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029510974884033\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036694526672363\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.60931396484375\n",
            "||∇_X meta|| = 0.0016080978093668818\n",
            "ΔX norm: 1.6080992281786166e-05\n",
            "Stage 3/10:  94%|███████████████████████████▎ | 283/300 [08:57<00:37,  2.21s/it]T Loss=2.30442476272583\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044426441192627\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303853750228882\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052165508270264\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033969402313232\n",
            "g_norm = tensor(0.0960, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4597625732422\n",
            "||∇_X meta|| = 0.0014783816877752542\n",
            "ΔX norm: 1.4783801816520281e-05\n",
            "Stage 3/10:  95%|███████████████████████████▍ | 284/300 [08:59<00:34,  2.15s/it]T Loss=2.303114891052246\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303192138671875\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038549423217773\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035783767700195\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303251266479492\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.61708068847656\n",
            "||∇_X meta|| = 0.0015082616591826081\n",
            "ΔX norm: 1.50826281242189e-05\n",
            "Stage 3/10:  95%|███████████████████████████▌ | 285/300 [09:00<00:30,  2.05s/it]T Loss=2.303689479827881\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304987668991089\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303314208984375\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042163848876953\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304370164871216\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.98143005371094\n",
            "||∇_X meta|| = 0.0015519547741860151\n",
            "ΔX norm: 1.5519573935307562e-05\n",
            "Stage 3/10:  95%|███████████████████████████▋ | 286/300 [09:02<00:27,  1.98s/it]T Loss=2.304339647293091\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303983211517334\n",
            "g_norm = tensor(0.0858, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30438494682312\n",
            "g_norm = tensor(0.0810, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048768043518066\n",
            "g_norm = tensor(0.0860, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304257392883301\n",
            "g_norm = tensor(0.0860, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.845703125\n",
            "||∇_X meta|| = 0.0016874335706233978\n",
            "ΔX norm: 1.687433905317448e-05\n",
            "Stage 3/10:  96%|███████████████████████████▋ | 287/300 [09:04<00:25,  1.97s/it]T Loss=2.3037095069885254\n",
            "g_norm = tensor(0.1561, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033432960510254\n",
            "g_norm = tensor(0.1472, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040411472320557\n",
            "g_norm = tensor(0.1206, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303696393966675\n",
            "g_norm = tensor(0.1612, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050754070281982\n",
            "g_norm = tensor(0.1413, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.01031494140625\n",
            "||∇_X meta|| = 0.0015541489701718092\n",
            "ΔX norm: 1.554151276650373e-05\n",
            "Stage 3/10:  96%|███████████████████████████▊ | 288/300 [09:06<00:23,  1.98s/it]T Loss=2.3040897846221924\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019306659698486\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30265212059021\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025524616241455\n",
            "g_norm = tensor(0.1153, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047776222229004\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4974365234375\n",
            "||∇_X meta|| = 0.0014255049172788858\n",
            "ΔX norm: 1.425508253305452e-05\n",
            "Stage 3/10:  96%|███████████████████████████▉ | 289/300 [09:08<00:21,  1.96s/it]T Loss=2.3017749786376953\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048298358917236\n",
            "g_norm = tensor(0.1184, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303157091140747\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034844398498535\n",
            "g_norm = tensor(0.1519, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302217721939087\n",
            "g_norm = tensor(0.1722, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5777130126953\n",
            "||∇_X meta|| = 0.001551050809212029\n",
            "ΔX norm: 1.5510566299781203e-05\n",
            "Stage 3/10:  97%|████████████████████████████ | 290/300 [09:10<00:19,  1.95s/it]T Loss=2.3046250343322754\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043742179870605\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303804636001587\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303114891052246\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034744262695312\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.96534729003906\n",
            "||∇_X meta|| = 0.0015311260940507054\n",
            "ΔX norm: 1.5311296010622755e-05\n",
            "Stage 3/10:  97%|████████████████████████████▏| 291/300 [09:12<00:17,  1.91s/it]T Loss=2.3039631843566895\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304530620574951\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305967330932617\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304980754852295\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046975135803223\n",
            "g_norm = tensor(0.1257, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.21971130371094\n",
            "||∇_X meta|| = 0.0015602713683620095\n",
            "ΔX norm: 1.560268174216617e-05\n",
            "Stage 3/10:  97%|████████████████████████████▏| 292/300 [09:14<00:15,  1.90s/it]T Loss=2.3034703731536865\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030154705047607\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035597801208496\n",
            "g_norm = tensor(0.0808, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023648262023926\n",
            "g_norm = tensor(0.0923, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034088611602783\n",
            "g_norm = tensor(0.0756, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.83609008789062\n",
            "||∇_X meta|| = 0.00132422661408782\n",
            "ΔX norm: 1.3242260138213169e-05\n",
            "Stage 3/10:  98%|████████████████████████████▎| 293/300 [09:16<00:13,  1.99s/it]T Loss=2.305513858795166\n",
            "g_norm = tensor(0.1860, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3006608486175537\n",
            "g_norm = tensor(0.1844, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306225538253784\n",
            "g_norm = tensor(0.1578, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040263652801514\n",
            "g_norm = tensor(0.1544, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305509567260742\n",
            "g_norm = tensor(0.1496, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0786590576172\n",
            "||∇_X meta|| = 0.0016026096418499947\n",
            "ΔX norm: 1.6026091543608345e-05\n",
            "Stage 3/10:  98%|████████████████████████████▍| 294/300 [09:18<00:12,  2.05s/it]T Loss=2.304436445236206\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303837299346924\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039872646331787\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046882152557373\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304084300994873\n",
            "g_norm = tensor(0.0947, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.6319122314453\n",
            "||∇_X meta|| = 0.0016268085455521941\n",
            "ΔX norm: 1.6268093531834893e-05\n",
            "Stage 3/10:  98%|████████████████████████████▌| 295/300 [09:20<00:10,  2.02s/it]T Loss=2.30391526222229\n",
            "g_norm = tensor(0.1456, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303130626678467\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302932024002075\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046810626983643\n",
            "g_norm = tensor(0.1369, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039896488189697\n",
            "g_norm = tensor(0.1640, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.20460510253906\n",
            "||∇_X meta|| = 0.0015076057752594352\n",
            "ΔX norm: 1.5076057934493292e-05\n",
            "Stage 3/10:  99%|████████████████████████████▌| 296/300 [09:22<00:07,  1.98s/it]T Loss=2.303767681121826\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020424842834473\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303694248199463\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303004741668701\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046414852142334\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6017303466797\n",
            "||∇_X meta|| = 0.0016259599942713976\n",
            "ΔX norm: 1.625960248929914e-05\n",
            "Stage 3/10:  99%|████████████████████████████▋| 297/300 [09:24<00:05,  1.93s/it]T Loss=2.3032047748565674\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045952320098877\n",
            "g_norm = tensor(0.1337, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304158926010132\n",
            "g_norm = tensor(0.1517, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305637836456299\n",
            "g_norm = tensor(0.1324, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304471969604492\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7191925048828\n",
            "||∇_X meta|| = 0.0015304622938856483\n",
            "ΔX norm: 1.530461486254353e-05\n",
            "Stage 3/10:  99%|████████████████████████████▊| 298/300 [09:25<00:03,  1.89s/it]T Loss=2.3035974502563477\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032219409942627\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039181232452393\n",
            "g_norm = tensor(0.1306, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301130771636963\n",
            "g_norm = tensor(0.1610, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019871711730957\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7669219970703\n",
            "||∇_X meta|| = 0.001580311101861298\n",
            "ΔX norm: 1.5803108908585273e-05\n",
            "Stage 3/10: 100%|████████████████████████████▉| 299/300 [09:27<00:01,  1.85s/it]T Loss=2.303694248199463\n",
            "g_norm = tensor(0.0838, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039448261260986\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034541606903076\n",
            "g_norm = tensor(0.0923, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041188716888428\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302508592605591\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.06719970703125\n",
            "||∇_X meta|| = 0.0015444166492670774\n",
            "ΔX norm: 1.544415863463655e-05\n",
            "Stage 2, class 0, loss 2.209                                                    \n",
            "Stage 2, class 1, loss 2.268\n",
            "Stage 2, class 2, loss 2.342\n",
            "Stage 2, class 3, loss 2.360\n",
            "Stage 2, class 4, loss 2.304\n",
            "Stage 2, class 5, loss 2.326\n",
            "Stage 2, class 6, loss 2.387\n",
            "Stage 2, class 7, loss 2.220\n",
            "Stage 2, class 8, loss 2.378\n",
            "Stage 2, class 9, loss 2.254\n",
            "Stage 4/10:   0%|                                       | 0/300 [00:00<?, ?it/s]T Loss=2.303758144378662\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038904666900635\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051095008850098\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041083812713623\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054118156433105\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.8203125\n",
            "||∇_X meta|| = 0.004046610090881586\n",
            "ΔX norm: 4.046604226459749e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 4/10:   0%|                               | 1/300 [00:01<09:48,  1.97s/it]T Loss=2.3049795627593994\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30462646484375\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047242164611816\n",
            "g_norm = tensor(0.1414, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304607629776001\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3063058853149414\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.60633850097656\n",
            "||∇_X meta|| = 0.0033470094203948975\n",
            "ΔX norm: 3.34700926032383e-05\n",
            "Stage 4/10:   1%|▏                              | 2/300 [00:04<11:01,  2.22s/it]T Loss=2.3036139011383057\n",
            "g_norm = tensor(0.0697, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034780025482178\n",
            "g_norm = tensor(0.0723, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302765369415283\n",
            "g_norm = tensor(0.0783, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031740188598633\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032619953155518\n",
            "g_norm = tensor(0.0705, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.79344177246094\n",
            "||∇_X meta|| = 0.0035899856593459845\n",
            "ΔX norm: 3.589980406104587e-05\n",
            "Stage 4/10:   1%|▎                              | 3/300 [00:06<10:10,  2.06s/it]T Loss=2.3039021492004395\n",
            "g_norm = tensor(0.1519, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043065071105957\n",
            "g_norm = tensor(0.1440, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301318883895874\n",
            "g_norm = tensor(0.1563, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035411834716797\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30265474319458\n",
            "g_norm = tensor(0.1595, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.32688903808594\n",
            "||∇_X meta|| = 0.003672431455925107\n",
            "ΔX norm: 3.672435195767321e-05\n",
            "Stage 4/10:   1%|▍                              | 4/300 [00:08<09:48,  1.99s/it]T Loss=2.303748369216919\n",
            "g_norm = tensor(0.0801, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044402599334717\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043644428253174\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304377794265747\n",
            "g_norm = tensor(0.0919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303426742553711\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.71791076660156\n",
            "||∇_X meta|| = 0.003478114726021886\n",
            "ΔX norm: 3.478113649180159e-05\n",
            "Stage 4/10:   2%|▌                              | 5/300 [00:09<09:24,  1.91s/it]T Loss=2.30273175239563\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029091358184814\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303189754486084\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303440570831299\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031623363494873\n",
            "g_norm = tensor(0.1285, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.388916015625\n",
            "||∇_X meta|| = 0.003953126259148121\n",
            "ΔX norm: 3.9531201764475554e-05\n",
            "Stage 4/10:   2%|▌                              | 6/300 [00:11<09:05,  1.85s/it]T Loss=2.3039698600769043\n",
            "g_norm = tensor(0.1276, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039700984954834\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053324222564697\n",
            "g_norm = tensor(0.1342, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048882484436035\n",
            "g_norm = tensor(0.1375, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050453662872314\n",
            "g_norm = tensor(0.1396, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4873046875\n",
            "||∇_X meta|| = 0.0038112907204777002\n",
            "ΔX norm: 3.811292481259443e-05\n",
            "Stage 4/10:   2%|▋                              | 7/300 [00:13<09:01,  1.85s/it]T Loss=2.303697347640991\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303213119506836\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30383563041687\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036506175994873\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035731315612793\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.32081604003906\n",
            "||∇_X meta|| = 0.0034661327954381704\n",
            "ΔX norm: 3.4661356039578095e-05\n",
            "Stage 4/10:   3%|▊                              | 8/300 [00:15<09:28,  1.95s/it]T Loss=2.305255651473999\n",
            "g_norm = tensor(0.1410, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045544624328613\n",
            "g_norm = tensor(0.1435, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028154373168945\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302889585494995\n",
            "g_norm = tensor(0.1266, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302304983139038\n",
            "g_norm = tensor(0.1221, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6943817138672\n",
            "||∇_X meta|| = 0.0036580527666956186\n",
            "ΔX norm: 3.658049172372557e-05\n",
            "Stage 4/10:   3%|▉                              | 9/300 [00:17<09:25,  1.94s/it]T Loss=2.3024115562438965\n",
            "g_norm = tensor(0.1460, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021793365478516\n",
            "g_norm = tensor(0.1504, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032679557800293\n",
            "g_norm = tensor(0.1473, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029582500457764\n",
            "g_norm = tensor(0.1407, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020567893981934\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4292449951172\n",
            "||∇_X meta|| = 0.00383385200984776\n",
            "ΔX norm: 3.8338504964485765e-05\n",
            "Stage 4/10:   3%|█                             | 10/300 [00:20<10:10,  2.10s/it]T Loss=2.3043205738067627\n",
            "g_norm = tensor(0.1506, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026702404022217\n",
            "g_norm = tensor(0.1754, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302978038787842\n",
            "g_norm = tensor(0.1736, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040316104888916\n",
            "g_norm = tensor(0.1376, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302971124649048\n",
            "g_norm = tensor(0.1417, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9530487060547\n",
            "||∇_X meta|| = 0.003241562517359853\n",
            "ΔX norm: 3.241561717004515e-05\n",
            "Stage 4/10:   4%|█                             | 11/300 [00:21<09:47,  2.03s/it]T Loss=2.303494930267334\n",
            "g_norm = tensor(0.1843, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304241418838501\n",
            "g_norm = tensor(0.1660, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039488792419434\n",
            "g_norm = tensor(0.1581, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024113178253174\n",
            "g_norm = tensor(0.2054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023295402526855\n",
            "g_norm = tensor(0.2051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.74827575683594\n",
            "||∇_X meta|| = 0.0036950302310287952\n",
            "ΔX norm: 3.695022314786911e-05\n",
            "Stage 4/10:   4%|█▏                            | 12/300 [00:23<09:27,  1.97s/it]T Loss=2.304990768432617\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304638624191284\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303802967071533\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046669960021973\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034205436706543\n",
            "g_norm = tensor(0.1415, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.74609375\n",
            "||∇_X meta|| = 0.003423424204811454\n",
            "ΔX norm: 3.4234199119964615e-05\n",
            "Stage 4/10:   4%|█▎                            | 13/300 [00:25<09:12,  1.92s/it]T Loss=2.303065299987793\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303703784942627\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033108711242676\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303513765335083\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302783727645874\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.68942260742188\n",
            "||∇_X meta|| = 0.003743457840755582\n",
            "ΔX norm: 3.743459819816053e-05\n",
            "Stage 4/10:   5%|█▍                            | 14/300 [00:27<08:59,  1.89s/it]T Loss=2.3052926063537598\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035976886749268\n",
            "g_norm = tensor(0.1080, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30496883392334\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303770065307617\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304175615310669\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4362030029297\n",
            "||∇_X meta|| = 0.0038397598545998335\n",
            "ΔX norm: 3.839763667201623e-05\n",
            "Stage 4/10:   5%|█▌                            | 15/300 [00:29<09:01,  1.90s/it]T Loss=2.3036816120147705\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303359031677246\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302694082260132\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303656578063965\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024768829345703\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3432159423828\n",
            "||∇_X meta|| = 0.0033773917239159346\n",
            "ΔX norm: 3.3773943869164214e-05\n",
            "Stage 4/10:   5%|█▌                            | 16/300 [00:31<08:53,  1.88s/it]T Loss=2.3042049407958984\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303307056427002\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303408145904541\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30513334274292\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045427799224854\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.524658203125\n",
            "||∇_X meta|| = 0.003210553666576743\n",
            "ΔX norm: 3.210549766663462e-05\n",
            "Stage 4/10:   6%|█▋                            | 17/300 [00:32<08:41,  1.84s/it]T Loss=2.305619478225708\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305225133895874\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304412841796875\n",
            "g_norm = tensor(0.1206, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3069941997528076\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303962230682373\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.80995178222656\n",
            "||∇_X meta|| = 0.0033538355492055416\n",
            "ΔX norm: 3.353837746544741e-05\n",
            "Stage 4/10:   6%|█▊                            | 18/300 [00:34<08:37,  1.84s/it]T Loss=2.303711414337158\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304008960723877\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305872917175293\n",
            "g_norm = tensor(0.1154, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303781032562256\n",
            "g_norm = tensor(0.0885, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042449951171875\n",
            "g_norm = tensor(0.0837, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4481658935547\n",
            "||∇_X meta|| = 0.003204584354534745\n",
            "ΔX norm: 3.204585664207116e-05\n",
            "Stage 4/10:   6%|█▉                            | 19/300 [00:36<08:36,  1.84s/it]T Loss=2.304333209991455\n",
            "g_norm = tensor(0.1434, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305807590484619\n",
            "g_norm = tensor(0.1583, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036258220672607\n",
            "g_norm = tensor(0.1448, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303366184234619\n",
            "g_norm = tensor(0.1389, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043148517608643\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.36312866210938\n",
            "||∇_X meta|| = 0.003253217553719878\n",
            "ΔX norm: 3.2532159821130335e-05\n",
            "Stage 4/10:   7%|██                            | 20/300 [00:38<08:32,  1.83s/it]T Loss=2.304492473602295\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051106929779053\n",
            "g_norm = tensor(0.0836, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040969371795654\n",
            "g_norm = tensor(0.0844, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304698944091797\n",
            "g_norm = tensor(0.0841, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304746150970459\n",
            "g_norm = tensor(0.0765, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.9263458251953\n",
            "||∇_X meta|| = 0.003465150948613882\n",
            "ΔX norm: 3.46515080309473e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 4/10:   7%|██                            | 21/300 [00:40<08:36,  1.85s/it]T Loss=2.304049491882324\n",
            "g_norm = tensor(0.0825, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045945167541504\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031561374664307\n",
            "g_norm = tensor(0.0812, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039917945861816\n",
            "g_norm = tensor(0.0838, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303896427154541\n",
            "g_norm = tensor(0.0772, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.21768188476562\n",
            "||∇_X meta|| = 0.0034670880995690823\n",
            "ΔX norm: 3.46708475262858e-05\n",
            "Stage 4/10:   7%|██▏                           | 22/300 [00:42<09:18,  2.01s/it]T Loss=2.3032047748565674\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038077354431152\n",
            "g_norm = tensor(0.1107, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303165912628174\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022453784942627\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045132160186768\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.46685791015625\n",
            "||∇_X meta|| = 0.002808559685945511\n",
            "ΔX norm: 2.8085622034268454e-05\n",
            "Stage 4/10:   8%|██▎                           | 23/300 [00:44<09:09,  1.98s/it]T Loss=2.303720235824585\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042352199554443\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302786350250244\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036999702453613\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303774118423462\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.41363525390625\n",
            "||∇_X meta|| = 0.0031306666787713766\n",
            "ΔX norm: 3.130665572825819e-05\n",
            "Stage 4/10:   8%|██▍                           | 24/300 [00:46<09:22,  2.04s/it]T Loss=2.3042006492614746\n",
            "g_norm = tensor(0.1595, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3007190227508545\n",
            "g_norm = tensor(0.1565, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040390014648438\n",
            "g_norm = tensor(0.1861, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304123640060425\n",
            "g_norm = tensor(0.1742, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037917613983154\n",
            "g_norm = tensor(0.1661, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.7443389892578\n",
            "||∇_X meta|| = 0.003011196618899703\n",
            "ΔX norm: 3.011202898051124e-05\n",
            "Stage 4/10:   8%|██▌                           | 25/300 [00:48<09:13,  2.01s/it]T Loss=2.3029136657714844\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032116889953613\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035082817077637\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033814430236816\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303532600402832\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.26597595214844\n",
            "||∇_X meta|| = 0.0029174385126680136\n",
            "ΔX norm: 2.9174378141760826e-05\n",
            "Stage 4/10:   9%|██▌                           | 26/300 [00:50<09:08,  2.00s/it]T Loss=2.3027777671813965\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032617568969727\n",
            "g_norm = tensor(0.1219, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30320405960083\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302412748336792\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018221855163574\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.94874572753906\n",
            "||∇_X meta|| = 0.0034714662469923496\n",
            "ΔX norm: 3.471464151516557e-05\n",
            "Stage 4/10:   9%|██▋                           | 27/300 [00:52<09:12,  2.02s/it]T Loss=2.305342197418213\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051705360412598\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027164936065674\n",
            "g_norm = tensor(0.1542, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3064494132995605\n",
            "g_norm = tensor(0.1454, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038735389709473\n",
            "g_norm = tensor(0.1474, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9691619873047\n",
            "||∇_X meta|| = 0.0026261424645781517\n",
            "ΔX norm: 2.6261428502039053e-05\n",
            "Stage 4/10:   9%|██▊                           | 28/300 [00:54<08:53,  1.96s/it]T Loss=2.3030688762664795\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029518127441406\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304058790206909\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029325008392334\n",
            "g_norm = tensor(0.1307, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025543689727783\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3059539794922\n",
            "||∇_X meta|| = 0.0028697585221379995\n",
            "ΔX norm: 2.869756644940935e-05\n",
            "Stage 4/10:  10%|██▉                           | 29/300 [00:56<09:23,  2.08s/it]T Loss=2.304147243499756\n",
            "g_norm = tensor(0.0960, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303929567337036\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304457902908325\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033688068389893\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304321765899658\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.35574340820312\n",
            "||∇_X meta|| = 0.0029781791381537914\n",
            "ΔX norm: 2.9781835110043176e-05\n",
            "Stage 4/10:  10%|███                           | 30/300 [00:58<09:17,  2.07s/it]T Loss=2.3046228885650635\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034489154815674\n",
            "g_norm = tensor(0.1216, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052783012390137\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3060216903686523\n",
            "g_norm = tensor(0.1295, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304574966430664\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.0081024169922\n",
            "||∇_X meta|| = 0.0028077554889023304\n",
            "ΔX norm: 2.80775402643485e-05\n",
            "Stage 4/10:  10%|███                           | 31/300 [01:00<09:06,  2.03s/it]T Loss=2.3037233352661133\n",
            "g_norm = tensor(0.1945, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303617000579834\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302737236022949\n",
            "g_norm = tensor(0.1462, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303882122039795\n",
            "g_norm = tensor(0.1703, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303454637527466\n",
            "g_norm = tensor(0.1533, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5995330810547\n",
            "||∇_X meta|| = 0.002932823495939374\n",
            "ΔX norm: 2.93282100756187e-05\n",
            "Stage 4/10:  11%|███▏                          | 32/300 [01:02<08:59,  2.01s/it]T Loss=2.304814338684082\n",
            "g_norm = tensor(0.2113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301783323287964\n",
            "g_norm = tensor(0.2139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3063700199127197\n",
            "g_norm = tensor(0.1649, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050827980041504\n",
            "g_norm = tensor(0.1804, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3067736625671387\n",
            "g_norm = tensor(0.2233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.81895446777344\n",
            "||∇_X meta|| = 0.0027799031231552362\n",
            "ΔX norm: 2.7799047529697418e-05\n",
            "Stage 4/10:  11%|███▎                          | 33/300 [01:04<08:45,  1.97s/it]T Loss=2.3028907775878906\n",
            "g_norm = tensor(0.1516, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30385684967041\n",
            "g_norm = tensor(0.1384, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032355308532715\n",
            "g_norm = tensor(0.1450, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30314302444458\n",
            "g_norm = tensor(0.1536, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039517402648926\n",
            "g_norm = tensor(0.1320, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4208984375\n",
            "||∇_X meta|| = 0.0030843617860227823\n",
            "ΔX norm: 3.0843631975585595e-05\n",
            "Stage 4/10:  11%|███▍                          | 34/300 [01:06<08:53,  2.01s/it]T Loss=2.3007705211639404\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3008835315704346\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303788661956787\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018107414245605\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3014719486236572\n",
            "g_norm = tensor(0.1542, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.84368896484375\n",
            "||∇_X meta|| = 0.0027969363145530224\n",
            "ΔX norm: 2.7969368602498434e-05\n",
            "Stage 4/10:  12%|███▌                          | 35/300 [01:08<08:50,  2.00s/it]T Loss=2.303642749786377\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051648139953613\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033134937286377\n",
            "g_norm = tensor(0.0945, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029866218566895\n",
            "g_norm = tensor(0.0810, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303710460662842\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2054901123047\n",
            "||∇_X meta|| = 0.0027362839318811893\n",
            "ΔX norm: 2.7362846594769508e-05\n",
            "Stage 4/10:  12%|███▌                          | 36/300 [01:10<08:39,  1.97s/it]T Loss=2.303866147994995\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304414987564087\n",
            "g_norm = tensor(0.1513, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031859397888184\n",
            "g_norm = tensor(0.1347, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038907051086426\n",
            "g_norm = tensor(0.1602, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043198585510254\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.0909881591797\n",
            "||∇_X meta|| = 0.0028246452566236258\n",
            "ΔX norm: 2.824644252541475e-05\n",
            "Stage 4/10:  12%|███▋                          | 37/300 [01:12<08:26,  1.93s/it]T Loss=2.3037095069885254\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303058624267578\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303292751312256\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303489923477173\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302563428878784\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8069610595703\n",
            "||∇_X meta|| = 0.0029593117069453\n",
            "ΔX norm: 2.959313860628754e-05\n",
            "Stage 4/10:  13%|███▊                          | 38/300 [01:14<08:18,  1.90s/it]T Loss=2.3049938678741455\n",
            "g_norm = tensor(0.0960, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304569721221924\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306356906890869\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303941011428833\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044121265411377\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.94313049316406\n",
            "||∇_X meta|| = 0.0031130460556596518\n",
            "ΔX norm: 3.1130475690588355e-05\n",
            "Stage 4/10:  13%|███▉                          | 39/300 [01:16<08:11,  1.88s/it]T Loss=2.3052897453308105\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053321838378906\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047337532043457\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30393648147583\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044142723083496\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.78469848632812\n",
            "||∇_X meta|| = 0.0027873653452843428\n",
            "ΔX norm: 2.787367338896729e-05\n",
            "Stage 4/10:  13%|████                          | 40/300 [01:18<08:17,  1.91s/it]T Loss=2.3043408393859863\n",
            "g_norm = tensor(0.1556, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055615425109863\n",
            "g_norm = tensor(0.1531, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046231269836426\n",
            "g_norm = tensor(0.1376, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304567813873291\n",
            "g_norm = tensor(0.1357, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039603233337402\n",
            "g_norm = tensor(0.1388, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.09744262695312\n",
            "||∇_X meta|| = 0.0027297090273350477\n",
            "ΔX norm: 2.7297090127831325e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 4/10:  14%|████                          | 41/300 [01:20<08:20,  1.93s/it]T Loss=2.304997682571411\n",
            "g_norm = tensor(0.1516, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039793968200684\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303663730621338\n",
            "g_norm = tensor(0.1380, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054845333099365\n",
            "g_norm = tensor(0.1451, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304187059402466\n",
            "g_norm = tensor(0.1562, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.282958984375\n",
            "||∇_X meta|| = 0.002759885974228382\n",
            "ΔX norm: 2.7598867745837197e-05\n",
            "Stage 4/10:  14%|████▏                         | 42/300 [01:22<09:14,  2.15s/it]T Loss=2.303903579711914\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034262657165527\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304208755493164\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040194511413574\n",
            "g_norm = tensor(0.0942, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019418716430664\n",
            "g_norm = tensor(0.0844, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0799102783203\n",
            "||∇_X meta|| = 0.002777681453153491\n",
            "ΔX norm: 2.777678491838742e-05\n",
            "Stage 4/10:  14%|████▎                         | 43/300 [01:24<08:50,  2.06s/it]T Loss=2.304363489151001\n",
            "g_norm = tensor(0.1305, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038341999053955\n",
            "g_norm = tensor(0.1259, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046793937683105\n",
            "g_norm = tensor(0.1406, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304060220718384\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029797077178955\n",
            "g_norm = tensor(0.1536, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.57623291015625\n",
            "||∇_X meta|| = 0.0026831096038222313\n",
            "ΔX norm: 2.6831119612324983e-05\n",
            "Stage 4/10:  15%|████▍                         | 44/300 [01:26<08:30,  2.00s/it]T Loss=2.303657293319702\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022687435150146\n",
            "g_norm = tensor(0.1422, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042123317718506\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303152322769165\n",
            "g_norm = tensor(0.1257, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018975257873535\n",
            "g_norm = tensor(0.1477, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7187957763672\n",
            "||∇_X meta|| = 0.0027930093929171562\n",
            "ΔX norm: 2.7930052965530194e-05\n",
            "Stage 4/10:  15%|████▌                         | 45/300 [01:28<08:22,  1.97s/it]T Loss=2.30374813079834\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035809993743896\n",
            "g_norm = tensor(0.0847, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025448322296143\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303617000579834\n",
            "g_norm = tensor(0.0840, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035950660705566\n",
            "g_norm = tensor(0.0865, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.67796325683594\n",
            "||∇_X meta|| = 0.002491587772965431\n",
            "ΔX norm: 2.4915912945289165e-05\n",
            "Stage 4/10:  15%|████▌                         | 46/300 [01:30<08:03,  1.90s/it]T Loss=2.3044724464416504\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305487632751465\n",
            "g_norm = tensor(0.1285, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303946018218994\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048295974731445\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026938438415527\n",
            "g_norm = tensor(0.1099, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.97357177734375\n",
            "||∇_X meta|| = 0.0027749352157115936\n",
            "ΔX norm: 2.7749356377171353e-05\n",
            "Stage 4/10:  16%|████▋                         | 47/300 [01:32<07:57,  1.89s/it]T Loss=2.304055690765381\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031678199768066\n",
            "g_norm = tensor(0.0868, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027801513671875\n",
            "g_norm = tensor(0.0869, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031506538391113\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037796020507812\n",
            "g_norm = tensor(0.0743, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.41265869140625\n",
            "||∇_X meta|| = 0.0025578071363270283\n",
            "ΔX norm: 2.557808329584077e-05\n",
            "Stage 4/10:  16%|████▊                         | 48/300 [01:33<07:41,  1.83s/it]T Loss=2.302248239517212\n",
            "g_norm = tensor(0.1652, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303016185760498\n",
            "g_norm = tensor(0.1756, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303842544555664\n",
            "g_norm = tensor(0.1646, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304001569747925\n",
            "g_norm = tensor(0.1643, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027563095092773\n",
            "g_norm = tensor(0.1785, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =233.11634826660156\n",
            "||∇_X meta|| = 0.0026738306041806936\n",
            "ΔX norm: 2.6738320229924284e-05\n",
            "Stage 4/10:  16%|████▉                         | 49/300 [01:35<07:47,  1.86s/it]T Loss=2.304323673248291\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303746223449707\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034729957580566\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302675247192383\n",
            "g_norm = tensor(0.0923, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303168535232544\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.2415771484375\n",
            "||∇_X meta|| = 0.002850674092769623\n",
            "ΔX norm: 2.8506716262199916e-05\n",
            "Stage 4/10:  17%|█████                         | 50/300 [01:37<07:58,  1.91s/it]T Loss=2.3040246963500977\n",
            "g_norm = tensor(0.1320, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032543659210205\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303391456604004\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303680896759033\n",
            "g_norm = tensor(0.1361, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038196563720703\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.41543579101562\n",
            "||∇_X meta|| = 0.0025322483852505684\n",
            "ΔX norm: 2.53224752668757e-05\n",
            "Stage 4/10:  17%|█████                         | 51/300 [01:39<08:04,  1.95s/it]T Loss=2.303175687789917\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035366535186768\n",
            "g_norm = tensor(0.1183, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303455114364624\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033030033111572\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030855655670166\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.922119140625\n",
            "||∇_X meta|| = 0.002567718271166086\n",
            "ΔX norm: 2.56771563726943e-05\n",
            "Stage 4/10:  17%|█████▏                        | 52/300 [01:41<08:14,  1.99s/it]T Loss=2.3037731647491455\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034064769744873\n",
            "g_norm = tensor(0.0777, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303480386734009\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043484687805176\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036413192749023\n",
            "g_norm = tensor(0.0832, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.87525939941406\n",
            "||∇_X meta|| = 0.002762857126072049\n",
            "ΔX norm: 2.7628593670669943e-05\n",
            "Stage 4/10:  18%|█████▎                        | 53/300 [01:43<08:19,  2.02s/it]T Loss=2.304849147796631\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303748369216919\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035385608673096\n",
            "g_norm = tensor(0.1549, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304273843765259\n",
            "g_norm = tensor(0.1388, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304337978363037\n",
            "g_norm = tensor(0.1498, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.74758911132812\n",
            "||∇_X meta|| = 0.0025718470569700003\n",
            "ΔX norm: 2.571844197518658e-05\n",
            "Stage 4/10:  18%|█████▍                        | 54/300 [01:45<08:10,  1.99s/it]T Loss=2.3018364906311035\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303997278213501\n",
            "g_norm = tensor(0.1183, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303938388824463\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028268814086914\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303464412689209\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.158203125\n",
            "||∇_X meta|| = 0.0023146646562963724\n",
            "ΔX norm: 2.3146636522142217e-05\n",
            "Stage 4/10:  18%|█████▌                        | 55/300 [01:47<07:54,  1.94s/it]T Loss=2.303823947906494\n",
            "g_norm = tensor(0.0647, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042893409729004\n",
            "g_norm = tensor(0.0594, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304023265838623\n",
            "g_norm = tensor(0.0674, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035595417022705\n",
            "g_norm = tensor(0.0674, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044676780700684\n",
            "g_norm = tensor(0.0662, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.90701293945312\n",
            "||∇_X meta|| = 0.0021709571592509747\n",
            "ΔX norm: 2.1709574866690673e-05\n",
            "Stage 4/10:  19%|█████▌                        | 56/300 [01:49<07:37,  1.87s/it]T Loss=2.304370403289795\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055248260498047\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303117036819458\n",
            "g_norm = tensor(0.1347, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038549423217773\n",
            "g_norm = tensor(0.1425, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042798042297363\n",
            "g_norm = tensor(0.1251, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.97422790527344\n",
            "||∇_X meta|| = 0.002481836127117276\n",
            "ΔX norm: 2.4818342353682965e-05\n",
            "Stage 4/10:  19%|█████▋                        | 57/300 [01:51<07:31,  1.86s/it]T Loss=2.3036751747131348\n",
            "g_norm = tensor(0.0660, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037376403808594\n",
            "g_norm = tensor(0.0723, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303001880645752\n",
            "g_norm = tensor(0.0599, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040924072265625\n",
            "g_norm = tensor(0.0862, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030598163604736\n",
            "g_norm = tensor(0.0709, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.2368621826172\n",
            "||∇_X meta|| = 0.002069778274744749\n",
            "ΔX norm: 2.0697794752777554e-05\n",
            "Stage 4/10:  19%|█████▊                        | 58/300 [01:53<07:28,  1.85s/it]T Loss=2.3031468391418457\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304137706756592\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039677143096924\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035247325897217\n",
            "g_norm = tensor(0.1248, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048784732818604\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.4679412841797\n",
            "||∇_X meta|| = 0.0026359744369983673\n",
            "ΔX norm: 2.6359753974247724e-05\n",
            "Stage 4/10:  20%|█████▉                        | 59/300 [01:55<07:45,  1.93s/it]T Loss=2.3042421340942383\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037643432617188\n",
            "g_norm = tensor(0.1243, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304368495941162\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038692474365234\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3068628311157227\n",
            "g_norm = tensor(0.1299, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.99966430664062\n",
            "||∇_X meta|| = 0.002564097521826625\n",
            "ΔX norm: 2.5640994863351807e-05\n",
            "Stage 4/10:  20%|██████                        | 60/300 [01:57<08:48,  2.20s/it]T Loss=2.3023734092712402\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037219047546387\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303098678588867\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031795024871826\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303081512451172\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4683837890625\n",
            "||∇_X meta|| = 0.002519128378480673\n",
            "ΔX norm: 2.5191260647261515e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 4/10:  20%|██████                        | 61/300 [01:59<08:18,  2.09s/it]T Loss=2.3030295372009277\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30236554145813\n",
            "g_norm = tensor(0.1216, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303546190261841\n",
            "g_norm = tensor(0.0993, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032569885253906\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303175926208496\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.23928833007812\n",
            "||∇_X meta|| = 0.0024036734830588102\n",
            "ΔX norm: 2.403669168415945e-05\n",
            "Stage 4/10:  21%|██████▏                       | 62/300 [02:02<08:36,  2.17s/it]T Loss=2.3038604259490967\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022940158843994\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30255389213562\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302798271179199\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026907444000244\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.37863159179688\n",
            "||∇_X meta|| = 0.0024731289595365524\n",
            "ΔX norm: 2.4731281882850453e-05\n",
            "Stage 4/10:  21%|██████▎                       | 63/300 [02:04<08:22,  2.12s/it]T Loss=2.303478240966797\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033270835876465\n",
            "g_norm = tensor(0.1178, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031232357025146\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033287525177\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030190467834473\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.22447204589844\n",
            "||∇_X meta|| = 0.002090113703161478\n",
            "ΔX norm: 2.0901174138998613e-05\n",
            "Stage 4/10:  21%|██████▍                       | 64/300 [02:06<08:09,  2.07s/it]T Loss=2.3052608966827393\n",
            "g_norm = tensor(0.1314, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036065101623535\n",
            "g_norm = tensor(0.1459, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30324125289917\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041980266571045\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032782077789307\n",
            "g_norm = tensor(0.1234, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1199951171875\n",
            "||∇_X meta|| = 0.002473174361512065\n",
            "ΔX norm: 2.4731774828978814e-05\n",
            "Stage 4/10:  22%|██████▌                       | 65/300 [02:07<07:53,  2.01s/it]T Loss=2.301858425140381\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027780055999756\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301365375518799\n",
            "g_norm = tensor(0.1367, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303048849105835\n",
            "g_norm = tensor(0.1222, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302643299102783\n",
            "g_norm = tensor(0.1326, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.00115966796875\n",
            "||∇_X meta|| = 0.0022197896614670753\n",
            "ΔX norm: 2.21979043999454e-05\n",
            "Stage 4/10:  22%|██████▌                       | 66/300 [02:10<07:56,  2.04s/it]T Loss=2.3041934967041016\n",
            "g_norm = tensor(0.0872, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036789894104004\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043599128723145\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303104877471924\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303368330001831\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.45083618164062\n",
            "||∇_X meta|| = 0.0022507591638714075\n",
            "ΔX norm: 2.250763282063417e-05\n",
            "Stage 4/10:  22%|██████▋                       | 67/300 [02:12<07:55,  2.04s/it]T Loss=2.3035900592803955\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304286479949951\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3059308528900146\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036580085754395\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033034801483154\n",
            "g_norm = tensor(0.1452, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.47396850585938\n",
            "||∇_X meta|| = 0.0020252815447747707\n",
            "ΔX norm: 2.0252839021850377e-05\n",
            "Stage 4/10:  23%|██████▊                       | 68/300 [02:13<07:40,  1.99s/it]T Loss=2.3036766052246094\n",
            "g_norm = tensor(0.1355, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039631843566895\n",
            "g_norm = tensor(0.1333, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028416633605957\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303874969482422\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029143810272217\n",
            "g_norm = tensor(0.1411, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.48974609375\n",
            "||∇_X meta|| = 0.0020325854420661926\n",
            "ΔX norm: 2.0325865989434533e-05\n",
            "Stage 4/10:  23%|██████▉                       | 69/300 [02:15<07:29,  1.95s/it]T Loss=2.303439140319824\n",
            "g_norm = tensor(0.1357, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303882122039795\n",
            "g_norm = tensor(0.1356, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032517433166504\n",
            "g_norm = tensor(0.1466, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30418062210083\n",
            "g_norm = tensor(0.1465, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303190231323242\n",
            "g_norm = tensor(0.1429, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.32627868652344\n",
            "||∇_X meta|| = 0.0020586515311151743\n",
            "ΔX norm: 2.0586503524100408e-05\n",
            "Stage 4/10:  23%|███████                       | 70/300 [02:17<07:26,  1.94s/it]T Loss=2.303400993347168\n",
            "g_norm = tensor(0.1334, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303835153579712\n",
            "g_norm = tensor(0.1380, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038330078125\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30448317527771\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30412220954895\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.57919311523438\n",
            "||∇_X meta|| = 0.001936606946401298\n",
            "ΔX norm: 1.9366074411664158e-05\n",
            "Stage 4/10:  24%|███████                       | 71/300 [02:19<07:16,  1.91s/it]T Loss=2.303640365600586\n",
            "g_norm = tensor(0.0941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029401302337646\n",
            "g_norm = tensor(0.0867, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304077625274658\n",
            "g_norm = tensor(0.0888, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039047718048096\n",
            "g_norm = tensor(0.0795, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036704063415527\n",
            "g_norm = tensor(0.0791, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.47207641601562\n",
            "||∇_X meta|| = 0.0021005517337471247\n",
            "ΔX norm: 2.1005522285122424e-05\n",
            "Stage 4/10:  24%|███████▏                      | 72/300 [02:21<07:10,  1.89s/it]T Loss=2.3030831813812256\n",
            "g_norm = tensor(0.1403, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30275559425354\n",
            "g_norm = tensor(0.1333, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033347129821777\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035531044006348\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302264451980591\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7421875\n",
            "||∇_X meta|| = 0.0021256350446492434\n",
            "ΔX norm: 2.1256370018818416e-05\n",
            "Stage 4/10:  24%|███████▎                      | 73/300 [02:23<07:04,  1.87s/it]T Loss=2.3037123680114746\n",
            "g_norm = tensor(0.1723, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029868602752686\n",
            "g_norm = tensor(0.1679, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052470684051514\n",
            "g_norm = tensor(0.1487, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038244247436523\n",
            "g_norm = tensor(0.1419, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048298358917236\n",
            "g_norm = tensor(0.1472, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2198944091797\n",
            "||∇_X meta|| = 0.002289742464199662\n",
            "ΔX norm: 2.2897456801729277e-05\n",
            "Stage 4/10:  25%|███████▍                      | 74/300 [02:25<07:01,  1.86s/it]T Loss=2.3041605949401855\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036880493164062\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303236484527588\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303617238998413\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303615093231201\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.69869995117188\n",
            "||∇_X meta|| = 0.0021627272944897413\n",
            "ΔX norm: 2.1627301975968294e-05\n",
            "Stage 4/10:  25%|███████▌                      | 75/300 [02:26<06:55,  1.85s/it]T Loss=2.3044304847717285\n",
            "g_norm = tensor(0.1255, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051743507385254\n",
            "g_norm = tensor(0.1504, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30553936958313\n",
            "g_norm = tensor(0.1369, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304131507873535\n",
            "g_norm = tensor(0.1110, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048360347747803\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2165985107422\n",
            "||∇_X meta|| = 0.0023470146115869284\n",
            "ΔX norm: 2.3470152882509865e-05\n",
            "Stage 4/10:  25%|███████▌                      | 76/300 [02:28<06:55,  1.86s/it]T Loss=2.3038477897644043\n",
            "g_norm = tensor(0.0809, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041512966156006\n",
            "g_norm = tensor(0.0834, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302887439727783\n",
            "g_norm = tensor(0.0736, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038830757141113\n",
            "g_norm = tensor(0.0829, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045356273651123\n",
            "g_norm = tensor(0.0761, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.54364013671875\n",
            "||∇_X meta|| = 0.002353416755795479\n",
            "ΔX norm: 2.3534174033557065e-05\n",
            "Stage 4/10:  26%|███████▋                      | 77/300 [02:30<06:44,  1.81s/it]T Loss=2.303764820098877\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303323268890381\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033721446990967\n",
            "g_norm = tensor(0.0993, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303712844848633\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040053844451904\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.44775390625\n",
            "||∇_X meta|| = 0.0019834362901747227\n",
            "ΔX norm: 1.9834371414617635e-05\n",
            "Stage 4/10:  26%|███████▊                      | 78/300 [02:32<06:39,  1.80s/it]T Loss=2.3038573265075684\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045334815979004\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304802417755127\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046469688415527\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302694320678711\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.04269409179688\n",
            "||∇_X meta|| = 0.00220559723675251\n",
            "ΔX norm: 2.2055961380829103e-05\n",
            "Stage 4/10:  26%|███████▉                      | 79/300 [02:34<06:34,  1.79s/it]T Loss=2.3040506839752197\n",
            "g_norm = tensor(0.0860, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034989833831787\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043808937072754\n",
            "g_norm = tensor(0.1187, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041341304779053\n",
            "g_norm = tensor(0.0897, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304318904876709\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.88522338867188\n",
            "||∇_X meta|| = 0.0019959716591984034\n",
            "ΔX norm: 1.995971797441598e-05\n",
            "Stage 4/10:  27%|████████                      | 80/300 [02:35<06:36,  1.80s/it]T Loss=2.3032455444335938\n",
            "g_norm = tensor(0.1118, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303758382797241\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042783737182617\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027806282043457\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30379056930542\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.63992309570312\n",
            "||∇_X meta|| = 0.0019681183621287346\n",
            "ΔX norm: 1.968116885109339e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 4/10:  27%|████████                      | 81/300 [02:37<06:31,  1.79s/it]T Loss=2.303982734680176\n",
            "g_norm = tensor(0.1592, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040266036987305\n",
            "g_norm = tensor(0.1510, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031015396118164\n",
            "g_norm = tensor(0.1444, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303335666656494\n",
            "g_norm = tensor(0.1538, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304503917694092\n",
            "g_norm = tensor(0.1684, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7014617919922\n",
            "||∇_X meta|| = 0.0020773098804056644\n",
            "ΔX norm: 2.077311000903137e-05\n",
            "Stage 4/10:  27%|████████▏                     | 82/300 [02:39<07:02,  1.94s/it]T Loss=2.3031184673309326\n",
            "g_norm = tensor(0.1230, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302112102508545\n",
            "g_norm = tensor(0.1335, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031747341156006\n",
            "g_norm = tensor(0.1273, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303114175796509\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302297353744507\n",
            "g_norm = tensor(0.1259, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.73773193359375\n",
            "||∇_X meta|| = 0.0022561929654330015\n",
            "ΔX norm: 2.2561909645446576e-05\n",
            "Stage 4/10:  28%|████████▎                     | 83/300 [02:41<07:00,  1.94s/it]T Loss=2.3042092323303223\n",
            "g_norm = tensor(0.1593, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050570487976074\n",
            "g_norm = tensor(0.1629, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053526878356934\n",
            "g_norm = tensor(0.1454, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303960084915161\n",
            "g_norm = tensor(0.1652, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042540550231934\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.58815002441406\n",
            "||∇_X meta|| = 0.0018956346902996302\n",
            "ΔX norm: 1.8956347048515454e-05\n",
            "Stage 4/10:  28%|████████▍                     | 84/300 [02:43<07:07,  1.98s/it]T Loss=2.3035178184509277\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037915229797363\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027591705322266\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037145137786865\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30281138420105\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.84678649902344\n",
            "||∇_X meta|| = 0.0021063347812741995\n",
            "ΔX norm: 2.1063362510176376e-05\n",
            "Stage 4/10:  28%|████████▌                     | 85/300 [02:45<06:52,  1.92s/it]T Loss=2.303535223007202\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035390377044678\n",
            "g_norm = tensor(0.1143, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026158809661865\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033649921417236\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301912307739258\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.96922302246094\n",
            "||∇_X meta|| = 0.002281752647832036\n",
            "ΔX norm: 2.2817501303507015e-05\n",
            "Stage 4/10:  29%|████████▌                     | 86/300 [02:47<06:40,  1.87s/it]T Loss=2.3030381202697754\n",
            "g_norm = tensor(0.0890, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304238796234131\n",
            "g_norm = tensor(0.0761, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045196533203125\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039231300354004\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304403781890869\n",
            "g_norm = tensor(0.0923, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.9782257080078\n",
            "||∇_X meta|| = 0.002058068523183465\n",
            "ΔX norm: 2.058068639598787e-05\n",
            "Stage 4/10:  29%|████████▋                     | 87/300 [02:49<06:30,  1.84s/it]T Loss=2.3050379753112793\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052823543548584\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304213762283325\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027262687683105\n",
            "g_norm = tensor(0.1143, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041205406188965\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.94195556640625\n",
            "||∇_X meta|| = 0.0021599140018224716\n",
            "ΔX norm: 2.1599154933937825e-05\n",
            "Stage 4/10:  29%|████████▊                     | 88/300 [02:51<06:50,  1.94s/it]T Loss=2.3053297996520996\n",
            "g_norm = tensor(0.1350, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024609088897705\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040432929992676\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303527355194092\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3013417720794678\n",
            "g_norm = tensor(0.1344, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.07276916503906\n",
            "||∇_X meta|| = 0.0020056599751114845\n",
            "ΔX norm: 2.0056584617123008e-05\n",
            "Stage 4/10:  30%|████████▉                     | 89/300 [02:53<06:41,  1.90s/it]T Loss=2.3050003051757812\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304605484008789\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304508686065674\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046622276306152\n",
            "g_norm = tensor(0.1270, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049533367156982\n",
            "g_norm = tensor(0.1389, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.91497802734375\n",
            "||∇_X meta|| = 0.002166891936212778\n",
            "ΔX norm: 2.1668951376341283e-05\n",
            "Stage 4/10:  30%|█████████                     | 90/300 [02:55<06:35,  1.88s/it]T Loss=2.3030788898468018\n",
            "g_norm = tensor(0.1297, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032209873199463\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045549392700195\n",
            "g_norm = tensor(0.1266, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304746389389038\n",
            "g_norm = tensor(0.1516, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302455186843872\n",
            "g_norm = tensor(0.1318, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2965087890625\n",
            "||∇_X meta|| = 0.001970128621906042\n",
            "ΔX norm: 1.970130870176945e-05\n",
            "Stage 4/10:  30%|█████████                     | 91/300 [02:57<07:02,  2.02s/it]T Loss=2.3037807941436768\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033194541931152\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034164905548096\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045589923858643\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303953170776367\n",
            "g_norm = tensor(0.0816, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.73138427734375\n",
            "||∇_X meta|| = 0.002223123097792268\n",
            "ΔX norm: 2.2231244656722993e-05\n",
            "Stage 4/10:  31%|█████████▏                    | 92/300 [02:59<06:43,  1.94s/it]T Loss=2.304471254348755\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303445816040039\n",
            "g_norm = tensor(0.1419, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036768436431885\n",
            "g_norm = tensor(0.1269, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025944232940674\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032310009002686\n",
            "g_norm = tensor(0.1572, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7289276123047\n",
            "||∇_X meta|| = 0.0022382994648069143\n",
            "ΔX norm: 2.2382992028724402e-05\n",
            "Stage 4/10:  31%|█████████▎                    | 93/300 [03:01<06:38,  1.93s/it]T Loss=2.3030943870544434\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040518760681152\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043885231018066\n",
            "g_norm = tensor(0.1206, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050200939178467\n",
            "g_norm = tensor(0.1139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052945137023926\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0813751220703\n",
            "||∇_X meta|| = 0.0018025808967649937\n",
            "ΔX norm: 1.802578117349185e-05\n",
            "Stage 4/10:  31%|█████████▍                    | 94/300 [03:02<06:31,  1.90s/it]T Loss=2.3023574352264404\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302999258041382\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038763999938965\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302593946456909\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303210496902466\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5604248046875\n",
            "||∇_X meta|| = 0.0016403686022385955\n",
            "ΔX norm: 1.6403648260165937e-05\n",
            "Stage 4/10:  32%|█████████▌                    | 95/300 [03:04<06:38,  1.94s/it]T Loss=2.303241491317749\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302889108657837\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302543878555298\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033478260040283\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024649620056152\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8114776611328\n",
            "||∇_X meta|| = 0.002095166128128767\n",
            "ΔX norm: 2.0951660189894028e-05\n",
            "Stage 4/10:  32%|█████████▌                    | 96/300 [03:06<06:36,  1.94s/it]T Loss=2.303959608078003\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304828405380249\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048481941223145\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043999671936035\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304814577102661\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.75587463378906\n",
            "||∇_X meta|| = 0.0016931555001065135\n",
            "ΔX norm: 1.693157355475705e-05\n",
            "Stage 4/10:  32%|█████████▋                    | 97/300 [03:08<06:31,  1.93s/it]T Loss=2.303224563598633\n",
            "g_norm = tensor(0.0834, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035426139831543\n",
            "g_norm = tensor(0.0764, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040685653686523\n",
            "g_norm = tensor(0.0782, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039019107818604\n",
            "g_norm = tensor(0.0706, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039331436157227\n",
            "g_norm = tensor(0.0735, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7602081298828\n",
            "||∇_X meta|| = 0.002155112102627754\n",
            "ΔX norm: 2.1551122699747793e-05\n",
            "Stage 4/10:  33%|█████████▊                    | 98/300 [03:10<06:22,  1.89s/it]T Loss=2.303781509399414\n",
            "g_norm = tensor(0.1011, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033547401428223\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303644895553589\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042044639587402\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038947582244873\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.53573608398438\n",
            "||∇_X meta|| = 0.0021778352092951536\n",
            "ΔX norm: 2.1778343580081128e-05\n",
            "Stage 4/10:  33%|█████████▉                    | 99/300 [03:12<06:14,  1.87s/it]T Loss=2.302722454071045\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303086996078491\n",
            "g_norm = tensor(0.0771, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031249046325684\n",
            "g_norm = tensor(0.0768, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030924797058105\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303609848022461\n",
            "g_norm = tensor(0.0813, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.90301513671875\n",
            "||∇_X meta|| = 0.0018855005037039518\n",
            "ΔX norm: 1.885500932985451e-05\n",
            "Stage 4/10:  33%|█████████▋                   | 100/300 [03:14<06:08,  1.84s/it]T Loss=2.30293345451355\n",
            "g_norm = tensor(0.1222, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302422285079956\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034491539001465\n",
            "g_norm = tensor(0.1382, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303772449493408\n",
            "g_norm = tensor(0.1139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029885292053223\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.87252807617188\n",
            "||∇_X meta|| = 0.001563081401400268\n",
            "ΔX norm: 1.5630803318344988e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 4/10:  34%|█████████▊                   | 101/300 [03:16<06:06,  1.84s/it]T Loss=2.3026063442230225\n",
            "g_norm = tensor(0.0817, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304116725921631\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034214973449707\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304337501525879\n",
            "g_norm = tensor(0.0793, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303788661956787\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.97494506835938\n",
            "||∇_X meta|| = 0.0018435189267620444\n",
            "ΔX norm: 1.843519748945255e-05\n",
            "Stage 4/10:  34%|█████████▊                   | 102/300 [03:18<07:12,  2.18s/it]T Loss=2.303684711456299\n",
            "g_norm = tensor(0.1365, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045363426208496\n",
            "g_norm = tensor(0.1328, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301868200302124\n",
            "g_norm = tensor(0.1462, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031508922576904\n",
            "g_norm = tensor(0.1418, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043861389160156\n",
            "g_norm = tensor(0.1492, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4588623046875\n",
            "||∇_X meta|| = 0.0020121082197874784\n",
            "ΔX norm: 2.012109507631976e-05\n",
            "Stage 4/10:  34%|█████████▉                   | 103/300 [03:21<07:11,  2.19s/it]T Loss=2.3038201332092285\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035075664520264\n",
            "g_norm = tensor(0.1234, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040637969970703\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031938076019287\n",
            "g_norm = tensor(0.1369, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043932914733887\n",
            "g_norm = tensor(0.1178, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.90017700195312\n",
            "||∇_X meta|| = 0.00204425398260355\n",
            "ΔX norm: 2.0442530512809753e-05\n",
            "Stage 4/10:  35%|██████████                   | 104/300 [03:23<06:46,  2.08s/it]T Loss=2.3062844276428223\n",
            "g_norm = tensor(0.1275, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306056261062622\n",
            "g_norm = tensor(0.1243, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029041290283203\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304530143737793\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305206298828125\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.77125549316406\n",
            "||∇_X meta|| = 0.0017065833089873195\n",
            "ΔX norm: 1.7065847714548e-05\n",
            "Stage 4/10:  35%|██████████▏                  | 105/300 [03:24<06:31,  2.01s/it]T Loss=2.3035318851470947\n",
            "g_norm = tensor(0.0753, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049585819244385\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044517040252686\n",
            "g_norm = tensor(0.0844, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30525541305542\n",
            "g_norm = tensor(0.0898, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049073219299316\n",
            "g_norm = tensor(0.0817, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.55091857910156\n",
            "||∇_X meta|| = 0.0017481783870607615\n",
            "ΔX norm: 1.7481779650552198e-05\n",
            "Stage 4/10:  35%|██████████▏                  | 106/300 [03:26<06:16,  1.94s/it]T Loss=2.30479097366333\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032305240631104\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031535148620605\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30438232421875\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022727966308594\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9079132080078\n",
            "||∇_X meta|| = 0.001967204501852393\n",
            "ΔX norm: 1.9672044800245203e-05\n",
            "Stage 4/10:  36%|██████████▎                  | 107/300 [03:28<06:00,  1.87s/it]T Loss=2.3041954040527344\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034470081329346\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30324387550354\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029141426086426\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302745819091797\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.74581909179688\n",
            "||∇_X meta|| = 0.0017130672931671143\n",
            "ΔX norm: 1.7130656488006935e-05\n",
            "Stage 4/10:  36%|██████████▍                  | 108/300 [03:30<05:53,  1.84s/it]T Loss=2.3040285110473633\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302412509918213\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024885654449463\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038196563720703\n",
            "g_norm = tensor(0.1337, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302891254425049\n",
            "g_norm = tensor(0.1378, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.35565185546875\n",
            "||∇_X meta|| = 0.0018008796032518148\n",
            "ΔX norm: 1.80087754415581e-05\n",
            "Stage 4/10:  36%|██████████▌                  | 109/300 [03:31<05:44,  1.81s/it]T Loss=2.3030974864959717\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034045696258545\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022003173828125\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302705764770508\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304978132247925\n",
            "g_norm = tensor(0.1243, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.40676879882812\n",
            "||∇_X meta|| = 0.001837545889429748\n",
            "ΔX norm: 1.8375478248344734e-05\n",
            "Stage 4/10:  37%|██████████▋                  | 110/300 [03:33<05:37,  1.78s/it]T Loss=2.3050522804260254\n",
            "g_norm = tensor(0.1481, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042469024658203\n",
            "g_norm = tensor(0.1590, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303356170654297\n",
            "g_norm = tensor(0.1321, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30387806892395\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029932975769043\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.09527587890625\n",
            "||∇_X meta|| = 0.0018255960894748569\n",
            "ΔX norm: 1.8255992472404614e-05\n",
            "Stage 4/10:  37%|██████████▋                  | 111/300 [03:35<05:47,  1.84s/it]T Loss=2.3033578395843506\n",
            "g_norm = tensor(0.0855, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036413192749023\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037352561950684\n",
            "g_norm = tensor(0.0800, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303187131881714\n",
            "g_norm = tensor(0.0828, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038806915283203\n",
            "g_norm = tensor(0.0872, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.01527404785156\n",
            "||∇_X meta|| = 0.0018006861209869385\n",
            "ΔX norm: 1.8006843674811535e-05\n",
            "Stage 4/10:  37%|██████████▊                  | 112/300 [03:37<05:48,  1.86s/it]T Loss=2.3036229610443115\n",
            "g_norm = tensor(0.1075, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036773204803467\n",
            "g_norm = tensor(0.1439, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044040203094482\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3069629669189453\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042519092559814\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.26565551757812\n",
            "||∇_X meta|| = 0.001941016991622746\n",
            "ΔX norm: 1.9410173990763724e-05\n",
            "Stage 4/10:  38%|██████████▉                  | 113/300 [03:39<05:49,  1.87s/it]T Loss=2.303158760070801\n",
            "g_norm = tensor(0.0846, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303382635116577\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036375045776367\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044819831848145\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303851842880249\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2228240966797\n",
            "||∇_X meta|| = 0.0021102612372487783\n",
            "ΔX norm: 2.1102616301504895e-05\n",
            "Stage 4/10:  38%|███████████                  | 114/300 [03:41<05:47,  1.87s/it]T Loss=2.3033242225646973\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041837215423584\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033525943756104\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042781352996826\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304025173187256\n",
            "g_norm = tensor(0.0898, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7965850830078\n",
            "||∇_X meta|| = 0.0018973390106111765\n",
            "ΔX norm: 1.897341280709952e-05\n",
            "Stage 4/10:  38%|███████████                  | 115/300 [03:42<05:40,  1.84s/it]T Loss=2.3059356212615967\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043556213378906\n",
            "g_norm = tensor(0.1411, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046326637268066\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039956092834473\n",
            "g_norm = tensor(0.1441, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051598072052\n",
            "g_norm = tensor(0.1345, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.39828491210938\n",
            "||∇_X meta|| = 0.0018434789963066578\n",
            "ΔX norm: 1.8434797311783768e-05\n",
            "Stage 4/10:  39%|███████████▏                 | 116/300 [03:44<05:34,  1.82s/it]T Loss=2.3049468994140625\n",
            "g_norm = tensor(0.1305, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042283058166504\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049795627593994\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305142641067505\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304382801055908\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.00892639160156\n",
            "||∇_X meta|| = 0.0017943279817700386\n",
            "ΔX norm: 1.79432663571788e-05\n",
            "Stage 4/10:  39%|███████████▎                 | 117/300 [03:46<05:40,  1.86s/it]T Loss=2.3032639026641846\n",
            "g_norm = tensor(0.1349, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029544353485107\n",
            "g_norm = tensor(0.1374, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303438186645508\n",
            "g_norm = tensor(0.1463, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022618293762207\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3016600608825684\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2624053955078\n",
            "||∇_X meta|| = 0.001743490807712078\n",
            "ΔX norm: 1.743490429362282e-05\n",
            "Stage 4/10:  39%|███████████▍                 | 118/300 [03:48<05:33,  1.83s/it]T Loss=2.3041579723358154\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032710552215576\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046722412109375\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054158687591553\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042585849761963\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.66415405273438\n",
            "||∇_X meta|| = 0.001950948964804411\n",
            "ΔX norm: 1.950948717421852e-05\n",
            "Stage 4/10:  40%|███████████▌                 | 119/300 [03:50<05:30,  1.83s/it]T Loss=2.3030903339385986\n",
            "g_norm = tensor(0.1271, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303650379180908\n",
            "g_norm = tensor(0.1337, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306185245513916\n",
            "g_norm = tensor(0.1368, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057446479797363\n",
            "g_norm = tensor(0.1382, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304856538772583\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7679901123047\n",
            "||∇_X meta|| = 0.0017005075933411717\n",
            "ΔX norm: 1.7005055269692093e-05\n",
            "Stage 4/10:  40%|███████████▌                 | 120/300 [03:52<05:25,  1.81s/it]T Loss=2.303847551345825\n",
            "g_norm = tensor(0.0715, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043320178985596\n",
            "g_norm = tensor(0.0843, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048653602600098\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049166202545166\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303215503692627\n",
            "g_norm = tensor(0.0785, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.17608642578125\n",
            "||∇_X meta|| = 0.0017482796683907509\n",
            "ΔX norm: 1.748279100866057e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 4/10:  40%|███████████▋                 | 121/300 [03:53<05:24,  1.81s/it]T Loss=2.302809238433838\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305027484893799\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038980960845947\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301805019378662\n",
            "g_norm = tensor(0.1359, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044121265411377\n",
            "g_norm = tensor(0.1348, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.80386352539062\n",
            "||∇_X meta|| = 0.001729705953039229\n",
            "ΔX norm: 1.7297081285505556e-05\n",
            "Stage 4/10:  41%|███████████▊                 | 122/300 [03:56<06:06,  2.06s/it]T Loss=2.303082227706909\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032748699188232\n",
            "g_norm = tensor(0.1458, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047146797180176\n",
            "g_norm = tensor(0.1677, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303270101547241\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041937351226807\n",
            "g_norm = tensor(0.1296, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.04164123535156\n",
            "||∇_X meta|| = 0.0016897624591365457\n",
            "ΔX norm: 1.689763303147629e-05\n",
            "Stage 4/10:  41%|███████████▉                 | 123/300 [03:58<06:05,  2.07s/it]T Loss=2.303980827331543\n",
            "g_norm = tensor(0.0897, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046915531158447\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3059544563293457\n",
            "g_norm = tensor(0.1286, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303008556365967\n",
            "g_norm = tensor(0.1370, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304399013519287\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1985321044922\n",
            "||∇_X meta|| = 0.0017186565091833472\n",
            "ΔX norm: 1.718653402349446e-05\n",
            "Stage 4/10:  41%|███████████▉                 | 124/300 [04:00<06:05,  2.08s/it]T Loss=2.3043134212493896\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030245304107666\n",
            "g_norm = tensor(0.0843, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048627376556396\n",
            "g_norm = tensor(0.0686, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304715633392334\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042824268341064\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2087860107422\n",
            "||∇_X meta|| = 0.001971762627363205\n",
            "ΔX norm: 1.9717628674698062e-05\n",
            "Stage 4/10:  42%|████████████                 | 125/300 [04:02<06:00,  2.06s/it]T Loss=2.3047878742218018\n",
            "g_norm = tensor(0.1395, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3067383766174316\n",
            "g_norm = tensor(0.2092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302898406982422\n",
            "g_norm = tensor(0.1484, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049793243408203\n",
            "g_norm = tensor(0.1466, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30568790435791\n",
            "g_norm = tensor(0.1332, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2270050048828\n",
            "||∇_X meta|| = 0.001720323576591909\n",
            "ΔX norm: 1.7203210518346168e-05\n",
            "Stage 4/10:  42%|████████████▏                | 126/300 [04:04<05:42,  1.97s/it]T Loss=2.303623676300049\n",
            "g_norm = tensor(0.0682, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040852546691895\n",
            "g_norm = tensor(0.0653, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303431987762451\n",
            "g_norm = tensor(0.0801, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050713539123535\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305030345916748\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.86904907226562\n",
            "||∇_X meta|| = 0.0017476266948506236\n",
            "ΔX norm: 1.747625537973363e-05\n",
            "Stage 4/10:  42%|████████████▎                | 127/300 [04:06<05:35,  1.94s/it]T Loss=2.3031935691833496\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031320571899414\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040077686309814\n",
            "g_norm = tensor(0.0782, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030991554260254\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303168535232544\n",
            "g_norm = tensor(0.0764, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.90765380859375\n",
            "||∇_X meta|| = 0.0015514824772253633\n",
            "ΔX norm: 1.551481182104908e-05\n",
            "Stage 4/10:  43%|████████████▎                | 128/300 [04:08<05:24,  1.89s/it]T Loss=2.304527997970581\n",
            "g_norm = tensor(0.1286, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306056499481201\n",
            "g_norm = tensor(0.1527, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305973768234253\n",
            "g_norm = tensor(0.1501, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044092655181885\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303861141204834\n",
            "g_norm = tensor(0.1365, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.62379455566406\n",
            "||∇_X meta|| = 0.0015585949877277017\n",
            "ΔX norm: 1.558595795358997e-05\n",
            "Stage 4/10:  43%|████████████▍                | 129/300 [04:09<05:17,  1.85s/it]T Loss=2.3039603233337402\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304400682449341\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028128147125244\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303784132003784\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303539752960205\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.51040649414062\n",
            "||∇_X meta|| = 0.0015473203966394067\n",
            "ΔX norm: 1.54732188093476e-05\n",
            "Stage 4/10:  43%|████████████▌                | 130/300 [04:11<05:14,  1.85s/it]T Loss=2.3036134243011475\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303436756134033\n",
            "g_norm = tensor(0.0778, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038835525512695\n",
            "g_norm = tensor(0.0795, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029167652130127\n",
            "g_norm = tensor(0.0812, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037896156311035\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.29019165039062\n",
            "||∇_X meta|| = 0.0017200649017468095\n",
            "ΔX norm: 1.720064210530836e-05\n",
            "Stage 4/10:  44%|████████████▋                | 131/300 [04:13<05:07,  1.82s/it]T Loss=2.304947853088379\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303781509399414\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042941093444824\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030285835266113\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047282695770264\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.61390686035156\n",
            "||∇_X meta|| = 0.001968472497537732\n",
            "ΔX norm: 1.968472497537732e-05\n",
            "Stage 4/10:  44%|████████████▊                | 132/300 [04:15<05:07,  1.83s/it]T Loss=2.3037829399108887\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048999309539795\n",
            "g_norm = tensor(0.1184, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302692174911499\n",
            "g_norm = tensor(0.1291, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038134574890137\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041248321533203\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.01290893554688\n",
            "||∇_X meta|| = 0.0017020470695570111\n",
            "ΔX norm: 1.7020460290950723e-05\n",
            "Stage 4/10:  44%|████████████▊                | 133/300 [04:17<05:07,  1.84s/it]T Loss=2.3023619651794434\n",
            "g_norm = tensor(0.1448, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305596113204956\n",
            "g_norm = tensor(0.1593, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304077625274658\n",
            "g_norm = tensor(0.1651, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031952381134033\n",
            "g_norm = tensor(0.1608, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028111457824707\n",
            "g_norm = tensor(0.1483, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.10044860839844\n",
            "||∇_X meta|| = 0.001687653362751007\n",
            "ΔX norm: 1.6876552763278596e-05\n",
            "Stage 4/10:  45%|████████████▉                | 134/300 [04:19<05:37,  2.04s/it]T Loss=2.303779125213623\n",
            "g_norm = tensor(0.1432, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045713901519775\n",
            "g_norm = tensor(0.1456, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057007789611816\n",
            "g_norm = tensor(0.1703, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304330348968506\n",
            "g_norm = tensor(0.1369, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042707443237305\n",
            "g_norm = tensor(0.1462, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.49203491210938\n",
            "||∇_X meta|| = 0.0014469604939222336\n",
            "ΔX norm: 1.4469598681898788e-05\n",
            "Stage 4/10:  45%|█████████████                | 135/300 [04:21<05:23,  1.96s/it]T Loss=2.3039259910583496\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040404319763184\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046441078186035\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044257164001465\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033077716827393\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.46578979492188\n",
            "||∇_X meta|| = 0.0016891516279429197\n",
            "ΔX norm: 1.6891510313143954e-05\n",
            "Stage 4/10:  45%|█████████████▏               | 136/300 [04:23<05:12,  1.90s/it]T Loss=2.303252696990967\n",
            "g_norm = tensor(0.0770, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041865825653076\n",
            "g_norm = tensor(0.0805, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028740882873535\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039498329162598\n",
            "g_norm = tensor(0.0884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035497665405273\n",
            "g_norm = tensor(0.0809, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.21507263183594\n",
            "||∇_X meta|| = 0.0017538426909595728\n",
            "ΔX norm: 1.7538417523610406e-05\n",
            "Stage 4/10:  46%|█████████████▏               | 137/300 [04:24<05:01,  1.85s/it]T Loss=2.3048269748687744\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304293394088745\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049864768981934\n",
            "g_norm = tensor(0.0883, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303812265396118\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304672956466675\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.03927612304688\n",
            "||∇_X meta|| = 0.0016408665105700493\n",
            "ΔX norm: 1.640865048102569e-05\n",
            "Stage 4/10:  46%|█████████████▎               | 138/300 [04:26<05:01,  1.86s/it]T Loss=2.3029582500457764\n",
            "g_norm = tensor(0.1263, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302276134490967\n",
            "g_norm = tensor(0.1221, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025403022766113\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041062355041504\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047749996185303\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.51718139648438\n",
            "||∇_X meta|| = 0.0019442969933152199\n",
            "ΔX norm: 1.9442955817794427e-05\n",
            "Stage 4/10:  46%|█████████████▍               | 139/300 [04:28<04:59,  1.86s/it]T Loss=2.3030056953430176\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304426670074463\n",
            "g_norm = tensor(0.1219, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024768829345703\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303861141204834\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303689479827881\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1879425048828\n",
            "||∇_X meta|| = 0.0017866621492430568\n",
            "ΔX norm: 1.786659049685113e-05\n",
            "Stage 4/10:  47%|█████████████▌               | 140/300 [04:30<04:55,  1.85s/it]T Loss=2.3030967712402344\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302201509475708\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031229972839355\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020427227020264\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302577257156372\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1621551513672\n",
            "||∇_X meta|| = 0.0015055133262649179\n",
            "ΔX norm: 1.505514228483662e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 4/10:  47%|█████████████▋               | 141/300 [04:32<04:51,  1.84s/it]T Loss=2.3041412830352783\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036437034606934\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036952018737793\n",
            "g_norm = tensor(0.1296, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304224729537964\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030049800872803\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.39122009277344\n",
            "||∇_X meta|| = 0.0015159080503508449\n",
            "ΔX norm: 1.5159082067839336e-05\n",
            "Stage 4/10:  47%|█████████████▋               | 142/300 [04:34<05:21,  2.03s/it]T Loss=2.303743839263916\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304821729660034\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304962158203125\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049161434173584\n",
            "g_norm = tensor(0.1308, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305302619934082\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.89988708496094\n",
            "||∇_X meta|| = 0.0017572506330907345\n",
            "ΔX norm: 1.7572496290085837e-05\n",
            "Stage 4/10:  48%|█████████████▊               | 143/300 [04:36<05:17,  2.02s/it]T Loss=2.3054392337799072\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30513334274292\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046839237213135\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303743362426758\n",
            "g_norm = tensor(0.1320, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036036491394043\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.04135131835938\n",
            "||∇_X meta|| = 0.0015876787947490811\n",
            "ΔX norm: 1.5876794350333512e-05\n",
            "Stage 4/10:  48%|█████████████▉               | 144/300 [04:38<05:02,  1.94s/it]T Loss=2.304182767868042\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303269863128662\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038840293884277\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044991493225098\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302274465560913\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.43739318847656\n",
            "||∇_X meta|| = 0.0015592171112075448\n",
            "ΔX norm: 1.5592153431498446e-05\n",
            "Stage 4/10:  48%|██████████████               | 145/300 [04:40<04:55,  1.91s/it]T Loss=2.302961826324463\n",
            "g_norm = tensor(0.1307, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047897815704346\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032333850860596\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049442768096924\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037216663360596\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1053924560547\n",
            "||∇_X meta|| = 0.001638808404095471\n",
            "ΔX norm: 1.6388077710871585e-05\n",
            "Stage 4/10:  49%|██████████████               | 146/300 [04:42<04:45,  1.85s/it]T Loss=2.3036274909973145\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055901527404785\n",
            "g_norm = tensor(0.1772, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303956985473633\n",
            "g_norm = tensor(0.1547, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30511212348938\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043441772460938\n",
            "g_norm = tensor(0.1459, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4119415283203\n",
            "||∇_X meta|| = 0.0016296765534207225\n",
            "ΔX norm: 1.6296775356750004e-05\n",
            "Stage 4/10:  49%|██████████████▏              | 147/300 [04:43<04:40,  1.83s/it]T Loss=2.3036770820617676\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036086559295654\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026747703552246\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037285804748535\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026509284973145\n",
            "g_norm = tensor(0.1276, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5592041015625\n",
            "||∇_X meta|| = 0.0015763095580041409\n",
            "ΔX norm: 1.5763080227770843e-05\n",
            "Stage 4/10:  49%|██████████████▎              | 148/300 [04:45<04:33,  1.80s/it]T Loss=2.3029611110687256\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032901287078857\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302940845489502\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035759925842285\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030104637145996\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.52935791015625\n",
            "||∇_X meta|| = 0.001637148903682828\n",
            "ΔX norm: 1.637148488953244e-05\n",
            "Stage 4/10:  50%|██████████████▍              | 149/300 [04:47<04:29,  1.79s/it]T Loss=2.304250478744507\n",
            "g_norm = tensor(0.0735, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304760217666626\n",
            "g_norm = tensor(0.0699, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049371242523193\n",
            "g_norm = tensor(0.0818, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044612407684326\n",
            "g_norm = tensor(0.0765, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043103218078613\n",
            "g_norm = tensor(0.0839, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.00436401367188\n",
            "||∇_X meta|| = 0.0016606777207925916\n",
            "ΔX norm: 1.660676753090229e-05\n",
            "Stage 4/10:  50%|██████████████▌              | 150/300 [04:49<04:25,  1.77s/it]T Loss=2.3030786514282227\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303223133087158\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303164005279541\n",
            "g_norm = tensor(0.1230, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303123950958252\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036701679229736\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7804718017578\n",
            "||∇_X meta|| = 0.0015528621152043343\n",
            "ΔX norm: 1.552863795950543e-05\n",
            "Stage 4/10:  50%|██████████████▌              | 151/300 [04:51<04:35,  1.85s/it]T Loss=2.3047008514404297\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039743900299072\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036158084869385\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033559322357178\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303868055343628\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.12745666503906\n",
            "||∇_X meta|| = 0.0016696436796337366\n",
            "ΔX norm: 1.6696461898391135e-05\n",
            "Stage 4/10:  51%|██████████████▋              | 152/300 [04:52<04:32,  1.84s/it]T Loss=2.303668737411499\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303809642791748\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303328275680542\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303994655609131\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303565502166748\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.10606384277344\n",
            "||∇_X meta|| = 0.0016544200479984283\n",
            "ΔX norm: 1.6544236132176593e-05\n",
            "Stage 4/10:  51%|██████████████▊              | 153/300 [04:54<04:26,  1.81s/it]T Loss=2.3037209510803223\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041181564331055\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028221130371094\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030598163604736\n",
            "g_norm = tensor(0.0890, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303166627883911\n",
            "g_norm = tensor(0.0790, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.53759765625\n",
            "||∇_X meta|| = 0.0018259868957102299\n",
            "ΔX norm: 1.8259901480632834e-05\n",
            "Stage 4/10:  51%|██████████████▉              | 154/300 [04:57<04:47,  1.97s/it]T Loss=2.3033785820007324\n",
            "g_norm = tensor(0.1306, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030896186828613\n",
            "g_norm = tensor(0.1412, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039631843566895\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304818630218506\n",
            "g_norm = tensor(0.1370, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303205966949463\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.81004333496094\n",
            "||∇_X meta|| = 0.0015393801731988788\n",
            "ΔX norm: 1.5393801731988788e-05\n",
            "Stage 4/10:  52%|██████████████▉              | 155/300 [04:58<04:38,  1.92s/it]T Loss=2.3044593334198\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304610013961792\n",
            "g_norm = tensor(0.0848, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304603338241577\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044419288635254\n",
            "g_norm = tensor(0.0832, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30430269241333\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.71543884277344\n",
            "||∇_X meta|| = 0.001620344934053719\n",
            "ΔX norm: 1.620344482944347e-05\n",
            "Stage 4/10:  52%|███████████████              | 156/300 [05:00<04:39,  1.94s/it]T Loss=2.305116653442383\n",
            "g_norm = tensor(0.0805, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053035736083984\n",
            "g_norm = tensor(0.0794, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040871620178223\n",
            "g_norm = tensor(0.0820, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305138349533081\n",
            "g_norm = tensor(0.0883, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050081729888916\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2965850830078\n",
            "||∇_X meta|| = 0.0016580960946157575\n",
            "ΔX norm: 1.6580950614297763e-05\n",
            "Stage 4/10:  52%|███████████████▏             | 157/300 [05:02<04:35,  1.92s/it]T Loss=2.303926467895508\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040714263916016\n",
            "g_norm = tensor(0.0947, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042492866516113\n",
            "g_norm = tensor(0.0897, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304349184036255\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302624464035034\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.76719665527344\n",
            "||∇_X meta|| = 0.0015710568986833096\n",
            "ΔX norm: 1.571059510752093e-05\n",
            "Stage 4/10:  53%|███████████████▎             | 158/300 [05:04<04:28,  1.89s/it]T Loss=2.306150436401367\n",
            "g_norm = tensor(0.1324, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303837299346924\n",
            "g_norm = tensor(0.1547, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305917263031006\n",
            "g_norm = tensor(0.1451, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050239086151123\n",
            "g_norm = tensor(0.1413, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037192821502686\n",
            "g_norm = tensor(0.1654, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.0170135498047\n",
            "||∇_X meta|| = 0.0016267196042463183\n",
            "ΔX norm: 1.6267174942186102e-05\n",
            "Stage 4/10:  53%|███████████████▎             | 159/300 [05:06<04:36,  1.96s/it]T Loss=2.303248882293701\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039698600769043\n",
            "g_norm = tensor(0.1351, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045287132263184\n",
            "g_norm = tensor(0.1154, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029773235321045\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029348850250244\n",
            "g_norm = tensor(0.1386, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5600128173828\n",
            "||∇_X meta|| = 0.0016663124551996589\n",
            "ΔX norm: 1.6663134374539368e-05\n",
            "Stage 4/10:  53%|███████████████▍             | 160/300 [05:08<04:31,  1.94s/it]T Loss=2.3026366233825684\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043808937072754\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040735721588135\n",
            "g_norm = tensor(0.0884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033413887023926\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303490400314331\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.20541381835938\n",
            "||∇_X meta|| = 0.0016791685484349728\n",
            "ΔX norm: 1.6791671441751532e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 4/10:  54%|███████████████▌             | 161/300 [05:10<04:36,  1.99s/it]T Loss=2.3036131858825684\n",
            "g_norm = tensor(0.1503, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033134937286377\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303229570388794\n",
            "g_norm = tensor(0.1302, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035008907318115\n",
            "g_norm = tensor(0.1309, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305215835571289\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.89385986328125\n",
            "||∇_X meta|| = 0.001529220724478364\n",
            "ΔX norm: 1.5292227544705383e-05\n",
            "Stage 4/10:  54%|███████████████▋             | 162/300 [05:12<04:46,  2.08s/it]T Loss=2.304515838623047\n",
            "g_norm = tensor(0.0852, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304051160812378\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032965660095215\n",
            "g_norm = tensor(0.1118, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304919719696045\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053224086761475\n",
            "g_norm = tensor(0.1110, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.71401977539062\n",
            "||∇_X meta|| = 0.0016884036595001817\n",
            "ΔX norm: 1.688402335275896e-05\n",
            "Stage 4/10:  54%|███████████████▊             | 163/300 [05:14<04:39,  2.04s/it]T Loss=2.3034322261810303\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302712917327881\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303872585296631\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035550117492676\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304468870162964\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.13804626464844\n",
            "||∇_X meta|| = 0.0015204459195956588\n",
            "ΔX norm: 1.5204474948404822e-05\n",
            "Stage 4/10:  55%|███████████████▊             | 164/300 [05:16<04:33,  2.01s/it]T Loss=2.3059566020965576\n",
            "g_norm = tensor(0.1383, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304081439971924\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051657676696777\n",
            "g_norm = tensor(0.1555, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305180072784424\n",
            "g_norm = tensor(0.1377, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048458099365234\n",
            "g_norm = tensor(0.1409, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =227.9881591796875\n",
            "||∇_X meta|| = 0.0017226539785042405\n",
            "ΔX norm: 1.722654269542545e-05\n",
            "Stage 4/10:  55%|███████████████▉             | 165/300 [05:18<04:24,  1.96s/it]T Loss=2.304260492324829\n",
            "g_norm = tensor(0.0831, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039729595184326\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304779052734375\n",
            "g_norm = tensor(0.0693, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305539846420288\n",
            "g_norm = tensor(0.0861, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047986030578613\n",
            "g_norm = tensor(0.0821, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.91993713378906\n",
            "||∇_X meta|| = 0.001586297177709639\n",
            "ΔX norm: 1.5862977306824178e-05\n",
            "Stage 4/10:  55%|████████████████             | 166/300 [05:20<04:15,  1.91s/it]T Loss=2.303330659866333\n",
            "g_norm = tensor(0.0923, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303178310394287\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024489879608154\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303353786468506\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023741245269775\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2232208251953\n",
            "||∇_X meta|| = 0.00154693063814193\n",
            "ΔX norm: 1.5469307982129976e-05\n",
            "Stage 4/10:  56%|████████████████▏            | 167/300 [05:22<04:24,  1.99s/it]T Loss=2.3037378787994385\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022823333740234\n",
            "g_norm = tensor(0.1418, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030946254730225\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303544282913208\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302823543548584\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.84219360351562\n",
            "||∇_X meta|| = 0.0017930594040080905\n",
            "ΔX norm: 1.7930560716195032e-05\n",
            "Stage 4/10:  56%|████████████████▏            | 168/300 [05:24<04:16,  1.94s/it]T Loss=2.303988218307495\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034636974334717\n",
            "g_norm = tensor(0.0857, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039214611053467\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040716648101807\n",
            "g_norm = tensor(0.0933, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046412467956543\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.06753540039062\n",
            "||∇_X meta|| = 0.0015607352834194899\n",
            "ΔX norm: 1.5607369277859107e-05\n",
            "Stage 4/10:  56%|████████████████▎            | 169/300 [05:26<04:10,  1.91s/it]T Loss=2.304316282272339\n",
            "g_norm = tensor(0.1326, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037171363830566\n",
            "g_norm = tensor(0.1262, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040549755096436\n",
            "g_norm = tensor(0.1243, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045339584350586\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042798042297363\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.6569366455078\n",
            "||∇_X meta|| = 0.0016909112455323339\n",
            "ΔX norm: 1.6909099940676242e-05\n",
            "Stage 4/10:  57%|████████████████▍            | 170/300 [05:28<04:07,  1.91s/it]T Loss=2.304546356201172\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046865463256836\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033878803253174\n",
            "g_norm = tensor(0.0851, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304450750350952\n",
            "g_norm = tensor(0.0818, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304152488708496\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0835723876953\n",
            "||∇_X meta|| = 0.0015437910333275795\n",
            "ΔX norm: 1.5437903130077757e-05\n",
            "Stage 4/10:  57%|████████████████▌            | 171/300 [05:30<04:03,  1.88s/it]T Loss=2.3035240173339844\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028993606567383\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303511619567871\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029143810272217\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302766799926758\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.302490234375\n",
            "||∇_X meta|| = 0.0015758323715999722\n",
            "ΔX norm: 1.5758332665427588e-05\n",
            "Stage 4/10:  57%|████████████████▋            | 172/300 [05:31<03:56,  1.85s/it]T Loss=2.3039462566375732\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304910182952881\n",
            "g_norm = tensor(0.1648, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043503761291504\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052890300750732\n",
            "g_norm = tensor(0.1609, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302313804626465\n",
            "g_norm = tensor(0.1620, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8648223876953\n",
            "||∇_X meta|| = 0.001543925842270255\n",
            "ΔX norm: 1.543926919111982e-05\n",
            "Stage 4/10:  58%|████████████████▋            | 173/300 [05:33<03:51,  1.83s/it]T Loss=2.301729202270508\n",
            "g_norm = tensor(0.1444, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056681156158447\n",
            "g_norm = tensor(0.1395, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027899265289307\n",
            "g_norm = tensor(0.1868, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041164875030518\n",
            "g_norm = tensor(0.1892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043415546417236\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.8427276611328\n",
            "||∇_X meta|| = 0.0014632816892117262\n",
            "ΔX norm: 1.463279204472201e-05\n",
            "Stage 4/10:  58%|████████████████▊            | 174/300 [05:35<03:55,  1.87s/it]T Loss=2.304314136505127\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042948246002197\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050291538238525\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305234432220459\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30375599861145\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.8687744140625\n",
            "||∇_X meta|| = 0.0017069251043722034\n",
            "ΔX norm: 1.7069247405743226e-05\n",
            "Stage 4/10:  58%|████████████████▉            | 175/300 [05:37<03:52,  1.86s/it]T Loss=2.302518844604492\n",
            "g_norm = tensor(0.1257, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033061027526855\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041415214538574\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046298027038574\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032193183898926\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4256591796875\n",
            "||∇_X meta|| = 0.0015160207403823733\n",
            "ΔX norm: 1.5160228940658271e-05\n",
            "Stage 4/10:  59%|█████████████████            | 176/300 [05:39<03:50,  1.86s/it]T Loss=2.303953170776367\n",
            "g_norm = tensor(0.0557, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303994655609131\n",
            "g_norm = tensor(0.0574, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045802116394043\n",
            "g_norm = tensor(0.0589, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037610054016113\n",
            "g_norm = tensor(0.0618, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037238121032715\n",
            "g_norm = tensor(0.0598, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.18511962890625\n",
            "||∇_X meta|| = 0.0015327821020036936\n",
            "ΔX norm: 1.5327814253396355e-05\n",
            "Stage 4/10:  59%|█████████████████            | 177/300 [05:41<03:49,  1.86s/it]T Loss=2.3034303188323975\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302644729614258\n",
            "g_norm = tensor(0.0779, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302724838256836\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023617267608643\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027195930480957\n",
            "g_norm = tensor(0.0793, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8551483154297\n",
            "||∇_X meta|| = 0.0019422017503529787\n",
            "ΔX norm: 1.9422028344706632e-05\n",
            "Stage 4/10:  59%|█████████████████▏           | 178/300 [05:42<03:45,  1.85s/it]T Loss=2.3062610626220703\n",
            "g_norm = tensor(0.1380, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042101860046387\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035049438476562\n",
            "g_norm = tensor(0.1344, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040177822113037\n",
            "g_norm = tensor(0.1438, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044214248657227\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.93359375\n",
            "||∇_X meta|| = 0.0016591990133747458\n",
            "ΔX norm: 1.6592000974924304e-05\n",
            "Stage 4/10:  60%|█████████████████▎           | 179/300 [05:44<03:43,  1.85s/it]T Loss=2.303597927093506\n",
            "g_norm = tensor(0.0796, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032631874084473\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030147552490234\n",
            "g_norm = tensor(0.0780, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045706748962402\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041415214538574\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4536895751953\n",
            "||∇_X meta|| = 0.0015478039858862758\n",
            "ΔX norm: 1.5478068235097453e-05\n",
            "Stage 4/10:  60%|█████████████████▍           | 180/300 [05:46<03:40,  1.84s/it]T Loss=2.304180383682251\n",
            "g_norm = tensor(0.0704, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303135633468628\n",
            "g_norm = tensor(0.0947, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038721084594727\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303158760070801\n",
            "g_norm = tensor(0.0682, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303385019302368\n",
            "g_norm = tensor(0.0816, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.75579833984375\n",
            "||∇_X meta|| = 0.0015898338751867414\n",
            "ΔX norm: 1.589833846082911e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 4/10:  60%|█████████████████▍           | 181/300 [05:48<03:47,  1.91s/it]T Loss=2.3024449348449707\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30342435836792\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302452564239502\n",
            "g_norm = tensor(0.0813, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039698600769043\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021392822265625\n",
            "g_norm = tensor(0.0934, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.57347106933594\n",
            "||∇_X meta|| = 0.001720748725347221\n",
            "ΔX norm: 1.7207472410518676e-05\n",
            "Stage 4/10:  61%|█████████████████▌           | 182/300 [05:51<04:02,  2.05s/it]T Loss=2.3045644760131836\n",
            "g_norm = tensor(0.1493, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048059940338135\n",
            "g_norm = tensor(0.1427, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3065037727355957\n",
            "g_norm = tensor(0.1708, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058314323425293\n",
            "g_norm = tensor(0.1616, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046703338623047\n",
            "g_norm = tensor(0.1713, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.35423278808594\n",
            "||∇_X meta|| = 0.0014903791015967727\n",
            "ΔX norm: 1.4903823284839746e-05\n",
            "Stage 4/10:  61%|█████████████████▋           | 183/300 [05:53<03:56,  2.02s/it]T Loss=2.302452564239502\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305241107940674\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051280975341797\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3059253692626953\n",
            "g_norm = tensor(0.1253, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30610990524292\n",
            "g_norm = tensor(0.1393, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.20086669921875\n",
            "||∇_X meta|| = 0.0016452631680294871\n",
            "ΔX norm: 1.6452651834697463e-05\n",
            "Stage 4/10:  61%|█████████████████▊           | 184/300 [05:54<03:50,  1.99s/it]T Loss=2.304192066192627\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303849697113037\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302366256713867\n",
            "g_norm = tensor(0.0923, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034908771514893\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30338716506958\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.29112243652344\n",
            "||∇_X meta|| = 0.0015348215820267797\n",
            "ΔX norm: 1.534822331450414e-05\n",
            "Stage 4/10:  62%|█████████████████▉           | 185/300 [05:57<03:58,  2.08s/it]T Loss=2.3022687435150146\n",
            "g_norm = tensor(0.1470, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028206825256348\n",
            "g_norm = tensor(0.1706, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304525852203369\n",
            "g_norm = tensor(0.1508, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046889305114746\n",
            "g_norm = tensor(0.1402, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033688068389893\n",
            "g_norm = tensor(0.1721, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.07777404785156\n",
            "||∇_X meta|| = 0.0016514369053766131\n",
            "ΔX norm: 1.65143828780856e-05\n",
            "Stage 4/10:  62%|█████████████████▉           | 186/300 [05:59<03:52,  2.04s/it]T Loss=2.3045105934143066\n",
            "g_norm = tensor(0.1292, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304879903793335\n",
            "g_norm = tensor(0.1118, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046207427978516\n",
            "g_norm = tensor(0.1379, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046863079071045\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053674697875977\n",
            "g_norm = tensor(0.1332, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.44703674316406\n",
            "||∇_X meta|| = 0.0016847033984959126\n",
            "ΔX norm: 1.6847034203237854e-05\n",
            "Stage 4/10:  62%|██████████████████           | 187/300 [06:01<03:45,  1.99s/it]T Loss=2.3033218383789062\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304828405380249\n",
            "g_norm = tensor(0.1411, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036088943481445\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305310010910034\n",
            "g_norm = tensor(0.1584, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304025173187256\n",
            "g_norm = tensor(0.1638, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.9667205810547\n",
            "||∇_X meta|| = 0.0015342130791395903\n",
            "ΔX norm: 1.5342136975959875e-05\n",
            "Stage 4/10:  63%|██████████████████▏          | 188/300 [06:03<03:43,  1.99s/it]T Loss=2.303114891052246\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032984733581543\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032689094543457\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027360439300537\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026540279388428\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.49313354492188\n",
            "||∇_X meta|| = 0.0014868410071358085\n",
            "ΔX norm: 1.4868416656099726e-05\n",
            "Stage 4/10:  63%|██████████████████▎          | 189/300 [06:05<03:41,  2.00s/it]T Loss=2.303231954574585\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039908409118652\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302692413330078\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303265333175659\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302412509918213\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.09718322753906\n",
            "||∇_X meta|| = 0.0015268676215782762\n",
            "ΔX norm: 1.5268686183844693e-05\n",
            "Stage 4/10:  63%|██████████████████▎          | 190/300 [06:06<03:37,  1.98s/it]T Loss=2.3045802116394043\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304835557937622\n",
            "g_norm = tensor(0.1270, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304260730743408\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039660453796387\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304863452911377\n",
            "g_norm = tensor(0.1612, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.6233367919922\n",
            "||∇_X meta|| = 0.0015946903731673956\n",
            "ΔX norm: 1.594688910699915e-05\n",
            "Stage 4/10:  64%|██████████████████▍          | 191/300 [06:08<03:31,  1.94s/it]T Loss=2.3025128841400146\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045990467071533\n",
            "g_norm = tensor(0.1288, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303044080734253\n",
            "g_norm = tensor(0.1369, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303223133087158\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304884433746338\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1780242919922\n",
            "||∇_X meta|| = 0.0015405835583806038\n",
            "ΔX norm: 1.540583798487205e-05\n",
            "Stage 4/10:  64%|██████████████████▌          | 192/300 [06:10<03:26,  1.91s/it]T Loss=2.300673246383667\n",
            "g_norm = tensor(0.1387, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301539897918701\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039958477020264\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301923990249634\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027822971343994\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9130401611328\n",
            "||∇_X meta|| = 0.0015862745931372046\n",
            "ΔX norm: 1.5862760847085156e-05\n",
            "Stage 4/10:  64%|██████████████████▋          | 193/300 [06:12<03:26,  1.93s/it]T Loss=2.304577350616455\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303593158721924\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030951023101807\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036961555480957\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303956985473633\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7698516845703\n",
            "||∇_X meta|| = 0.0015223623486235738\n",
            "ΔX norm: 1.5223612535919528e-05\n",
            "Stage 4/10:  65%|██████████████████▊          | 194/300 [06:14<03:22,  1.91s/it]T Loss=2.3031561374664307\n",
            "g_norm = tensor(0.0840, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028903007507324\n",
            "g_norm = tensor(0.0937, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304711103439331\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302901268005371\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034987449645996\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.12791442871094\n",
            "||∇_X meta|| = 0.001681224093772471\n",
            "ΔX norm: 1.6812249668873847e-05\n",
            "Stage 4/10:  65%|██████████████████▊          | 195/300 [06:16<03:23,  1.94s/it]T Loss=2.3028526306152344\n",
            "g_norm = tensor(0.1412, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058924674987793\n",
            "g_norm = tensor(0.1370, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039143085479736\n",
            "g_norm = tensor(0.1487, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3059029579162598\n",
            "g_norm = tensor(0.1433, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303597927093506\n",
            "g_norm = tensor(0.1462, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.63343811035156\n",
            "||∇_X meta|| = 0.0014542770804837346\n",
            "ΔX norm: 1.4542766621161718e-05\n",
            "Stage 4/10:  65%|██████████████████▉          | 196/300 [06:18<03:20,  1.93s/it]T Loss=2.3036322593688965\n",
            "g_norm = tensor(0.0883, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041622638702393\n",
            "g_norm = tensor(0.0836, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044087886810303\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041794300079346\n",
            "g_norm = tensor(0.0856, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303530216217041\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7933807373047\n",
            "||∇_X meta|| = 0.0015822681598365307\n",
            "ΔX norm: 1.5822717614355497e-05\n",
            "Stage 4/10:  66%|███████████████████          | 197/300 [06:20<03:16,  1.91s/it]T Loss=2.3017916679382324\n",
            "g_norm = tensor(0.1457, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019683361053467\n",
            "g_norm = tensor(0.1442, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036487102508545\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033785820007324\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301536798477173\n",
            "g_norm = tensor(0.1302, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7342987060547\n",
            "||∇_X meta|| = 0.0016009912360459566\n",
            "ΔX norm: 1.6009933460736647e-05\n",
            "Stage 4/10:  66%|███████████████████▏         | 198/300 [06:22<03:23,  1.99s/it]T Loss=2.3034281730651855\n",
            "g_norm = tensor(0.1390, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302013397216797\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304224729537964\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037493228912354\n",
            "g_norm = tensor(0.1319, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034136295318604\n",
            "g_norm = tensor(0.1312, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.63534545898438\n",
            "||∇_X meta|| = 0.0015905573964118958\n",
            "ΔX norm: 1.5905594409559853e-05\n",
            "Stage 4/10:  66%|███████████████████▏         | 199/300 [06:24<03:21,  2.00s/it]T Loss=2.3019142150878906\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303524971008301\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033199310302734\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033547401428223\n",
            "g_norm = tensor(0.1312, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30291748046875\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.66036987304688\n",
            "||∇_X meta|| = 0.0015866504982113838\n",
            "ΔX norm: 1.586650250828825e-05\n",
            "Stage 4/10:  67%|███████████████████▎         | 200/300 [06:26<03:19,  2.00s/it]T Loss=2.3031558990478516\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302891969680786\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026041984558105\n",
            "g_norm = tensor(0.0980, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031184673309326\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041203022003174\n",
            "g_norm = tensor(0.0879, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.03822326660156\n",
            "||∇_X meta|| = 0.0015618661418557167\n",
            "ΔX norm: 1.5618670659023337e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 4/10:  67%|███████████████████▍         | 201/300 [06:28<03:17,  1.99s/it]T Loss=2.301999807357788\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031911849975586\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022170066833496\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3013439178466797\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034725189208984\n",
            "g_norm = tensor(0.1342, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.17152404785156\n",
            "||∇_X meta|| = 0.0016152072930708528\n",
            "ΔX norm: 1.615206383576151e-05\n",
            "Stage 4/10:  67%|███████████████████▌         | 202/300 [06:30<03:26,  2.11s/it]T Loss=2.302600145339966\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058152198791504\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040966987609863\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032004833221436\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039822578430176\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.96534729003906\n",
            "||∇_X meta|| = 0.0015579465543851256\n",
            "ΔX norm: 1.5579476894345134e-05\n",
            "Stage 4/10:  68%|███████████████████▌         | 203/300 [06:32<03:21,  2.08s/it]T Loss=2.303248167037964\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034534454345703\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303124189376831\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017327785491943\n",
            "g_norm = tensor(0.1283, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30243182182312\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.80889892578125\n",
            "||∇_X meta|| = 0.001634152140468359\n",
            "ΔX norm: 1.6341533410013653e-05\n",
            "Stage 4/10:  68%|███████████████████▋         | 204/300 [06:34<03:17,  2.06s/it]T Loss=2.304344892501831\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036396503448486\n",
            "g_norm = tensor(0.1289, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034491539001465\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304063320159912\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041908740997314\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.50523376464844\n",
            "||∇_X meta|| = 0.001462262123823166\n",
            "ΔX norm: 1.4622602975578047e-05\n",
            "Stage 4/10:  68%|███████████████████▊         | 205/300 [06:36<03:09,  1.99s/it]T Loss=2.3052077293395996\n",
            "g_norm = tensor(0.0765, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046891689300537\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054962158203125\n",
            "g_norm = tensor(0.0832, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305650234222412\n",
            "g_norm = tensor(0.0833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305036783218384\n",
            "g_norm = tensor(0.0824, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.95155334472656\n",
            "||∇_X meta|| = 0.001543478574603796\n",
            "ΔX norm: 1.5434781744261272e-05\n",
            "Stage 4/10:  69%|███████████████████▉         | 206/300 [06:38<03:07,  1.99s/it]T Loss=2.3036916255950928\n",
            "g_norm = tensor(0.0500, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303759813308716\n",
            "g_norm = tensor(0.0457, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036389350891113\n",
            "g_norm = tensor(0.0478, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036913871765137\n",
            "g_norm = tensor(0.0485, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038806915283203\n",
            "g_norm = tensor(0.0476, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.99905395507812\n",
            "||∇_X meta|| = 0.0015501047018915415\n",
            "ΔX norm: 1.550103843328543e-05\n",
            "Stage 4/10:  69%|████████████████████         | 207/300 [06:40<03:02,  1.96s/it]T Loss=2.3033952713012695\n",
            "g_norm = tensor(0.0919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303206205368042\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303690195083618\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303412914276123\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302595376968384\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6824951171875\n",
            "||∇_X meta|| = 0.0015887803165242076\n",
            "ΔX norm: 1.588783743500244e-05\n",
            "Stage 4/10:  69%|████████████████████         | 208/300 [06:42<02:55,  1.91s/it]T Loss=2.305586338043213\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305144786834717\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305001735687256\n",
            "g_norm = tensor(0.1099, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032639026641846\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032121658325195\n",
            "g_norm = tensor(0.1282, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.88621520996094\n",
            "||∇_X meta|| = 0.0016074834857136011\n",
            "ΔX norm: 1.6074831364676356e-05\n",
            "Stage 4/10:  70%|████████████████████▏        | 209/300 [06:44<02:53,  1.91s/it]T Loss=2.3045401573181152\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040273189544678\n",
            "g_norm = tensor(0.0841, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034141063690186\n",
            "g_norm = tensor(0.0740, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045668601989746\n",
            "g_norm = tensor(0.0815, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303924322128296\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.10987854003906\n",
            "||∇_X meta|| = 0.0016093074809759855\n",
            "ΔX norm: 1.609310675121378e-05\n",
            "Stage 4/10:  70%|████████████████████▎        | 210/300 [06:46<02:50,  1.89s/it]T Loss=2.3046517372131348\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047163486480713\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040852546691895\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045296669006348\n",
            "g_norm = tensor(0.1022, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304993152618408\n",
            "g_norm = tensor(0.1278, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.01170349121094\n",
            "||∇_X meta|| = 0.001439424930140376\n",
            "ΔX norm: 1.4394263416761532e-05\n",
            "Stage 4/10:  70%|████████████████████▍        | 211/300 [06:47<02:46,  1.87s/it]T Loss=2.3034443855285645\n",
            "g_norm = tensor(0.0806, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038840293884277\n",
            "g_norm = tensor(0.0844, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303593397140503\n",
            "g_norm = tensor(0.0820, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036792278289795\n",
            "g_norm = tensor(0.0880, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30365252494812\n",
            "g_norm = tensor(0.0762, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4587860107422\n",
            "||∇_X meta|| = 0.0014896625652909279\n",
            "ΔX norm: 1.4896641914674547e-05\n",
            "Stage 4/10:  71%|████████████████████▍        | 212/300 [06:49<02:42,  1.85s/it]T Loss=2.303455352783203\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037941455841064\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038432598114014\n",
            "g_norm = tensor(0.0809, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303377389907837\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30399751663208\n",
            "g_norm = tensor(0.0733, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1927947998047\n",
            "||∇_X meta|| = 0.0015639500925317407\n",
            "ΔX norm: 1.563949990668334e-05\n",
            "Stage 4/10:  71%|████████████████████▌        | 213/300 [06:51<02:41,  1.86s/it]T Loss=2.302396535873413\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303804874420166\n",
            "g_norm = tensor(0.1219, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032422065734863\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30328631401062\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303684711456299\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8193817138672\n",
            "||∇_X meta|| = 0.0016686271410435438\n",
            "ΔX norm: 1.668628101469949e-05\n",
            "Stage 4/10:  71%|████████████████████▋        | 214/300 [06:53<02:42,  1.89s/it]T Loss=2.3046727180480957\n",
            "g_norm = tensor(0.0862, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304427146911621\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035778999328613\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304931163787842\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034417629241943\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.7414093017578\n",
            "||∇_X meta|| = 0.0015192184364423156\n",
            "ΔX norm: 1.5192195860436186e-05\n",
            "Stage 4/10:  72%|████████████████████▊        | 215/300 [06:56<03:02,  2.14s/it]T Loss=2.3030967712402344\n",
            "g_norm = tensor(0.1596, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026721477508545\n",
            "g_norm = tensor(0.1230, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034870624542236\n",
            "g_norm = tensor(0.1431, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303881883621216\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027381896972656\n",
            "g_norm = tensor(0.1511, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.65875244140625\n",
            "||∇_X meta|| = 0.001509312423877418\n",
            "ΔX norm: 1.50931446114555e-05\n",
            "Stage 4/10:  72%|████████████████████▉        | 216/300 [06:58<02:58,  2.13s/it]T Loss=2.303328037261963\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036437034606934\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302849292755127\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30253267288208\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303495407104492\n",
            "g_norm = tensor(0.0945, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.66915893554688\n",
            "||∇_X meta|| = 0.001589920953847468\n",
            "ΔX norm: 1.5899227946647443e-05\n",
            "Stage 4/10:  72%|████████████████████▉        | 217/300 [07:00<03:06,  2.25s/it]T Loss=2.304384469985962\n",
            "g_norm = tensor(0.1425, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30353045463562\n",
            "g_norm = tensor(0.1686, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302672863006592\n",
            "g_norm = tensor(0.1157, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303748369216919\n",
            "g_norm = tensor(0.1560, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032028675079346\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.13990783691406\n",
            "||∇_X meta|| = 0.0014500722754746675\n",
            "ΔX norm: 1.4500736142508686e-05\n",
            "Stage 4/10:  73%|█████████████████████        | 218/300 [07:02<02:55,  2.14s/it]T Loss=2.3042056560516357\n",
            "g_norm = tensor(0.1021, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304189920425415\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302600145339966\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038532733917236\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048925399780273\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.57040405273438\n",
            "||∇_X meta|| = 0.0016880203038454056\n",
            "ΔX norm: 1.68801961990539e-05\n",
            "Stage 4/10:  73%|█████████████████████▏       | 219/300 [07:04<02:48,  2.08s/it]T Loss=2.3049793243408203\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304378032684326\n",
            "g_norm = tensor(0.1213, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304626226425171\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045172691345215\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048036098480225\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.99569702148438\n",
            "||∇_X meta|| = 0.0016588290454819798\n",
            "ΔX norm: 1.658827022765763e-05\n",
            "Stage 4/10:  73%|█████████████████████▎       | 220/300 [07:06<02:45,  2.07s/it]T Loss=2.30375599861145\n",
            "g_norm = tensor(0.1495, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303623676300049\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304394483566284\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040380477905273\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027455806732178\n",
            "g_norm = tensor(0.1438, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.28465270996094\n",
            "||∇_X meta|| = 0.0017111710039898753\n",
            "ΔX norm: 1.711169898044318e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 4/10:  74%|█████████████████████▎       | 221/300 [07:08<02:42,  2.06s/it]T Loss=2.30322003364563\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303969621658325\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041465282440186\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041112422943115\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048746585845947\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8047332763672\n",
            "||∇_X meta|| = 0.0015576491132378578\n",
            "ΔX norm: 1.557648829475511e-05\n",
            "Stage 4/10:  74%|█████████████████████▍       | 222/300 [07:11<02:51,  2.20s/it]T Loss=2.30427885055542\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039767742156982\n",
            "g_norm = tensor(0.0816, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056724071502686\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304403305053711\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302900552749634\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.92098999023438\n",
            "||∇_X meta|| = 0.0015893717063590884\n",
            "ΔX norm: 1.5893694580881856e-05\n",
            "Stage 4/10:  74%|█████████████████████▌       | 223/300 [07:13<02:43,  2.13s/it]T Loss=2.301940441131592\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303691864013672\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023173809051514\n",
            "g_norm = tensor(0.1428, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020312786102295\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021509647369385\n",
            "g_norm = tensor(0.1183, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.99920654296875\n",
            "||∇_X meta|| = 0.0016101837391033769\n",
            "ΔX norm: 1.6101859728223644e-05\n",
            "Stage 4/10:  75%|█████████████████████▋       | 224/300 [07:15<02:35,  2.05s/it]T Loss=2.303471088409424\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030152320861816\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304154872894287\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303880214691162\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303880214691162\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.24209594726562\n",
            "||∇_X meta|| = 0.0015455688117071986\n",
            "ΔX norm: 1.5455672837560996e-05\n",
            "Stage 4/10:  75%|█████████████████████▊       | 225/300 [07:16<02:27,  1.97s/it]T Loss=2.3038010597229004\n",
            "g_norm = tensor(0.0755, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039543628692627\n",
            "g_norm = tensor(0.0746, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040599822998047\n",
            "g_norm = tensor(0.0730, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034255504608154\n",
            "g_norm = tensor(0.0705, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303844451904297\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5313262939453\n",
            "||∇_X meta|| = 0.0015423228032886982\n",
            "ΔX norm: 1.542322752356995e-05\n",
            "Stage 4/10:  75%|█████████████████████▊       | 226/300 [07:18<02:23,  1.94s/it]T Loss=2.3040435314178467\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039157390594482\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302913188934326\n",
            "g_norm = tensor(0.1235, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026585578918457\n",
            "g_norm = tensor(0.1327, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050217628479004\n",
            "g_norm = tensor(0.1392, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.50277709960938\n",
            "||∇_X meta|| = 0.0015310003655031323\n",
            "ΔX norm: 1.53100372699555e-05\n",
            "Stage 4/10:  76%|█████████████████████▉       | 227/300 [07:20<02:20,  1.93s/it]T Loss=2.3040735721588135\n",
            "g_norm = tensor(0.0800, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30430269241333\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036720752716064\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038535118103027\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304513454437256\n",
            "g_norm = tensor(0.0937, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8271026611328\n",
            "||∇_X meta|| = 0.0016208234010264277\n",
            "ΔX norm: 1.620827788428869e-05\n",
            "Stage 4/10:  76%|██████████████████████       | 228/300 [07:22<02:23,  1.99s/it]T Loss=2.3039865493774414\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303671360015869\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303666591644287\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047218322753906\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037779331207275\n",
            "g_norm = tensor(0.1465, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1611328125\n",
            "||∇_X meta|| = 0.0015945769846439362\n",
            "ΔX norm: 1.5945777704473585e-05\n",
            "Stage 4/10:  76%|██████████████████████▏      | 229/300 [07:24<02:20,  1.98s/it]T Loss=2.3028502464294434\n",
            "g_norm = tensor(0.1509, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041269779205322\n",
            "g_norm = tensor(0.1737, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034069538116455\n",
            "g_norm = tensor(0.1842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303098201751709\n",
            "g_norm = tensor(0.1857, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052420616149902\n",
            "g_norm = tensor(0.1900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.3843536376953\n",
            "||∇_X meta|| = 0.0017391237197443843\n",
            "ΔX norm: 1.7391204892192036e-05\n",
            "Stage 4/10:  77%|██████████████████████▏      | 230/300 [07:26<02:18,  1.98s/it]T Loss=2.304028034210205\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046844005584717\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045806884765625\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039438724517822\n",
            "g_norm = tensor(0.1366, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045244216918945\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1340789794922\n",
            "||∇_X meta|| = 0.0016570546431466937\n",
            "ΔX norm: 1.6570555089856498e-05\n",
            "Stage 4/10:  77%|██████████████████████▎      | 231/300 [07:28<02:19,  2.02s/it]T Loss=2.3042280673980713\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303466558456421\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041129112243652\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041434288024902\n",
            "g_norm = tensor(0.1139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034722805023193\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7432861328125\n",
            "||∇_X meta|| = 0.0016376945422962308\n",
            "ΔX norm: 1.6376934581785463e-05\n",
            "Stage 4/10:  77%|██████████████████████▍      | 232/300 [07:30<02:16,  2.01s/it]T Loss=2.3044536113739014\n",
            "g_norm = tensor(0.0840, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044891357421875\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032174110412598\n",
            "g_norm = tensor(0.0864, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039166927337646\n",
            "g_norm = tensor(0.0807, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304788112640381\n",
            "g_norm = tensor(0.0865, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.33670043945312\n",
            "||∇_X meta|| = 0.0017356370808556676\n",
            "ΔX norm: 1.7356347598251887e-05\n",
            "Stage 4/10:  78%|██████████████████████▌      | 233/300 [07:32<02:11,  1.96s/it]T Loss=2.303236246109009\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304074764251709\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303779125213623\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303499937057495\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303493022918701\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.37831115722656\n",
            "||∇_X meta|| = 0.0017449385486543179\n",
            "ΔX norm: 1.744937435432803e-05\n",
            "Stage 4/10:  78%|██████████████████████▌      | 234/300 [07:34<02:06,  1.92s/it]T Loss=2.3023455142974854\n",
            "g_norm = tensor(0.1340, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041186332702637\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036465644836426\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034462928771973\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303297758102417\n",
            "g_norm = tensor(0.1358, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.65728759765625\n",
            "||∇_X meta|| = 0.0015165412332862616\n",
            "ΔX norm: 1.5165420336415991e-05\n",
            "Stage 4/10:  78%|██████████████████████▋      | 235/300 [07:36<02:03,  1.89s/it]T Loss=2.3041934967041016\n",
            "g_norm = tensor(0.0648, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304802894592285\n",
            "g_norm = tensor(0.0724, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037269115448\n",
            "g_norm = tensor(0.0708, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037772178649902\n",
            "g_norm = tensor(0.0732, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304335117340088\n",
            "g_norm = tensor(0.0716, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.82240295410156\n",
            "||∇_X meta|| = 0.001597127877175808\n",
            "ΔX norm: 1.5971261746017262e-05\n",
            "Stage 4/10:  79%|██████████████████████▊      | 236/300 [07:38<02:00,  1.88s/it]T Loss=2.304093837738037\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303518772125244\n",
            "g_norm = tensor(0.0897, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040356636047363\n",
            "g_norm = tensor(0.0760, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044025897979736\n",
            "g_norm = tensor(0.0844, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303795337677002\n",
            "g_norm = tensor(0.0689, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1367950439453\n",
            "||∇_X meta|| = 0.0015290837036445737\n",
            "ΔX norm: 1.5290857845684513e-05\n",
            "Stage 4/10:  79%|██████████████████████▉      | 237/300 [07:40<01:58,  1.88s/it]T Loss=2.3047842979431152\n",
            "g_norm = tensor(0.1318, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046295642852783\n",
            "g_norm = tensor(0.1357, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303664207458496\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302403211593628\n",
            "g_norm = tensor(0.1916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302450656890869\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.87118530273438\n",
            "||∇_X meta|| = 0.0015139238676056266\n",
            "ΔX norm: 1.5139269635255914e-05\n",
            "Stage 4/10:  79%|███████████████████████      | 238/300 [07:42<01:57,  1.89s/it]T Loss=2.3050968647003174\n",
            "g_norm = tensor(0.1580, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304534673690796\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040502071380615\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049428462982178\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045220375061035\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.59255981445312\n",
            "||∇_X meta|| = 0.0015511695528402925\n",
            "ΔX norm: 1.5511684978264384e-05\n",
            "Stage 4/10:  80%|███████████████████████      | 239/300 [07:43<01:56,  1.90s/it]T Loss=2.301922082901001\n",
            "g_norm = tensor(0.0872, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302380084991455\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033711910247803\n",
            "g_norm = tensor(0.1021, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026318550109863\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022875785827637\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.03277587890625\n",
            "||∇_X meta|| = 0.0016398398438468575\n",
            "ΔX norm: 1.6398389561800286e-05\n",
            "Stage 4/10:  80%|███████████████████████▏     | 240/300 [07:45<01:53,  1.90s/it]T Loss=2.303563356399536\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035683631896973\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029308319091797\n",
            "g_norm = tensor(0.1153, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302978515625\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037772178649902\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.00665283203125\n",
            "||∇_X meta|| = 0.0016089187702164054\n",
            "ΔX norm: 1.6089210475911386e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 4/10:  80%|███████████████████████▎     | 241/300 [07:47<01:52,  1.91s/it]T Loss=2.3057525157928467\n",
            "g_norm = tensor(0.1675, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040595054626465\n",
            "g_norm = tensor(0.1374, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3073229789733887\n",
            "g_norm = tensor(0.1603, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017258644104004\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304710865020752\n",
            "g_norm = tensor(0.1617, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.33502197265625\n",
            "||∇_X meta|| = 0.001510815229266882\n",
            "ΔX norm: 1.510815491201356e-05\n",
            "Stage 4/10:  81%|███████████████████████▍     | 242/300 [07:50<01:55,  2.00s/it]T Loss=2.3031744956970215\n",
            "g_norm = tensor(0.1361, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303433895111084\n",
            "g_norm = tensor(0.1578, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302407741546631\n",
            "g_norm = tensor(0.1299, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301234722137451\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029255867004395\n",
            "g_norm = tensor(0.1140, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.27931213378906\n",
            "||∇_X meta|| = 0.0015394148649647832\n",
            "ΔX norm: 1.5394165529869497e-05\n",
            "Stage 4/10:  81%|███████████████████████▍     | 243/300 [07:52<02:00,  2.12s/it]T Loss=2.3034825325012207\n",
            "g_norm = tensor(0.0844, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30328369140625\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302494525909424\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303845167160034\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303499698638916\n",
            "g_norm = tensor(0.1011, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9742431640625\n",
            "||∇_X meta|| = 0.0016310653882101178\n",
            "ΔX norm: 1.6310663340846077e-05\n",
            "Stage 4/10:  81%|███████████████████████▌     | 244/300 [07:54<01:55,  2.06s/it]T Loss=2.303560733795166\n",
            "g_norm = tensor(0.0751, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041634559631348\n",
            "g_norm = tensor(0.0866, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304781675338745\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304030656814575\n",
            "g_norm = tensor(0.0803, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037030696868896\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.83633422851562\n",
            "||∇_X meta|| = 0.0015110243111848831\n",
            "ΔX norm: 1.5110234926396515e-05\n",
            "Stage 4/10:  82%|███████████████████████▋     | 245/300 [07:56<01:57,  2.13s/it]T Loss=2.3019707202911377\n",
            "g_norm = tensor(0.0777, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029046058654785\n",
            "g_norm = tensor(0.0757, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041083812713623\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036208152770996\n",
            "g_norm = tensor(0.0751, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302751064300537\n",
            "g_norm = tensor(0.0931, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.42715454101562\n",
            "||∇_X meta|| = 0.0015386801678687334\n",
            "ΔX norm: 1.5386798622785136e-05\n",
            "Stage 4/10:  82%|███████████████████████▊     | 246/300 [07:58<01:52,  2.08s/it]T Loss=2.3028855323791504\n",
            "g_norm = tensor(0.0941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303123712539673\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302380084991455\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302685260772705\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024187088012695\n",
            "g_norm = tensor(0.1110, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.76211547851562\n",
            "||∇_X meta|| = 0.001592395594343543\n",
            "ΔX norm: 1.592396802152507e-05\n",
            "Stage 4/10:  82%|███████████████████████▉     | 247/300 [08:00<01:46,  2.02s/it]T Loss=2.3035712242126465\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051886558532715\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303764820098877\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304713726043701\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048441410064697\n",
            "g_norm = tensor(0.1371, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.8689727783203\n",
            "||∇_X meta|| = 0.0015400602715089917\n",
            "ΔX norm: 1.5400597476400435e-05\n",
            "Stage 4/10:  83%|███████████████████████▉     | 248/300 [08:02<01:42,  1.98s/it]T Loss=2.3029003143310547\n",
            "g_norm = tensor(0.1235, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029441833496094\n",
            "g_norm = tensor(0.1218, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303009510040283\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022570610046387\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303542375564575\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4302520751953\n",
            "||∇_X meta|| = 0.0017345460364595056\n",
            "ΔX norm: 1.7345475498586893e-05\n",
            "Stage 4/10:  83%|████████████████████████     | 249/300 [08:04<01:39,  1.95s/it]T Loss=2.3036623001098633\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303133964538574\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303295612335205\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029534816741943\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025851249694824\n",
            "g_norm = tensor(0.1350, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.83340454101562\n",
            "||∇_X meta|| = 0.001652939710766077\n",
            "ΔX norm: 1.652939317864366e-05\n",
            "Stage 4/10:  83%|████████████████████████▏    | 250/300 [08:06<01:38,  1.96s/it]T Loss=2.303825855255127\n",
            "g_norm = tensor(0.1257, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303234815597534\n",
            "g_norm = tensor(0.1867, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302034854888916\n",
            "g_norm = tensor(0.1473, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303370237350464\n",
            "g_norm = tensor(0.1442, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034725189208984\n",
            "g_norm = tensor(0.1503, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.60423278808594\n",
            "||∇_X meta|| = 0.0015020252903923392\n",
            "ΔX norm: 1.5020226783235557e-05\n",
            "Stage 4/10:  84%|████████████████████████▎    | 251/300 [08:08<01:35,  1.95s/it]T Loss=2.303126811981201\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30269718170166\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033974170684814\n",
            "g_norm = tensor(0.0810, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302473545074463\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303318500518799\n",
            "g_norm = tensor(0.0854, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.81724548339844\n",
            "||∇_X meta|| = 0.0015370959881693125\n",
            "ΔX norm: 1.537098978587892e-05\n",
            "Stage 4/10:  84%|████████████████████████▎    | 252/300 [08:09<01:31,  1.91s/it]T Loss=2.303297519683838\n",
            "g_norm = tensor(0.1402, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039608001708984\n",
            "g_norm = tensor(0.1412, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030848503112793\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040788173675537\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045825958251953\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.64295959472656\n",
            "||∇_X meta|| = 0.0015256816986948252\n",
            "ΔX norm: 1.52567881741561e-05\n",
            "Stage 4/10:  84%|████████████████████████▍    | 253/300 [08:12<01:38,  2.09s/it]T Loss=2.303781509399414\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304442882537842\n",
            "g_norm = tensor(0.0820, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303570508956909\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039164543151855\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033528327941895\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6517791748047\n",
            "||∇_X meta|| = 0.001583859440870583\n",
            "ΔX norm: 1.5838604667806067e-05\n",
            "Stage 4/10:  85%|████████████████████████▌    | 254/300 [08:14<01:34,  2.05s/it]T Loss=2.3032138347625732\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304232597351074\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056302070617676\n",
            "g_norm = tensor(0.1222, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049206733703613\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045222759246826\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1214599609375\n",
            "||∇_X meta|| = 0.001517939381301403\n",
            "ΔX norm: 1.5179400179476943e-05\n",
            "Stage 4/10:  85%|████████████████████████▋    | 255/300 [08:16<01:31,  2.02s/it]T Loss=2.30405592918396\n",
            "g_norm = tensor(0.0823, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303368091583252\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027424812316895\n",
            "g_norm = tensor(0.0747, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303928852081299\n",
            "g_norm = tensor(0.0844, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032784461975098\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.50831604003906\n",
            "||∇_X meta|| = 0.0015343271661549807\n",
            "ΔX norm: 1.534325747343246e-05\n",
            "Stage 4/10:  85%|████████████████████████▋    | 256/300 [08:18<01:27,  1.99s/it]T Loss=2.3033556938171387\n",
            "g_norm = tensor(0.1153, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050196170806885\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046116828918457\n",
            "g_norm = tensor(0.1327, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051095008850098\n",
            "g_norm = tensor(0.1338, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054513931274414\n",
            "g_norm = tensor(0.1262, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.44139099121094\n",
            "||∇_X meta|| = 0.0015070319641381502\n",
            "ΔX norm: 1.5070299923536368e-05\n",
            "Stage 4/10:  86%|████████████████████████▊    | 257/300 [08:20<01:25,  1.98s/it]T Loss=2.303248882293701\n",
            "g_norm = tensor(0.0880, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043997287750244\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039393424987793\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301737070083618\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033974170684814\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.56027221679688\n",
            "||∇_X meta|| = 0.0015991369727998972\n",
            "ΔX norm: 1.5991383406799287e-05\n",
            "Stage 4/10:  86%|████████████████████████▉    | 258/300 [08:22<01:22,  1.96s/it]T Loss=2.304584503173828\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038387298583984\n",
            "g_norm = tensor(0.1309, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046364784240723\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302617073059082\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304060459136963\n",
            "g_norm = tensor(0.1295, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3720245361328\n",
            "||∇_X meta|| = 0.0015346468426287174\n",
            "ΔX norm: 1.5346487998613156e-05\n",
            "Stage 4/10:  86%|█████████████████████████    | 259/300 [08:24<01:19,  1.93s/it]T Loss=2.3039488792419434\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304527759552002\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029520511627197\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303382158279419\n",
            "g_norm = tensor(0.0942, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037831783294678\n",
            "g_norm = tensor(0.0871, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.81809997558594\n",
            "||∇_X meta|| = 0.0016025797231122851\n",
            "ΔX norm: 1.602579141035676e-05\n",
            "Stage 4/10:  87%|█████████████████████████▏   | 260/300 [08:26<01:18,  1.97s/it]T Loss=2.304175853729248\n",
            "g_norm = tensor(0.1388, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043267726898193\n",
            "g_norm = tensor(0.1362, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304969072341919\n",
            "g_norm = tensor(0.1320, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053994178771973\n",
            "g_norm = tensor(0.1447, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036437034606934\n",
            "g_norm = tensor(0.1327, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2665557861328\n",
            "||∇_X meta|| = 0.001508502522483468\n",
            "ΔX norm: 1.508502919023158e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 4/10:  87%|█████████████████████████▏   | 261/300 [08:28<01:17,  1.99s/it]T Loss=2.303142547607422\n",
            "g_norm = tensor(0.0825, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030805587768555\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034722805023193\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303095579147339\n",
            "g_norm = tensor(0.0774, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026015758514404\n",
            "g_norm = tensor(0.0772, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2035675048828\n",
            "||∇_X meta|| = 0.0015861649299040437\n",
            "ΔX norm: 1.5861622159718536e-05\n",
            "Stage 4/10:  87%|█████████████████████████▎   | 262/300 [08:30<01:21,  2.14s/it]T Loss=2.304097890853882\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303431987762451\n",
            "g_norm = tensor(0.0835, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303412437438965\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303231954574585\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302342176437378\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.27224731445312\n",
            "||∇_X meta|| = 0.0014961670385673642\n",
            "ΔX norm: 1.4961678971303627e-05\n",
            "Stage 4/10:  88%|█████████████████████████▍   | 263/300 [08:32<01:17,  2.10s/it]T Loss=2.3031251430511475\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302447557449341\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301927089691162\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302685260772705\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028721809387207\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6593017578125\n",
            "||∇_X meta|| = 0.001563537516631186\n",
            "ΔX norm: 1.5635358067811467e-05\n",
            "Stage 4/10:  88%|█████████████████████████▌   | 264/300 [08:34<01:14,  2.08s/it]T Loss=2.3022522926330566\n",
            "g_norm = tensor(0.1221, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024184703826904\n",
            "g_norm = tensor(0.1255, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304241180419922\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032443523406982\n",
            "g_norm = tensor(0.1216, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304274320602417\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.99087524414062\n",
            "||∇_X meta|| = 0.0014830437721684575\n",
            "ΔX norm: 1.4830439795332495e-05\n",
            "Stage 4/10:  88%|█████████████████████████▌   | 265/300 [08:37<01:19,  2.27s/it]T Loss=2.3040878772735596\n",
            "g_norm = tensor(0.1103, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302277088165283\n",
            "g_norm = tensor(0.1163, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028512001037598\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023743629455566\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036184310913086\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9600372314453\n",
            "||∇_X meta|| = 0.0015696113696321845\n",
            "ΔX norm: 1.569612322782632e-05\n",
            "Stage 4/10:  89%|█████████████████████████▋   | 266/300 [08:39<01:15,  2.23s/it]T Loss=2.30364727973938\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044257164001465\n",
            "g_norm = tensor(0.0983, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031835556030273\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303307056427002\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031160831451416\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.67799377441406\n",
            "||∇_X meta|| = 0.0014468372100964189\n",
            "ΔX norm: 1.4468379958998412e-05\n",
            "Stage 4/10:  89%|█████████████████████████▊   | 267/300 [08:41<01:11,  2.17s/it]T Loss=2.303574800491333\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302637815475464\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303729295730591\n",
            "g_norm = tensor(0.0736, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043768405914307\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304251194000244\n",
            "g_norm = tensor(0.0819, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9159698486328\n",
            "||∇_X meta|| = 0.0016887496458366513\n",
            "ΔX norm: 1.6887488527572714e-05\n",
            "Stage 4/10:  89%|█████████████████████████▉   | 268/300 [08:43<01:08,  2.14s/it]T Loss=2.3033955097198486\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30413818359375\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052268028259277\n",
            "g_norm = tensor(0.0937, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303231716156006\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303830862045288\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.77899169921875\n",
            "||∇_X meta|| = 0.0014084074646234512\n",
            "ΔX norm: 1.408408297720598e-05\n",
            "Stage 4/10:  90%|██████████████████████████   | 269/300 [08:45<01:03,  2.05s/it]T Loss=2.3044934272766113\n",
            "g_norm = tensor(0.0856, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303959369659424\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039355278015137\n",
            "g_norm = tensor(0.0922, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041322231292725\n",
            "g_norm = tensor(0.0871, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033928871154785\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.69744873046875\n",
            "||∇_X meta|| = 0.0015786667354404926\n",
            "ΔX norm: 1.5786654330440797e-05\n",
            "Stage 4/10:  90%|██████████████████████████   | 270/300 [08:47<00:59,  1.99s/it]T Loss=2.303532838821411\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049533367156982\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303217649459839\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029375076293945\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304849147796631\n",
            "g_norm = tensor(0.1011, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.18312072753906\n",
            "||∇_X meta|| = 0.0015084455953910947\n",
            "ΔX norm: 1.5084431652212515e-05\n",
            "Stage 4/10:  90%|██████████████████████████▏  | 271/300 [08:49<00:56,  1.97s/it]T Loss=2.303459644317627\n",
            "g_norm = tensor(0.0933, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303386688232422\n",
            "g_norm = tensor(0.0933, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037028312683105\n",
            "g_norm = tensor(0.0849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303968906402588\n",
            "g_norm = tensor(0.0846, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302966594696045\n",
            "g_norm = tensor(0.0843, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.9671173095703\n",
            "||∇_X meta|| = 0.001542758895084262\n",
            "ΔX norm: 1.5427571270265616e-05\n",
            "Stage 4/10:  91%|██████████████████████████▎  | 272/300 [08:51<00:54,  1.95s/it]T Loss=2.303708076477051\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305436611175537\n",
            "g_norm = tensor(0.1371, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304673433303833\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051323890686035\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304767608642578\n",
            "g_norm = tensor(0.1251, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.58677673339844\n",
            "||∇_X meta|| = 0.0014775122981518507\n",
            "ΔX norm: 1.4775137969991192e-05\n",
            "Stage 4/10:  91%|██████████████████████████▍  | 273/300 [08:53<00:52,  1.95s/it]T Loss=2.30189847946167\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032684326171875\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303699016571045\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302359104156494\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037164211273193\n",
            "g_norm = tensor(0.0820, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.51519775390625\n",
            "||∇_X meta|| = 0.0015157336601987481\n",
            "ΔX norm: 1.515732947154902e-05\n",
            "Stage 4/10:  91%|██████████████████████████▍  | 274/300 [08:55<00:51,  1.99s/it]T Loss=2.303530693054199\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040928840637207\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303758382797241\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304736614227295\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302673578262329\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.91732788085938\n",
            "||∇_X meta|| = 0.0015449195634573698\n",
            "ΔX norm: 1.5449188140337355e-05\n",
            "Stage 4/10:  92%|██████████████████████████▌  | 275/300 [08:57<00:53,  2.16s/it]T Loss=2.30263090133667\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303518772125244\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304110527038574\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303786516189575\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048458099365234\n",
            "g_norm = tensor(0.1107, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.44549560546875\n",
            "||∇_X meta|| = 0.0015087065985426307\n",
            "ΔX norm: 1.5087072824826464e-05\n",
            "Stage 4/10:  92%|██████████████████████████▋  | 276/300 [08:59<00:51,  2.14s/it]T Loss=2.3035671710968018\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038554191589355\n",
            "g_norm = tensor(0.1323, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304352045059204\n",
            "g_norm = tensor(0.1370, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304258346557617\n",
            "g_norm = tensor(0.1432, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027844429016113\n",
            "g_norm = tensor(0.1411, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.50006103515625\n",
            "||∇_X meta|| = 0.0015851486241444945\n",
            "ΔX norm: 1.585148675076198e-05\n",
            "Stage 4/10:  92%|██████████████████████████▊  | 277/300 [09:01<00:48,  2.09s/it]T Loss=2.303337574005127\n",
            "g_norm = tensor(0.0756, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303283214569092\n",
            "g_norm = tensor(0.0722, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304389238357544\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032965660095215\n",
            "g_norm = tensor(0.0846, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028171062469482\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.49114990234375\n",
            "||∇_X meta|| = 0.0017063772538676858\n",
            "ΔX norm: 1.7063774066627957e-05\n",
            "Stage 4/10:  93%|██████████████████████████▊  | 278/300 [09:04<00:47,  2.17s/it]T Loss=2.304758310317993\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303969144821167\n",
            "g_norm = tensor(0.0876, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303597927093506\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044533729553223\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033664226531982\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4186248779297\n",
            "||∇_X meta|| = 0.0015827901661396027\n",
            "ΔX norm: 1.582791628607083e-05\n",
            "Stage 4/10:  93%|██████████████████████████▉  | 279/300 [09:06<00:47,  2.25s/it]T Loss=2.304347515106201\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041579723358154\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304274082183838\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304628372192383\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305398941040039\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.26051330566406\n",
            "||∇_X meta|| = 0.0015962811885401607\n",
            "ΔX norm: 1.596279616933316e-05\n",
            "Stage 4/10:  93%|███████████████████████████  | 280/300 [09:08<00:44,  2.22s/it]T Loss=2.3039021492004395\n",
            "g_norm = tensor(0.1529, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303394317626953\n",
            "g_norm = tensor(0.1325, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045365810394287\n",
            "g_norm = tensor(0.1484, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051013946533203\n",
            "g_norm = tensor(0.1396, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30584716796875\n",
            "g_norm = tensor(0.1523, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.82138061523438\n",
            "||∇_X meta|| = 0.0015939432196319103\n",
            "ΔX norm: 1.5939453078317456e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 4/10:  94%|███████████████████████████▏ | 281/300 [09:10<00:41,  2.19s/it]T Loss=2.3043458461761475\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047592639923096\n",
            "g_norm = tensor(0.0866, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057608604431152\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305025577545166\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048906326293945\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.86192321777344\n",
            "||∇_X meta|| = 0.0017247856594622135\n",
            "ΔX norm: 1.7247848518309183e-05\n",
            "Stage 4/10:  94%|███████████████████████████▎ | 282/300 [09:13<00:43,  2.41s/it]T Loss=2.304666519165039\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040382862091064\n",
            "g_norm = tensor(0.1317, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048605918884277\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043036460876465\n",
            "g_norm = tensor(0.1425, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305243968963623\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.67955017089844\n",
            "||∇_X meta|| = 0.0014322628267109394\n",
            "ΔX norm: 1.4322625247586984e-05\n",
            "Stage 4/10:  94%|███████████████████████████▎ | 283/300 [09:16<00:41,  2.45s/it]T Loss=2.3046698570251465\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051438331604004\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042187690734863\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053293228149414\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304689884185791\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.69805908203125\n",
            "||∇_X meta|| = 0.0016774049727246165\n",
            "ΔX norm: 1.6774047253420576e-05\n",
            "Stage 4/10:  95%|███████████████████████████▍ | 284/300 [09:18<00:38,  2.43s/it]T Loss=2.3033738136291504\n",
            "g_norm = tensor(0.0787, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041625022888184\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303316831588745\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303997039794922\n",
            "g_norm = tensor(0.0802, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304199695587158\n",
            "g_norm = tensor(0.0865, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.16160583496094\n",
            "||∇_X meta|| = 0.0014904583804309368\n",
            "ΔX norm: 1.4904590898368042e-05\n",
            "Stage 4/10:  95%|███████████████████████████▌ | 285/300 [09:21<00:37,  2.47s/it]T Loss=2.3032758235931396\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30397367477417\n",
            "g_norm = tensor(0.1213, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033347129821777\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302450180053711\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30397367477417\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.31666564941406\n",
            "||∇_X meta|| = 0.0017063746927306056\n",
            "ΔX norm: 1.7063746781786904e-05\n",
            "Stage 4/10:  95%|███████████████████████████▋ | 286/300 [09:23<00:33,  2.42s/it]T Loss=2.3037657737731934\n",
            "g_norm = tensor(0.0669, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044793605804443\n",
            "g_norm = tensor(0.0827, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036537170410156\n",
            "g_norm = tensor(0.0784, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304043769836426\n",
            "g_norm = tensor(0.0723, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304352283477783\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.21737670898438\n",
            "||∇_X meta|| = 0.0014001370873302221\n",
            "ΔX norm: 1.4001354429638013e-05\n",
            "Stage 4/10:  96%|███████████████████████████▋ | 287/300 [09:26<00:32,  2.51s/it]T Loss=2.304971933364868\n",
            "g_norm = tensor(0.1396, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029818534851074\n",
            "g_norm = tensor(0.1423, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303925037384033\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036317825317383\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037314414978027\n",
            "g_norm = tensor(0.1559, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.89491271972656\n",
            "||∇_X meta|| = 0.0015320003731176257\n",
            "ΔX norm: 1.5320007150876336e-05\n",
            "Stage 4/10:  96%|███████████████████████████▊ | 288/300 [09:28<00:28,  2.35s/it]T Loss=2.3025193214416504\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301809549331665\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303534984588623\n",
            "g_norm = tensor(0.0860, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302755117416382\n",
            "g_norm = tensor(0.0941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302933931350708\n",
            "g_norm = tensor(0.1213, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.16993713378906\n",
            "||∇_X meta|| = 0.0017245090566575527\n",
            "ΔX norm: 1.724510730127804e-05\n",
            "Stage 4/10:  96%|███████████████████████████▉ | 289/300 [09:30<00:24,  2.20s/it]T Loss=2.3029775619506836\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303978681564331\n",
            "g_norm = tensor(0.1053, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035054206848145\n",
            "g_norm = tensor(0.0879, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304503917694092\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036205768585205\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.8521728515625\n",
            "||∇_X meta|| = 0.001684247748926282\n",
            "ΔX norm: 1.6842479453771375e-05\n",
            "Stage 4/10:  97%|████████████████████████████ | 290/300 [09:31<00:20,  2.08s/it]T Loss=2.303419351577759\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303833484649658\n",
            "g_norm = tensor(0.0928, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026351928710938\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037877082824707\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303539276123047\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3898468017578\n",
            "||∇_X meta|| = 0.0014898376539349556\n",
            "ΔX norm: 1.4898370864102617e-05\n",
            "Stage 4/10:  97%|████████████████████████████▏| 291/300 [09:33<00:18,  2.04s/it]T Loss=2.304788112640381\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042068481445312\n",
            "g_norm = tensor(0.1184, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043205738067627\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304154396057129\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303018093109131\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.30690002441406\n",
            "||∇_X meta|| = 0.0016437391750514507\n",
            "ΔX norm: 1.64373832376441e-05\n",
            "Stage 4/10:  97%|████████████████████████████▏| 292/300 [09:35<00:16,  2.00s/it]T Loss=2.3045382499694824\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047142028808594\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304941415786743\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039488792419434\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303941011428833\n",
            "g_norm = tensor(0.0736, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.087890625\n",
            "||∇_X meta|| = 0.0014524183934554458\n",
            "ΔX norm: 1.4524204743793234e-05\n",
            "Stage 4/10:  98%|████████████████████████████▎| 293/300 [09:38<00:16,  2.35s/it]T Loss=2.302943706512451\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303130626678467\n",
            "g_norm = tensor(0.1375, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302812337875366\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302173137664795\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302812099456787\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9196014404297\n",
            "||∇_X meta|| = 0.001706485403701663\n",
            "ΔX norm: 1.706485272734426e-05\n",
            "Stage 4/10:  98%|████████████████████████████▍| 294/300 [09:41<00:15,  2.53s/it]T Loss=2.3037197589874268\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304288148880005\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039393424987793\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046576976776123\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034701347351074\n",
            "g_norm = tensor(0.0919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.14486694335938\n",
            "||∇_X meta|| = 0.0014105414738878608\n",
            "ΔX norm: 1.4105424270383082e-05\n",
            "Stage 4/10:  98%|████████████████████████████▌| 295/300 [09:45<00:13,  2.76s/it]T Loss=2.3029096126556396\n",
            "g_norm = tensor(0.1532, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304720163345337\n",
            "g_norm = tensor(0.1454, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040831089019775\n",
            "g_norm = tensor(0.1447, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30442476272583\n",
            "g_norm = tensor(0.1275, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021864891052246\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6909637451172\n",
            "||∇_X meta|| = 0.0016152928583323956\n",
            "ΔX norm: 1.615290057088714e-05\n",
            "Stage 4/10:  99%|████████████████████████████▌| 296/300 [09:47<00:10,  2.59s/it]T Loss=2.3047878742218018\n",
            "g_norm = tensor(0.0934, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048012256622314\n",
            "g_norm = tensor(0.0861, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042826652526855\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043627738952637\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30461049079895\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.0536346435547\n",
            "||∇_X meta|| = 0.0015065181069076061\n",
            "ΔX norm: 1.5065198567754123e-05\n",
            "Stage 4/10:  99%|████████████████████████████▋| 297/300 [09:49<00:07,  2.38s/it]T Loss=2.304138660430908\n",
            "g_norm = tensor(0.0734, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037242889404297\n",
            "g_norm = tensor(0.0825, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035888671875\n",
            "g_norm = tensor(0.0879, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046936988830566\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041348457336426\n",
            "g_norm = tensor(0.0785, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.34591674804688\n",
            "||∇_X meta|| = 0.001446609036065638\n",
            "ΔX norm: 1.4466076208918821e-05\n",
            "Stage 4/10:  99%|████████████████████████████▊| 298/300 [09:51<00:04,  2.23s/it]T Loss=2.3047657012939453\n",
            "g_norm = tensor(0.0851, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041934967041016\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058085441589355\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044025897979736\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303974151611328\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.50132751464844\n",
            "||∇_X meta|| = 0.0016298858681693673\n",
            "ΔX norm: 1.6298878108500503e-05\n",
            "Stage 4/10: 100%|████████████████████████████▉| 299/300 [09:53<00:02,  2.13s/it]T Loss=2.304917812347412\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042869567871094\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033065795898438\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039391040802\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029065132141113\n",
            "g_norm = tensor(0.0849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.30001831054688\n",
            "||∇_X meta|| = 0.0014767292886972427\n",
            "ΔX norm: 1.4767295397177804e-05\n",
            "Stage 3, class 0, loss 2.208                                                    \n",
            "Stage 3, class 1, loss 2.268\n",
            "Stage 3, class 2, loss 2.341\n",
            "Stage 3, class 3, loss 2.360\n",
            "Stage 3, class 4, loss 2.304\n",
            "Stage 3, class 5, loss 2.327\n",
            "Stage 3, class 6, loss 2.384\n",
            "Stage 3, class 7, loss 2.222\n",
            "Stage 3, class 8, loss 2.376\n",
            "Stage 3, class 9, loss 2.256\n",
            "Stage 5/10:   0%|                                       | 0/300 [00:00<?, ?it/s]T Loss=2.3033041954040527\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026833534240723\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3016486167907715\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028862476348877\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034048080444336\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9267120361328\n",
            "||∇_X meta|| = 0.0037014612462371588\n",
            "ΔX norm: 3.701460809679702e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 5/10:   0%|                               | 1/300 [00:02<11:07,  2.23s/it]T Loss=2.3050737380981445\n",
            "g_norm = tensor(0.1718, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053083419799805\n",
            "g_norm = tensor(0.1400, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043153285980225\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058624267578125\n",
            "g_norm = tensor(0.1297, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045151233673096\n",
            "g_norm = tensor(0.1374, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.51475524902344\n",
            "||∇_X meta|| = 0.0038965679705142975\n",
            "ΔX norm: 3.896568887284957e-05\n",
            "Stage 5/10:   1%|▏                              | 2/300 [00:04<11:36,  2.34s/it]T Loss=2.3057544231414795\n",
            "g_norm = tensor(0.1555, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035082817077637\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303441047668457\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304015874862671\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032772541046143\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7387237548828\n",
            "||∇_X meta|| = 0.004536988213658333\n",
            "ΔX norm: 4.5369943109108135e-05\n",
            "Stage 5/10:   1%|▎                              | 3/300 [00:06<10:17,  2.08s/it]T Loss=2.3028106689453125\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303373336791992\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303130626678467\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024485111236572\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304198741912842\n",
            "g_norm = tensor(0.1378, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.93617248535156\n",
            "||∇_X meta|| = 0.0037073593121021986\n",
            "ΔX norm: 3.707361611304805e-05\n",
            "Stage 5/10:   1%|▍                              | 4/300 [00:08<09:18,  1.89s/it]T Loss=2.3029708862304688\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035426139831543\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303581714630127\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302426815032959\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30355167388916\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.71926879882812\n",
            "||∇_X meta|| = 0.0038215573877096176\n",
            "ΔX norm: 3.821560676442459e-05\n",
            "Stage 5/10:   2%|▌                              | 5/300 [00:09<08:42,  1.77s/it]T Loss=2.3045248985290527\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304269790649414\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051154613494873\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044381141662598\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048272132873535\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.86798095703125\n",
            "||∇_X meta|| = 0.0035424032248556614\n",
            "ΔX norm: 3.542398917488754e-05\n",
            "Stage 5/10:   2%|▌                              | 6/300 [00:11<08:31,  1.74s/it]T Loss=2.3044466972351074\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303396224975586\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303422212600708\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047914505004883\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028743267059326\n",
            "g_norm = tensor(0.0849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.16128540039062\n",
            "||∇_X meta|| = 0.003104360541328788\n",
            "ΔX norm: 3.104360803263262e-05\n",
            "Stage 5/10:   2%|▋                              | 7/300 [00:13<08:36,  1.76s/it]T Loss=2.3047666549682617\n",
            "g_norm = tensor(0.1556, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035197257995605\n",
            "g_norm = tensor(0.1273, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037190437316895\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030381202697754\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038454055786133\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.59873962402344\n",
            "||∇_X meta|| = 0.003933015279471874\n",
            "ΔX norm: 3.933011248591356e-05\n",
            "Stage 5/10:   3%|▊                              | 8/300 [00:14<08:42,  1.79s/it]T Loss=2.3047289848327637\n",
            "g_norm = tensor(0.1513, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303412914276123\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036677837371826\n",
            "g_norm = tensor(0.1491, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048369884490967\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303189754486084\n",
            "g_norm = tensor(0.1515, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.4503936767578\n",
            "||∇_X meta|| = 0.004002297762781382\n",
            "ΔX norm: 4.0022918255999684e-05\n",
            "Stage 5/10:   3%|▉                              | 9/300 [00:16<08:49,  1.82s/it]T Loss=2.302802562713623\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303581714630127\n",
            "g_norm = tensor(0.1317, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044331073760986\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303424596786499\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054614067077637\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.6477508544922\n",
            "||∇_X meta|| = 0.0030713758897036314\n",
            "ΔX norm: 3.071377068408765e-05\n",
            "Stage 5/10:   3%|█                             | 10/300 [00:19<09:23,  1.94s/it]T Loss=2.3051397800445557\n",
            "g_norm = tensor(0.1332, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304732084274292\n",
            "g_norm = tensor(0.1434, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047144412994385\n",
            "g_norm = tensor(0.1588, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305563449859619\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058340549468994\n",
            "g_norm = tensor(0.1139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9503631591797\n",
            "||∇_X meta|| = 0.004028430208563805\n",
            "ΔX norm: 4.028430339531042e-05\n",
            "Stage 5/10:   4%|█                             | 11/300 [00:22<11:09,  2.32s/it]T Loss=2.3044474124908447\n",
            "g_norm = tensor(0.1285, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049569129943848\n",
            "g_norm = tensor(0.1341, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040895462036133\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304612159729004\n",
            "g_norm = tensor(0.1225, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050708770751953\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.87303161621094\n",
            "||∇_X meta|| = 0.003627035766839981\n",
            "ΔX norm: 3.627029582276009e-05\n",
            "Stage 5/10:   4%|█▏                            | 12/300 [00:24<11:34,  2.41s/it]T Loss=2.3048183917999268\n",
            "g_norm = tensor(0.1349, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037736415863037\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054556846618652\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048651218414307\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040127754211426\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4121551513672\n",
            "||∇_X meta|| = 0.0037064198404550552\n",
            "ΔX norm: 3.706416464410722e-05\n",
            "Stage 5/10:   4%|█▎                            | 13/300 [00:26<11:02,  2.31s/it]T Loss=2.303912878036499\n",
            "g_norm = tensor(0.1253, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303772449493408\n",
            "g_norm = tensor(0.1255, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037121295928955\n",
            "g_norm = tensor(0.1566, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304443836212158\n",
            "g_norm = tensor(0.1472, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023829460144043\n",
            "g_norm = tensor(0.1567, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5535125732422\n",
            "||∇_X meta|| = 0.0036085008177906275\n",
            "ΔX norm: 3.60850099241361e-05\n",
            "Stage 5/10:   5%|█▍                            | 14/300 [00:28<10:37,  2.23s/it]T Loss=2.3031764030456543\n",
            "g_norm = tensor(0.0693, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034169673919678\n",
            "g_norm = tensor(0.0724, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036670684814453\n",
            "g_norm = tensor(0.0789, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303983211517334\n",
            "g_norm = tensor(0.0589, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304133653640747\n",
            "g_norm = tensor(0.0634, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.02955627441406\n",
            "||∇_X meta|| = 0.0032148032914847136\n",
            "ΔX norm: 3.214805474271998e-05\n",
            "Stage 5/10:   5%|█▌                            | 15/300 [00:31<10:32,  2.22s/it]T Loss=2.304269313812256\n",
            "g_norm = tensor(0.0815, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042044639587402\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303792715072632\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053462505340576\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306529998779297\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.36997985839844\n",
            "||∇_X meta|| = 0.0034353455994278193\n",
            "ΔX norm: 3.4353448427282274e-05\n",
            "Stage 5/10:   5%|█▌                            | 16/300 [00:33<10:49,  2.29s/it]T Loss=2.3036398887634277\n",
            "g_norm = tensor(0.1516, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039803504943848\n",
            "g_norm = tensor(0.1926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305293560028076\n",
            "g_norm = tensor(0.1449, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043923377990723\n",
            "g_norm = tensor(0.1378, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034939765930176\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.03707885742188\n",
            "||∇_X meta|| = 0.00341962743550539\n",
            "ΔX norm: 3.41962804668583e-05\n",
            "Stage 5/10:   6%|█▋                            | 17/300 [00:35<10:33,  2.24s/it]T Loss=2.3037352561950684\n",
            "g_norm = tensor(0.0816, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038883209228516\n",
            "g_norm = tensor(0.0704, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041062355041504\n",
            "g_norm = tensor(0.0800, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303903102874756\n",
            "g_norm = tensor(0.0775, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043923377990723\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.92208862304688\n",
            "||∇_X meta|| = 0.0034654950723052025\n",
            "ΔX norm: 3.465491681708954e-05\n",
            "Stage 5/10:   6%|█▊                            | 18/300 [00:37<10:12,  2.17s/it]T Loss=2.3036696910858154\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303175687789917\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304131031036377\n",
            "g_norm = tensor(0.0839, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303229808807373\n",
            "g_norm = tensor(0.0865, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034238815307617\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2334747314453\n",
            "||∇_X meta|| = 0.0035259879659861326\n",
            "ΔX norm: 3.525990905473009e-05\n",
            "Stage 5/10:   6%|█▉                            | 19/300 [00:40<10:53,  2.32s/it]T Loss=2.3046059608459473\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044514656066895\n",
            "g_norm = tensor(0.0860, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303920269012451\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040974140167236\n",
            "g_norm = tensor(0.0844, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037850856781006\n",
            "g_norm = tensor(0.0792, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.95274353027344\n",
            "||∇_X meta|| = 0.0032456903718411922\n",
            "ΔX norm: 3.245692641939968e-05\n",
            "Stage 5/10:   7%|██                            | 20/300 [00:43<11:26,  2.45s/it]T Loss=2.3035311698913574\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041982650756836\n",
            "g_norm = tensor(0.1107, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304720401763916\n",
            "g_norm = tensor(0.1364, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304739475250244\n",
            "g_norm = tensor(0.1459, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043646812438965\n",
            "g_norm = tensor(0.1278, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.89511108398438\n",
            "||∇_X meta|| = 0.0031814915128052235\n",
            "ΔX norm: 3.181485953973606e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 5/10:   7%|██                            | 21/300 [00:45<11:14,  2.42s/it]T Loss=2.3027756214141846\n",
            "g_norm = tensor(0.1154, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038740158081055\n",
            "g_norm = tensor(0.1230, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304060459136963\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040027618408203\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036961555480957\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.3994903564453\n",
            "||∇_X meta|| = 0.003485660767182708\n",
            "ΔX norm: 3.4856595448218286e-05\n",
            "Stage 5/10:   7%|██▏                           | 22/300 [00:48<11:58,  2.58s/it]T Loss=2.304095506668091\n",
            "g_norm = tensor(0.0960, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040988445281982\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304321527481079\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029677867889404\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304330587387085\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.91226196289062\n",
            "||∇_X meta|| = 0.0034051917027682066\n",
            "ΔX norm: 3.40519254677929e-05\n",
            "Stage 5/10:   8%|██▎                           | 23/300 [00:50<11:13,  2.43s/it]T Loss=2.30329966545105\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303330659866333\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042221069335938\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304719924926758\n",
            "g_norm = tensor(0.1278, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021912574768066\n",
            "g_norm = tensor(0.1304, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4566192626953\n",
            "||∇_X meta|| = 0.0031611539889127016\n",
            "ΔX norm: 3.1611547456122935e-05\n",
            "Stage 5/10:   8%|██▍                           | 24/300 [00:52<10:39,  2.32s/it]T Loss=2.3039090633392334\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304853916168213\n",
            "g_norm = tensor(0.1306, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035647869110107\n",
            "g_norm = tensor(0.1929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301997661590576\n",
            "g_norm = tensor(0.1564, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032586574554443\n",
            "g_norm = tensor(0.1618, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.0999755859375\n",
            "||∇_X meta|| = 0.0032261700835078955\n",
            "ΔX norm: 3.226173430448398e-05\n",
            "Stage 5/10:   8%|██▌                           | 25/300 [00:54<10:08,  2.21s/it]T Loss=2.3058784008026123\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038434982299805\n",
            "g_norm = tensor(0.1139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303980588912964\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057682514190674\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30462384223938\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.00962829589844\n",
            "||∇_X meta|| = 0.0030801882967352867\n",
            "ΔX norm: 3.080184615100734e-05\n",
            "Stage 5/10:   9%|██▌                           | 26/300 [00:56<09:44,  2.13s/it]T Loss=2.303286075592041\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029732704162598\n",
            "g_norm = tensor(0.0980, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303917407989502\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047821521759033\n",
            "g_norm = tensor(0.1214, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050293922424316\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.89151000976562\n",
            "||∇_X meta|| = 0.002989999484270811\n",
            "ΔX norm: 2.9900011213612743e-05\n",
            "Stage 5/10:   9%|██▋                           | 27/300 [00:58<09:20,  2.05s/it]T Loss=2.3044888973236084\n",
            "g_norm = tensor(0.1390, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303335428237915\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026323318481445\n",
            "g_norm = tensor(0.1304, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301640033721924\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035194873809814\n",
            "g_norm = tensor(0.1361, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6398468017578\n",
            "||∇_X meta|| = 0.0031458542216569185\n",
            "ΔX norm: 3.145853406749666e-05\n",
            "Stage 5/10:   9%|██▊                           | 28/300 [01:00<09:30,  2.10s/it]T Loss=2.304769515991211\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304084062576294\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035035133361816\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042969703674316\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044941425323486\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.92990112304688\n",
            "||∇_X meta|| = 0.003066479926928878\n",
            "ΔX norm: 3.066479257540777e-05\n",
            "Stage 5/10:  10%|██▉                           | 29/300 [01:02<09:17,  2.06s/it]T Loss=2.30403470993042\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302724599838257\n",
            "g_norm = tensor(0.1354, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303724765777588\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304784059524536\n",
            "g_norm = tensor(0.1358, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302715301513672\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.0587921142578\n",
            "||∇_X meta|| = 0.003262871177867055\n",
            "ΔX norm: 3.2628729968564585e-05\n",
            "Stage 5/10:  10%|███                           | 30/300 [01:04<09:08,  2.03s/it]T Loss=2.303117036819458\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302522897720337\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303607702255249\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028030395507812\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303654193878174\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.54437255859375\n",
            "||∇_X meta|| = 0.00288370531052351\n",
            "ΔX norm: 2.883703746192623e-05\n",
            "Stage 5/10:  10%|███                           | 31/300 [01:06<08:57,  2.00s/it]T Loss=2.303737163543701\n",
            "g_norm = tensor(0.1491, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303126811981201\n",
            "g_norm = tensor(0.1305, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304007053375244\n",
            "g_norm = tensor(0.1270, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043081760406494\n",
            "g_norm = tensor(0.1350, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030972480773926\n",
            "g_norm = tensor(0.1406, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4934844970703\n",
            "||∇_X meta|| = 0.003049686085432768\n",
            "ΔX norm: 3.0496887120534666e-05\n",
            "Stage 5/10:  11%|███▏                          | 32/300 [01:08<09:02,  2.02s/it]T Loss=2.303898572921753\n",
            "g_norm = tensor(0.1434, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055100440979004\n",
            "g_norm = tensor(0.1417, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037657737731934\n",
            "g_norm = tensor(0.1613, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303887367248535\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304521083831787\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.27023315429688\n",
            "||∇_X meta|| = 0.003089062636718154\n",
            "ΔX norm: 3.0890641937730834e-05\n",
            "Stage 5/10:  11%|███▎                          | 33/300 [01:10<08:55,  2.01s/it]T Loss=2.3039708137512207\n",
            "g_norm = tensor(0.1611, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30582857131958\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303232192993164\n",
            "g_norm = tensor(0.1251, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046953678131104\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.300624370574951\n",
            "g_norm = tensor(0.1565, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.62130737304688\n",
            "||∇_X meta|| = 0.0028034669812768698\n",
            "ΔX norm: 2.8034637580276467e-05\n",
            "Stage 5/10:  11%|███▍                          | 34/300 [01:12<08:47,  1.98s/it]T Loss=2.3041961193084717\n",
            "g_norm = tensor(0.1484, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032078742980957\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047218322753906\n",
            "g_norm = tensor(0.1519, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302351236343384\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051388263702393\n",
            "g_norm = tensor(0.1494, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.15078735351562\n",
            "||∇_X meta|| = 0.0030330163426697254\n",
            "ΔX norm: 3.033016218978446e-05\n",
            "Stage 5/10:  12%|███▌                          | 35/300 [01:14<08:40,  1.97s/it]T Loss=2.3046274185180664\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303610324859619\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027522563934326\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037924766540527\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30308198928833\n",
            "g_norm = tensor(0.1139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.707275390625\n",
            "||∇_X meta|| = 0.0029864052776247263\n",
            "ΔX norm: 2.986401887028478e-05\n",
            "Stage 5/10:  12%|███▌                          | 36/300 [01:16<09:12,  2.09s/it]T Loss=2.3034145832061768\n",
            "g_norm = tensor(0.1980, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30314302444458\n",
            "g_norm = tensor(0.1544, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032097816467285\n",
            "g_norm = tensor(0.1708, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044328689575195\n",
            "g_norm = tensor(0.1702, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304795503616333\n",
            "g_norm = tensor(0.1591, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.21206665039062\n",
            "||∇_X meta|| = 0.0027121531311422586\n",
            "ΔX norm: 2.7121473976876587e-05\n",
            "Stage 5/10:  12%|███▋                          | 37/300 [01:19<09:29,  2.17s/it]T Loss=2.3044445514678955\n",
            "g_norm = tensor(0.0848, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30452036857605\n",
            "g_norm = tensor(0.0802, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041348457336426\n",
            "g_norm = tensor(0.0861, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036375045776367\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303814172744751\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.80557250976562\n",
            "||∇_X meta|| = 0.00288033508695662\n",
            "ΔX norm: 2.8803320674342103e-05\n",
            "Stage 5/10:  13%|███▊                          | 38/300 [01:21<09:28,  2.17s/it]T Loss=2.303609848022461\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037476539611816\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036227226257324\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044965267181396\n",
            "g_norm = tensor(0.1324, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302940845489502\n",
            "g_norm = tensor(0.1255, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.03109741210938\n",
            "||∇_X meta|| = 0.0028376837726682425\n",
            "ΔX norm: 2.8376842237776145e-05\n",
            "Stage 5/10:  13%|███▉                          | 39/300 [01:23<09:11,  2.11s/it]T Loss=2.3033173084259033\n",
            "g_norm = tensor(0.1368, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025877475738525\n",
            "g_norm = tensor(0.1560, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024439811706543\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304291009902954\n",
            "g_norm = tensor(0.1545, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042995929718018\n",
            "g_norm = tensor(0.1567, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2411346435547\n",
            "||∇_X meta|| = 0.0025260429829359055\n",
            "ΔX norm: 2.5260476832045242e-05\n",
            "Stage 5/10:  13%|████                          | 40/300 [01:25<08:54,  2.05s/it]T Loss=2.304245710372925\n",
            "g_norm = tensor(0.1420, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305333375930786\n",
            "g_norm = tensor(0.1366, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304318428039551\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305227756500244\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038408756256104\n",
            "g_norm = tensor(0.1292, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.64634704589844\n",
            "||∇_X meta|| = 0.0030231873970478773\n",
            "ΔX norm: 3.0231882192310877e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 5/10:  14%|████                          | 41/300 [01:27<09:16,  2.15s/it]T Loss=2.3049590587615967\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30427885055542\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034133911132812\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304810047149658\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048276901245117\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2679443359375\n",
            "||∇_X meta|| = 0.002946790773421526\n",
            "ΔX norm: 2.94678975478746e-05\n",
            "Stage 5/10:  14%|████▏                         | 42/300 [01:30<09:43,  2.26s/it]T Loss=2.303718328475952\n",
            "g_norm = tensor(0.0873, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035635948181152\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303475856781006\n",
            "g_norm = tensor(0.0810, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038480281829834\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028228282928467\n",
            "g_norm = tensor(0.0775, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.79898071289062\n",
            "||∇_X meta|| = 0.002624316606670618\n",
            "ΔX norm: 2.6243176762363873e-05\n",
            "Stage 5/10:  14%|████▎                         | 43/300 [01:32<09:50,  2.30s/it]T Loss=2.303981065750122\n",
            "g_norm = tensor(0.1456, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304736614227295\n",
            "g_norm = tensor(0.1423, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303450107574463\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025577068328857\n",
            "g_norm = tensor(0.1288, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029139041900635\n",
            "g_norm = tensor(0.1283, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.60549926757812\n",
            "||∇_X meta|| = 0.002742139855399728\n",
            "ΔX norm: 2.7421432605478913e-05\n",
            "Stage 5/10:  15%|████▍                         | 44/300 [01:34<09:36,  2.25s/it]T Loss=2.3037004470825195\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043978214263916\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304504871368408\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304755687713623\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044769763946533\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.6276397705078\n",
            "||∇_X meta|| = 0.0027428986504673958\n",
            "ΔX norm: 2.7428970497567207e-05\n",
            "Stage 5/10:  15%|████▌                         | 45/300 [01:36<09:13,  2.17s/it]T Loss=2.302825450897217\n",
            "g_norm = tensor(0.1263, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022007942199707\n",
            "g_norm = tensor(0.1291, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019633293151855\n",
            "g_norm = tensor(0.1225, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304823160171509\n",
            "g_norm = tensor(0.1357, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022561073303223\n",
            "g_norm = tensor(0.1351, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.96612548828125\n",
            "||∇_X meta|| = 0.002488012658432126\n",
            "ΔX norm: 2.488012978574261e-05\n",
            "Stage 5/10:  15%|████▌                         | 46/300 [01:38<08:42,  2.06s/it]T Loss=2.3038039207458496\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035879135131836\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029367923736572\n",
            "g_norm = tensor(0.0960, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024044036865234\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030447959899902\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4400177001953\n",
            "||∇_X meta|| = 0.0028660129755735397\n",
            "ΔX norm: 2.8660146199399605e-05\n",
            "Stage 5/10:  16%|████▋                         | 47/300 [01:40<08:38,  2.05s/it]T Loss=2.302992343902588\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302293062210083\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022592067718506\n",
            "g_norm = tensor(0.0817, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026371002197266\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023452758789062\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.24073791503906\n",
            "||∇_X meta|| = 0.00269138952717185\n",
            "ΔX norm: 2.6913896363112144e-05\n",
            "Stage 5/10:  16%|████▊                         | 48/300 [01:42<08:32,  2.03s/it]T Loss=2.303452253341675\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024232387542725\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040995597839355\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3015758991241455\n",
            "g_norm = tensor(0.1461, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029732704162598\n",
            "g_norm = tensor(0.0884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8330078125\n",
            "||∇_X meta|| = 0.002627977402880788\n",
            "ΔX norm: 2.6279798476025462e-05\n",
            "Stage 5/10:  16%|████▉                         | 49/300 [01:44<08:23,  2.01s/it]T Loss=2.304234743118286\n",
            "g_norm = tensor(0.0931, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034212589263916\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303424119949341\n",
            "g_norm = tensor(0.0807, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026535511016846\n",
            "g_norm = tensor(0.1157, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028199672698975\n",
            "g_norm = tensor(0.0902, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.55941772460938\n",
            "||∇_X meta|| = 0.0028602243401110172\n",
            "ΔX norm: 2.86022786895046e-05\n",
            "Stage 5/10:  17%|█████                         | 50/300 [01:46<08:24,  2.02s/it]T Loss=2.3037760257720947\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034815788269043\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303506374359131\n",
            "g_norm = tensor(0.0897, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303640365600586\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302776575088501\n",
            "g_norm = tensor(0.1292, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4990692138672\n",
            "||∇_X meta|| = 0.002617011545225978\n",
            "ΔX norm: 2.617006794025656e-05\n",
            "Stage 5/10:  17%|█████                         | 51/300 [01:48<08:58,  2.16s/it]T Loss=2.303245782852173\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025283813476562\n",
            "g_norm = tensor(0.1210, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036510944366455\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037450313568115\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302504301071167\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.0200958251953\n",
            "||∇_X meta|| = 0.0028632788453251123\n",
            "ΔX norm: 2.8632779503823258e-05\n",
            "Stage 5/10:  17%|█████▏                        | 52/300 [01:51<09:01,  2.18s/it]T Loss=2.3034934997558594\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041059970855713\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043465614318848\n",
            "g_norm = tensor(0.1210, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303516387939453\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037142753601074\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.59373474121094\n",
            "||∇_X meta|| = 0.002570047974586487\n",
            "ΔX norm: 2.5700444894027896e-05\n",
            "Stage 5/10:  18%|█████▎                        | 53/300 [01:53<09:07,  2.22s/it]T Loss=2.3039886951446533\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045737743377686\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055009841918945\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042454719543457\n",
            "g_norm = tensor(0.1374, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304515838623047\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.49195861816406\n",
            "||∇_X meta|| = 0.0024018839467316866\n",
            "ΔX norm: 2.4018851036089472e-05\n",
            "Stage 5/10:  18%|█████▍                        | 54/300 [01:55<09:16,  2.26s/it]T Loss=2.304145336151123\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303530693054199\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044581413269043\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302968978881836\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040084838867188\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.84332275390625\n",
            "||∇_X meta|| = 0.002684659557417035\n",
            "ΔX norm: 2.6846608307096176e-05\n",
            "Stage 5/10:  18%|█████▌                        | 55/300 [01:57<09:01,  2.21s/it]T Loss=2.3032329082489014\n",
            "g_norm = tensor(0.1388, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30411434173584\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037705421447754\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046460151672363\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304104804992676\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.97218322753906\n",
            "||∇_X meta|| = 0.0024575248826295137\n",
            "ΔX norm: 2.4575239876867272e-05\n",
            "Stage 5/10:  19%|█████▌                        | 56/300 [02:00<09:01,  2.22s/it]T Loss=2.3031036853790283\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302696704864502\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031444549560547\n",
            "g_norm = tensor(0.0878, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036086559295654\n",
            "g_norm = tensor(0.1053, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302032947540283\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6497344970703\n",
            "||∇_X meta|| = 0.002652611816301942\n",
            "ΔX norm: 2.6526127840043046e-05\n",
            "Stage 5/10:  19%|█████▋                        | 57/300 [02:02<08:50,  2.18s/it]T Loss=2.303345203399658\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035480976104736\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303253173828125\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041183948516846\n",
            "g_norm = tensor(0.1262, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303771495819092\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.30455017089844\n",
            "||∇_X meta|| = 0.002213752828538418\n",
            "ΔX norm: 2.2137513951747678e-05\n",
            "Stage 5/10:  19%|█████▊                        | 58/300 [02:04<08:43,  2.17s/it]T Loss=2.30497670173645\n",
            "g_norm = tensor(0.1286, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303358554840088\n",
            "g_norm = tensor(0.1110, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304253578186035\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30446195602417\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045806884765625\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.31564331054688\n",
            "||∇_X meta|| = 0.0023037041537463665\n",
            "ΔX norm: 2.3037055143504404e-05\n",
            "Stage 5/10:  20%|█████▉                        | 59/300 [02:06<08:29,  2.12s/it]T Loss=2.3042781352996826\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303431510925293\n",
            "g_norm = tensor(0.1412, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303976058959961\n",
            "g_norm = tensor(0.1259, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302175521850586\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025062084198\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3408966064453\n",
            "||∇_X meta|| = 0.002481504576280713\n",
            "ΔX norm: 2.4815028154989704e-05\n",
            "Stage 5/10:  20%|██████                        | 60/300 [02:08<08:14,  2.06s/it]T Loss=2.305170774459839\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038430213928223\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046422004699707\n",
            "g_norm = tensor(0.1380, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305856227874756\n",
            "g_norm = tensor(0.1103, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305217981338501\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.1715545654297\n",
            "||∇_X meta|| = 0.0023669933434575796\n",
            "ΔX norm: 2.3669916117796674e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 5/10:  20%|██████                        | 61/300 [02:10<08:07,  2.04s/it]T Loss=2.3042001724243164\n",
            "g_norm = tensor(0.0902, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037526607513428\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303956985473633\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301351547241211\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032469749450684\n",
            "g_norm = tensor(0.0866, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.48289489746094\n",
            "||∇_X meta|| = 0.001988818170502782\n",
            "ΔX norm: 1.9888189854100347e-05\n",
            "Stage 5/10:  21%|██████▏                       | 62/300 [02:12<08:41,  2.19s/it]T Loss=2.304180860519409\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30334734916687\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038341999053955\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304034471511841\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303518533706665\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.61155700683594\n",
            "||∇_X meta|| = 0.002288305200636387\n",
            "ΔX norm: 2.2883070414536633e-05\n",
            "Stage 5/10:  21%|██████▎                       | 63/300 [02:15<08:49,  2.23s/it]T Loss=2.303980588912964\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043551445007324\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042402267456055\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30421781539917\n",
            "g_norm = tensor(0.0836, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304840087890625\n",
            "g_norm = tensor(0.0830, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5275115966797\n",
            "||∇_X meta|| = 0.001925841555930674\n",
            "ΔX norm: 1.9258415704825893e-05\n",
            "Stage 5/10:  21%|██████▍                       | 64/300 [02:17<08:28,  2.15s/it]T Loss=2.3040194511413574\n",
            "g_norm = tensor(0.1355, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020501136779785\n",
            "g_norm = tensor(0.1351, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024497032165527\n",
            "g_norm = tensor(0.1263, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043417930603027\n",
            "g_norm = tensor(0.1402, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043320178985596\n",
            "g_norm = tensor(0.1500, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.78512573242188\n",
            "||∇_X meta|| = 0.0022317401599138975\n",
            "ΔX norm: 2.2317413822747767e-05\n",
            "Stage 5/10:  22%|██████▌                       | 65/300 [02:19<08:21,  2.13s/it]T Loss=2.3043651580810547\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304490327835083\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303276777267456\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305035352706909\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304414987564087\n",
            "g_norm = tensor(0.1139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9547119140625\n",
            "||∇_X meta|| = 0.0022705839946866035\n",
            "ΔX norm: 2.2705844457959756e-05\n",
            "Stage 5/10:  22%|██████▌                       | 66/300 [02:21<08:11,  2.10s/it]T Loss=2.3030898571014404\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041272163391113\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040194511413574\n",
            "g_norm = tensor(0.0833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021817207336426\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036069869995117\n",
            "g_norm = tensor(0.0756, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.20518493652344\n",
            "||∇_X meta|| = 0.002056513214483857\n",
            "ΔX norm: 2.056514313153457e-05\n",
            "Stage 5/10:  22%|██████▋                       | 67/300 [02:23<08:01,  2.07s/it]T Loss=2.3047189712524414\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051371574401855\n",
            "g_norm = tensor(0.1519, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304098606109619\n",
            "g_norm = tensor(0.1356, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053390979766846\n",
            "g_norm = tensor(0.1665, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304114818572998\n",
            "g_norm = tensor(0.1278, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.09121704101562\n",
            "||∇_X meta|| = 0.00243943789973855\n",
            "ΔX norm: 2.439433774270583e-05\n",
            "Stage 5/10:  23%|██████▊                       | 68/300 [02:24<07:43,  2.00s/it]T Loss=2.30472469329834\n",
            "g_norm = tensor(0.0933, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035640716552734\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048298358917236\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035519123077393\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303309917449951\n",
            "g_norm = tensor(0.0720, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8834686279297\n",
            "||∇_X meta|| = 0.0023269462399184704\n",
            "ΔX norm: 2.3269454686669633e-05\n",
            "Stage 5/10:  23%|██████▉                       | 69/300 [02:27<07:59,  2.07s/it]T Loss=2.3029415607452393\n",
            "g_norm = tensor(0.0980, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304269313812256\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30409574508667\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041579723358154\n",
            "g_norm = tensor(0.0856, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035969734191895\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.75900268554688\n",
            "||∇_X meta|| = 0.0023954336065799\n",
            "ΔX norm: 2.3954338757903315e-05\n",
            "Stage 5/10:  23%|███████                       | 70/300 [02:29<07:43,  2.01s/it]T Loss=2.302917003631592\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023524284362793\n",
            "g_norm = tensor(0.1153, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303539276123047\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035454750061035\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303879499435425\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.63363647460938\n",
            "||∇_X meta|| = 0.002430402673780918\n",
            "ΔX norm: 2.4304037651745602e-05\n",
            "Stage 5/10:  24%|███████                       | 71/300 [02:30<07:33,  1.98s/it]T Loss=2.3043487071990967\n",
            "g_norm = tensor(0.1345, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30379056930542\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037936687469482\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30680251121521\n",
            "g_norm = tensor(0.1493, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041350841522217\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.15151977539062\n",
            "||∇_X meta|| = 0.002504478907212615\n",
            "ΔX norm: 2.504481017240323e-05\n",
            "Stage 5/10:  24%|███████▏                      | 72/300 [02:33<08:09,  2.15s/it]T Loss=2.304320812225342\n",
            "g_norm = tensor(0.0803, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031086921691895\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037304878234863\n",
            "g_norm = tensor(0.0774, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303953170776367\n",
            "g_norm = tensor(0.0834, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044230937957764\n",
            "g_norm = tensor(0.0768, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9563446044922\n",
            "||∇_X meta|| = 0.002021599328145385\n",
            "ΔX norm: 2.021599721047096e-05\n",
            "Stage 5/10:  24%|███████▎                      | 73/300 [02:35<07:56,  2.10s/it]T Loss=2.30307936668396\n",
            "g_norm = tensor(0.1314, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041088581085205\n",
            "g_norm = tensor(0.1599, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028030395507812\n",
            "g_norm = tensor(0.1581, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058266639709473\n",
            "g_norm = tensor(0.1695, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038978576660156\n",
            "g_norm = tensor(0.1230, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.62831115722656\n",
            "||∇_X meta|| = 0.0020981277339160442\n",
            "ΔX norm: 2.0981273337383755e-05\n",
            "Stage 5/10:  25%|███████▍                      | 74/300 [02:37<07:52,  2.09s/it]T Loss=2.3051466941833496\n",
            "g_norm = tensor(0.1689, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047022819519043\n",
            "g_norm = tensor(0.1562, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302863836288452\n",
            "g_norm = tensor(0.1640, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302424192428589\n",
            "g_norm = tensor(0.1597, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033649921417236\n",
            "g_norm = tensor(0.1460, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.68032836914062\n",
            "||∇_X meta|| = 0.0019642591942101717\n",
            "ΔX norm: 1.9642584447865374e-05\n",
            "Stage 5/10:  25%|███████▌                      | 75/300 [02:39<07:38,  2.04s/it]T Loss=2.3037874698638916\n",
            "g_norm = tensor(0.0830, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037381172180176\n",
            "g_norm = tensor(0.0762, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036670684814453\n",
            "g_norm = tensor(0.0807, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044018745422363\n",
            "g_norm = tensor(0.0791, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052432537078857\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3155059814453\n",
            "||∇_X meta|| = 0.0021335252095013857\n",
            "ΔX norm: 2.13352595892502e-05\n",
            "Stage 5/10:  25%|███████▌                      | 76/300 [02:41<07:57,  2.13s/it]T Loss=2.3037967681884766\n",
            "g_norm = tensor(0.1206, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302272319793701\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303168773651123\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302495241165161\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301849842071533\n",
            "g_norm = tensor(0.1342, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.08399963378906\n",
            "||∇_X meta|| = 0.002184916753321886\n",
            "ΔX norm: 2.184917866543401e-05\n",
            "Stage 5/10:  26%|███████▋                      | 77/300 [02:44<08:11,  2.20s/it]T Loss=2.3032639026641846\n",
            "g_norm = tensor(0.1481, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045413494110107\n",
            "g_norm = tensor(0.1615, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045220375061035\n",
            "g_norm = tensor(0.1420, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303738832473755\n",
            "g_norm = tensor(0.1397, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040592670440674\n",
            "g_norm = tensor(0.1748, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.47962951660156\n",
            "||∇_X meta|| = 0.0021266075782477856\n",
            "ΔX norm: 2.126606705132872e-05\n",
            "Stage 5/10:  26%|███████▊                      | 78/300 [02:46<08:01,  2.17s/it]T Loss=2.3038628101348877\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028485774993896\n",
            "g_norm = tensor(0.0858, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024959564208984\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039517402648926\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30401611328125\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.44351196289062\n",
            "||∇_X meta|| = 0.0020067612640559673\n",
            "ΔX norm: 2.0067596778972074e-05\n",
            "Stage 5/10:  26%|███████▉                      | 79/300 [02:48<07:43,  2.10s/it]T Loss=2.3040530681610107\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305516242980957\n",
            "g_norm = tensor(0.1459, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303321599960327\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057761192321777\n",
            "g_norm = tensor(0.1370, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304119348526001\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.62167358398438\n",
            "||∇_X meta|| = 0.0020387752447277308\n",
            "ΔX norm: 2.0387773474794813e-05\n",
            "Stage 5/10:  27%|████████                      | 80/300 [02:50<07:32,  2.06s/it]T Loss=2.303231954574585\n",
            "g_norm = tensor(0.0779, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035614490509033\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303799629211426\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304154634475708\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303926944732666\n",
            "g_norm = tensor(0.1139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9803009033203\n",
            "||∇_X meta|| = 0.0018365277210250497\n",
            "ΔX norm: 1.8365264622843824e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 5/10:  27%|████████                      | 81/300 [02:52<07:31,  2.06s/it]T Loss=2.3031797409057617\n",
            "g_norm = tensor(0.0679, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303555965423584\n",
            "g_norm = tensor(0.0841, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035480976104736\n",
            "g_norm = tensor(0.0786, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304323196411133\n",
            "g_norm = tensor(0.0734, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040313720703125\n",
            "g_norm = tensor(0.0760, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.94471740722656\n",
            "||∇_X meta|| = 0.0020138907711952925\n",
            "ΔX norm: 2.0138919353485107e-05\n",
            "Stage 5/10:  27%|████████▏                     | 82/300 [02:54<08:07,  2.23s/it]T Loss=2.303039073944092\n",
            "g_norm = tensor(0.0824, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039751052856445\n",
            "g_norm = tensor(0.0934, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036813735961914\n",
            "g_norm = tensor(0.0820, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040409088134766\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30291485786438\n",
            "g_norm = tensor(0.0839, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9481658935547\n",
            "||∇_X meta|| = 0.0018297850620001554\n",
            "ΔX norm: 1.82978455995908e-05\n",
            "Stage 5/10:  28%|████████▎                     | 83/300 [02:56<07:54,  2.19s/it]T Loss=2.3022186756134033\n",
            "g_norm = tensor(0.0941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304203748703003\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303433895111084\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303422212600708\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023955821990967\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.49227905273438\n",
            "||∇_X meta|| = 0.0020102784037590027\n",
            "ΔX norm: 2.0102786947973073e-05\n",
            "Stage 5/10:  28%|████████▍                     | 84/300 [02:58<07:30,  2.09s/it]T Loss=2.304792642593384\n",
            "g_norm = tensor(0.1110, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304109573364258\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046703338623047\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304203510284424\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046038150787354\n",
            "g_norm = tensor(0.1154, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.3162841796875\n",
            "||∇_X meta|| = 0.001813492737710476\n",
            "ΔX norm: 1.81349187187152e-05\n",
            "Stage 5/10:  28%|████████▌                     | 85/300 [03:00<07:18,  2.04s/it]T Loss=2.3023407459259033\n",
            "g_norm = tensor(0.0835, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303205966949463\n",
            "g_norm = tensor(0.0860, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303342580795288\n",
            "g_norm = tensor(0.0850, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303802967071533\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302624225616455\n",
            "g_norm = tensor(0.0872, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5430145263672\n",
            "||∇_X meta|| = 0.0018401469569653273\n",
            "ΔX norm: 1.840145887399558e-05\n",
            "Stage 5/10:  29%|████████▌                     | 86/300 [03:02<07:06,  1.99s/it]T Loss=2.3040430545806885\n",
            "g_norm = tensor(0.1269, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302955150604248\n",
            "g_norm = tensor(0.1210, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032188415527344\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3007888793945312\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303328275680542\n",
            "g_norm = tensor(0.1269, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3356475830078\n",
            "||∇_X meta|| = 0.0020644378382712603\n",
            "ΔX norm: 2.0644361939048395e-05\n",
            "Stage 5/10:  29%|████████▋                     | 87/300 [03:04<07:13,  2.04s/it]T Loss=2.3051018714904785\n",
            "g_norm = tensor(0.0883, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045907020568848\n",
            "g_norm = tensor(0.0804, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303967237472534\n",
            "g_norm = tensor(0.0878, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303764581680298\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044962882995605\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4616241455078\n",
            "||∇_X meta|| = 0.002140020951628685\n",
            "ΔX norm: 2.1400192053988576e-05\n",
            "Stage 5/10:  29%|████████▊                     | 88/300 [03:06<07:01,  1.99s/it]T Loss=2.304476261138916\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053975105285645\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304340362548828\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045687675476074\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049182891845703\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.43080139160156\n",
            "||∇_X meta|| = 0.002058186801150441\n",
            "ΔX norm: 2.0581888747983612e-05\n",
            "Stage 5/10:  30%|████████▉                     | 89/300 [03:08<06:49,  1.94s/it]T Loss=2.303298234939575\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302548885345459\n",
            "g_norm = tensor(0.1285, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022193908691406\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303022623062134\n",
            "g_norm = tensor(0.1455, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304788589477539\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.68923950195312\n",
            "||∇_X meta|| = 0.0023631295189261436\n",
            "ΔX norm: 2.3631284420844167e-05\n",
            "Stage 5/10:  30%|█████████                     | 90/300 [03:10<06:42,  1.92s/it]T Loss=2.304232358932495\n",
            "g_norm = tensor(0.1595, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036415576934814\n",
            "g_norm = tensor(0.1345, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040013313293457\n",
            "g_norm = tensor(0.1397, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304046392440796\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051538467407227\n",
            "g_norm = tensor(0.1498, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.30563354492188\n",
            "||∇_X meta|| = 0.0020293695852160454\n",
            "ΔX norm: 2.029369534284342e-05\n",
            "Stage 5/10:  30%|█████████                     | 91/300 [03:12<06:31,  1.87s/it]T Loss=2.3043618202209473\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037924766540527\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303426504135132\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303811550140381\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303790330886841\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1344451904297\n",
            "||∇_X meta|| = 0.0020105328876525164\n",
            "ΔX norm: 2.010532443819102e-05\n",
            "Stage 5/10:  31%|█████████▏                    | 92/300 [03:13<06:26,  1.86s/it]T Loss=2.3047962188720703\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043017387390137\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045811653137207\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042807579040527\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043484687805176\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.37474060058594\n",
            "||∇_X meta|| = 0.0018530808156356215\n",
            "ΔX norm: 1.8530810848460533e-05\n",
            "Stage 5/10:  31%|█████████▎                    | 93/300 [03:16<06:36,  1.92s/it]T Loss=2.30078125\n",
            "g_norm = tensor(0.1849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022332191467285\n",
            "g_norm = tensor(0.1431, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30403995513916\n",
            "g_norm = tensor(0.1623, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303311586380005\n",
            "g_norm = tensor(0.1341, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052759170532227\n",
            "g_norm = tensor(0.1732, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.66705322265625\n",
            "||∇_X meta|| = 0.002220685826614499\n",
            "ΔX norm: 2.2206902940524742e-05\n",
            "Stage 5/10:  31%|█████████▍                    | 94/300 [03:17<06:35,  1.92s/it]T Loss=2.3043112754821777\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029491901397705\n",
            "g_norm = tensor(0.0942, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303574800491333\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038926124572754\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036186695098877\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.59024047851562\n",
            "||∇_X meta|| = 0.002097981283441186\n",
            "ΔX norm: 2.0979830878786743e-05\n",
            "Stage 5/10:  32%|█████████▌                    | 95/300 [03:19<06:33,  1.92s/it]T Loss=2.304367780685425\n",
            "g_norm = tensor(0.1408, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043673038482666\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302527666091919\n",
            "g_norm = tensor(0.1285, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040852546691895\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034777641296387\n",
            "g_norm = tensor(0.1433, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.86151123046875\n",
            "||∇_X meta|| = 0.0020244657061994076\n",
            "ΔX norm: 2.0244640836608596e-05\n",
            "Stage 5/10:  32%|█████████▌                    | 96/300 [03:21<06:27,  1.90s/it]T Loss=2.3032450675964355\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041281700134277\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034005165100098\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304016590118408\n",
            "g_norm = tensor(0.0960, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040759563446045\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.16871643066406\n",
            "||∇_X meta|| = 0.0019474057480692863\n",
            "ΔX norm: 1.9474087821436115e-05\n",
            "Stage 5/10:  32%|█████████▋                    | 97/300 [03:23<06:21,  1.88s/it]T Loss=2.30456805229187\n",
            "g_norm = tensor(0.0784, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037900924682617\n",
            "g_norm = tensor(0.0771, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30428147315979\n",
            "g_norm = tensor(0.0732, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039896488189697\n",
            "g_norm = tensor(0.0669, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040528297424316\n",
            "g_norm = tensor(0.0741, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.05116271972656\n",
            "||∇_X meta|| = 0.001955034676939249\n",
            "ΔX norm: 1.9550334400264546e-05\n",
            "Stage 5/10:  33%|█████████▊                    | 98/300 [03:25<06:15,  1.86s/it]T Loss=2.304269790649414\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034934997558594\n",
            "g_norm = tensor(0.0828, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038320541381836\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304898738861084\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053958415985107\n",
            "g_norm = tensor(0.1099, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.50001525878906\n",
            "||∇_X meta|| = 0.0019906095694750547\n",
            "ΔX norm: 1.9906108718714677e-05\n",
            "Stage 5/10:  33%|█████████▉                    | 99/300 [03:27<06:14,  1.86s/it]T Loss=2.3035311698913574\n",
            "g_norm = tensor(0.0878, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037571907043457\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303011655807495\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032407760620117\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037960529327393\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.88270568847656\n",
            "||∇_X meta|| = 0.0018081818707287312\n",
            "ΔX norm: 1.8081849702866748e-05\n",
            "Stage 5/10:  33%|█████████▋                   | 100/300 [03:29<06:10,  1.85s/it]T Loss=2.3056869506835938\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303046464920044\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033478260040283\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303344488143921\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039071559906006\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2125244140625\n",
            "||∇_X meta|| = 0.0016318585257977247\n",
            "ΔX norm: 1.6318617781507783e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 5/10:  34%|█████████▊                   | 101/300 [03:30<06:10,  1.86s/it]T Loss=2.3031954765319824\n",
            "g_norm = tensor(0.1258, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304180860519409\n",
            "g_norm = tensor(0.1273, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304103374481201\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303175449371338\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303978681564331\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.43402099609375\n",
            "||∇_X meta|| = 0.0020428718999028206\n",
            "ΔX norm: 2.0428737116162665e-05\n",
            "Stage 5/10:  34%|█████████▊                   | 102/300 [03:33<07:04,  2.15s/it]T Loss=2.30446457862854\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029723167419434\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037214279174805\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303668260574341\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303826093673706\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2431640625\n",
            "||∇_X meta|| = 0.0017808007542043924\n",
            "ΔX norm: 1.780800630513113e-05\n",
            "Stage 5/10:  34%|█████████▉                   | 103/300 [03:36<07:13,  2.20s/it]T Loss=2.304079532623291\n",
            "g_norm = tensor(0.1321, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304100513458252\n",
            "g_norm = tensor(0.1328, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049066066741943\n",
            "g_norm = tensor(0.1309, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042147159576416\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035502433776855\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3442840576172\n",
            "||∇_X meta|| = 0.0016638959059491754\n",
            "ΔX norm: 1.6638976376270875e-05\n",
            "Stage 5/10:  35%|██████████                   | 104/300 [03:38<06:57,  2.13s/it]T Loss=2.3032689094543457\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303544759750366\n",
            "g_norm = tensor(0.1324, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038527965545654\n",
            "g_norm = tensor(0.0960, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303818464279175\n",
            "g_norm = tensor(0.1270, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303774833679199\n",
            "g_norm = tensor(0.1285, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.32627868652344\n",
            "||∇_X meta|| = 0.001679499982856214\n",
            "ΔX norm: 1.679496926954016e-05\n",
            "Stage 5/10:  35%|██████████▏                  | 105/300 [03:39<06:38,  2.04s/it]T Loss=2.3028242588043213\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029637336730957\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044281005859375\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30285906791687\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041136264801025\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.90721130371094\n",
            "||∇_X meta|| = 0.002006995026022196\n",
            "ΔX norm: 2.0069930542376824e-05\n",
            "Stage 5/10:  35%|██████████▏                  | 106/300 [03:41<06:30,  2.01s/it]T Loss=2.303767681121826\n",
            "g_norm = tensor(0.1291, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303328037261963\n",
            "g_norm = tensor(0.1675, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030853271484375\n",
            "g_norm = tensor(0.1333, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302766799926758\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305427074432373\n",
            "g_norm = tensor(0.1318, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.9344024658203\n",
            "||∇_X meta|| = 0.0017621504375711083\n",
            "ΔX norm: 1.7621516235521995e-05\n",
            "Stage 5/10:  36%|██████████▎                  | 107/300 [03:43<06:25,  2.00s/it]T Loss=2.3037352561950684\n",
            "g_norm = tensor(0.1588, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302964210510254\n",
            "g_norm = tensor(0.2016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304842233657837\n",
            "g_norm = tensor(0.1856, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304076910018921\n",
            "g_norm = tensor(0.1419, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305558681488037\n",
            "g_norm = tensor(0.1658, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7439422607422\n",
            "||∇_X meta|| = 0.001719932071864605\n",
            "ΔX norm: 1.7199336070916615e-05\n",
            "Stage 5/10:  36%|██████████▍                  | 108/300 [03:45<06:18,  1.97s/it]T Loss=2.3031702041625977\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044586181640625\n",
            "g_norm = tensor(0.1341, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029518127441406\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304042100906372\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303591251373291\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0625762939453\n",
            "||∇_X meta|| = 0.0018553186673671007\n",
            "ΔX norm: 1.8553184418124147e-05\n",
            "Stage 5/10:  36%|██████████▌                  | 109/300 [03:47<06:30,  2.04s/it]T Loss=2.3043980598449707\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044545650482178\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305054187774658\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303983211517334\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053202629089355\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0406494140625\n",
            "||∇_X meta|| = 0.0018142799381166697\n",
            "ΔX norm: 1.8142802218790166e-05\n",
            "Stage 5/10:  37%|██████████▋                  | 110/300 [03:49<06:28,  2.04s/it]T Loss=2.302210807800293\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302669048309326\n",
            "g_norm = tensor(0.0831, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033785820007324\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031039237976074\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027217388153076\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.16331481933594\n",
            "||∇_X meta|| = 0.0017909703310579062\n",
            "ΔX norm: 1.790969690773636e-05\n",
            "Stage 5/10:  37%|██████████▋                  | 111/300 [03:52<06:31,  2.07s/it]T Loss=2.303602457046509\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042523860931396\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30379056930542\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302306652069092\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303819179534912\n",
            "g_norm = tensor(0.0919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.71929931640625\n",
            "||∇_X meta|| = 0.0015755585627630353\n",
            "ΔX norm: 1.5755556887597777e-05\n",
            "Stage 5/10:  37%|██████████▊                  | 112/300 [03:54<06:28,  2.07s/it]T Loss=2.303596019744873\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037405014038086\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045921325683594\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303818941116333\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303579807281494\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.690185546875\n",
            "||∇_X meta|| = 0.0018360662506893277\n",
            "ΔX norm: 1.8360657122684643e-05\n",
            "Stage 5/10:  38%|██████████▉                  | 113/300 [03:56<06:19,  2.03s/it]T Loss=2.3049864768981934\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048012256622314\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051514625549316\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304610013961792\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3060944080352783\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.39291381835938\n",
            "||∇_X meta|| = 0.0019283316796645522\n",
            "ΔX norm: 1.9283317669760436e-05\n",
            "Stage 5/10:  38%|███████████                  | 114/300 [03:58<06:11,  2.00s/it]T Loss=2.3038015365600586\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304133176803589\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044159412384033\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302462339401245\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044557571411133\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.15965270996094\n",
            "||∇_X meta|| = 0.0017662819009274244\n",
            "ΔX norm: 1.766283457982354e-05\n",
            "Stage 5/10:  38%|███████████                  | 115/300 [03:59<05:58,  1.94s/it]T Loss=2.3041954040527344\n",
            "g_norm = tensor(0.0808, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304164171218872\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303420066833496\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027470111846924\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039095401763916\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.36343383789062\n",
            "||∇_X meta|| = 0.0017212112434208393\n",
            "ΔX norm: 1.721212720440235e-05\n",
            "Stage 5/10:  39%|███████████▏                 | 116/300 [04:01<05:52,  1.92s/it]T Loss=2.304698944091797\n",
            "g_norm = tensor(0.1370, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029491901397705\n",
            "g_norm = tensor(0.1426, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040311336517334\n",
            "g_norm = tensor(0.1213, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039515018463135\n",
            "g_norm = tensor(0.1390, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054163455963135\n",
            "g_norm = tensor(0.1633, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.82997131347656\n",
            "||∇_X meta|| = 0.001907230238430202\n",
            "ΔX norm: 1.907227488118224e-05\n",
            "Stage 5/10:  39%|███████████▎                 | 117/300 [04:03<05:56,  1.95s/it]T Loss=2.3042948246002197\n",
            "g_norm = tensor(0.1218, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050122261047363\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046255111694336\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304089307785034\n",
            "g_norm = tensor(0.1296, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054873943328857\n",
            "g_norm = tensor(0.1286, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8743438720703\n",
            "||∇_X meta|| = 0.001871830434538424\n",
            "ΔX norm: 1.8718294086284004e-05\n",
            "Stage 5/10:  39%|███████████▍                 | 118/300 [04:05<05:54,  1.95s/it]T Loss=2.302359104156494\n",
            "g_norm = tensor(0.1394, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035812377929688\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030238151550293\n",
            "g_norm = tensor(0.1321, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302057981491089\n",
            "g_norm = tensor(0.1397, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303982734680176\n",
            "g_norm = tensor(0.1255, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.50003051757812\n",
            "||∇_X meta|| = 0.0014482132392004132\n",
            "ΔX norm: 1.4482144251815043e-05\n",
            "Stage 5/10:  40%|███████████▌                 | 119/300 [04:07<05:47,  1.92s/it]T Loss=2.3034090995788574\n",
            "g_norm = tensor(0.1360, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022396564483643\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046646118164062\n",
            "g_norm = tensor(0.1472, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302138090133667\n",
            "g_norm = tensor(0.1410, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031182289123535\n",
            "g_norm = tensor(0.1292, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3256378173828\n",
            "||∇_X meta|| = 0.001814193674363196\n",
            "ΔX norm: 1.8141934560844675e-05\n",
            "Stage 5/10:  40%|███████████▌                 | 120/300 [04:09<05:37,  1.88s/it]T Loss=2.303527593612671\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302421808242798\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303084135055542\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302412271499634\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302346706390381\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5247802734375\n",
            "||∇_X meta|| = 0.0019209127640351653\n",
            "ΔX norm: 1.9209142919862643e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 5/10:  40%|███████████▋                 | 121/300 [04:11<05:50,  1.96s/it]T Loss=2.30357027053833\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043346405029297\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304198741912842\n",
            "g_norm = tensor(0.0884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038666248321533\n",
            "g_norm = tensor(0.0864, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034896850585938\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.95721435546875\n",
            "||∇_X meta|| = 0.001745491405017674\n",
            "ΔX norm: 1.7454916815040633e-05\n",
            "Stage 5/10:  41%|███████████▊                 | 122/300 [04:13<06:13,  2.10s/it]T Loss=2.3043324947357178\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050503730773926\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045268058776855\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038487434387207\n",
            "g_norm = tensor(0.0922, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303541660308838\n",
            "g_norm = tensor(0.1021, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.00848388671875\n",
            "||∇_X meta|| = 0.0017215448897331953\n",
            "ΔX norm: 1.7215465049957857e-05\n",
            "Stage 5/10:  41%|███████████▉                 | 123/300 [04:15<06:09,  2.09s/it]T Loss=2.3044466972351074\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029632568359375\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031187057495117\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029885292053223\n",
            "g_norm = tensor(0.1184, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305126667022705\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.87510681152344\n",
            "||∇_X meta|| = 0.001727014547213912\n",
            "ΔX norm: 1.7270114767597988e-05\n",
            "Stage 5/10:  41%|███████████▉                 | 124/300 [04:17<06:02,  2.06s/it]T Loss=2.304051637649536\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3062584400177\n",
            "g_norm = tensor(0.1347, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035640716552734\n",
            "g_norm = tensor(0.1392, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302858352661133\n",
            "g_norm = tensor(0.1276, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049049377441406\n",
            "g_norm = tensor(0.1368, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.20480346679688\n",
            "||∇_X meta|| = 0.0017996573587879539\n",
            "ΔX norm: 1.7996604583458975e-05\n",
            "Stage 5/10:  42%|████████████                 | 125/300 [04:19<05:48,  1.99s/it]T Loss=2.303839921951294\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044016361236572\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047592639923096\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305492401123047\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303189754486084\n",
            "g_norm = tensor(0.0928, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.37701416015625\n",
            "||∇_X meta|| = 0.0017686068313196301\n",
            "ΔX norm: 1.7686039427644573e-05\n",
            "Stage 5/10:  42%|████████████▏                | 126/300 [04:21<05:36,  1.94s/it]T Loss=2.3029561042785645\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037900924682617\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043317794799805\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049569129943848\n",
            "g_norm = tensor(0.1379, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303903579711914\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.17391967773438\n",
            "||∇_X meta|| = 0.0015067593194544315\n",
            "ΔX norm: 1.5067611457197927e-05\n",
            "Stage 5/10:  42%|████████████▎                | 127/300 [04:23<05:29,  1.90s/it]T Loss=2.3031527996063232\n",
            "g_norm = tensor(0.1390, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303889751434326\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303147792816162\n",
            "g_norm = tensor(0.1304, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035457134246826\n",
            "g_norm = tensor(0.1416, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017737865448\n",
            "g_norm = tensor(0.1491, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.28334045410156\n",
            "||∇_X meta|| = 0.001778207952156663\n",
            "ΔX norm: 1.7782098439056426e-05\n",
            "Stage 5/10:  43%|████████████▎                | 128/300 [04:25<05:22,  1.88s/it]T Loss=2.3036553859710693\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033413887023926\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304405689239502\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026344776153564\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048055171966553\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6593780517578\n",
            "||∇_X meta|| = 0.0017187432385981083\n",
            "ΔX norm: 1.718741623335518e-05\n",
            "Stage 5/10:  43%|████████████▍                | 129/300 [04:27<05:31,  1.94s/it]T Loss=2.304119348526001\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305081844329834\n",
            "g_norm = tensor(0.1140, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045928478240967\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033857345581055\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049588203430176\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.2051239013672\n",
            "||∇_X meta|| = 0.0017605108441784978\n",
            "ΔX norm: 1.7605107132112607e-05\n",
            "Stage 5/10:  43%|████████████▌                | 130/300 [04:29<05:22,  1.90s/it]T Loss=2.3045668601989746\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034119606018066\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026235103607178\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303894281387329\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026537895202637\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.66217041015625\n",
            "||∇_X meta|| = 0.0016129869036376476\n",
            "ΔX norm: 1.61298976308899e-05\n",
            "Stage 5/10:  44%|████████████▋                | 131/300 [04:30<05:20,  1.89s/it]T Loss=2.3041000366210938\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054487705230713\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050122261047363\n",
            "g_norm = tensor(0.1399, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048200607299805\n",
            "g_norm = tensor(0.1230, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304626941680908\n",
            "g_norm = tensor(0.1275, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.65684509277344\n",
            "||∇_X meta|| = 0.0017825524555519223\n",
            "ΔX norm: 1.782555045792833e-05\n",
            "Stage 5/10:  44%|████████████▊                | 132/300 [04:33<05:45,  2.06s/it]T Loss=2.304269313812256\n",
            "g_norm = tensor(0.0848, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044955730438232\n",
            "g_norm = tensor(0.0888, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303096294403076\n",
            "g_norm = tensor(0.0785, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305436611175537\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303638219833374\n",
            "g_norm = tensor(0.0816, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.92955017089844\n",
            "||∇_X meta|| = 0.0017804027302190661\n",
            "ΔX norm: 1.780402635631617e-05\n",
            "Stage 5/10:  44%|████████████▊                | 133/300 [04:36<06:19,  2.27s/it]T Loss=2.3041088581085205\n",
            "g_norm = tensor(0.0830, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304111957550049\n",
            "g_norm = tensor(0.0837, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304272174835205\n",
            "g_norm = tensor(0.0810, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042397499084473\n",
            "g_norm = tensor(0.0848, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031468391418457\n",
            "g_norm = tensor(0.0744, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.4197235107422\n",
            "||∇_X meta|| = 0.001541437697596848\n",
            "ΔX norm: 1.5414370864164084e-05\n",
            "Stage 5/10:  45%|████████████▉                | 134/300 [04:38<06:06,  2.21s/it]T Loss=2.303701877593994\n",
            "g_norm = tensor(0.0583, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038580417633057\n",
            "g_norm = tensor(0.0841, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026883602142334\n",
            "g_norm = tensor(0.0698, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303107261657715\n",
            "g_norm = tensor(0.0766, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303861141204834\n",
            "g_norm = tensor(0.0699, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.35618591308594\n",
            "||∇_X meta|| = 0.001737804152071476\n",
            "ΔX norm: 1.7378024494973943e-05\n",
            "Stage 5/10:  45%|█████████████                | 135/300 [04:40<05:49,  2.12s/it]T Loss=2.3026328086853027\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303502321243286\n",
            "g_norm = tensor(0.1103, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042359352111816\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041129112243652\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046696186065674\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.12875366210938\n",
            "||∇_X meta|| = 0.0017796338070183992\n",
            "ΔX norm: 1.779633021214977e-05\n",
            "Stage 5/10:  45%|█████████████▏               | 136/300 [04:42<05:40,  2.07s/it]T Loss=2.304335594177246\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035244941711426\n",
            "g_norm = tensor(0.1450, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053712844848633\n",
            "g_norm = tensor(0.1483, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304384231567383\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304246425628662\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.23779296875\n",
            "||∇_X meta|| = 0.001803437015041709\n",
            "ΔX norm: 1.8034384993370622e-05\n",
            "Stage 5/10:  46%|█████████████▏               | 137/300 [04:44<05:48,  2.14s/it]T Loss=2.3045992851257324\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302682399749756\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031935691833496\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041906356811523\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038761615753174\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.17074584960938\n",
            "||∇_X meta|| = 0.0016640352550894022\n",
            "ΔX norm: 1.6640336980344728e-05\n",
            "Stage 5/10:  46%|█████████████▎               | 138/300 [04:46<05:41,  2.11s/it]T Loss=2.304161548614502\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047380447387695\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039143085479736\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043980598449707\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041586875915527\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.60865783691406\n",
            "||∇_X meta|| = 0.001742761698551476\n",
            "ΔX norm: 1.7427622879040428e-05\n",
            "Stage 5/10:  46%|█████████████▍               | 139/300 [04:48<05:31,  2.06s/it]T Loss=2.3038787841796875\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031790256500244\n",
            "g_norm = tensor(0.0884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303123950958252\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039913177490234\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036704063415527\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.16793823242188\n",
            "||∇_X meta|| = 0.0016007591038942337\n",
            "ΔX norm: 1.6007574231480248e-05\n",
            "Stage 5/10:  47%|█████████████▌               | 140/300 [04:50<05:31,  2.07s/it]T Loss=2.3033061027526855\n",
            "g_norm = tensor(0.1531, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3013288974761963\n",
            "g_norm = tensor(0.1622, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044910430908203\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304037570953369\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303983688354492\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7605438232422\n",
            "||∇_X meta|| = 0.001710122567601502\n",
            "ΔX norm: 1.710127071419265e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 5/10:  47%|█████████████▋               | 141/300 [04:52<05:28,  2.07s/it]T Loss=2.3043270111083984\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303349733352661\n",
            "g_norm = tensor(0.0898, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027584552764893\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037054538726807\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303936004638672\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.25662231445312\n",
            "||∇_X meta|| = 0.0016624958952888846\n",
            "ΔX norm: 1.662496470089536e-05\n",
            "Stage 5/10:  47%|█████████████▋               | 142/300 [04:54<05:45,  2.19s/it]T Loss=2.3025596141815186\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302553653717041\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304241180419922\n",
            "g_norm = tensor(0.1455, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031184673309326\n",
            "g_norm = tensor(0.1364, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026511669158936\n",
            "g_norm = tensor(0.1438, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.6025390625\n",
            "||∇_X meta|| = 0.0014381872024387121\n",
            "ΔX norm: 1.4381882465386298e-05\n",
            "Stage 5/10:  48%|█████████████▊               | 143/300 [04:57<05:34,  2.13s/it]T Loss=2.3028109073638916\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304042339324951\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042142391204834\n",
            "g_norm = tensor(0.0849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042900562286377\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303673028945923\n",
            "g_norm = tensor(0.0804, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6931915283203\n",
            "||∇_X meta|| = 0.0016892364947125316\n",
            "ΔX norm: 1.6892367057153024e-05\n",
            "Stage 5/10:  48%|█████████████▉               | 144/300 [04:58<05:22,  2.07s/it]T Loss=2.305790662765503\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050754070281982\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304986000061035\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046529293060303\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305819511413574\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.49208068847656\n",
            "||∇_X meta|| = 0.0016397582367062569\n",
            "ΔX norm: 1.6397603758377954e-05\n",
            "Stage 5/10:  48%|██████████████               | 145/300 [05:00<05:13,  2.02s/it]T Loss=2.3032219409942627\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027586936950684\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304258346557617\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038296699523926\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029837608337402\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7267608642578\n",
            "||∇_X meta|| = 0.0017986089223995805\n",
            "ΔX norm: 1.7986083548748866e-05\n",
            "Stage 5/10:  49%|██████████████               | 146/300 [05:02<05:14,  2.04s/it]T Loss=2.3039262294769287\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041067123413086\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041229248046875\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30359148979187\n",
            "g_norm = tensor(0.1332, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039908409118652\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.25392150878906\n",
            "||∇_X meta|| = 0.0016757036792114377\n",
            "ΔX norm: 1.675703242653981e-05\n",
            "Stage 5/10:  49%|██████████████▏              | 147/300 [05:04<05:05,  2.00s/it]T Loss=2.3037304878234863\n",
            "g_norm = tensor(0.0697, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039393424987793\n",
            "g_norm = tensor(0.0649, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304377794265747\n",
            "g_norm = tensor(0.0730, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043417930603027\n",
            "g_norm = tensor(0.0725, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039612770080566\n",
            "g_norm = tensor(0.0707, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.8374481201172\n",
            "||∇_X meta|| = 0.0015149903483688831\n",
            "ΔX norm: 1.514992709417129e-05\n",
            "Stage 5/10:  49%|██████████████▎              | 148/300 [05:06<04:55,  1.94s/it]T Loss=2.3039352893829346\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303619623184204\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036928176879883\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304389476776123\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302689552307129\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7787322998047\n",
            "||∇_X meta|| = 0.0015848156763240695\n",
            "ΔX norm: 1.5848167095100507e-05\n",
            "Stage 5/10:  50%|██████████████▍              | 149/300 [05:08<04:46,  1.89s/it]T Loss=2.3032710552215576\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030781745910645\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043313026428223\n",
            "g_norm = tensor(0.0931, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046398162841797\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304523468017578\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.49778747558594\n",
            "||∇_X meta|| = 0.0016559212235733867\n",
            "ΔX norm: 1.6559228242840618e-05\n",
            "Stage 5/10:  50%|██████████████▌              | 150/300 [05:10<04:41,  1.87s/it]T Loss=2.3046412467956543\n",
            "g_norm = tensor(0.1357, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305535078048706\n",
            "g_norm = tensor(0.1389, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040707111358643\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057827949523926\n",
            "g_norm = tensor(0.1235, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050153255462646\n",
            "g_norm = tensor(0.1324, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.05397033691406\n",
            "||∇_X meta|| = 0.0016312848310917616\n",
            "ΔX norm: 1.6312833395204507e-05\n",
            "Stage 5/10:  50%|██████████████▌              | 151/300 [05:12<04:37,  1.86s/it]T Loss=2.3028433322906494\n",
            "g_norm = tensor(0.1258, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303626537322998\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302879810333252\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30314302444458\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304405450820923\n",
            "g_norm = tensor(0.1358, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.51467895507812\n",
            "||∇_X meta|| = 0.0015672434819862247\n",
            "ΔX norm: 1.567244908073917e-05\n",
            "Stage 5/10:  51%|██████████████▋              | 152/300 [05:14<04:48,  1.95s/it]T Loss=2.3030083179473877\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303236484527588\n",
            "g_norm = tensor(0.0980, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029985427856445\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029050827026367\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024566173553467\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.19268798828125\n",
            "||∇_X meta|| = 0.0017524037975817919\n",
            "ΔX norm: 1.752403113641776e-05\n",
            "Stage 5/10:  51%|██████████████▊              | 153/300 [05:16<04:41,  1.91s/it]T Loss=2.3046467304229736\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303981065750122\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304269313812256\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304170846939087\n",
            "g_norm = tensor(0.1075, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304330825805664\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6356964111328\n",
            "||∇_X meta|| = 0.0015503785107284784\n",
            "ΔX norm: 1.5503774193348363e-05\n",
            "Stage 5/10:  51%|██████████████▉              | 154/300 [05:17<04:38,  1.91s/it]T Loss=2.3030481338500977\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304473400115967\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303741216659546\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30281400680542\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031184673309326\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4186553955078\n",
            "||∇_X meta|| = 0.0015721312956884503\n",
            "ΔX norm: 1.572133260197006e-05\n",
            "Stage 5/10:  52%|██████████████▉              | 155/300 [05:19<04:35,  1.90s/it]T Loss=2.3035836219787598\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040924072265625\n",
            "g_norm = tensor(0.0839, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046648502349854\n",
            "g_norm = tensor(0.0885, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046391010284424\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302922010421753\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.70008850097656\n",
            "||∇_X meta|| = 0.0016660172259435058\n",
            "ΔX norm: 1.666016578383278e-05\n",
            "Stage 5/10:  52%|███████████████              | 156/300 [05:21<04:31,  1.89s/it]T Loss=2.302607774734497\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034167289733887\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303833484649658\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025662899017334\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035683631896973\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5449676513672\n",
            "||∇_X meta|| = 0.0015705135883763433\n",
            "ΔX norm: 1.5705132682342082e-05\n",
            "Stage 5/10:  52%|███████████████▏             | 157/300 [05:23<04:27,  1.87s/it]T Loss=2.3033416271209717\n",
            "g_norm = tensor(0.0841, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041481971740723\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031888008117676\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056442737579346\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30444598197937\n",
            "g_norm = tensor(0.1080, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.40420532226562\n",
            "||∇_X meta|| = 0.0016843047924339771\n",
            "ΔX norm: 1.684302515059244e-05\n",
            "Stage 5/10:  53%|███████████████▎             | 158/300 [05:25<04:27,  1.88s/it]T Loss=2.303497076034546\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303774356842041\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044137954711914\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304565668106079\n",
            "g_norm = tensor(0.0841, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304945230484009\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5835723876953\n",
            "||∇_X meta|| = 0.0015608379617333412\n",
            "ΔX norm: 1.56083915499039e-05\n",
            "Stage 5/10:  53%|███████████████▎             | 159/300 [05:27<04:26,  1.89s/it]T Loss=2.3045098781585693\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038268089294434\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039703369140625\n",
            "g_norm = tensor(0.1214, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303950548171997\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038394451141357\n",
            "g_norm = tensor(0.1447, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.37973022460938\n",
            "||∇_X meta|| = 0.0015801979461684823\n",
            "ΔX norm: 1.58019938680809e-05\n",
            "Stage 5/10:  53%|███████████████▍             | 160/300 [05:29<04:34,  1.96s/it]T Loss=2.301117420196533\n",
            "g_norm = tensor(0.1251, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024346828460693\n",
            "g_norm = tensor(0.1306, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040127754211426\n",
            "g_norm = tensor(0.1302, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3014416694641113\n",
            "g_norm = tensor(0.1320, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301896572113037\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.80406188964844\n",
            "||∇_X meta|| = 0.0014702725457027555\n",
            "ΔX norm: 1.4702763110108208e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 5/10:  54%|███████████████▌             | 161/300 [05:31<04:51,  2.10s/it]T Loss=2.302891492843628\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302234172821045\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304594039916992\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038477897644043\n",
            "g_norm = tensor(0.0843, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303316354751587\n",
            "g_norm = tensor(0.0865, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.80470275878906\n",
            "||∇_X meta|| = 0.0016119347419589758\n",
            "ΔX norm: 1.6119354768306948e-05\n",
            "Stage 5/10:  54%|███████████████▋             | 162/300 [05:34<05:11,  2.26s/it]T Loss=2.3030714988708496\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030529022216797\n",
            "g_norm = tensor(0.0847, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035337924957275\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302669048309326\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302358627319336\n",
            "g_norm = tensor(0.0831, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0958709716797\n",
            "||∇_X meta|| = 0.0015706568956375122\n",
            "ΔX norm: 1.5706558770034462e-05\n",
            "Stage 5/10:  54%|███████████████▊             | 163/300 [05:36<05:02,  2.21s/it]T Loss=2.304879665374756\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304614305496216\n",
            "g_norm = tensor(0.1107, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304269790649414\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040499687194824\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304086208343506\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8865203857422\n",
            "||∇_X meta|| = 0.0018305559642612934\n",
            "ΔX norm: 1.8305589037481695e-05\n",
            "Stage 5/10:  55%|███████████████▊             | 164/300 [05:38<04:50,  2.14s/it]T Loss=2.302774429321289\n",
            "g_norm = tensor(0.1470, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047595024108887\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033251762390137\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304384708404541\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30307674407959\n",
            "g_norm = tensor(0.1183, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.99432373046875\n",
            "||∇_X meta|| = 0.0016716078389436007\n",
            "ΔX norm: 1.671609607001301e-05\n",
            "Stage 5/10:  55%|███████████████▉             | 165/300 [05:40<04:38,  2.06s/it]T Loss=2.3032641410827637\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051819801330566\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035149574279785\n",
            "g_norm = tensor(0.1157, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303056240081787\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026580810546875\n",
            "g_norm = tensor(0.1225, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.84201049804688\n",
            "||∇_X meta|| = 0.0014929329045116901\n",
            "ΔX norm: 1.4929308235878125e-05\n",
            "Stage 5/10:  55%|████████████████             | 166/300 [05:42<04:28,  2.01s/it]T Loss=2.3050308227539062\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305366039276123\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043837547302246\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304476261138916\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056983947753906\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.9388427734375\n",
            "||∇_X meta|| = 0.0014713603304699063\n",
            "ΔX norm: 1.4713617929373868e-05\n",
            "Stage 5/10:  56%|████████████████▏            | 167/300 [05:44<04:21,  1.97s/it]T Loss=2.303602933883667\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30383038520813\n",
            "g_norm = tensor(0.1206, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030776977539062\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045012950897217\n",
            "g_norm = tensor(0.1235, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042445182800293\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1566925048828\n",
            "||∇_X meta|| = 0.001557663781568408\n",
            "ΔX norm: 1.557664290885441e-05\n",
            "Stage 5/10:  56%|████████████████▏            | 168/300 [05:46<04:16,  1.94s/it]T Loss=2.3036844730377197\n",
            "g_norm = tensor(0.0854, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043415546417236\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037991523742676\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041956424713135\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304159164428711\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.68869018554688\n",
            "||∇_X meta|| = 0.0016464166110381484\n",
            "ΔX norm: 1.6464160580653697e-05\n",
            "Stage 5/10:  56%|████████████████▎            | 169/300 [05:48<04:28,  2.05s/it]T Loss=2.3035788536071777\n",
            "g_norm = tensor(0.0708, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304506540298462\n",
            "g_norm = tensor(0.0758, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040688037872314\n",
            "g_norm = tensor(0.0750, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037116527557373\n",
            "g_norm = tensor(0.0793, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037517070770264\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.73313903808594\n",
            "||∇_X meta|| = 0.0015955542912706733\n",
            "ΔX norm: 1.5955545677570626e-05\n",
            "Stage 5/10:  57%|████████████████▍            | 170/300 [05:50<04:22,  2.02s/it]T Loss=2.3032612800598145\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032243251800537\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031697273254395\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304001569747925\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30326771736145\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0366668701172\n",
            "||∇_X meta|| = 0.0017654651310294867\n",
            "ΔX norm: 1.765464367053937e-05\n",
            "Stage 5/10:  57%|████████████████▌            | 171/300 [05:52<04:17,  2.00s/it]T Loss=2.303612232208252\n",
            "g_norm = tensor(0.1422, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303056478500366\n",
            "g_norm = tensor(0.1366, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038525581359863\n",
            "g_norm = tensor(0.1433, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3010497093200684\n",
            "g_norm = tensor(0.1367, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303135395050049\n",
            "g_norm = tensor(0.1221, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.13153076171875\n",
            "||∇_X meta|| = 0.001582638593390584\n",
            "ΔX norm: 1.5826413800823502e-05\n",
            "Stage 5/10:  57%|████████████████▋            | 172/300 [05:54<04:15,  1.99s/it]T Loss=2.3039066791534424\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043136596679688\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034634590148926\n",
            "g_norm = tensor(0.0980, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304651975631714\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044281005859375\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.95506286621094\n",
            "||∇_X meta|| = 0.0016858922317624092\n",
            "ΔX norm: 1.6858919480000623e-05\n",
            "Stage 5/10:  58%|████████████████▋            | 173/300 [05:56<04:13,  1.99s/it]T Loss=2.307006359100342\n",
            "g_norm = tensor(0.1655, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030848503112793\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303277015686035\n",
            "g_norm = tensor(0.1503, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.300814628601074\n",
            "g_norm = tensor(0.1526, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303859233856201\n",
            "g_norm = tensor(0.1394, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1852569580078\n",
            "||∇_X meta|| = 0.0016322850715368986\n",
            "ΔX norm: 1.632283783692401e-05\n",
            "Stage 5/10:  58%|████████████████▊            | 174/300 [05:58<04:08,  1.97s/it]T Loss=2.3031585216522217\n",
            "g_norm = tensor(0.0694, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039932250976562\n",
            "g_norm = tensor(0.0868, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303964138031006\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024678230285645\n",
            "g_norm = tensor(0.0822, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302896022796631\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8118133544922\n",
            "||∇_X meta|| = 0.0015421919524669647\n",
            "ΔX norm: 1.5421934222104028e-05\n",
            "Stage 5/10:  58%|████████████████▉            | 175/300 [06:00<04:05,  1.96s/it]T Loss=2.3035542964935303\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304481029510498\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304009437561035\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303837776184082\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040213584899902\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3358612060547\n",
            "||∇_X meta|| = 0.0016013453714549541\n",
            "ΔX norm: 1.601347503310535e-05\n",
            "Stage 5/10:  59%|█████████████████            | 176/300 [06:02<04:04,  1.97s/it]T Loss=2.3039064407348633\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302995204925537\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30416202545166\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025197982788086\n",
            "g_norm = tensor(0.1424, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038010597229004\n",
            "g_norm = tensor(0.1583, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8795928955078\n",
            "||∇_X meta|| = 0.001744285225868225\n",
            "ΔX norm: 1.7442871467210352e-05\n",
            "Stage 5/10:  59%|█████████████████            | 177/300 [06:04<04:02,  1.97s/it]T Loss=2.3038408756256104\n",
            "g_norm = tensor(0.0933, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304504632949829\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037476539611816\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033335208892822\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035736083984375\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.0714569091797\n",
            "||∇_X meta|| = 0.0016206729924306273\n",
            "ΔX norm: 1.620674811420031e-05\n",
            "Stage 5/10:  59%|█████████████████▏           | 178/300 [06:06<03:58,  1.96s/it]T Loss=2.3048157691955566\n",
            "g_norm = tensor(0.0733, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304171085357666\n",
            "g_norm = tensor(0.0720, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033993244171143\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304020404815674\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040835857391357\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.38299560546875\n",
            "||∇_X meta|| = 0.0016107732662931085\n",
            "ΔX norm: 1.6107704141177237e-05\n",
            "Stage 5/10:  60%|█████████████████▎           | 179/300 [06:07<03:55,  1.94s/it]T Loss=2.3033127784729004\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036186695098877\n",
            "g_norm = tensor(0.1183, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048207759857178\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034560680389404\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048300743103027\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.98654174804688\n",
            "||∇_X meta|| = 0.0015813015634194016\n",
            "ΔX norm: 1.5813000572961755e-05\n",
            "Stage 5/10:  60%|█████████████████▍           | 180/300 [06:09<03:50,  1.92s/it]T Loss=2.3035190105438232\n",
            "g_norm = tensor(0.1704, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302910327911377\n",
            "g_norm = tensor(0.1489, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040552139282227\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039798736572266\n",
            "g_norm = tensor(0.1570, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038604259490967\n",
            "g_norm = tensor(0.1255, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.79849243164062\n",
            "||∇_X meta|| = 0.0015850025229156017\n",
            "ΔX norm: 1.585003519721795e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 5/10:  60%|█████████████████▍           | 181/300 [06:11<03:52,  1.96s/it]T Loss=2.305377960205078\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305394411087036\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049724102020264\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303676128387451\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304593086242676\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.75555419921875\n",
            "||∇_X meta|| = 0.0016536619514226913\n",
            "ΔX norm: 1.6536625480512157e-05\n",
            "Stage 5/10:  61%|█████████████████▌           | 182/300 [06:15<04:39,  2.37s/it]T Loss=2.304142475128174\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302870512008667\n",
            "g_norm = tensor(0.1099, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044238090515137\n",
            "g_norm = tensor(0.1107, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039181232452393\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038575649261475\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.20330810546875\n",
            "||∇_X meta|| = 0.0015695294132456183\n",
            "ΔX norm: 1.5695306501584128e-05\n",
            "Stage 5/10:  61%|█████████████████▋           | 183/300 [06:17<04:38,  2.38s/it]T Loss=2.303436756134033\n",
            "g_norm = tensor(0.0931, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031411170959473\n",
            "g_norm = tensor(0.1303, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043293952941895\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028759956359863\n",
            "g_norm = tensor(0.1301, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043017387390137\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.40628051757812\n",
            "||∇_X meta|| = 0.0015133086126297712\n",
            "ΔX norm: 1.5133076885831542e-05\n",
            "Stage 5/10:  61%|█████████████████▊           | 184/300 [06:19<04:35,  2.37s/it]T Loss=2.304330587387085\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303864002227783\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043088912963867\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050649166107178\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051414489746094\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2847900390625\n",
            "||∇_X meta|| = 0.0015554978745058179\n",
            "ΔX norm: 1.555496965011116e-05\n",
            "Stage 5/10:  62%|█████████████████▉           | 185/300 [06:22<04:44,  2.47s/it]T Loss=2.30349063873291\n",
            "g_norm = tensor(0.1402, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031342029571533\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033337593078613\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302001476287842\n",
            "g_norm = tensor(0.1573, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302450656890869\n",
            "g_norm = tensor(0.1385, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5977325439453\n",
            "||∇_X meta|| = 0.0015518197324126959\n",
            "ΔX norm: 1.5518211512244307e-05\n",
            "Stage 5/10:  62%|█████████████████▉           | 186/300 [06:25<04:44,  2.50s/it]T Loss=2.303905487060547\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019042015075684\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022704124450684\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033359050750732\n",
            "g_norm = tensor(0.0833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042664527893066\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.78367614746094\n",
            "||∇_X meta|| = 0.0016783048631623387\n",
            "ΔX norm: 1.6783033061074093e-05\n",
            "Stage 5/10:  62%|██████████████████           | 187/300 [06:27<04:32,  2.41s/it]T Loss=2.3039233684539795\n",
            "g_norm = tensor(0.0683, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304248332977295\n",
            "g_norm = tensor(0.0664, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041536808013916\n",
            "g_norm = tensor(0.0751, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040051460266113\n",
            "g_norm = tensor(0.0781, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045718669891357\n",
            "g_norm = tensor(0.0757, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6566162109375\n",
            "||∇_X meta|| = 0.0015854352386668324\n",
            "ΔX norm: 1.5854346202104352e-05\n",
            "Stage 5/10:  63%|██████████████████▏          | 188/300 [06:29<04:28,  2.40s/it]T Loss=2.3026492595672607\n",
            "g_norm = tensor(0.0851, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303691864013672\n",
            "g_norm = tensor(0.0830, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029520511627197\n",
            "g_norm = tensor(0.0655, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303389072418213\n",
            "g_norm = tensor(0.0762, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303122043609619\n",
            "g_norm = tensor(0.0832, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.83853149414062\n",
            "||∇_X meta|| = 0.0015934532275423408\n",
            "ΔX norm: 1.5934518160065636e-05\n",
            "Stage 5/10:  63%|██████████████████▎          | 189/300 [06:32<04:52,  2.64s/it]T Loss=2.3034114837646484\n",
            "g_norm = tensor(0.1494, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035378456115723\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304137706756592\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303849697113037\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036844730377197\n",
            "g_norm = tensor(0.1451, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.64486694335938\n",
            "||∇_X meta|| = 0.0015784124843776226\n",
            "ΔX norm: 1.5784144125063904e-05\n",
            "Stage 5/10:  63%|██████████████████▎          | 190/300 [06:35<04:46,  2.61s/it]T Loss=2.3025717735290527\n",
            "g_norm = tensor(0.1502, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018758296966553\n",
            "g_norm = tensor(0.1391, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031320571899414\n",
            "g_norm = tensor(0.1322, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020434379577637\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3006625175476074\n",
            "g_norm = tensor(0.1409, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.33030700683594\n",
            "||∇_X meta|| = 0.0014843345852568746\n",
            "ΔX norm: 1.4843330063740723e-05\n",
            "Stage 5/10:  64%|██████████████████▍          | 191/300 [06:37<04:35,  2.52s/it]T Loss=2.3056156635284424\n",
            "g_norm = tensor(0.0844, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304600477218628\n",
            "g_norm = tensor(0.0778, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30407977104187\n",
            "g_norm = tensor(0.0739, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304685115814209\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045003414154053\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.71104431152344\n",
            "||∇_X meta|| = 0.0015627003740519285\n",
            "ΔX norm: 1.562700344948098e-05\n",
            "Stage 5/10:  64%|██████████████████▌          | 192/300 [06:40<04:24,  2.45s/it]T Loss=2.303410291671753\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304328441619873\n",
            "g_norm = tensor(0.1319, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30299973487854\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304609775543213\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034846782684326\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.08657836914062\n",
            "||∇_X meta|| = 0.0016330047510564327\n",
            "ΔX norm: 1.6330028302036226e-05\n",
            "Stage 5/10:  64%|██████████████████▋          | 193/300 [06:43<04:53,  2.75s/it]T Loss=2.3033127784729004\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303724527359009\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302539348602295\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303063154220581\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043875694274902\n",
            "g_norm = tensor(0.0789, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.560302734375\n",
            "||∇_X meta|| = 0.0015941736055538058\n",
            "ΔX norm: 1.5941734091029502e-05\n",
            "Stage 5/10:  65%|██████████████████▊          | 194/300 [06:47<05:25,  3.07s/it]T Loss=2.3036890029907227\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039469718933105\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302865505218506\n",
            "g_norm = tensor(0.0883, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033711910247803\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302464246749878\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5028533935547\n",
            "||∇_X meta|| = 0.001669007004238665\n",
            "ΔX norm: 1.6690080883563496e-05\n",
            "Stage 5/10:  65%|██████████████████▊          | 195/300 [06:50<05:34,  3.19s/it]T Loss=2.303647518157959\n",
            "g_norm = tensor(0.1434, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042244911193848\n",
            "g_norm = tensor(0.1443, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043975830078125\n",
            "g_norm = tensor(0.1234, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034141063690186\n",
            "g_norm = tensor(0.1382, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049252033233643\n",
            "g_norm = tensor(0.1629, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.16087341308594\n",
            "||∇_X meta|| = 0.0015251029981300235\n",
            "ΔX norm: 1.525105290056672e-05\n",
            "Stage 5/10:  65%|██████████████████▉          | 196/300 [06:54<05:32,  3.20s/it]T Loss=2.3044323921203613\n",
            "g_norm = tensor(0.1480, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304295539855957\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043019771575928\n",
            "g_norm = tensor(0.1351, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042025566101074\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037095069885254\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.37539672851562\n",
            "||∇_X meta|| = 0.001614432199858129\n",
            "ΔX norm: 1.6144316759891808e-05\n",
            "Stage 5/10:  66%|███████████████████          | 197/300 [06:56<05:06,  2.98s/it]T Loss=2.303854465484619\n",
            "g_norm = tensor(0.1363, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040215969085693\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302844762802124\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019235134124756\n",
            "g_norm = tensor(0.1075, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30366587638855\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3725128173828\n",
            "||∇_X meta|| = 0.0014744499931111932\n",
            "ΔX norm: 1.4744508916919585e-05\n",
            "Stage 5/10:  66%|███████████████████▏         | 198/300 [06:59<05:10,  3.04s/it]T Loss=2.3022818565368652\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304316997528076\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303905487060547\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030543327331543\n",
            "g_norm = tensor(0.1378, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3013319969177246\n",
            "g_norm = tensor(0.1425, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.01565551757812\n",
            "||∇_X meta|| = 0.0016156008932739496\n",
            "ΔX norm: 1.6155996490851976e-05\n",
            "Stage 5/10:  66%|███████████████████▏         | 199/300 [07:02<04:55,  2.93s/it]T Loss=2.3042569160461426\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029978275299072\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041765689849854\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045992851257324\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040778636932373\n",
            "g_norm = tensor(0.1285, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.15342712402344\n",
            "||∇_X meta|| = 0.0015636231983080506\n",
            "ΔX norm: 1.5636229363735765e-05\n",
            "Stage 5/10:  67%|███████████████████▎         | 200/300 [07:04<04:43,  2.83s/it]T Loss=2.303997755050659\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038811683654785\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041162490844727\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304374933242798\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041698932647705\n",
            "g_norm = tensor(0.0864, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.45046997070312\n",
            "||∇_X meta|| = 0.0014729531249031425\n",
            "ΔX norm: 1.4729519534739666e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 5/10:  67%|███████████████████▍         | 201/300 [07:07<04:24,  2.67s/it]T Loss=2.3023648262023926\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027215003967285\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304872512817383\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303220272064209\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021445274353027\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.71002197265625\n",
            "||∇_X meta|| = 0.0015474011888727546\n",
            "ΔX norm: 1.547400461276993e-05\n",
            "Stage 5/10:  67%|███████████████████▌         | 202/300 [07:09<04:16,  2.61s/it]T Loss=2.3053698539733887\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304447650909424\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042991161346436\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30461049079895\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046927452087402\n",
            "g_norm = tensor(0.1235, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.95596313476562\n",
            "||∇_X meta|| = 0.0016751008806750178\n",
            "ΔX norm: 1.6751004295656458e-05\n",
            "Stage 5/10:  68%|███████████████████▌         | 203/300 [07:12<04:07,  2.55s/it]T Loss=2.3043723106384277\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052890300750732\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040003776550293\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3013908863067627\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303326368331909\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.04019165039062\n",
            "||∇_X meta|| = 0.001568928943015635\n",
            "ΔX norm: 1.5689354768255726e-05\n",
            "Stage 5/10:  68%|███████████████████▋         | 204/300 [07:14<03:55,  2.46s/it]T Loss=2.3035213947296143\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043808937072754\n",
            "g_norm = tensor(0.0754, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303752899169922\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039193153381348\n",
            "g_norm = tensor(0.0830, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303661823272705\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.957275390625\n",
            "||∇_X meta|| = 0.0013079813215881586\n",
            "ΔX norm: 1.3079815289529506e-05\n",
            "Stage 5/10:  68%|███████████████████▊         | 205/300 [07:16<03:47,  2.40s/it]T Loss=2.3011322021484375\n",
            "g_norm = tensor(0.1733, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304255247116089\n",
            "g_norm = tensor(0.1743, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019027709960938\n",
            "g_norm = tensor(0.1495, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302645683288574\n",
            "g_norm = tensor(0.1672, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304473400115967\n",
            "g_norm = tensor(0.1819, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =227.8446044921875\n",
            "||∇_X meta|| = 0.0015731427120044827\n",
            "ΔX norm: 1.5731429812149145e-05\n",
            "Stage 5/10:  69%|███████████████████▉         | 206/300 [07:19<03:43,  2.38s/it]T Loss=2.3028645515441895\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048763275146484\n",
            "g_norm = tensor(0.1393, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030765056610107\n",
            "g_norm = tensor(0.1318, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304220199584961\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302780866622925\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.89122009277344\n",
            "||∇_X meta|| = 0.0014991823118180037\n",
            "ΔX norm: 1.4991817806730978e-05\n",
            "Stage 5/10:  69%|████████████████████         | 207/300 [07:21<03:47,  2.45s/it]T Loss=2.303767204284668\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036856651306152\n",
            "g_norm = tensor(0.0849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035311698913574\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303863763809204\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302555561065674\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.30848693847656\n",
            "||∇_X meta|| = 0.0016296872636303306\n",
            "ΔX norm: 1.6296873582177795e-05\n",
            "Stage 5/10:  69%|████████████████████         | 208/300 [07:24<03:46,  2.46s/it]T Loss=2.3057353496551514\n",
            "g_norm = tensor(0.0841, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050549030303955\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051724433898926\n",
            "g_norm = tensor(0.0697, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049979209899902\n",
            "g_norm = tensor(0.0770, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30496883392334\n",
            "g_norm = tensor(0.0837, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7582550048828\n",
            "||∇_X meta|| = 0.0016008466482162476\n",
            "ΔX norm: 1.60084728122456e-05\n",
            "Stage 5/10:  70%|████████████████████▏        | 209/300 [07:26<03:48,  2.51s/it]T Loss=2.304718017578125\n",
            "g_norm = tensor(0.1359, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304147243499756\n",
            "g_norm = tensor(0.1426, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045921325683594\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044867515563965\n",
            "g_norm = tensor(0.1314, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043136596679688\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =227.81773376464844\n",
            "||∇_X meta|| = 0.001577335991896689\n",
            "ΔX norm: 1.5773341146996245e-05\n",
            "Stage 5/10:  70%|████████████████████▎        | 210/300 [07:29<03:46,  2.52s/it]T Loss=2.3048386573791504\n",
            "g_norm = tensor(0.1375, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033416271209717\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303192615509033\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303217887878418\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30458402633667\n",
            "g_norm = tensor(0.1369, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6981201171875\n",
            "||∇_X meta|| = 0.001604526536539197\n",
            "ΔX norm: 1.6045281881815754e-05\n",
            "Stage 5/10:  70%|████████████████████▍        | 211/300 [07:31<03:46,  2.55s/it]T Loss=2.3046250343322754\n",
            "g_norm = tensor(0.0864, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050806522369385\n",
            "g_norm = tensor(0.0922, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052849769592285\n",
            "g_norm = tensor(0.0885, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047657012939453\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034396171569824\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.00079345703125\n",
            "||∇_X meta|| = 0.0014429951552301645\n",
            "ΔX norm: 1.4429953807848506e-05\n",
            "Stage 5/10:  71%|████████████████████▍        | 212/300 [07:34<03:43,  2.54s/it]T Loss=2.303919553756714\n",
            "g_norm = tensor(0.1812, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038506507873535\n",
            "g_norm = tensor(0.1363, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028578758239746\n",
            "g_norm = tensor(0.1510, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042654991149902\n",
            "g_norm = tensor(0.1500, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033950328826904\n",
            "g_norm = tensor(0.1360, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.46707153320312\n",
            "||∇_X meta|| = 0.0017206046031787992\n",
            "ΔX norm: 1.720610453048721e-05\n",
            "Stage 5/10:  71%|████████████████████▌        | 213/300 [07:36<03:37,  2.49s/it]T Loss=2.3044042587280273\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304161548614502\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303283214569092\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045432567596436\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303603410720825\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.9790496826172\n",
            "||∇_X meta|| = 0.0015846957685425878\n",
            "ΔX norm: 1.584695746714715e-05\n",
            "Stage 5/10:  71%|████████████████████▋        | 214/300 [07:39<03:33,  2.48s/it]T Loss=2.3041892051696777\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305119037628174\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051135540008545\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304248094558716\n",
            "g_norm = tensor(0.0956, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040771484375\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3967742919922\n",
            "||∇_X meta|| = 0.0014961170963943005\n",
            "ΔX norm: 1.4961160559323616e-05\n",
            "Stage 5/10:  72%|████████████████████▊        | 215/300 [07:41<03:25,  2.42s/it]T Loss=2.305248737335205\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306284189224243\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058695793151855\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049445152282715\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305856227874756\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4017333984375\n",
            "||∇_X meta|| = 0.0013731078943237662\n",
            "ΔX norm: 1.3731065337196924e-05\n",
            "Stage 5/10:  72%|████████████████████▉        | 216/300 [07:44<03:25,  2.44s/it]T Loss=2.3032386302948\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303236484527588\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303352117538452\n",
            "g_norm = tensor(0.0844, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302931547164917\n",
            "g_norm = tensor(0.0822, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033957481384277\n",
            "g_norm = tensor(0.0871, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.60733032226562\n",
            "||∇_X meta|| = 0.001558475662022829\n",
            "ΔX norm: 1.558475923957303e-05\n",
            "Stage 5/10:  72%|████████████████████▉        | 217/300 [07:46<03:29,  2.53s/it]T Loss=2.3036153316497803\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302399158477783\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032970428466797\n",
            "g_norm = tensor(0.0833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034188747406006\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031392097473145\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.86611938476562\n",
            "||∇_X meta|| = 0.001697550411336124\n",
            "ΔX norm: 1.6975502148852684e-05\n",
            "Stage 5/10:  73%|█████████████████████        | 218/300 [07:49<03:24,  2.49s/it]T Loss=2.304121255874634\n",
            "g_norm = tensor(0.1304, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034493923187256\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304814100265503\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039183616638184\n",
            "g_norm = tensor(0.1248, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045763969421387\n",
            "g_norm = tensor(0.1262, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4844207763672\n",
            "||∇_X meta|| = 0.001632650033570826\n",
            "ΔX norm: 1.632650673855096e-05\n",
            "Stage 5/10:  73%|█████████████████████▏       | 219/300 [07:51<03:18,  2.45s/it]T Loss=2.304270029067993\n",
            "g_norm = tensor(0.1251, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043012619018555\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304030418395996\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303226947784424\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304640531539917\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.31918334960938\n",
            "||∇_X meta|| = 0.0014626051997765899\n",
            "ΔX norm: 1.4626050869992469e-05\n",
            "Stage 5/10:  73%|█████████████████████▎       | 220/300 [07:54<03:25,  2.57s/it]T Loss=2.303313970565796\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054816722869873\n",
            "g_norm = tensor(0.1289, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303647041320801\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303677558898926\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304145097732544\n",
            "g_norm = tensor(0.1153, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.14834594726562\n",
            "||∇_X meta|| = 0.0016476979944854975\n",
            "ΔX norm: 1.6476975361001678e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 5/10:  74%|█████████████████████▎       | 221/300 [07:56<03:20,  2.54s/it]T Loss=2.3034021854400635\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303873300552368\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053646087646484\n",
            "g_norm = tensor(0.1178, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303297519683838\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053202629089355\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.02732849121094\n",
            "||∇_X meta|| = 0.00143091706559062\n",
            "ΔX norm: 1.4309156540548429e-05\n",
            "Stage 5/10:  74%|█████████████████████▍       | 222/300 [07:59<03:29,  2.68s/it]T Loss=2.3036067485809326\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304858446121216\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033483028411865\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045761585235596\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050849437713623\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.66064453125\n",
            "||∇_X meta|| = 0.001564797479659319\n",
            "ΔX norm: 1.5647992768208496e-05\n",
            "Stage 5/10:  74%|█████████████████████▌       | 223/300 [08:02<03:20,  2.60s/it]T Loss=2.3036952018737793\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30527925491333\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303488254547119\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302870750427246\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043177127838135\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.6684112548828\n",
            "||∇_X meta|| = 0.0016037739114835858\n",
            "ΔX norm: 1.6037740351748653e-05\n",
            "Stage 5/10:  75%|█████████████████████▋       | 224/300 [08:04<03:10,  2.51s/it]T Loss=2.3038840293884277\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303009510040283\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304039478302002\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304112672805786\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043372631073\n",
            "g_norm = tensor(0.1103, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4169158935547\n",
            "||∇_X meta|| = 0.0016489742556586862\n",
            "ΔX norm: 1.6489737390656956e-05\n",
            "Stage 5/10:  75%|█████████████████████▊       | 225/300 [08:06<03:06,  2.48s/it]T Loss=2.3043971061706543\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035030364990234\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039793968200684\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048391342163086\n",
            "g_norm = tensor(0.0983, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037846088409424\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1224822998047\n",
            "||∇_X meta|| = 0.0015383007703348994\n",
            "ΔX norm: 1.5383018762804568e-05\n",
            "Stage 5/10:  75%|█████████████████████▊       | 226/300 [08:09<02:58,  2.41s/it]T Loss=2.30484676361084\n",
            "g_norm = tensor(0.1535, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055152893066406\n",
            "g_norm = tensor(0.1588, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304900884628296\n",
            "g_norm = tensor(0.1386, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303591251373291\n",
            "g_norm = tensor(0.1638, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304786205291748\n",
            "g_norm = tensor(0.1692, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6963348388672\n",
            "||∇_X meta|| = 0.0015492381062358618\n",
            "ΔX norm: 1.5492350939894095e-05\n",
            "Stage 5/10:  76%|█████████████████████▉       | 227/300 [08:11<02:53,  2.37s/it]T Loss=2.303112030029297\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032214641571045\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028197288513184\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303821086883545\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031530380249023\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1500244140625\n",
            "||∇_X meta|| = 0.0015317007200792432\n",
            "ΔX norm: 1.5317002180381678e-05\n",
            "Stage 5/10:  76%|██████████████████████       | 228/300 [08:13<02:48,  2.33s/it]T Loss=2.3028340339660645\n",
            "g_norm = tensor(0.0797, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036723136901855\n",
            "g_norm = tensor(0.0848, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304133415222168\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303347587585449\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304021120071411\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.94601440429688\n",
            "||∇_X meta|| = 0.001501427381299436\n",
            "ΔX norm: 1.5014290511317085e-05\n",
            "Stage 5/10:  76%|██████████████████████▏      | 229/300 [08:15<02:43,  2.30s/it]T Loss=2.303582191467285\n",
            "g_norm = tensor(0.1346, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027195930480957\n",
            "g_norm = tensor(0.1592, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302119255065918\n",
            "g_norm = tensor(0.1584, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051815032958984\n",
            "g_norm = tensor(0.1494, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303457498550415\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.59967041015625\n",
            "||∇_X meta|| = 0.0014902628026902676\n",
            "ΔX norm: 1.4902644579706248e-05\n",
            "Stage 5/10:  77%|██████████████████████▏      | 230/300 [08:18<02:38,  2.26s/it]T Loss=2.3043293952941895\n",
            "g_norm = tensor(0.1337, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043646812438965\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035812377929688\n",
            "g_norm = tensor(0.1523, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044142723083496\n",
            "g_norm = tensor(0.1376, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037970066070557\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.893798828125\n",
            "||∇_X meta|| = 0.0015602036146447062\n",
            "ΔX norm: 1.560204145789612e-05\n",
            "Stage 5/10:  77%|██████████████████████▎      | 231/300 [08:20<02:38,  2.30s/it]T Loss=2.3048129081726074\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044464588165283\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304999828338623\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047449588775635\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039698600769043\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.574462890625\n",
            "||∇_X meta|| = 0.00164573744405061\n",
            "ΔX norm: 1.645739575906191e-05\n",
            "Stage 5/10:  77%|██████████████████████▍      | 232/300 [08:22<02:34,  2.27s/it]T Loss=2.3031764030456543\n",
            "g_norm = tensor(0.1022, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042101860046387\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035449981689453\n",
            "g_norm = tensor(0.1103, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303837299346924\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303344488143921\n",
            "g_norm = tensor(0.0934, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8336639404297\n",
            "||∇_X meta|| = 0.0016926670214161277\n",
            "ΔX norm: 1.692666410235688e-05\n",
            "Stage 5/10:  78%|██████████████████████▌      | 233/300 [08:24<02:29,  2.23s/it]T Loss=2.3045241832733154\n",
            "g_norm = tensor(0.0937, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304084300994873\n",
            "g_norm = tensor(0.0767, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303971290588379\n",
            "g_norm = tensor(0.0983, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041157722473145\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043160438537598\n",
            "g_norm = tensor(0.0723, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.81338500976562\n",
            "||∇_X meta|| = 0.0014343070797622204\n",
            "ΔX norm: 1.4343082511913963e-05\n",
            "Stage 5/10:  78%|██████████████████████▌      | 234/300 [08:26<02:25,  2.20s/it]T Loss=2.303431987762451\n",
            "g_norm = tensor(0.1283, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303408622741699\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038058280944824\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301931858062744\n",
            "g_norm = tensor(0.1509, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303346872329712\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.50010681152344\n",
            "||∇_X meta|| = 0.0015283190878108144\n",
            "ΔX norm: 1.5283219909179024e-05\n",
            "Stage 5/10:  78%|██████████████████████▋      | 235/300 [08:29<02:23,  2.21s/it]T Loss=2.302189350128174\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031046390533447\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030359745025635\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029215335845947\n",
            "g_norm = tensor(0.1021, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031787872314453\n",
            "g_norm = tensor(0.1053, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3207244873047\n",
            "||∇_X meta|| = 0.001475860015489161\n",
            "ΔX norm: 1.4758604265807662e-05\n",
            "Stage 5/10:  79%|██████████████████████▊      | 236/300 [08:31<02:20,  2.20s/it]T Loss=2.3047327995300293\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038768768310547\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304370164871216\n",
            "g_norm = tensor(0.1598, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040342330932617\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056910037994385\n",
            "g_norm = tensor(0.1394, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.13546752929688\n",
            "||∇_X meta|| = 0.0015651448629796505\n",
            "ΔX norm: 1.565147795190569e-05\n",
            "Stage 5/10:  79%|██████████████████████▉      | 237/300 [08:34<02:33,  2.44s/it]T Loss=2.305194616317749\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301753520965576\n",
            "g_norm = tensor(0.1250, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302647113800049\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032844066619873\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304226875305176\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.58078002929688\n",
            "||∇_X meta|| = 0.001516066025942564\n",
            "ΔX norm: 1.5160681869019754e-05\n",
            "Stage 5/10:  79%|███████████████████████      | 238/300 [08:36<02:32,  2.47s/it]T Loss=2.3027100563049316\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031251430511475\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30308198928833\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303983688354492\n",
            "g_norm = tensor(0.1286, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021230697631836\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1652374267578\n",
            "||∇_X meta|| = 0.0015869074268266559\n",
            "ΔX norm: 1.5869060007389635e-05\n",
            "Stage 5/10:  80%|███████████████████████      | 239/300 [08:39<02:26,  2.40s/it]T Loss=2.305764675140381\n",
            "g_norm = tensor(0.1783, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030214309692383\n",
            "g_norm = tensor(0.1342, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30281400680542\n",
            "g_norm = tensor(0.1206, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025176525115967\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304170608520508\n",
            "g_norm = tensor(0.1410, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.08729553222656\n",
            "||∇_X meta|| = 0.001536242663860321\n",
            "ΔX norm: 1.53624132508412e-05\n",
            "Stage 5/10:  80%|███████████████████████▏     | 240/300 [08:41<02:21,  2.36s/it]T Loss=2.3037991523742676\n",
            "g_norm = tensor(0.0760, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040049076080322\n",
            "g_norm = tensor(0.0739, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034911155700684\n",
            "g_norm = tensor(0.0803, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037831783294678\n",
            "g_norm = tensor(0.0819, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029472827911377\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.97166442871094\n",
            "||∇_X meta|| = 0.001589110936038196\n",
            "ΔX norm: 1.5891109796939418e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 5/10:  80%|███████████████████████▎     | 241/300 [08:43<02:20,  2.38s/it]T Loss=2.303389072418213\n",
            "g_norm = tensor(0.1599, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028931617736816\n",
            "g_norm = tensor(0.1334, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026907444000244\n",
            "g_norm = tensor(0.1323, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026938438415527\n",
            "g_norm = tensor(0.1582, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017616271972656\n",
            "g_norm = tensor(0.1396, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =227.86453247070312\n",
            "||∇_X meta|| = 0.0016302685253322124\n",
            "ΔX norm: 1.6302679796353914e-05\n",
            "Stage 5/10:  81%|███████████████████████▍     | 242/300 [08:46<02:26,  2.53s/it]T Loss=2.3035788536071777\n",
            "g_norm = tensor(0.0721, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030574321746826\n",
            "g_norm = tensor(0.0678, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032948970794678\n",
            "g_norm = tensor(0.0643, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036742210388184\n",
            "g_norm = tensor(0.0723, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033981323242188\n",
            "g_norm = tensor(0.0739, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.490966796875\n",
            "||∇_X meta|| = 0.0015572905540466309\n",
            "ΔX norm: 1.557292853249237e-05\n",
            "Stage 5/10:  81%|███████████████████████▍     | 243/300 [08:49<02:24,  2.53s/it]T Loss=2.302724838256836\n",
            "g_norm = tensor(0.0908, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025901317596436\n",
            "g_norm = tensor(0.0805, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303618907928467\n",
            "g_norm = tensor(0.0871, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303229808807373\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303704023361206\n",
            "g_norm = tensor(0.0854, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.873046875\n",
            "||∇_X meta|| = 0.0015834589721634984\n",
            "ΔX norm: 1.5834588339203037e-05\n",
            "Stage 5/10:  81%|███████████████████████▌     | 244/300 [08:51<02:23,  2.56s/it]T Loss=2.3039188385009766\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041884899139404\n",
            "g_norm = tensor(0.0880, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028688430786133\n",
            "g_norm = tensor(0.0878, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026108741760254\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304027557373047\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.73013305664062\n",
            "||∇_X meta|| = 0.0015655140159651637\n",
            "ΔX norm: 1.5655128663638607e-05\n",
            "Stage 5/10:  82%|███████████████████████▋     | 245/300 [08:54<02:17,  2.49s/it]T Loss=2.303527355194092\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040902614593506\n",
            "g_norm = tensor(0.1489, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303727626800537\n",
            "g_norm = tensor(0.1399, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303752899169922\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041586875915527\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.46685791015625\n",
            "||∇_X meta|| = 0.0015847678296267986\n",
            "ΔX norm: 1.5847674148972146e-05\n",
            "Stage 5/10:  82%|███████████████████████▊     | 246/300 [08:56<02:12,  2.45s/it]T Loss=2.303452968597412\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033809661865234\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018436431884766\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302790641784668\n",
            "g_norm = tensor(0.1355, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303093194961548\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.99127197265625\n",
            "||∇_X meta|| = 0.001517541240900755\n",
            "ΔX norm: 1.5175416592683177e-05\n",
            "Stage 5/10:  82%|███████████████████████▉     | 247/300 [08:58<02:05,  2.37s/it]T Loss=2.3041956424713135\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305236339569092\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049213886260986\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302947998046875\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304006576538086\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1264190673828\n",
            "||∇_X meta|| = 0.0015596416778862476\n",
            "ΔX norm: 1.559639349579811e-05\n",
            "Stage 5/10:  83%|███████████████████████▉     | 248/300 [09:01<02:06,  2.44s/it]T Loss=2.303636074066162\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038885593414307\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034873008728027\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036303520202637\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037209510803223\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9068603515625\n",
            "||∇_X meta|| = 0.0015224853996187449\n",
            "ΔX norm: 1.5224887647491414e-05\n",
            "Stage 5/10:  83%|████████████████████████     | 249/300 [09:03<02:01,  2.38s/it]T Loss=2.303436279296875\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302459239959717\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027472496032715\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035900592803955\n",
            "g_norm = tensor(0.1053, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302963972091675\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.12416076660156\n",
            "||∇_X meta|| = 0.0015443929005414248\n",
            "ΔX norm: 1.5443925803992897e-05\n",
            "Stage 5/10:  83%|████████████████████████▏    | 250/300 [09:05<01:57,  2.35s/it]T Loss=2.3048295974731445\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047146797180176\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305429697036743\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052878379821777\n",
            "g_norm = tensor(0.1367, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028533458709717\n",
            "g_norm = tensor(0.1154, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.57655334472656\n",
            "||∇_X meta|| = 0.0017296678852289915\n",
            "ΔX norm: 1.729667383187916e-05\n",
            "Stage 5/10:  84%|████████████████████████▎    | 251/300 [09:08<01:51,  2.28s/it]T Loss=2.3053135871887207\n",
            "g_norm = tensor(0.1021, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302945613861084\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046927452087402\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304835557937622\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045597076416016\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.52203369140625\n",
            "||∇_X meta|| = 0.0017371615394949913\n",
            "ΔX norm: 1.7371628928231075e-05\n",
            "Stage 5/10:  84%|████████████████████████▎    | 252/300 [09:10<01:47,  2.23s/it]T Loss=2.3046610355377197\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040812015533447\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029959201812744\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048903942108154\n",
            "g_norm = tensor(0.0993, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051981925964355\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1640625\n",
            "||∇_X meta|| = 0.0015089986845850945\n",
            "ΔX norm: 1.5089998669282068e-05\n",
            "Stage 5/10:  84%|████████████████████████▍    | 253/300 [09:12<01:43,  2.21s/it]T Loss=2.3040778636932373\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304389715194702\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303652286529541\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032305240631104\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303712844848633\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9890899658203\n",
            "||∇_X meta|| = 0.0015283634420484304\n",
            "ΔX norm: 1.528362372482661e-05\n",
            "Stage 5/10:  85%|████████████████████████▌    | 254/300 [09:14<01:42,  2.22s/it]T Loss=2.3026697635650635\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302856922149658\n",
            "g_norm = tensor(0.0853, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040053844451904\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303529739379883\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302537679672241\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.98663330078125\n",
            "||∇_X meta|| = 0.0015842510620132089\n",
            "ΔX norm: 1.584249002917204e-05\n",
            "Stage 5/10:  85%|████████████████████████▋    | 255/300 [09:16<01:38,  2.20s/it]T Loss=2.30538272857666\n",
            "g_norm = tensor(0.1291, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3060219287872314\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303683280944824\n",
            "g_norm = tensor(0.1140, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040661811828613\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047728538513184\n",
            "g_norm = tensor(0.1328, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7654266357422\n",
            "||∇_X meta|| = 0.0014859361108392477\n",
            "ΔX norm: 1.485935445089126e-05\n",
            "Stage 5/10:  85%|████████████████████████▋    | 256/300 [09:18<01:37,  2.21s/it]T Loss=2.304168701171875\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304746150970459\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303312301635742\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304112434387207\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031468391418457\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5596923828125\n",
            "||∇_X meta|| = 0.001571709057316184\n",
            "ΔX norm: 1.5717116184532642e-05\n",
            "Stage 5/10:  86%|████████████████████████▊    | 257/300 [09:21<01:36,  2.25s/it]T Loss=2.303905487060547\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303406000137329\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038582801818848\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041536808013916\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040528297424316\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.41729736328125\n",
            "||∇_X meta|| = 0.0016609379090368748\n",
            "ΔX norm: 1.6609395970590413e-05\n",
            "Stage 5/10:  86%|████████████████████████▉    | 258/300 [09:23<01:33,  2.22s/it]T Loss=2.3033149242401123\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302694320678711\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034825325012207\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303391218185425\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304774522781372\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5331573486328\n",
            "||∇_X meta|| = 0.0015750094316899776\n",
            "ΔX norm: 1.5750109014334157e-05\n",
            "Stage 5/10:  86%|█████████████████████████    | 259/300 [09:25<01:29,  2.19s/it]T Loss=2.3052773475646973\n",
            "g_norm = tensor(0.1394, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052918910980225\n",
            "g_norm = tensor(0.1381, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303311824798584\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306579113006592\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041388988494873\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.72616577148438\n",
            "||∇_X meta|| = 0.0015271772863343358\n",
            "ΔX norm: 1.527180938865058e-05\n",
            "Stage 5/10:  87%|█████████████████████████▏   | 260/300 [09:27<01:26,  2.17s/it]T Loss=2.3043670654296875\n",
            "g_norm = tensor(0.1011, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303788661956787\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037586212158203\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30387282371521\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033764362335205\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.6997833251953\n",
            "||∇_X meta|| = 0.001794711104594171\n",
            "ΔX norm: 1.7947120795724913e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 5/10:  87%|█████████████████████████▏   | 261/300 [09:29<01:24,  2.16s/it]T Loss=2.303346872329712\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30346417427063\n",
            "g_norm = tensor(0.0873, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302759885787964\n",
            "g_norm = tensor(0.0941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303027629852295\n",
            "g_norm = tensor(0.0851, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30283784866333\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.75213623046875\n",
            "||∇_X meta|| = 0.001488816924393177\n",
            "ΔX norm: 1.488816360506462e-05\n",
            "Stage 5/10:  87%|█████████████████████████▎   | 262/300 [09:32<01:30,  2.39s/it]T Loss=2.3042166233062744\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035693168640137\n",
            "g_norm = tensor(0.0806, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044185638427734\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304304838180542\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30391263961792\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.70230102539062\n",
            "||∇_X meta|| = 0.0016014121938496828\n",
            "ΔX norm: 1.601415169716347e-05\n",
            "Stage 5/10:  88%|█████████████████████████▍   | 263/300 [09:35<01:28,  2.40s/it]T Loss=2.3056488037109375\n",
            "g_norm = tensor(0.1487, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303658962249756\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304486036300659\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047940731048584\n",
            "g_norm = tensor(0.1365, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046727180480957\n",
            "g_norm = tensor(0.1330, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.42550659179688\n",
            "||∇_X meta|| = 0.0015748398145660758\n",
            "ΔX norm: 1.5748406440252438e-05\n",
            "Stage 5/10:  88%|█████████████████████████▌   | 264/300 [09:37<01:24,  2.34s/it]T Loss=2.303908109664917\n",
            "g_norm = tensor(0.1107, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304166555404663\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304431200027466\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303434371948242\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035519123077393\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.01043701171875\n",
            "||∇_X meta|| = 0.001579662086442113\n",
            "ΔX norm: 1.5796620573382825e-05\n",
            "Stage 5/10:  88%|█████████████████████████▌   | 265/300 [09:39<01:19,  2.26s/it]T Loss=2.30389666557312\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045265674591064\n",
            "g_norm = tensor(0.1299, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304739236831665\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047914505004883\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045096397399902\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.65130615234375\n",
            "||∇_X meta|| = 0.0017498695524409413\n",
            "ΔX norm: 1.749868351907935e-05\n",
            "Stage 5/10:  89%|█████████████████████████▋   | 266/300 [09:41<01:19,  2.34s/it]T Loss=2.303708553314209\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027846813201904\n",
            "g_norm = tensor(0.1370, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026270866394043\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3016223907470703\n",
            "g_norm = tensor(0.1305, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303305149078369\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3945770263672\n",
            "||∇_X meta|| = 0.001581465476192534\n",
            "ΔX norm: 1.5814655853318982e-05\n",
            "Stage 5/10:  89%|█████████████████████████▊   | 267/300 [09:44<01:17,  2.35s/it]T Loss=2.303544521331787\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302790641784668\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303556203842163\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034355640411377\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038363456726074\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.03172302246094\n",
            "||∇_X meta|| = 0.0014273141277953982\n",
            "ΔX norm: 1.4273152373789344e-05\n",
            "Stage 5/10:  89%|█████████████████████████▉   | 268/300 [09:46<01:13,  2.28s/it]T Loss=2.304691791534424\n",
            "g_norm = tensor(0.1586, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304522752761841\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031809329986572\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304971218109131\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039636611938477\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.07533264160156\n",
            "||∇_X meta|| = 0.0014953408390283585\n",
            "ΔX norm: 1.4953417121432722e-05\n",
            "Stage 5/10:  90%|██████████████████████████   | 269/300 [09:48<01:09,  2.26s/it]T Loss=2.3027400970458984\n",
            "g_norm = tensor(0.0818, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029046058654785\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303051471710205\n",
            "g_norm = tensor(0.0672, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025107383728027\n",
            "g_norm = tensor(0.0811, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039052486419678\n",
            "g_norm = tensor(0.0809, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.98497009277344\n",
            "||∇_X meta|| = 0.0015740279341116548\n",
            "ΔX norm: 1.5740299204480834e-05\n",
            "Stage 5/10:  90%|██████████████████████████   | 270/300 [09:50<01:08,  2.28s/it]T Loss=2.3034162521362305\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036727905273438\n",
            "g_norm = tensor(0.0775, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038930892944336\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044838905334473\n",
            "g_norm = tensor(0.0878, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30452823638916\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.85377502441406\n",
            "||∇_X meta|| = 0.00163147016428411\n",
            "ΔX norm: 1.6314719687215984e-05\n",
            "Stage 5/10:  90%|██████████████████████████▏  | 271/300 [09:54<01:16,  2.65s/it]T Loss=2.30374813079834\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303204298019409\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303978204727173\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020541667938232\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033547401428223\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.26959228515625\n",
            "||∇_X meta|| = 0.0013981742085888982\n",
            "ΔX norm: 1.3981743904878385e-05\n",
            "Stage 5/10:  91%|██████████████████████████▎  | 272/300 [09:57<01:13,  2.62s/it]T Loss=2.3033642768859863\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032915592193604\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042142391204834\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303889751434326\n",
            "g_norm = tensor(0.1421, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034701347351074\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.81689453125\n",
            "||∇_X meta|| = 0.0014459227677434683\n",
            "ΔX norm: 1.445925317966612e-05\n",
            "Stage 5/10:  91%|██████████████████████████▍  | 273/300 [09:59<01:05,  2.43s/it]T Loss=2.302619457244873\n",
            "g_norm = tensor(0.0787, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302672863006592\n",
            "g_norm = tensor(0.0793, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032479286193848\n",
            "g_norm = tensor(0.0779, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025312423706055\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023948669433594\n",
            "g_norm = tensor(0.0902, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2061309814453\n",
            "||∇_X meta|| = 0.0015687559498474002\n",
            "ΔX norm: 1.5687590348534286e-05\n",
            "Stage 5/10:  91%|██████████████████████████▍  | 274/300 [10:01<01:00,  2.33s/it]T Loss=2.3039004802703857\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028564453125\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038408756256104\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030881881713867\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304384231567383\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0117645263672\n",
            "||∇_X meta|| = 0.001590097788721323\n",
            "ΔX norm: 1.5900966900517233e-05\n",
            "Stage 5/10:  92%|██████████████████████████▌  | 275/300 [10:03<00:55,  2.22s/it]T Loss=2.303666353225708\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304028034210205\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042759895324707\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302462577819824\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30316424369812\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.573974609375\n",
            "||∇_X meta|| = 0.0015443742740899324\n",
            "ΔX norm: 1.5443745724041946e-05\n",
            "Stage 5/10:  92%|██████████████████████████▋  | 276/300 [10:05<00:51,  2.15s/it]T Loss=2.304215908050537\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303910493850708\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304375171661377\n",
            "g_norm = tensor(0.1210, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30295991897583\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303030014038086\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.9183349609375\n",
            "||∇_X meta|| = 0.0014964708825573325\n",
            "ΔX norm: 1.4964699403208215e-05\n",
            "Stage 5/10:  92%|██████████████████████████▊  | 277/300 [10:06<00:47,  2.05s/it]T Loss=2.3048720359802246\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304081439971924\n",
            "g_norm = tensor(0.0746, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046164512634277\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305508852005005\n",
            "g_norm = tensor(0.0803, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303732395172119\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.7925567626953\n",
            "||∇_X meta|| = 0.0015447244513779879\n",
            "ΔX norm: 1.5447221812792122e-05\n",
            "Stage 5/10:  93%|██████████████████████████▊  | 278/300 [10:08<00:44,  2.01s/it]T Loss=2.304743528366089\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305248737335205\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305765151977539\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30350399017334\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304887533187866\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.73565673828125\n",
            "||∇_X meta|| = 0.001540512079373002\n",
            "ΔX norm: 1.540516495879274e-05\n",
            "Stage 5/10:  93%|██████████████████████████▉  | 279/300 [10:10<00:41,  1.98s/it]T Loss=2.304506301879883\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044610023498535\n",
            "g_norm = tensor(0.0776, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303267002105713\n",
            "g_norm = tensor(0.0768, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032562732696533\n",
            "g_norm = tensor(0.0817, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304043769836426\n",
            "g_norm = tensor(0.0823, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.10614013671875\n",
            "||∇_X meta|| = 0.001550867804326117\n",
            "ΔX norm: 1.550870183564257e-05\n",
            "Stage 5/10:  93%|███████████████████████████  | 280/300 [10:12<00:39,  1.97s/it]T Loss=2.3036608695983887\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041234016418457\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302860736846924\n",
            "g_norm = tensor(0.0830, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302779197692871\n",
            "g_norm = tensor(0.0931, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034965991973877\n",
            "g_norm = tensor(0.0933, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.51039123535156\n",
            "||∇_X meta|| = 0.0015497731510549784\n",
            "ΔX norm: 1.54977406054968e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 5/10:  94%|███████████████████████████▏ | 281/300 [10:14<00:37,  1.95s/it]T Loss=2.3035621643066406\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046419620513916\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30428147315979\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046772480010986\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30456280708313\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =233.22528076171875\n",
            "||∇_X meta|| = 0.0014577697729691863\n",
            "ΔX norm: 1.4577654837921727e-05\n",
            "Stage 5/10:  94%|███████████████████████████▎ | 282/300 [10:16<00:36,  2.05s/it]T Loss=2.3050646781921387\n",
            "g_norm = tensor(0.1402, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046374320983887\n",
            "g_norm = tensor(0.1872, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050637245178223\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041343688964844\n",
            "g_norm = tensor(0.1654, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058667182922363\n",
            "g_norm = tensor(0.1695, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.06069946289062\n",
            "||∇_X meta|| = 0.0016945037059485912\n",
            "ΔX norm: 1.6945041352300905e-05\n",
            "Stage 5/10:  94%|███████████████████████████▎ | 283/300 [10:18<00:34,  2.04s/it]T Loss=2.3027377128601074\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303903818130493\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303133010864258\n",
            "g_norm = tensor(0.1333, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303341865539551\n",
            "g_norm = tensor(0.1110, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029470443725586\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.88710021972656\n",
            "||∇_X meta|| = 0.0016131288139149547\n",
            "ΔX norm: 1.6131301890709437e-05\n",
            "Stage 5/10:  95%|███████████████████████████▍ | 284/300 [10:20<00:32,  2.02s/it]T Loss=2.3056154251098633\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037538528442383\n",
            "g_norm = tensor(0.0928, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054261207580566\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049399852752686\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304469108581543\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2444610595703\n",
            "||∇_X meta|| = 0.0015733905602246523\n",
            "ΔX norm: 1.573389454279095e-05\n",
            "Stage 5/10:  95%|███████████████████████████▌ | 285/300 [10:22<00:29,  1.98s/it]T Loss=2.3035800457000732\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303105354309082\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304022789001465\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30326509475708\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303828716278076\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9530487060547\n",
            "||∇_X meta|| = 0.0014898352092131972\n",
            "ΔX norm: 1.4898340850777458e-05\n",
            "Stage 5/10:  95%|███████████████████████████▋ | 286/300 [10:24<00:27,  1.94s/it]T Loss=2.3047354221343994\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043580055236816\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036949634552\n",
            "g_norm = tensor(0.1317, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304863452911377\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050167560577393\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.62042236328125\n",
            "||∇_X meta|| = 0.001791390823200345\n",
            "ΔX norm: 1.7913884221343324e-05\n",
            "Stage 5/10:  96%|███████████████████████████▋ | 287/300 [10:26<00:25,  1.94s/it]T Loss=2.305588722229004\n",
            "g_norm = tensor(0.1819, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039684295654297\n",
            "g_norm = tensor(0.1426, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303590774536133\n",
            "g_norm = tensor(0.1674, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040671348571777\n",
            "g_norm = tensor(0.1415, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043460845947266\n",
            "g_norm = tensor(0.1760, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.22885131835938\n",
            "||∇_X meta|| = 0.0015774001367390156\n",
            "ΔX norm: 1.5774059647810645e-05\n",
            "Stage 5/10:  96%|███████████████████████████▊ | 288/300 [10:28<00:23,  1.93s/it]T Loss=2.3031907081604004\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304138660430908\n",
            "g_norm = tensor(0.0843, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303370952606201\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301274299621582\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030924797058105\n",
            "g_norm = tensor(0.0866, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.91021728515625\n",
            "||∇_X meta|| = 0.0015141507610678673\n",
            "ΔX norm: 1.5141518815653399e-05\n",
            "Stage 5/10:  96%|███████████████████████████▉ | 289/300 [10:30<00:21,  1.93s/it]T Loss=2.3048059940338135\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043506145477295\n",
            "g_norm = tensor(0.1107, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042893409729004\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304478883743286\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30393648147583\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.22183227539062\n",
            "||∇_X meta|| = 0.0016076561296358705\n",
            "ΔX norm: 1.6076548490673304e-05\n",
            "Stage 5/10:  97%|████████████████████████████ | 290/300 [10:32<00:21,  2.12s/it]T Loss=2.303689956665039\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3010966777801514\n",
            "g_norm = tensor(0.1206, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303561210632324\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30529522895813\n",
            "g_norm = tensor(0.1519, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30558705329895\n",
            "g_norm = tensor(0.1576, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8324737548828\n",
            "||∇_X meta|| = 0.001525334781035781\n",
            "ΔX norm: 1.5253354831656907e-05\n",
            "Stage 5/10:  97%|████████████████████████████▏| 291/300 [10:35<00:19,  2.15s/it]T Loss=2.303083658218384\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303802013397217\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304389715194702\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304053783416748\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303344964981079\n",
            "g_norm = tensor(0.0993, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.04931640625\n",
            "||∇_X meta|| = 0.0015919724246487021\n",
            "ΔX norm: 1.5919737052172422e-05\n",
            "Stage 5/10:  97%|████████████████████████████▏| 292/300 [10:37<00:16,  2.12s/it]T Loss=2.3058266639709473\n",
            "g_norm = tensor(0.1539, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029637336730957\n",
            "g_norm = tensor(0.1350, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303309202194214\n",
            "g_norm = tensor(0.1306, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040595054626465\n",
            "g_norm = tensor(0.1464, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303065776824951\n",
            "g_norm = tensor(0.1296, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.64065551757812\n",
            "||∇_X meta|| = 0.0016035723965615034\n",
            "ΔX norm: 1.60357121785637e-05\n",
            "Stage 5/10:  98%|████████████████████████████▎| 293/300 [10:39<00:14,  2.09s/it]T Loss=2.3041510581970215\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051440715789795\n",
            "g_norm = tensor(0.1021, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304757595062256\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049912452697754\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032069206237793\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.24188232421875\n",
            "||∇_X meta|| = 0.0013847313821315765\n",
            "ΔX norm: 1.3847319678461645e-05\n",
            "Stage 5/10:  98%|████████████████████████████▍| 294/300 [10:41<00:12,  2.09s/it]T Loss=2.3038864135742188\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042514324188232\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304579019546509\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30342435836792\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303617238998413\n",
            "g_norm = tensor(0.1383, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.89743041992188\n",
            "||∇_X meta|| = 0.0016378331929445267\n",
            "ΔX norm: 1.637834429857321e-05\n",
            "Stage 5/10:  98%|████████████████████████████▌| 295/300 [10:43<00:10,  2.03s/it]T Loss=2.303879499435425\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028156757354736\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030898571014404\n",
            "g_norm = tensor(0.1296, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30434250831604\n",
            "g_norm = tensor(0.1219, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047804832458496\n",
            "g_norm = tensor(0.1369, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.37692260742188\n",
            "||∇_X meta|| = 0.0016444994835183024\n",
            "ΔX norm: 1.644500116526615e-05\n",
            "Stage 5/10:  99%|████████████████████████████▌| 296/300 [10:45<00:08,  2.02s/it]T Loss=2.304497241973877\n",
            "g_norm = tensor(0.1463, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304739475250244\n",
            "g_norm = tensor(0.1659, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023009300231934\n",
            "g_norm = tensor(0.1497, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033902645111084\n",
            "g_norm = tensor(0.1873, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053524494171143\n",
            "g_norm = tensor(0.1355, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.6297607421875\n",
            "||∇_X meta|| = 0.0016218188684433699\n",
            "ΔX norm: 1.6218253222177736e-05\n",
            "Stage 5/10:  99%|████████████████████████████▋| 297/300 [10:47<00:05,  1.99s/it]T Loss=2.303184986114502\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304882287979126\n",
            "g_norm = tensor(0.1320, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304171562194824\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056817054748535\n",
            "g_norm = tensor(0.1340, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031070232391357\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.90872192382812\n",
            "||∇_X meta|| = 0.0016920279012992978\n",
            "ΔX norm: 1.6920294001465663e-05\n",
            "Stage 5/10:  99%|████████████████████████████▊| 298/300 [10:48<00:03,  1.95s/it]T Loss=2.304309368133545\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303746223449707\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042688369750977\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043739795684814\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030123710632324\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1993408203125\n",
            "||∇_X meta|| = 0.0014800794888287783\n",
            "ΔX norm: 1.4800811186432838e-05\n",
            "Stage 5/10: 100%|████████████████████████████▉| 299/300 [10:50<00:01,  1.95s/it]T Loss=2.3045694828033447\n",
            "g_norm = tensor(0.1756, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044276237487793\n",
            "g_norm = tensor(0.1842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046157360076904\n",
            "g_norm = tensor(0.1723, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302940845489502\n",
            "g_norm = tensor(0.1794, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3069825172424316\n",
            "g_norm = tensor(0.1849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.68328857421875\n",
            "||∇_X meta|| = 0.0014832689194008708\n",
            "ΔX norm: 1.4832708075118717e-05\n",
            "Stage 4, class 0, loss 2.208                                                    \n",
            "Stage 4, class 1, loss 2.268\n",
            "Stage 4, class 2, loss 2.341\n",
            "Stage 4, class 3, loss 2.359\n",
            "Stage 4, class 4, loss 2.306\n",
            "Stage 4, class 5, loss 2.327\n",
            "Stage 4, class 6, loss 2.385\n",
            "Stage 4, class 7, loss 2.223\n",
            "Stage 4, class 8, loss 2.374\n",
            "Stage 4, class 9, loss 2.256\n",
            "Stage 6/10:   0%|                                       | 0/300 [00:00<?, ?it/s]T Loss=2.3041863441467285\n",
            "g_norm = tensor(0.0993, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027164936065674\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028934001922607\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048737049102783\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027775287628174\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3273162841797\n",
            "||∇_X meta|| = 0.0034130557905882597\n",
            "ΔX norm: 3.413061494939029e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 6/10:   0%|                               | 1/300 [00:02<11:11,  2.25s/it]T Loss=2.304978609085083\n",
            "g_norm = tensor(0.1251, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305417060852051\n",
            "g_norm = tensor(0.1297, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042190074920654\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044075965881348\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044698238372803\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.52479553222656\n",
            "||∇_X meta|| = 0.003521447768434882\n",
            "ΔX norm: 3.5214441595599055e-05\n",
            "Stage 6/10:   1%|▏                              | 2/300 [00:04<11:43,  2.36s/it]T Loss=2.302581787109375\n",
            "g_norm = tensor(0.1463, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031275272369385\n",
            "g_norm = tensor(0.1542, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3004376888275146\n",
            "g_norm = tensor(0.1792, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3015084266662598\n",
            "g_norm = tensor(0.1271, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021507263183594\n",
            "g_norm = tensor(0.1225, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0818328857422\n",
            "||∇_X meta|| = 0.004135661758482456\n",
            "ΔX norm: 4.1356666770298034e-05\n",
            "Stage 6/10:   1%|▎                              | 3/300 [00:06<11:16,  2.28s/it]T Loss=2.3020122051239014\n",
            "g_norm = tensor(0.1436, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040213584899902\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026509284973145\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302333354949951\n",
            "g_norm = tensor(0.1391, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029983043670654\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.58262634277344\n",
            "||∇_X meta|| = 0.0039829364977777\n",
            "ΔX norm: 3.982934504165314e-05\n",
            "Stage 6/10:   1%|▍                              | 4/300 [00:09<12:27,  2.53s/it]T Loss=2.30346417427063\n",
            "g_norm = tensor(0.1545, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025259971618652\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303590774536133\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302487373352051\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031299114227295\n",
            "g_norm = tensor(0.1501, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.36886596679688\n",
            "||∇_X meta|| = 0.00362926977686584\n",
            "ΔX norm: 3.6292716686148196e-05\n",
            "Stage 6/10:   2%|▌                              | 5/300 [00:12<11:56,  2.43s/it]T Loss=2.3034424781799316\n",
            "g_norm = tensor(0.0755, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303679943084717\n",
            "g_norm = tensor(0.0810, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303514003753662\n",
            "g_norm = tensor(0.0923, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039278984069824\n",
            "g_norm = tensor(0.0629, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303187608718872\n",
            "g_norm = tensor(0.0827, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.36851501464844\n",
            "||∇_X meta|| = 0.003797580022364855\n",
            "ΔX norm: 3.797577301156707e-05\n",
            "Stage 6/10:   2%|▌                              | 6/300 [00:13<11:05,  2.26s/it]T Loss=2.3043951988220215\n",
            "g_norm = tensor(0.1487, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038063049316406\n",
            "g_norm = tensor(0.1573, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306142807006836\n",
            "g_norm = tensor(0.1535, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304529905319214\n",
            "g_norm = tensor(0.1946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046300411224365\n",
            "g_norm = tensor(0.1602, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2837371826172\n",
            "||∇_X meta|| = 0.003505571512505412\n",
            "ΔX norm: 3.505576751194894e-05\n",
            "Stage 6/10:   2%|▋                              | 7/300 [00:15<10:40,  2.19s/it]T Loss=2.304166793823242\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304137706756592\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058042526245117\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305354118347168\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048315048217773\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.72325134277344\n",
            "||∇_X meta|| = 0.003945779055356979\n",
            "ΔX norm: 3.945780190406367e-05\n",
            "Stage 6/10:   3%|▊                              | 8/300 [00:17<10:19,  2.12s/it]T Loss=2.302039623260498\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035037517547607\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035695552825928\n",
            "g_norm = tensor(0.0879, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032989501953125\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301889419555664\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.37782287597656\n",
            "||∇_X meta|| = 0.0034558139741420746\n",
            "ΔX norm: 3.45581465808209e-05\n",
            "Stage 6/10:   3%|▉                              | 9/300 [00:19<10:05,  2.08s/it]T Loss=2.3043744564056396\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024322986602783\n",
            "g_norm = tensor(0.1278, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303828716278076\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026959896087646\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035998344421387\n",
            "g_norm = tensor(0.1301, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.90940856933594\n",
            "||∇_X meta|| = 0.003948147874325514\n",
            "ΔX norm: 3.9481463318224996e-05\n",
            "Stage 6/10:   3%|█                             | 10/300 [00:21<09:53,  2.05s/it]T Loss=2.3034420013427734\n",
            "g_norm = tensor(0.0850, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303697347640991\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304391384124756\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031139373779297\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039021492004395\n",
            "g_norm = tensor(0.0806, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.23631286621094\n",
            "||∇_X meta|| = 0.003703881287947297\n",
            "ΔX norm: 3.7038818845758215e-05\n",
            "Stage 6/10:   4%|█                             | 11/300 [00:23<09:47,  2.03s/it]T Loss=2.3028767108917236\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027303218841553\n",
            "g_norm = tensor(0.1323, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024067878723145\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031604290008545\n",
            "g_norm = tensor(0.1219, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037490844726562\n",
            "g_norm = tensor(0.1334, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4988555908203\n",
            "||∇_X meta|| = 0.003712095320224762\n",
            "ΔX norm: 3.7120938941370696e-05\n",
            "Stage 6/10:   4%|█▏                            | 12/300 [00:25<09:41,  2.02s/it]T Loss=2.3032281398773193\n",
            "g_norm = tensor(0.1606, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304548740386963\n",
            "g_norm = tensor(0.1531, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303880214691162\n",
            "g_norm = tensor(0.1708, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038713932037354\n",
            "g_norm = tensor(0.1855, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304068088531494\n",
            "g_norm = tensor(0.1663, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7198944091797\n",
            "||∇_X meta|| = 0.0034029523376375437\n",
            "ΔX norm: 3.402947913855314e-05\n",
            "Stage 6/10:   4%|█▎                            | 13/300 [00:27<09:29,  1.98s/it]T Loss=2.304060697555542\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045496940612793\n",
            "g_norm = tensor(0.0827, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039791584014893\n",
            "g_norm = tensor(0.1250, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303798198699951\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040459156036377\n",
            "g_norm = tensor(0.0854, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.80751037597656\n",
            "||∇_X meta|| = 0.0035369847901165485\n",
            "ΔX norm: 3.5369826946407557e-05\n",
            "Stage 6/10:   5%|█▍                            | 14/300 [00:29<09:33,  2.01s/it]T Loss=2.3042163848876953\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045384883880615\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036630153656006\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040432929992676\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036131858825684\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.76144409179688\n",
            "||∇_X meta|| = 0.00324804475530982\n",
            "ΔX norm: 3.248043867642991e-05\n",
            "Stage 6/10:   5%|█▌                            | 15/300 [00:31<09:14,  1.95s/it]T Loss=2.30515718460083\n",
            "g_norm = tensor(0.1406, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3059263229370117\n",
            "g_norm = tensor(0.1527, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304912567138672\n",
            "g_norm = tensor(0.1368, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044753074645996\n",
            "g_norm = tensor(0.1466, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056774139404297\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.36569213867188\n",
            "||∇_X meta|| = 0.0033872323110699654\n",
            "ΔX norm: 3.387234755791724e-05\n",
            "Stage 6/10:   5%|█▌                            | 16/300 [00:33<09:35,  2.02s/it]T Loss=2.3036715984344482\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035361766815186\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054070472717285\n",
            "g_norm = tensor(0.1388, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054888248443604\n",
            "g_norm = tensor(0.1297, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042588233947754\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9257354736328\n",
            "||∇_X meta|| = 0.003279587486758828\n",
            "ΔX norm: 3.279585507698357e-05\n",
            "Stage 6/10:   6%|█▋                            | 17/300 [00:35<09:33,  2.03s/it]T Loss=2.30357027053833\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038785457611084\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304748058319092\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304248332977295\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306267261505127\n",
            "g_norm = tensor(0.1356, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5640411376953\n",
            "||∇_X meta|| = 0.003777812235057354\n",
            "ΔX norm: 3.777809251914732e-05\n",
            "Stage 6/10:   6%|█▊                            | 18/300 [00:38<10:14,  2.18s/it]T Loss=2.306579351425171\n",
            "g_norm = tensor(0.1809, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053689002990723\n",
            "g_norm = tensor(0.1797, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032097816467285\n",
            "g_norm = tensor(0.1519, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30582857131958\n",
            "g_norm = tensor(0.1626, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049497604370117\n",
            "g_norm = tensor(0.1598, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.54150390625\n",
            "||∇_X meta|| = 0.0033458974212408066\n",
            "ΔX norm: 3.345894583617337e-05\n",
            "Stage 6/10:   6%|█▉                            | 19/300 [00:40<10:15,  2.19s/it]T Loss=2.3029866218566895\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303818464279175\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303586959838867\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036229610443115\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303527355194092\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.67550659179688\n",
            "||∇_X meta|| = 0.003215592820197344\n",
            "ΔX norm: 3.215594551875256e-05\n",
            "Stage 6/10:   7%|██                            | 20/300 [00:42<09:52,  2.12s/it]T Loss=2.3046932220458984\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303305149078369\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045802116394043\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030142784118652\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038125038146973\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.21017456054688\n",
            "||∇_X meta|| = 0.003275454044342041\n",
            "ΔX norm: 3.275453491369262e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 6/10:   7%|██                            | 21/300 [00:44<09:36,  2.07s/it]T Loss=2.303366184234619\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038761615753174\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038852214813232\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037612438201904\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027262687683105\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.62376403808594\n",
            "||∇_X meta|| = 0.00323243229649961\n",
            "ΔX norm: 3.232435483369045e-05\n",
            "Stage 6/10:   7%|██▏                           | 22/300 [00:47<10:05,  2.18s/it]T Loss=2.3029980659484863\n",
            "g_norm = tensor(0.0890, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041584491729736\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035778999328613\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304687976837158\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033547401428223\n",
            "g_norm = tensor(0.1154, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7117462158203\n",
            "||∇_X meta|| = 0.002975624753162265\n",
            "ΔX norm: 2.9756231015198864e-05\n",
            "Stage 6/10:   8%|██▎                           | 23/300 [00:49<09:59,  2.16s/it]T Loss=2.3042213916778564\n",
            "g_norm = tensor(0.1409, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304659366607666\n",
            "g_norm = tensor(0.1598, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046317100524902\n",
            "g_norm = tensor(0.1416, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306312084197998\n",
            "g_norm = tensor(0.1397, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304037570953369\n",
            "g_norm = tensor(0.1364, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.11282348632812\n",
            "||∇_X meta|| = 0.0029807810205966234\n",
            "ΔX norm: 2.9807792088831775e-05\n",
            "Stage 6/10:   8%|██▍                           | 24/300 [00:51<09:35,  2.09s/it]T Loss=2.3038363456726074\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305326461791992\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30488657951355\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040566444396973\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305081605911255\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6648406982422\n",
            "||∇_X meta|| = 0.0033997970167547464\n",
            "ΔX norm: 3.3997941500274464e-05\n",
            "Stage 6/10:   8%|██▌                           | 25/300 [00:53<09:22,  2.05s/it]T Loss=2.3051843643188477\n",
            "g_norm = tensor(0.1648, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305854320526123\n",
            "g_norm = tensor(0.1549, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043861389160156\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046762943267822\n",
            "g_norm = tensor(0.1450, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303114891052246\n",
            "g_norm = tensor(0.1478, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.56671142578125\n",
            "||∇_X meta|| = 0.003223996376618743\n",
            "ΔX norm: 3.2239950087387115e-05\n",
            "Stage 6/10:   9%|██▌                           | 26/300 [00:55<09:57,  2.18s/it]T Loss=2.302250862121582\n",
            "g_norm = tensor(0.1317, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024706840515137\n",
            "g_norm = tensor(0.1377, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038651943206787\n",
            "g_norm = tensor(0.1541, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044049739837646\n",
            "g_norm = tensor(0.1494, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050081729888916\n",
            "g_norm = tensor(0.1436, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8257598876953\n",
            "||∇_X meta|| = 0.003215334378182888\n",
            "ΔX norm: 3.2153311622096226e-05\n",
            "Stage 6/10:   9%|██▋                           | 27/300 [00:57<09:38,  2.12s/it]T Loss=2.304917812347412\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039679527282715\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303941011428833\n",
            "g_norm = tensor(0.1107, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044180870056152\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303299903869629\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.39825439453125\n",
            "||∇_X meta|| = 0.0031841688323765993\n",
            "ΔX norm: 3.184170418535359e-05\n",
            "Stage 6/10:   9%|██▊                           | 28/300 [00:59<09:19,  2.06s/it]T Loss=2.3049187660217285\n",
            "g_norm = tensor(0.1259, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038241863250732\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030619621276855\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301952362060547\n",
            "g_norm = tensor(0.1282, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026835918426514\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2725830078125\n",
            "||∇_X meta|| = 0.0029337762389332056\n",
            "ΔX norm: 2.9337763407966122e-05\n",
            "Stage 6/10:  10%|██▉                           | 29/300 [01:01<09:18,  2.06s/it]T Loss=2.305138111114502\n",
            "g_norm = tensor(0.1472, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052589893341064\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026835918426514\n",
            "g_norm = tensor(0.1251, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046040534973145\n",
            "g_norm = tensor(0.1306, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048672676086426\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5890350341797\n",
            "||∇_X meta|| = 0.0034456225112080574\n",
            "ΔX norm: 3.445621769060381e-05\n",
            "Stage 6/10:  10%|███                           | 30/300 [01:03<09:35,  2.13s/it]T Loss=2.303732395172119\n",
            "g_norm = tensor(0.0947, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037471771240234\n",
            "g_norm = tensor(0.0847, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034043312072754\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302361249923706\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303853750228882\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4404296875\n",
            "||∇_X meta|| = 0.0030847766902297735\n",
            "ΔX norm: 3.084777563344687e-05\n",
            "Stage 6/10:  10%|███                           | 31/300 [01:05<09:25,  2.10s/it]T Loss=2.3036534786224365\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018879890441895\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031563758850098\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026938438415527\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038878440856934\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.68060302734375\n",
            "||∇_X meta|| = 0.0028193769976496696\n",
            "ΔX norm: 2.819374276441522e-05\n",
            "Stage 6/10:  11%|███▏                          | 32/300 [01:07<09:07,  2.04s/it]T Loss=2.3036606311798096\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044447898864746\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041880130767822\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304753303527832\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041112422943115\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.82257080078125\n",
            "||∇_X meta|| = 0.0029330060351639986\n",
            "ΔX norm: 2.933008727268316e-05\n",
            "Stage 6/10:  11%|███▎                          | 33/300 [01:10<09:43,  2.19s/it]T Loss=2.30326509475708\n",
            "g_norm = tensor(0.1808, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033435344696045\n",
            "g_norm = tensor(0.1579, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302879810333252\n",
            "g_norm = tensor(0.1942, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303650379180908\n",
            "g_norm = tensor(0.1888, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301319122314453\n",
            "g_norm = tensor(0.1622, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.89825439453125\n",
            "||∇_X meta|| = 0.0030333937611430883\n",
            "ΔX norm: 3.033395296370145e-05\n",
            "Stage 6/10:  11%|███▍                          | 34/300 [01:12<09:26,  2.13s/it]T Loss=2.3038179874420166\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028955459594727\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044440746307373\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031373023986816\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037540912628174\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.15879821777344\n",
            "||∇_X meta|| = 0.002684606472030282\n",
            "ΔX norm: 2.6846106266020797e-05\n",
            "Stage 6/10:  12%|███▌                          | 35/300 [01:14<09:18,  2.11s/it]T Loss=2.303619384765625\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038604259490967\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304619550704956\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037753105163574\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045499324798584\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.26266479492188\n",
            "||∇_X meta|| = 0.003021754091605544\n",
            "ΔX norm: 3.0217539460863918e-05\n",
            "Stage 6/10:  12%|███▌                          | 36/300 [01:16<09:07,  2.07s/it]T Loss=2.303023338317871\n",
            "g_norm = tensor(0.1214, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020670413970947\n",
            "g_norm = tensor(0.1420, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3014976978302\n",
            "g_norm = tensor(0.1728, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023674488067627\n",
            "g_norm = tensor(0.1427, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302201747894287\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.82830810546875\n",
            "||∇_X meta|| = 0.003467351896688342\n",
            "ΔX norm: 3.4673528716666624e-05\n",
            "Stage 6/10:  12%|███▋                          | 37/300 [01:18<09:04,  2.07s/it]T Loss=2.3051745891571045\n",
            "g_norm = tensor(0.1593, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041718006134033\n",
            "g_norm = tensor(0.1649, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305546283721924\n",
            "g_norm = tensor(0.1599, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304769515991211\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043341636657715\n",
            "g_norm = tensor(0.1502, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =233.14398193359375\n",
            "||∇_X meta|| = 0.003151861485093832\n",
            "ΔX norm: 3.1518578907707706e-05\n",
            "Stage 6/10:  13%|███▊                          | 38/300 [01:20<09:03,  2.07s/it]T Loss=2.3040971755981445\n",
            "g_norm = tensor(0.0811, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044347763061523\n",
            "g_norm = tensor(0.0781, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303913116455078\n",
            "g_norm = tensor(0.0917, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304854154586792\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303279161453247\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.744384765625\n",
            "||∇_X meta|| = 0.0024785585701465607\n",
            "ΔX norm: 2.478554961271584e-05\n",
            "Stage 6/10:  13%|███▉                          | 39/300 [01:22<08:51,  2.04s/it]T Loss=2.30448055267334\n",
            "g_norm = tensor(0.1473, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048737049102783\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304405927658081\n",
            "g_norm = tensor(0.0942, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018503189086914\n",
            "g_norm = tensor(0.1314, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053061962127686\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1348114013672\n",
            "||∇_X meta|| = 0.0026314782444387674\n",
            "ΔX norm: 2.631476309034042e-05\n",
            "Stage 6/10:  13%|████                          | 40/300 [01:24<08:50,  2.04s/it]T Loss=2.3042633533477783\n",
            "g_norm = tensor(0.1765, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031582832336426\n",
            "g_norm = tensor(0.1655, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030102252960205\n",
            "g_norm = tensor(0.1803, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303950786590576\n",
            "g_norm = tensor(0.1503, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032326698303223\n",
            "g_norm = tensor(0.1646, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9289093017578\n",
            "||∇_X meta|| = 0.0028720428235828876\n",
            "ΔX norm: 2.8720385671476834e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 6/10:  14%|████                          | 41/300 [01:26<08:38,  2.00s/it]T Loss=2.303269147872925\n",
            "g_norm = tensor(0.1347, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026885986328125\n",
            "g_norm = tensor(0.1347, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029608726501465\n",
            "g_norm = tensor(0.1389, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030545711517334\n",
            "g_norm = tensor(0.1489, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039348125457764\n",
            "g_norm = tensor(0.1453, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.676025390625\n",
            "||∇_X meta|| = 0.0027353467885404825\n",
            "ΔX norm: 2.7353489713277668e-05\n",
            "Stage 6/10:  14%|████▏                         | 42/300 [01:29<09:29,  2.21s/it]T Loss=2.3040664196014404\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303269624710083\n",
            "g_norm = tensor(0.1250, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033576011657715\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302898406982422\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042547702789307\n",
            "g_norm = tensor(0.1354, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.6785125732422\n",
            "||∇_X meta|| = 0.0027335654012858868\n",
            "ΔX norm: 2.7335601771483198e-05\n",
            "Stage 6/10:  14%|████▎                         | 43/300 [01:31<09:13,  2.15s/it]T Loss=2.302271842956543\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020312786102295\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30299711227417\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030648231506348\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30314564704895\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4222412109375\n",
            "||∇_X meta|| = 0.0028573800809681416\n",
            "ΔX norm: 2.8573818781296723e-05\n",
            "Stage 6/10:  15%|████▍                         | 44/300 [01:32<08:52,  2.08s/it]T Loss=2.302628993988037\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302672863006592\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30372953414917\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303823471069336\n",
            "g_norm = tensor(0.1140, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035900592803955\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.6438446044922\n",
            "||∇_X meta|| = 0.0024565313942730427\n",
            "ΔX norm: 2.456529728078749e-05\n",
            "Stage 6/10:  15%|████▌                         | 45/300 [01:34<08:26,  1.99s/it]T Loss=2.3037614822387695\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042783737182617\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027710914611816\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037781715393066\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038835525512695\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1968231201172\n",
            "||∇_X meta|| = 0.002575882012024522\n",
            "ΔX norm: 2.5758854462765157e-05\n",
            "Stage 6/10:  15%|████▌                         | 46/300 [01:36<08:11,  1.93s/it]T Loss=2.303128719329834\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302427291870117\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302496910095215\n",
            "g_norm = tensor(0.1099, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303255081176758\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302455425262451\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5687255859375\n",
            "||∇_X meta|| = 0.002644964959472418\n",
            "ΔX norm: 2.6449644792592153e-05\n",
            "Stage 6/10:  16%|████▋                         | 47/300 [01:38<08:03,  1.91s/it]T Loss=2.303480863571167\n",
            "g_norm = tensor(0.1333, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035836219787598\n",
            "g_norm = tensor(0.1299, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304865837097168\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042795658111572\n",
            "g_norm = tensor(0.1437, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303234815597534\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.994873046875\n",
            "||∇_X meta|| = 0.002540155313909054\n",
            "ΔX norm: 2.5401544917258434e-05\n",
            "Stage 6/10:  16%|████▊                         | 48/300 [01:40<07:54,  1.88s/it]T Loss=2.3043599128723145\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031539916992188\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022851943969727\n",
            "g_norm = tensor(0.1250, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303790330886841\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024373054504395\n",
            "g_norm = tensor(0.1235, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.4374237060547\n",
            "||∇_X meta|| = 0.0027732697781175375\n",
            "ΔX norm: 2.7732701710192487e-05\n",
            "Stage 6/10:  16%|████▉                         | 49/300 [01:42<07:47,  1.86s/it]T Loss=2.3025717735290527\n",
            "g_norm = tensor(0.1648, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024282455444336\n",
            "g_norm = tensor(0.1331, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038249015808105\n",
            "g_norm = tensor(0.1688, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301882266998291\n",
            "g_norm = tensor(0.1348, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045878410339355\n",
            "g_norm = tensor(0.1505, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.23898315429688\n",
            "||∇_X meta|| = 0.00248773954808712\n",
            "ΔX norm: 2.487742676748894e-05\n",
            "Stage 6/10:  17%|█████                         | 50/300 [01:43<07:41,  1.85s/it]T Loss=2.302699327468872\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303271770477295\n",
            "g_norm = tensor(0.1206, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303840160369873\n",
            "g_norm = tensor(0.1673, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033392429351807\n",
            "g_norm = tensor(0.1221, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303590774536133\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.61415100097656\n",
            "||∇_X meta|| = 0.0024121995083987713\n",
            "ΔX norm: 2.41219768213341e-05\n",
            "Stage 6/10:  17%|█████                         | 51/300 [01:45<07:34,  1.83s/it]T Loss=2.303236722946167\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030924797058105\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032584190368652\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025877475738525\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037264347076416\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5743865966797\n",
            "||∇_X meta|| = 0.0029302046168595552\n",
            "ΔX norm: 2.93020984827308e-05\n",
            "Stage 6/10:  17%|█████▏                        | 52/300 [01:47<07:43,  1.87s/it]T Loss=2.303189992904663\n",
            "g_norm = tensor(0.1440, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305345296859741\n",
            "g_norm = tensor(0.1342, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30346417427063\n",
            "g_norm = tensor(0.1486, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303697109222412\n",
            "g_norm = tensor(0.1431, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303190231323242\n",
            "g_norm = tensor(0.1309, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.07330322265625\n",
            "||∇_X meta|| = 0.002460503252223134\n",
            "ΔX norm: 2.460504401824437e-05\n",
            "Stage 6/10:  18%|█████▎                        | 53/300 [01:49<07:52,  1.91s/it]T Loss=2.304234504699707\n",
            "g_norm = tensor(0.1401, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302727699279785\n",
            "g_norm = tensor(0.1475, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037350177764893\n",
            "g_norm = tensor(0.1550, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302720308303833\n",
            "g_norm = tensor(0.1488, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303112745285034\n",
            "g_norm = tensor(0.1531, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.84312438964844\n",
            "||∇_X meta|| = 0.002571816323325038\n",
            "ΔX norm: 2.571817640273366e-05\n",
            "Stage 6/10:  18%|█████▍                        | 54/300 [01:51<07:48,  1.91s/it]T Loss=2.303597927093506\n",
            "g_norm = tensor(0.1301, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032515048980713\n",
            "g_norm = tensor(0.1210, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304826021194458\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038816452026367\n",
            "g_norm = tensor(0.1282, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303806781768799\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.30038452148438\n",
            "||∇_X meta|| = 0.0025418384466320276\n",
            "ΔX norm: 2.541838875913527e-05\n",
            "Stage 6/10:  18%|█████▌                        | 55/300 [01:53<07:41,  1.88s/it]T Loss=2.303248167037964\n",
            "g_norm = tensor(0.0813, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028564453125\n",
            "g_norm = tensor(0.0832, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303539514541626\n",
            "g_norm = tensor(0.0786, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042702674865723\n",
            "g_norm = tensor(0.0764, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023433685302734\n",
            "g_norm = tensor(0.0811, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0270538330078\n",
            "||∇_X meta|| = 0.002373747993260622\n",
            "ΔX norm: 2.373748429818079e-05\n",
            "Stage 6/10:  19%|█████▌                        | 56/300 [01:55<07:35,  1.87s/it]T Loss=2.3041300773620605\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304542064666748\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304342031478882\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303417682647705\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304424524307251\n",
            "g_norm = tensor(0.1255, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7166748046875\n",
            "||∇_X meta|| = 0.0024707417469471693\n",
            "ΔX norm: 2.470737490511965e-05\n",
            "Stage 6/10:  19%|█████▋                        | 57/300 [01:57<07:42,  1.90s/it]T Loss=2.303623914718628\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302722215652466\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304682731628418\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303823947906494\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027777671813965\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.66375732421875\n",
            "||∇_X meta|| = 0.0024831064511090517\n",
            "ΔX norm: 2.483105708961375e-05\n",
            "Stage 6/10:  19%|█████▊                        | 58/300 [01:58<07:34,  1.88s/it]T Loss=2.3039517402648926\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303490161895752\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032801151275635\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301469326019287\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304281234741211\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.3934326171875\n",
            "||∇_X meta|| = 0.002296928782016039\n",
            "ΔX norm: 2.296927777933888e-05\n",
            "Stage 6/10:  20%|█████▉                        | 59/300 [02:01<07:48,  1.94s/it]T Loss=2.302396535873413\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302809953689575\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30293607711792\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303255319595337\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303338050842285\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.73033142089844\n",
            "||∇_X meta|| = 0.0022227459121495485\n",
            "ΔX norm: 2.222745752078481e-05\n",
            "Stage 6/10:  20%|██████                        | 60/300 [02:02<07:43,  1.93s/it]T Loss=2.3032026290893555\n",
            "g_norm = tensor(0.1154, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303987979888916\n",
            "g_norm = tensor(0.1262, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302375316619873\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039000034332275\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302621364593506\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.36029052734375\n",
            "||∇_X meta|| = 0.002279333770275116\n",
            "ΔX norm: 2.2793334210291505e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 6/10:  20%|██████                        | 61/300 [02:04<07:36,  1.91s/it]T Loss=2.301158905029297\n",
            "g_norm = tensor(0.1414, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.300711154937744\n",
            "g_norm = tensor(0.1524, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302647829055786\n",
            "g_norm = tensor(0.1347, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3013129234313965\n",
            "g_norm = tensor(0.1616, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3012876510620117\n",
            "g_norm = tensor(0.1620, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.65548706054688\n",
            "||∇_X meta|| = 0.0024808847811073065\n",
            "ΔX norm: 2.4808801754261367e-05\n",
            "Stage 6/10:  21%|██████▏                       | 62/300 [02:07<08:04,  2.03s/it]T Loss=2.3032493591308594\n",
            "g_norm = tensor(0.1221, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303893566131592\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036370277404785\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019936084747314\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032021522521973\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.08328247070312\n",
            "||∇_X meta|| = 0.0026594994124025106\n",
            "ΔX norm: 2.659497295098845e-05\n",
            "Stage 6/10:  21%|██████▎                       | 63/300 [02:09<08:29,  2.15s/it]T Loss=2.303663730621338\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036136627197266\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303997278213501\n",
            "g_norm = tensor(0.1538, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303774833679199\n",
            "g_norm = tensor(0.1424, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019821643829346\n",
            "g_norm = tensor(0.1474, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.33285522460938\n",
            "||∇_X meta|| = 0.0024829136673361063\n",
            "ΔX norm: 2.4829147150740027e-05\n",
            "Stage 6/10:  21%|██████▍                       | 64/300 [02:11<08:23,  2.14s/it]T Loss=2.303673267364502\n",
            "g_norm = tensor(0.0983, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303311586380005\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302680492401123\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302724599838257\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038973808288574\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.01504516601562\n",
            "||∇_X meta|| = 0.0023483566474169493\n",
            "ΔX norm: 2.348358066228684e-05\n",
            "Stage 6/10:  22%|██████▌                       | 65/300 [02:13<08:02,  2.05s/it]T Loss=2.304576873779297\n",
            "g_norm = tensor(0.1712, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304152011871338\n",
            "g_norm = tensor(0.1996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019676208496094\n",
            "g_norm = tensor(0.1958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032286167144775\n",
            "g_norm = tensor(0.1464, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051815032958984\n",
            "g_norm = tensor(0.2134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0942840576172\n",
            "||∇_X meta|| = 0.0021749222651124\n",
            "ΔX norm: 2.174927794840187e-05\n",
            "Stage 6/10:  22%|██████▌                       | 66/300 [02:15<07:51,  2.02s/it]T Loss=2.303493022918701\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301614761352539\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048856258392334\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035552501678467\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302931308746338\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.6550750732422\n",
            "||∇_X meta|| = 0.0021693201269954443\n",
            "ΔX norm: 2.169320941902697e-05\n",
            "Stage 6/10:  22%|██████▋                       | 67/300 [02:17<07:37,  1.96s/it]T Loss=2.3041770458221436\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038763999938965\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035013675689697\n",
            "g_norm = tensor(0.1140, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035378456115723\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302841901779175\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.45799255371094\n",
            "||∇_X meta|| = 0.002585944253951311\n",
            "ΔX norm: 2.5859431843855418e-05\n",
            "Stage 6/10:  23%|██████▊                       | 68/300 [02:19<07:48,  2.02s/it]T Loss=2.302846908569336\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303067207336426\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029561042785645\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034636974334717\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302628755569458\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2652587890625\n",
            "||∇_X meta|| = 0.002146030543372035\n",
            "ΔX norm: 2.146034239558503e-05\n",
            "Stage 6/10:  23%|██████▉                       | 69/300 [02:21<07:37,  1.98s/it]T Loss=2.303396701812744\n",
            "g_norm = tensor(0.0717, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043389320373535\n",
            "g_norm = tensor(0.0831, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041152954101562\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033435344696045\n",
            "g_norm = tensor(0.0680, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039612770080566\n",
            "g_norm = tensor(0.0820, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8943328857422\n",
            "||∇_X meta|| = 0.002242632210254669\n",
            "ΔX norm: 2.242631853732746e-05\n",
            "Stage 6/10:  23%|███████                       | 70/300 [02:23<07:22,  1.92s/it]T Loss=2.3048527240753174\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305018663406372\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303589344024658\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303520679473877\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302624464035034\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5907440185547\n",
            "||∇_X meta|| = 0.0024363177362829447\n",
            "ΔX norm: 2.4363207558053546e-05\n",
            "Stage 6/10:  24%|███████                       | 71/300 [02:24<07:13,  1.89s/it]T Loss=2.3032584190368652\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036320209503174\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303056001663208\n",
            "g_norm = tensor(0.1347, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045613765716553\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040623664855957\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.03118896484375\n",
            "||∇_X meta|| = 0.0023061297833919525\n",
            "ΔX norm: 2.306130227225367e-05\n",
            "Stage 6/10:  24%|███████▏                      | 72/300 [02:26<07:06,  1.87s/it]T Loss=2.3030853271484375\n",
            "g_norm = tensor(0.1793, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033504486083984\n",
            "g_norm = tensor(0.1807, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032150268554688\n",
            "g_norm = tensor(0.1859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302398204803467\n",
            "g_norm = tensor(0.1819, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304948091506958\n",
            "g_norm = tensor(0.1883, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.79176330566406\n",
            "||∇_X meta|| = 0.0023655961267650127\n",
            "ΔX norm: 2.3655999029870145e-05\n",
            "Stage 6/10:  24%|███████▎                      | 73/300 [02:28<07:16,  1.92s/it]T Loss=2.303335189819336\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304046154022217\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302628517150879\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302492618560791\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301978349685669\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.13279724121094\n",
            "||∇_X meta|| = 0.0022939385380595922\n",
            "ΔX norm: 2.2939399059396237e-05\n",
            "Stage 6/10:  25%|███████▍                      | 74/300 [02:30<07:12,  1.91s/it]T Loss=2.3028411865234375\n",
            "g_norm = tensor(0.1345, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301840305328369\n",
            "g_norm = tensor(0.1153, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019511699676514\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027100563049316\n",
            "g_norm = tensor(0.0739, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304075241088867\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.58145141601562\n",
            "||∇_X meta|| = 0.002106898697093129\n",
            "ΔX norm: 2.106897773046512e-05\n",
            "Stage 6/10:  25%|███████▌                      | 75/300 [02:32<07:05,  1.89s/it]T Loss=2.3053791522979736\n",
            "g_norm = tensor(0.1553, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031182289123535\n",
            "g_norm = tensor(0.1323, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050758838653564\n",
            "g_norm = tensor(0.1563, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034751415252686\n",
            "g_norm = tensor(0.1469, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038275241851807\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9502716064453\n",
            "||∇_X meta|| = 0.002590785501524806\n",
            "ΔX norm: 2.590788426459767e-05\n",
            "Stage 6/10:  25%|███████▌                      | 76/300 [02:34<07:16,  1.95s/it]T Loss=2.3034520149230957\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038055896759033\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034355640411377\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048925399780273\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304471492767334\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.75559997558594\n",
            "||∇_X meta|| = 0.0023292184341698885\n",
            "ΔX norm: 2.3292197511182167e-05\n",
            "Stage 6/10:  26%|███████▋                      | 77/300 [02:36<07:11,  1.94s/it]T Loss=2.303605318069458\n",
            "g_norm = tensor(0.0723, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036932945251465\n",
            "g_norm = tensor(0.0746, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044724464416504\n",
            "g_norm = tensor(0.0866, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041768074035645\n",
            "g_norm = tensor(0.0785, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304288387298584\n",
            "g_norm = tensor(0.0771, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.42465209960938\n",
            "||∇_X meta|| = 0.002358095720410347\n",
            "ΔX norm: 2.3580972992931493e-05\n",
            "Stage 6/10:  26%|███████▊                      | 78/300 [02:38<07:09,  1.93s/it]T Loss=2.3050084114074707\n",
            "g_norm = tensor(0.1525, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304081678390503\n",
            "g_norm = tensor(0.1360, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048970699310303\n",
            "g_norm = tensor(0.1374, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030052185058594\n",
            "g_norm = tensor(0.1405, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037781715393066\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5078582763672\n",
            "||∇_X meta|| = 0.001975487917661667\n",
            "ΔX norm: 1.9754872482735664e-05\n",
            "Stage 6/10:  26%|███████▉                      | 79/300 [02:40<07:06,  1.93s/it]T Loss=2.303131580352783\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302672863006592\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037545680999756\n",
            "g_norm = tensor(0.1118, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046536445617676\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041794300079346\n",
            "g_norm = tensor(0.1259, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.94126892089844\n",
            "||∇_X meta|| = 0.002118606586009264\n",
            "ΔX norm: 2.118609700119123e-05\n",
            "Stage 6/10:  27%|████████                      | 80/300 [02:42<06:59,  1.91s/it]T Loss=2.305954694747925\n",
            "g_norm = tensor(0.1595, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054394721984863\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304664373397827\n",
            "g_norm = tensor(0.1548, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057093620300293\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304767370223999\n",
            "g_norm = tensor(0.1631, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.24098205566406\n",
            "||∇_X meta|| = 0.002060574246570468\n",
            "ΔX norm: 2.060574115603231e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 6/10:  27%|████████                      | 81/300 [02:44<07:12,  1.98s/it]T Loss=2.3051209449768066\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027732372283936\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304262638092041\n",
            "g_norm = tensor(0.1393, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305652141571045\n",
            "g_norm = tensor(0.1462, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027076721191406\n",
            "g_norm = tensor(0.1436, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.48204040527344\n",
            "||∇_X meta|| = 0.002220278140157461\n",
            "ΔX norm: 2.2202795662451535e-05\n",
            "Stage 6/10:  27%|████████▏                     | 82/300 [02:46<07:35,  2.09s/it]T Loss=2.3029465675354004\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045239448547363\n",
            "g_norm = tensor(0.1523, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052074909210205\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041763305664062\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029236793518066\n",
            "g_norm = tensor(0.1426, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.35302734375\n",
            "||∇_X meta|| = 0.0021806908771395683\n",
            "ΔX norm: 2.1806932636536658e-05\n",
            "Stage 6/10:  28%|████████▎                     | 83/300 [02:48<07:27,  2.06s/it]T Loss=2.302860975265503\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031504154205322\n",
            "g_norm = tensor(0.1325, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303438663482666\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302929639816284\n",
            "g_norm = tensor(0.1153, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028995990753174\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7417449951172\n",
            "||∇_X meta|| = 0.0020083049312233925\n",
            "ΔX norm: 2.008303090406116e-05\n",
            "Stage 6/10:  28%|████████▍                     | 84/300 [02:50<07:09,  1.99s/it]T Loss=2.3020005226135254\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021934032440186\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024425506591797\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024449348449707\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303831100463867\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.10972595214844\n",
            "||∇_X meta|| = 0.002169617684558034\n",
            "ΔX norm: 2.1696227122447453e-05\n",
            "Stage 6/10:  28%|████████▌                     | 85/300 [02:52<06:53,  1.93s/it]T Loss=2.3034634590148926\n",
            "g_norm = tensor(0.1586, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304786205291748\n",
            "g_norm = tensor(0.1561, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048903942108154\n",
            "g_norm = tensor(0.1410, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305377960205078\n",
            "g_norm = tensor(0.1574, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058383464813232\n",
            "g_norm = tensor(0.1549, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.56056213378906\n",
            "||∇_X meta|| = 0.0019790437072515488\n",
            "ΔX norm: 1.9790430087596178e-05\n",
            "Stage 6/10:  29%|████████▌                     | 86/300 [02:54<06:45,  1.89s/it]T Loss=2.303126811981201\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304243803024292\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042099475860596\n",
            "g_norm = tensor(0.1214, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033316135406494\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304501533508301\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0641326904297\n",
            "||∇_X meta|| = 0.0022747740149497986\n",
            "ΔX norm: 2.2747724869986996e-05\n",
            "Stage 6/10:  29%|████████▋                     | 87/300 [02:55<06:34,  1.85s/it]T Loss=2.304957866668701\n",
            "g_norm = tensor(0.1502, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049845695495605\n",
            "g_norm = tensor(0.1376, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043298721313477\n",
            "g_norm = tensor(0.1522, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305004596710205\n",
            "g_norm = tensor(0.1295, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304053783416748\n",
            "g_norm = tensor(0.1507, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5006866455078\n",
            "||∇_X meta|| = 0.001932732411660254\n",
            "ΔX norm: 1.932732993736863e-05\n",
            "Stage 6/10:  29%|████████▊                     | 88/300 [02:57<06:39,  1.88s/it]T Loss=2.302682876586914\n",
            "g_norm = tensor(0.1634, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028481006622314\n",
            "g_norm = tensor(0.1640, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304002285003662\n",
            "g_norm = tensor(0.1475, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042032718658447\n",
            "g_norm = tensor(0.1469, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303924083709717\n",
            "g_norm = tensor(0.1463, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.32730102539062\n",
            "||∇_X meta|| = 0.0018032107036560774\n",
            "ΔX norm: 1.8032102161669172e-05\n",
            "Stage 6/10:  30%|████████▉                     | 89/300 [02:59<06:30,  1.85s/it]T Loss=2.3030622005462646\n",
            "g_norm = tensor(0.1615, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304766893386841\n",
            "g_norm = tensor(0.1656, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028323650360107\n",
            "g_norm = tensor(0.1674, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034989833831787\n",
            "g_norm = tensor(0.1335, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039140701293945\n",
            "g_norm = tensor(0.1394, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.66082763671875\n",
            "||∇_X meta|| = 0.002104438142850995\n",
            "ΔX norm: 2.1044408640591428e-05\n",
            "Stage 6/10:  30%|█████████                     | 90/300 [03:02<07:17,  2.08s/it]T Loss=2.3045406341552734\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302833080291748\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033299446105957\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302006244659424\n",
            "g_norm = tensor(0.1107, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304856777191162\n",
            "g_norm = tensor(0.1222, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.33810424804688\n",
            "||∇_X meta|| = 0.0017054504714906216\n",
            "ΔX norm: 1.7054486306733452e-05\n",
            "Stage 6/10:  30%|█████████                     | 91/300 [03:05<08:07,  2.33s/it]T Loss=2.3036296367645264\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037827014923096\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037636280059814\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039565086364746\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033628463745117\n",
            "g_norm = tensor(0.0817, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2312469482422\n",
            "||∇_X meta|| = 0.0017328438116237521\n",
            "ΔX norm: 1.732843156787567e-05\n",
            "Stage 6/10:  31%|█████████▏                    | 92/300 [03:07<07:56,  2.29s/it]T Loss=2.3030261993408203\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303515911102295\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037452697753906\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304379940032959\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304020404815674\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.94735717773438\n",
            "||∇_X meta|| = 0.0017667156644165516\n",
            "ΔX norm: 1.7667161955614574e-05\n",
            "Stage 6/10:  31%|█████████▎                    | 93/300 [03:09<08:03,  2.34s/it]T Loss=2.3028295040130615\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304190158843994\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30391788482666\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034462928771973\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302032232284546\n",
            "g_norm = tensor(0.1283, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.30206298828125\n",
            "||∇_X meta|| = 0.0020481746178120375\n",
            "ΔX norm: 2.048173701041378e-05\n",
            "Stage 6/10:  31%|█████████▍                    | 94/300 [03:11<07:41,  2.24s/it]T Loss=2.3020529747009277\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303804874420166\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302635669708252\n",
            "g_norm = tensor(0.0885, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30153226852417\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303868293762207\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.6177215576172\n",
            "||∇_X meta|| = 0.0019035753794014454\n",
            "ΔX norm: 1.9035738660022616e-05\n",
            "Stage 6/10:  32%|█████████▌                    | 95/300 [03:13<07:22,  2.16s/it]T Loss=2.3041908740997314\n",
            "g_norm = tensor(0.0983, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304608106613159\n",
            "g_norm = tensor(0.0947, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035120964050293\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304180383682251\n",
            "g_norm = tensor(0.0883, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040976524353027\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.9193572998047\n",
            "||∇_X meta|| = 0.00184898532461375\n",
            "ΔX norm: 1.848985266406089e-05\n",
            "Stage 6/10:  32%|█████████▌                    | 96/300 [03:15<07:18,  2.15s/it]T Loss=2.3038816452026367\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043386936187744\n",
            "g_norm = tensor(0.1154, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041350841522217\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303378105163574\n",
            "g_norm = tensor(0.0937, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039355278015137\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1595916748047\n",
            "||∇_X meta|| = 0.002071791561320424\n",
            "ΔX norm: 2.071790731861256e-05\n",
            "Stage 6/10:  32%|█████████▋                    | 97/300 [03:17<07:01,  2.07s/it]T Loss=2.3039474487304688\n",
            "g_norm = tensor(0.1390, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035812377929688\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30515193939209\n",
            "g_norm = tensor(0.1433, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041608333587646\n",
            "g_norm = tensor(0.1234, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306642532348633\n",
            "g_norm = tensor(0.1583, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.57041931152344\n",
            "||∇_X meta|| = 0.0019003929337486625\n",
            "ΔX norm: 1.9003920897375792e-05\n",
            "Stage 6/10:  33%|█████████▊                    | 98/300 [03:19<06:46,  2.01s/it]T Loss=2.303842544555664\n",
            "g_norm = tensor(0.0785, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304431200027466\n",
            "g_norm = tensor(0.0772, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304375171661377\n",
            "g_norm = tensor(0.0748, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043088912963867\n",
            "g_norm = tensor(0.0805, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037517070770264\n",
            "g_norm = tensor(0.0830, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =227.73806762695312\n",
            "||∇_X meta|| = 0.0019048843532800674\n",
            "ΔX norm: 1.9048828107770532e-05\n",
            "Stage 6/10:  33%|█████████▉                    | 99/300 [03:21<06:36,  1.97s/it]T Loss=2.305067539215088\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051464557647705\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050589561462402\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037030696868896\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056721687316895\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.67210388183594\n",
            "||∇_X meta|| = 0.0020785031374543905\n",
            "ΔX norm: 2.0785026208614e-05\n",
            "Stage 6/10:  33%|█████████▋                   | 100/300 [03:23<06:28,  1.94s/it]T Loss=2.303248882293701\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037877082824707\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304269552230835\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028690814971924\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043479919433594\n",
            "g_norm = tensor(0.1118, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7530975341797\n",
            "||∇_X meta|| = 0.0021480857394635677\n",
            "ΔX norm: 2.1480884242919274e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 6/10:  34%|█████████▊                   | 101/300 [03:25<06:20,  1.91s/it]T Loss=2.3028883934020996\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303731679916382\n",
            "g_norm = tensor(0.1291, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302021026611328\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036234378814697\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035521507263184\n",
            "g_norm = tensor(0.1461, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4750213623047\n",
            "||∇_X meta|| = 0.0018781590042635798\n",
            "ΔX norm: 1.8781556718749925e-05\n",
            "Stage 6/10:  34%|█████████▊                   | 102/300 [03:27<06:46,  2.05s/it]T Loss=2.305030345916748\n",
            "g_norm = tensor(0.1636, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305042266845703\n",
            "g_norm = tensor(0.2253, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303138256072998\n",
            "g_norm = tensor(0.1742, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054308891296387\n",
            "g_norm = tensor(0.1552, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305752992630005\n",
            "g_norm = tensor(0.1526, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.86099243164062\n",
            "||∇_X meta|| = 0.0017927977023646235\n",
            "ΔX norm: 1.7927986846189015e-05\n",
            "Stage 6/10:  34%|█████████▉                   | 103/300 [03:30<07:05,  2.16s/it]T Loss=2.3041787147521973\n",
            "g_norm = tensor(0.1234, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038761615753174\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30336332321167\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020119667053223\n",
            "g_norm = tensor(0.1486, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017325401306152\n",
            "g_norm = tensor(0.1393, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.21957397460938\n",
            "||∇_X meta|| = 0.0018600178882479668\n",
            "ΔX norm: 1.860017073340714e-05\n",
            "Stage 6/10:  35%|██████████                   | 104/300 [03:31<06:46,  2.07s/it]T Loss=2.303572416305542\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049087524414062\n",
            "g_norm = tensor(0.1376, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305025815963745\n",
            "g_norm = tensor(0.1393, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304253578186035\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304924488067627\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1101837158203\n",
            "||∇_X meta|| = 0.0018227321561425924\n",
            "ΔX norm: 1.8227323380415328e-05\n",
            "Stage 6/10:  35%|██████████▏                  | 105/300 [03:33<06:31,  2.01s/it]T Loss=2.304478883743286\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30431866645813\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303999662399292\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033246994018555\n",
            "g_norm = tensor(0.0866, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030102252960205\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.52159118652344\n",
            "||∇_X meta|| = 0.0021231293212622404\n",
            "ΔX norm: 2.123133344866801e-05\n",
            "Stage 6/10:  35%|██████████▏                  | 106/300 [03:36<06:45,  2.09s/it]T Loss=2.3050239086151123\n",
            "g_norm = tensor(0.1053, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305208206176758\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305095672607422\n",
            "g_norm = tensor(0.0858, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055336475372314\n",
            "g_norm = tensor(0.0879, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304621458053589\n",
            "g_norm = tensor(0.0759, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.02723693847656\n",
            "||∇_X meta|| = 0.0019936023745685816\n",
            "ΔX norm: 1.993601836147718e-05\n",
            "Stage 6/10:  36%|██████████▎                  | 107/300 [03:38<06:38,  2.07s/it]T Loss=2.3051414489746094\n",
            "g_norm = tensor(0.1368, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303741693496704\n",
            "g_norm = tensor(0.1648, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023247718811035\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053982257843018\n",
            "g_norm = tensor(0.1442, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303920269012451\n",
            "g_norm = tensor(0.1704, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.86526489257812\n",
            "||∇_X meta|| = 0.0019932580180466175\n",
            "ΔX norm: 1.9932602299377322e-05\n",
            "Stage 6/10:  36%|██████████▍                  | 108/300 [03:39<06:29,  2.03s/it]T Loss=2.3045716285705566\n",
            "g_norm = tensor(0.0855, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036694526672363\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028602600097656\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302811861038208\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303044319152832\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4710693359375\n",
            "||∇_X meta|| = 0.0019106593681499362\n",
            "ΔX norm: 1.9106613763142377e-05\n",
            "Stage 6/10:  36%|██████████▌                  | 109/300 [03:42<06:40,  2.10s/it]T Loss=2.303271532058716\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302419900894165\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031911849975586\n",
            "g_norm = tensor(0.0834, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305307149887085\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037867546081543\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7384796142578\n",
            "||∇_X meta|| = 0.0018634971929714084\n",
            "ΔX norm: 1.8634984371601604e-05\n",
            "Stage 6/10:  37%|██████████▋                  | 110/300 [03:44<06:29,  2.05s/it]T Loss=2.3032288551330566\n",
            "g_norm = tensor(0.0810, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30419659614563\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303274631500244\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042407035827637\n",
            "g_norm = tensor(0.0867, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034024238586426\n",
            "g_norm = tensor(0.0785, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6580810546875\n",
            "||∇_X meta|| = 0.0017322914209216833\n",
            "ΔX norm: 1.73229072970571e-05\n",
            "Stage 6/10:  37%|██████████▋                  | 111/300 [03:46<06:14,  1.98s/it]T Loss=2.3029990196228027\n",
            "g_norm = tensor(0.0956, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035824298858643\n",
            "g_norm = tensor(0.0876, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303309679031372\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038430213928223\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038971424102783\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.24264526367188\n",
            "||∇_X meta|| = 0.0016826745122671127\n",
            "ΔX norm: 1.6826741557451896e-05\n",
            "Stage 6/10:  37%|██████████▊                  | 112/300 [03:47<06:05,  1.94s/it]T Loss=2.303401470184326\n",
            "g_norm = tensor(0.1590, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305448055267334\n",
            "g_norm = tensor(0.1693, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302711009979248\n",
            "g_norm = tensor(0.1656, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057148456573486\n",
            "g_norm = tensor(0.1494, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30436635017395\n",
            "g_norm = tensor(0.1455, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.98863220214844\n",
            "||∇_X meta|| = 0.0017929791938513517\n",
            "ΔX norm: 1.792983130144421e-05\n",
            "Stage 6/10:  38%|██████████▉                  | 113/300 [03:49<05:57,  1.91s/it]T Loss=2.303239345550537\n",
            "g_norm = tensor(0.0856, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019187450408936\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303061008453369\n",
            "g_norm = tensor(0.0865, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304503917694092\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034400939941406\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.04153442382812\n",
            "||∇_X meta|| = 0.0019472045823931694\n",
            "ΔX norm: 1.9472039639367722e-05\n",
            "Stage 6/10:  38%|███████████                  | 114/300 [03:52<06:33,  2.12s/it]T Loss=2.3043270111083984\n",
            "g_norm = tensor(0.0797, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304438591003418\n",
            "g_norm = tensor(0.0838, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052773475646973\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303867816925049\n",
            "g_norm = tensor(0.0791, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056883811950684\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.07394409179688\n",
            "||∇_X meta|| = 0.0018067844212055206\n",
            "ΔX norm: 1.8067828932544217e-05\n",
            "Stage 6/10:  38%|███████████                  | 115/300 [03:54<06:19,  2.05s/it]T Loss=2.303410053253174\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040242195129395\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033957481384277\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303861618041992\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304699182510376\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4810791015625\n",
            "||∇_X meta|| = 0.0020502754487097263\n",
            "ΔX norm: 2.0502751794992946e-05\n",
            "Stage 6/10:  39%|███████████▏                 | 116/300 [03:56<06:30,  2.12s/it]T Loss=2.3031094074249268\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050460815429688\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304516315460205\n",
            "g_norm = tensor(0.1312, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045847415924072\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303689479827881\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.12635803222656\n",
            "||∇_X meta|| = 0.0017859243089333177\n",
            "ΔX norm: 1.785923268471379e-05\n",
            "Stage 6/10:  39%|███████████▎                 | 117/300 [03:58<06:23,  2.10s/it]T Loss=2.3041720390319824\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039791584014893\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303213596343994\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303997039794922\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303201198577881\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.75099182128906\n",
            "||∇_X meta|| = 0.0017754489090293646\n",
            "ΔX norm: 1.7754489817889407e-05\n",
            "Stage 6/10:  39%|███████████▍                 | 118/300 [04:00<06:11,  2.04s/it]T Loss=2.305128574371338\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303837299346924\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304279088973999\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038763999938965\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041558265686035\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.881591796875\n",
            "||∇_X meta|| = 0.0015726082492619753\n",
            "ΔX norm: 1.57260710693663e-05\n",
            "Stage 6/10:  40%|███████████▌                 | 119/300 [04:02<06:00,  1.99s/it]T Loss=2.3042073249816895\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302781105041504\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042969703674316\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034491539001465\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045847415924072\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.06082153320312\n",
            "||∇_X meta|| = 0.0017940030666068196\n",
            "ΔX norm: 1.794002491806168e-05\n",
            "Stage 6/10:  40%|███████████▌                 | 120/300 [04:04<05:50,  1.95s/it]T Loss=2.3032054901123047\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029587268829346\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044517040252686\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305208921432495\n",
            "g_norm = tensor(0.1326, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303189992904663\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5328369140625\n",
            "||∇_X meta|| = 0.0016588963335379958\n",
            "ΔX norm: 1.658896144363098e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 6/10:  40%|███████████▋                 | 121/300 [04:06<05:53,  1.97s/it]T Loss=2.3035855293273926\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303410768508911\n",
            "g_norm = tensor(0.1258, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303203821182251\n",
            "g_norm = tensor(0.1378, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029372692108154\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305494785308838\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.37232971191406\n",
            "||∇_X meta|| = 0.0017095569055527449\n",
            "ΔX norm: 1.7095564544433728e-05\n",
            "Stage 6/10:  41%|███████████▊                 | 122/300 [04:09<06:48,  2.30s/it]T Loss=2.3043248653411865\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048815727233887\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051962852478027\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039462566375732\n",
            "g_norm = tensor(0.1345, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304929494857788\n",
            "g_norm = tensor(0.1278, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.91665649414062\n",
            "||∇_X meta|| = 0.0017072834307327867\n",
            "ΔX norm: 1.7072818081942387e-05\n",
            "Stage 6/10:  41%|███████████▉                 | 123/300 [04:11<06:36,  2.24s/it]T Loss=2.3043525218963623\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052096366882324\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303783655166626\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305154323577881\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053417205810547\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.82620239257812\n",
            "||∇_X meta|| = 0.0017875973135232925\n",
            "ΔX norm: 1.7876005586003885e-05\n",
            "Stage 6/10:  41%|███████████▉                 | 124/300 [04:13<06:26,  2.20s/it]T Loss=2.3037614822387695\n",
            "g_norm = tensor(0.0792, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031258583068848\n",
            "g_norm = tensor(0.0785, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303647994995117\n",
            "g_norm = tensor(0.0809, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032965660095215\n",
            "g_norm = tensor(0.0855, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303774118423462\n",
            "g_norm = tensor(0.0799, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9430694580078\n",
            "||∇_X meta|| = 0.0018403397407382727\n",
            "ΔX norm: 1.840339245973155e-05\n",
            "Stage 6/10:  42%|████████████                 | 125/300 [04:15<06:16,  2.15s/it]T Loss=2.3053476810455322\n",
            "g_norm = tensor(0.1505, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052096366882324\n",
            "g_norm = tensor(0.1360, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043570518493652\n",
            "g_norm = tensor(0.1662, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3059325218200684\n",
            "g_norm = tensor(0.1646, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046505451202393\n",
            "g_norm = tensor(0.1507, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.34530639648438\n",
            "||∇_X meta|| = 0.00172062823548913\n",
            "ΔX norm: 1.7206300981342793e-05\n",
            "Stage 6/10:  42%|████████████▏                | 126/300 [04:17<06:22,  2.20s/it]T Loss=2.3053364753723145\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044049739837646\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304776668548584\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050644397735596\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057668209075928\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.99057006835938\n",
            "||∇_X meta|| = 0.001598260598257184\n",
            "ΔX norm: 1.5982606782927178e-05\n",
            "Stage 6/10:  42%|████████████▎                | 127/300 [04:19<06:11,  2.15s/it]T Loss=2.303098678588867\n",
            "g_norm = tensor(0.1275, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303497314453125\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035037517547607\n",
            "g_norm = tensor(0.1571, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040895462036133\n",
            "g_norm = tensor(0.1163, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303410530090332\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.28248596191406\n",
            "||∇_X meta|| = 0.0017031403258442879\n",
            "ΔX norm: 1.703142152109649e-05\n",
            "Stage 6/10:  43%|████████████▎                | 128/300 [04:21<06:03,  2.11s/it]T Loss=2.303624391555786\n",
            "g_norm = tensor(0.1537, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045523166656494\n",
            "g_norm = tensor(0.1321, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040268421173096\n",
            "g_norm = tensor(0.1655, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035287857055664\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039937019348145\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8581085205078\n",
            "||∇_X meta|| = 0.0016984930261969566\n",
            "ΔX norm: 1.6984986359602772e-05\n",
            "Stage 6/10:  43%|████████████▍                | 129/300 [04:23<05:48,  2.04s/it]T Loss=2.302820920944214\n",
            "g_norm = tensor(0.1474, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025612831115723\n",
            "g_norm = tensor(0.1456, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302147626876831\n",
            "g_norm = tensor(0.1322, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3016083240509033\n",
            "g_norm = tensor(0.1793, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302154064178467\n",
            "g_norm = tensor(0.1686, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.42018127441406\n",
            "||∇_X meta|| = 0.0016286408063024282\n",
            "ΔX norm: 1.6286358004435897e-05\n",
            "Stage 6/10:  43%|████████████▌                | 130/300 [04:25<05:55,  2.09s/it]T Loss=2.3049845695495605\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304591655731201\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055968284606934\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047428131103516\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057844638824463\n",
            "g_norm = tensor(0.1306, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.92254638671875\n",
            "||∇_X meta|| = 0.0015984814381226897\n",
            "ΔX norm: 1.5984836863935925e-05\n",
            "Stage 6/10:  44%|████████████▋                | 131/300 [04:28<05:57,  2.11s/it]T Loss=2.305485725402832\n",
            "g_norm = tensor(0.1561, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038952350616455\n",
            "g_norm = tensor(0.1591, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303401470184326\n",
            "g_norm = tensor(0.1363, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056774139404297\n",
            "g_norm = tensor(0.1470, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30185866355896\n",
            "g_norm = tensor(0.1875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0179901123047\n",
            "||∇_X meta|| = 0.0017516898224130273\n",
            "ΔX norm: 1.751687887008302e-05\n",
            "Stage 6/10:  44%|████████████▊                | 132/300 [04:30<05:57,  2.13s/it]T Loss=2.3050377368927\n",
            "g_norm = tensor(0.0934, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044400215148926\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305359363555908\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045260906219482\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303283214569092\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.1953887939453\n",
            "||∇_X meta|| = 0.0014923386042937636\n",
            "ΔX norm: 1.492339106334839e-05\n",
            "Stage 6/10:  44%|████████████▊                | 133/300 [04:32<05:45,  2.07s/it]T Loss=2.303267002105713\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043501377105713\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032119274139404\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303480863571167\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303969383239746\n",
            "g_norm = tensor(0.0825, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.75228881835938\n",
            "||∇_X meta|| = 0.0016799956792965531\n",
            "ΔX norm: 1.6799956938484684e-05\n",
            "Stage 6/10:  45%|████████████▉                | 134/300 [04:34<05:37,  2.03s/it]T Loss=2.30464768409729\n",
            "g_norm = tensor(0.1321, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044626712799072\n",
            "g_norm = tensor(0.1413, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304187536239624\n",
            "g_norm = tensor(0.1309, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303342819213867\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041300773620605\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.16639709472656\n",
            "||∇_X meta|| = 0.0018699225038290024\n",
            "ΔX norm: 1.8699209249462e-05\n",
            "Stage 6/10:  45%|█████████████                | 135/300 [04:36<05:29,  2.00s/it]T Loss=2.303683042526245\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303323268890381\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037521839141846\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038523197174072\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049252033233643\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.05821228027344\n",
            "||∇_X meta|| = 0.0016733624506741762\n",
            "ΔX norm: 1.6733627489884384e-05\n",
            "Stage 6/10:  45%|█████████████▏               | 136/300 [04:38<05:31,  2.02s/it]T Loss=2.303464889526367\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303574800491333\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029704093933105\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034069538116455\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302793264389038\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.48048400878906\n",
            "||∇_X meta|| = 0.0016122888773679733\n",
            "ΔX norm: 1.6122903616633266e-05\n",
            "Stage 6/10:  46%|█████████████▏               | 137/300 [04:40<05:41,  2.09s/it]T Loss=2.3036580085754395\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303514242172241\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304766893386841\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304293155670166\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30385160446167\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.51934814453125\n",
            "||∇_X meta|| = 0.0015540814492851496\n",
            "ΔX norm: 1.554083610244561e-05\n",
            "Stage 6/10:  46%|█████████████▎               | 138/300 [04:42<05:29,  2.04s/it]T Loss=2.3039190769195557\n",
            "g_norm = tensor(0.0805, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304335832595825\n",
            "g_norm = tensor(0.0843, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048312664031982\n",
            "g_norm = tensor(0.0808, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036975860595703\n",
            "g_norm = tensor(0.0701, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043224811553955\n",
            "g_norm = tensor(0.0761, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.41799926757812\n",
            "||∇_X meta|| = 0.0016033867141231894\n",
            "ΔX norm: 1.603386044735089e-05\n",
            "Stage 6/10:  46%|█████████████▍               | 139/300 [04:44<05:19,  1.98s/it]T Loss=2.3048152923583984\n",
            "g_norm = tensor(0.1011, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304074764251709\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304387092590332\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303985595703125\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030283451080322\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1084442138672\n",
            "||∇_X meta|| = 0.0015825702575966716\n",
            "ΔX norm: 1.582570985192433e-05\n",
            "Stage 6/10:  47%|█████████████▌               | 140/300 [04:46<05:13,  1.96s/it]T Loss=2.303140878677368\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036277294158936\n",
            "g_norm = tensor(0.1496, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027021884918213\n",
            "g_norm = tensor(0.1535, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303175449371338\n",
            "g_norm = tensor(0.1378, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034160137176514\n",
            "g_norm = tensor(0.1213, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0334014892578\n",
            "||∇_X meta|| = 0.0015726004494354129\n",
            "ΔX norm: 1.5726012861705385e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 6/10:  47%|█████████████▋               | 141/300 [04:48<05:16,  1.99s/it]T Loss=2.302762985229492\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040828704833984\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034045696258545\n",
            "g_norm = tensor(0.0960, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028273582458496\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034133911132812\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.93357849121094\n",
            "||∇_X meta|| = 0.001563125872053206\n",
            "ΔX norm: 1.563126170367468e-05\n",
            "Stage 6/10:  47%|█████████████▋               | 142/300 [04:50<05:38,  2.14s/it]T Loss=2.3039379119873047\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036653995513916\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050663471221924\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055522441864014\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058009147644043\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.69581604003906\n",
            "||∇_X meta|| = 0.0016147656133398414\n",
            "ΔX norm: 1.6147680071298964e-05\n",
            "Stage 6/10:  48%|█████████████▊               | 143/300 [04:52<05:28,  2.09s/it]T Loss=2.3029677867889404\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027431964874268\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034491539001465\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304281234741211\n",
            "g_norm = tensor(0.1278, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303779125213623\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1726837158203\n",
            "||∇_X meta|| = 0.0016032696003094316\n",
            "ΔX norm: 1.6032681742217392e-05\n",
            "Stage 6/10:  48%|█████████████▉               | 144/300 [04:54<05:17,  2.04s/it]T Loss=2.3037798404693604\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303921937942505\n",
            "g_norm = tensor(0.1248, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038089275360107\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035099506378174\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052713871002197\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.3382110595703\n",
            "||∇_X meta|| = 0.00179162563290447\n",
            "ΔX norm: 1.7916219803737476e-05\n",
            "Stage 6/10:  48%|██████████████               | 145/300 [04:56<05:12,  2.02s/it]T Loss=2.303208351135254\n",
            "g_norm = tensor(0.1421, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024144172668457\n",
            "g_norm = tensor(0.1844, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029379844665527\n",
            "g_norm = tensor(0.1520, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032925128936768\n",
            "g_norm = tensor(0.1342, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30299711227417\n",
            "g_norm = tensor(0.1413, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.42080688476562\n",
            "||∇_X meta|| = 0.0016285139136016369\n",
            "ΔX norm: 1.62851283675991e-05\n",
            "Stage 6/10:  49%|██████████████               | 146/300 [04:58<05:13,  2.04s/it]T Loss=2.303020715713501\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303480625152588\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303694248199463\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304328203201294\n",
            "g_norm = tensor(0.1448, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041694164276123\n",
            "g_norm = tensor(0.1270, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.55908203125\n",
            "||∇_X meta|| = 0.0016189937014132738\n",
            "ΔX norm: 1.6189909729291685e-05\n",
            "Stage 6/10:  49%|██████████████▏              | 147/300 [05:00<05:05,  2.00s/it]T Loss=2.3033149242401123\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043570518493652\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050456047058105\n",
            "g_norm = tensor(0.0861, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041698932647705\n",
            "g_norm = tensor(0.0880, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039653301239014\n",
            "g_norm = tensor(0.0788, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.82313537597656\n",
            "||∇_X meta|| = 0.0016213293420150876\n",
            "ΔX norm: 1.621331466594711e-05\n",
            "Stage 6/10:  49%|██████████████▎              | 148/300 [05:02<04:59,  1.97s/it]T Loss=2.3055038452148438\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304516553878784\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303652048110962\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304508686065674\n",
            "g_norm = tensor(0.1183, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032586574554443\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.06544494628906\n",
            "||∇_X meta|| = 0.001696151914075017\n",
            "ΔX norm: 1.6961528672254644e-05\n",
            "Stage 6/10:  50%|██████████████▍              | 149/300 [05:04<04:51,  1.93s/it]T Loss=2.3041956424713135\n",
            "g_norm = tensor(0.0790, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303187847137451\n",
            "g_norm = tensor(0.0830, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303300380706787\n",
            "g_norm = tensor(0.0783, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020784854888916\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021187782287598\n",
            "g_norm = tensor(0.0868, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.56961059570312\n",
            "||∇_X meta|| = 0.0014937786618247628\n",
            "ΔX norm: 1.4937778360035736e-05\n",
            "Stage 6/10:  50%|██████████████▌              | 150/300 [05:06<04:54,  1.96s/it]T Loss=2.3030147552490234\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304379940032959\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303928852081299\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304729700088501\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304102659225464\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.81044006347656\n",
            "||∇_X meta|| = 0.0018802443519234657\n",
            "ΔX norm: 1.8802445993060246e-05\n",
            "Stage 6/10:  50%|██████████████▌              | 151/300 [05:09<05:42,  2.30s/it]T Loss=2.304194927215576\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046507835388184\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304957389831543\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045380115509033\n",
            "g_norm = tensor(0.0814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305114984512329\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4510955810547\n",
            "||∇_X meta|| = 0.0017471309984102845\n",
            "ΔX norm: 1.7471302271587774e-05\n",
            "Stage 6/10:  51%|██████████████▋              | 152/300 [05:11<05:37,  2.28s/it]T Loss=2.3035502433776855\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036293983459473\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30206298828125\n",
            "g_norm = tensor(0.1360, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045549392700195\n",
            "g_norm = tensor(0.1210, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044800758361816\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.4447021484375\n",
            "||∇_X meta|| = 0.0016546370461583138\n",
            "ΔX norm: 1.654637890169397e-05\n",
            "Stage 6/10:  51%|██████████████▊              | 153/300 [05:13<05:30,  2.25s/it]T Loss=2.3045568466186523\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038926124572754\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038856983184814\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035435676574707\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304408311843872\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5476837158203\n",
            "||∇_X meta|| = 0.001610809937119484\n",
            "ΔX norm: 1.6108138879644684e-05\n",
            "Stage 6/10:  51%|██████████████▉              | 154/300 [05:15<05:17,  2.17s/it]T Loss=2.303729772567749\n",
            "g_norm = tensor(0.0898, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303490400314331\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303475856781006\n",
            "g_norm = tensor(0.0833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303196430206299\n",
            "g_norm = tensor(0.0782, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038926124572754\n",
            "g_norm = tensor(0.0791, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.79873657226562\n",
            "||∇_X meta|| = 0.0016335479449480772\n",
            "ΔX norm: 1.6335470718331635e-05\n",
            "Stage 6/10:  52%|██████████████▉              | 155/300 [05:17<05:10,  2.14s/it]T Loss=2.304790496826172\n",
            "g_norm = tensor(0.1566, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304189443588257\n",
            "g_norm = tensor(0.1154, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034894466400146\n",
            "g_norm = tensor(0.1434, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051743507385254\n",
            "g_norm = tensor(0.1363, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033382892608643\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.38633728027344\n",
            "||∇_X meta|| = 0.0016599522205069661\n",
            "ΔX norm: 1.659955523791723e-05\n",
            "Stage 6/10:  52%|███████████████              | 156/300 [05:19<05:00,  2.09s/it]T Loss=2.3047029972076416\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303440570831299\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045506477355957\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036134243011475\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304286003112793\n",
            "g_norm = tensor(0.1250, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6045684814453\n",
            "||∇_X meta|| = 0.0017081790138036013\n",
            "ΔX norm: 1.7081792975659482e-05\n",
            "Stage 6/10:  52%|███████████████▏             | 157/300 [05:21<04:52,  2.05s/it]T Loss=2.304333448410034\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304692029953003\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304217576980591\n",
            "g_norm = tensor(0.0945, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303225040435791\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052332401275635\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.27684020996094\n",
            "||∇_X meta|| = 0.0017022350803017616\n",
            "ΔX norm: 1.7022348401951604e-05\n",
            "Stage 6/10:  53%|███████████████▎             | 158/300 [05:24<05:10,  2.19s/it]T Loss=2.303662061691284\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303830623626709\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035099506378174\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035051822662354\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301992893218994\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.01148986816406\n",
            "||∇_X meta|| = 0.0015944483457133174\n",
            "ΔX norm: 1.594450804986991e-05\n",
            "Stage 6/10:  53%|███████████████▎             | 159/300 [05:26<05:16,  2.24s/it]T Loss=2.3032004833221436\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037211894989014\n",
            "g_norm = tensor(0.0658, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303826332092285\n",
            "g_norm = tensor(0.0751, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038761615753174\n",
            "g_norm = tensor(0.0822, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304459810256958\n",
            "g_norm = tensor(0.0846, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2288818359375\n",
            "||∇_X meta|| = 0.001646780176088214\n",
            "ΔX norm: 1.6467804016429e-05\n",
            "Stage 6/10:  53%|███████████████▍             | 160/300 [05:28<05:13,  2.24s/it]T Loss=2.30442214012146\n",
            "g_norm = tensor(0.1711, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055553436279297\n",
            "g_norm = tensor(0.1722, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043556213378906\n",
            "g_norm = tensor(0.1397, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305509328842163\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031368255615234\n",
            "g_norm = tensor(0.1549, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.01113891601562\n",
            "||∇_X meta|| = 0.0017723205965012312\n",
            "ΔX norm: 1.772322502802126e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 6/10:  54%|███████████████▌             | 161/300 [05:30<05:02,  2.18s/it]T Loss=2.3033478260040283\n",
            "g_norm = tensor(0.0756, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044872283935547\n",
            "g_norm = tensor(0.0750, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043627738952637\n",
            "g_norm = tensor(0.0798, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035597801208496\n",
            "g_norm = tensor(0.0709, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031375408172607\n",
            "g_norm = tensor(0.0759, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.02951049804688\n",
            "||∇_X meta|| = 0.0015998486196622252\n",
            "ΔX norm: 1.5998475646483712e-05\n",
            "Stage 6/10:  54%|███████████████▋             | 162/300 [05:33<05:27,  2.38s/it]T Loss=2.3024847507476807\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304542064666748\n",
            "g_norm = tensor(0.0983, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303316354751587\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033204078674316\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034300804138184\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3009033203125\n",
            "||∇_X meta|| = 0.00175013008993119\n",
            "ΔX norm: 1.750129922584165e-05\n",
            "Stage 6/10:  54%|███████████████▊             | 163/300 [05:35<05:09,  2.26s/it]T Loss=2.3030519485473633\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301828622817993\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028504848480225\n",
            "g_norm = tensor(0.1154, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028502464294434\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033671379089355\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.84909057617188\n",
            "||∇_X meta|| = 0.001481249462813139\n",
            "ΔX norm: 1.4812510926276445e-05\n",
            "Stage 6/10:  55%|███████████████▊             | 164/300 [05:37<04:52,  2.15s/it]T Loss=2.303894519805908\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048789501190186\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041129112243652\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036139011383057\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044466972351074\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.20179748535156\n",
            "||∇_X meta|| = 0.0017186551121994853\n",
            "ΔX norm: 1.7186568584293127e-05\n",
            "Stage 6/10:  55%|███████████████▉             | 165/300 [05:39<04:39,  2.07s/it]T Loss=2.305206775665283\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046488761901855\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049278259277344\n",
            "g_norm = tensor(0.0853, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047022819519043\n",
            "g_norm = tensor(0.0849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051114082336426\n",
            "g_norm = tensor(0.0786, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9740753173828\n",
            "||∇_X meta|| = 0.0016708394978195429\n",
            "ΔX norm: 1.67083962878678e-05\n",
            "Stage 6/10:  55%|████████████████             | 166/300 [05:41<04:30,  2.02s/it]T Loss=2.3044910430908203\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030381202697754\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047518730163574\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303661823272705\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038697242736816\n",
            "g_norm = tensor(0.0956, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.08932495117188\n",
            "||∇_X meta|| = 0.0015821971464902163\n",
            "ΔX norm: 1.582199001859408e-05\n",
            "Stage 6/10:  56%|████████████████▏            | 167/300 [05:43<04:23,  1.98s/it]T Loss=2.3053042888641357\n",
            "g_norm = tensor(0.2132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306074619293213\n",
            "g_norm = tensor(0.1958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306201457977295\n",
            "g_norm = tensor(0.1965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30543851852417\n",
            "g_norm = tensor(0.1657, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305936336517334\n",
            "g_norm = tensor(0.1698, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1554718017578\n",
            "||∇_X meta|| = 0.0014546839520335197\n",
            "ΔX norm: 1.4546854799846187e-05\n",
            "Stage 6/10:  56%|████████████████▏            | 168/300 [05:45<04:15,  1.94s/it]T Loss=2.301896810531616\n",
            "g_norm = tensor(0.1218, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024773597717285\n",
            "g_norm = tensor(0.1345, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041179180145264\n",
            "g_norm = tensor(0.1303, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302868604660034\n",
            "g_norm = tensor(0.1356, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040268421173096\n",
            "g_norm = tensor(0.1309, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.22901916503906\n",
            "||∇_X meta|| = 0.001878677518106997\n",
            "ΔX norm: 1.878678631328512e-05\n",
            "Stage 6/10:  56%|████████████████▎            | 169/300 [05:47<04:22,  2.00s/it]T Loss=2.303727626800537\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302643299102783\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303372621536255\n",
            "g_norm = tensor(0.0839, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303180456161499\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303612470626831\n",
            "g_norm = tensor(0.0791, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.75701904296875\n",
            "||∇_X meta|| = 0.0014794031158089638\n",
            "ΔX norm: 1.4794038179388735e-05\n",
            "Stage 6/10:  57%|████████████████▍            | 170/300 [05:49<04:17,  1.98s/it]T Loss=2.3051421642303467\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304847002029419\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304159641265869\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305614948272705\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30566143989563\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.28053283691406\n",
            "||∇_X meta|| = 0.0016391974641010165\n",
            "ΔX norm: 1.639195397729054e-05\n",
            "Stage 6/10:  57%|████████████████▌            | 171/300 [05:51<04:09,  1.93s/it]T Loss=2.303741693496704\n",
            "g_norm = tensor(0.1187, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043999671936035\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304924964904785\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036160469055176\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303917646408081\n",
            "g_norm = tensor(0.1184, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1778564453125\n",
            "||∇_X meta|| = 0.0016550843138247728\n",
            "ΔX norm: 1.6550844520679675e-05\n",
            "Stage 6/10:  57%|████████████████▋            | 172/300 [05:52<04:01,  1.89s/it]T Loss=2.3024322986602783\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035683631896973\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032054901123047\n",
            "g_norm = tensor(0.1330, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304499626159668\n",
            "g_norm = tensor(0.1434, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024959564208984\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.75741577148438\n",
            "||∇_X meta|| = 0.0014874279731884599\n",
            "ΔX norm: 1.4874300177325495e-05\n",
            "Stage 6/10:  58%|████████████████▋            | 173/300 [05:54<04:01,  1.90s/it]T Loss=2.3040969371795654\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305694103240967\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305219888687134\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039419651031494\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043785095214844\n",
            "g_norm = tensor(0.1351, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.16583251953125\n",
            "||∇_X meta|| = 0.001563599449582398\n",
            "ΔX norm: 1.5636014722986147e-05\n",
            "Stage 6/10:  58%|████████████████▊            | 174/300 [05:56<04:01,  1.92s/it]T Loss=2.303762435913086\n",
            "g_norm = tensor(0.1702, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046836853027344\n",
            "g_norm = tensor(0.1474, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30202054977417\n",
            "g_norm = tensor(0.1537, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304236888885498\n",
            "g_norm = tensor(0.1719, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046762943267822\n",
            "g_norm = tensor(0.1570, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.38137817382812\n",
            "||∇_X meta|| = 0.0016047247918322682\n",
            "ΔX norm: 1.6047248209360987e-05\n",
            "Stage 6/10:  58%|████████████████▉            | 175/300 [05:58<04:04,  1.96s/it]T Loss=2.3041024208068848\n",
            "g_norm = tensor(0.1508, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033416271209717\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30373477935791\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030037879943848\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040106296539307\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5411834716797\n",
            "||∇_X meta|| = 0.0014985940651968122\n",
            "ΔX norm: 1.4985944289946929e-05\n",
            "Stage 6/10:  59%|█████████████████            | 176/300 [06:00<04:02,  1.95s/it]T Loss=2.302187442779541\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301443576812744\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303178548812866\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303527355194092\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303081512451172\n",
            "g_norm = tensor(0.1268, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.9980010986328\n",
            "||∇_X meta|| = 0.0015769499586895108\n",
            "ΔX norm: 1.5769493984407745e-05\n",
            "Stage 6/10:  59%|█████████████████            | 177/300 [06:02<03:59,  1.95s/it]T Loss=2.3027100563049316\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041577339172363\n",
            "g_norm = tensor(0.1361, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303405523300171\n",
            "g_norm = tensor(0.1435, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033692836761475\n",
            "g_norm = tensor(0.1493, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039467334747314\n",
            "g_norm = tensor(0.1582, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.26475524902344\n",
            "||∇_X meta|| = 0.0014433609321713448\n",
            "ΔX norm: 1.4433599062613212e-05\n",
            "Stage 6/10:  59%|█████████████████▏           | 178/300 [06:05<04:17,  2.11s/it]T Loss=2.302757978439331\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042352199554443\n",
            "g_norm = tensor(0.1307, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043229579925537\n",
            "g_norm = tensor(0.1408, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303483486175537\n",
            "g_norm = tensor(0.1403, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048486709594727\n",
            "g_norm = tensor(0.1454, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.02023315429688\n",
            "||∇_X meta|| = 0.001663359347730875\n",
            "ΔX norm: 1.6633564882795326e-05\n",
            "Stage 6/10:  60%|█████████████████▎           | 179/300 [06:07<04:12,  2.08s/it]T Loss=2.3054354190826416\n",
            "g_norm = tensor(0.1606, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303588628768921\n",
            "g_norm = tensor(0.1400, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023033142089844\n",
            "g_norm = tensor(0.1449, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038389682769775\n",
            "g_norm = tensor(0.1099, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303910732269287\n",
            "g_norm = tensor(0.1276, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3568878173828\n",
            "||∇_X meta|| = 0.0015440654242411256\n",
            "ΔX norm: 1.5440667993971147e-05\n",
            "Stage 6/10:  60%|█████████████████▍           | 180/300 [06:09<04:17,  2.14s/it]T Loss=2.302419424057007\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303596019744873\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304068088531494\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302838087081909\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041863441467285\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.32252502441406\n",
            "||∇_X meta|| = 0.0015209937701001763\n",
            "ΔX norm: 1.52099528349936e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 6/10:  60%|█████████████████▍           | 181/300 [06:11<04:13,  2.13s/it]T Loss=2.304935932159424\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303651809692383\n",
            "g_norm = tensor(0.1346, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047077655792236\n",
            "g_norm = tensor(0.1230, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032634258270264\n",
            "g_norm = tensor(0.1316, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303300142288208\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.34852600097656\n",
            "||∇_X meta|| = 0.0014900865498930216\n",
            "ΔX norm: 1.4900861060596071e-05\n",
            "Stage 6/10:  61%|█████████████████▌           | 182/300 [06:14<04:45,  2.42s/it]T Loss=2.3031907081604004\n",
            "g_norm = tensor(0.1534, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301244020462036\n",
            "g_norm = tensor(0.1433, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302626132965088\n",
            "g_norm = tensor(0.1312, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303374767303467\n",
            "g_norm = tensor(0.1488, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017067909240723\n",
            "g_norm = tensor(0.1687, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.61280822753906\n",
            "||∇_X meta|| = 0.001518621458671987\n",
            "ΔX norm: 1.518623139418196e-05\n",
            "Stage 6/10:  61%|█████████████████▋           | 183/300 [06:16<04:26,  2.27s/it]T Loss=2.3037333488464355\n",
            "g_norm = tensor(0.1253, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037571907043457\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029184341430664\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057146072387695\n",
            "g_norm = tensor(0.1323, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303276300430298\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.55848693847656\n",
            "||∇_X meta|| = 0.0015255723847076297\n",
            "ΔX norm: 1.5255737707775552e-05\n",
            "Stage 6/10:  61%|█████████████████▊           | 184/300 [06:18<04:13,  2.18s/it]T Loss=2.3038010597229004\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303652763366699\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303448438644409\n",
            "g_norm = tensor(0.1493, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049237728118896\n",
            "g_norm = tensor(0.1421, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035595417022705\n",
            "g_norm = tensor(0.1447, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8985595703125\n",
            "||∇_X meta|| = 0.001514720031991601\n",
            "ΔX norm: 1.5147195881581865e-05\n",
            "Stage 6/10:  62%|█████████████████▉           | 185/300 [06:20<04:01,  2.10s/it]T Loss=2.3041253089904785\n",
            "g_norm = tensor(0.0824, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039557933807373\n",
            "g_norm = tensor(0.0727, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304766893386841\n",
            "g_norm = tensor(0.0822, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043274879455566\n",
            "g_norm = tensor(0.0686, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304736614227295\n",
            "g_norm = tensor(0.0757, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.0684051513672\n",
            "||∇_X meta|| = 0.0015380443073809147\n",
            "ΔX norm: 1.5380441254819743e-05\n",
            "Stage 6/10:  62%|█████████████████▉           | 186/300 [06:22<03:54,  2.06s/it]T Loss=2.303769588470459\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30476975440979\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040337562561035\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305018186569214\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030362129211426\n",
            "g_norm = tensor(0.0947, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.32275390625\n",
            "||∇_X meta|| = 0.001564855338074267\n",
            "ΔX norm: 1.5648571206838824e-05\n",
            "Stage 6/10:  62%|██████████████████           | 187/300 [06:24<03:45,  1.99s/it]T Loss=2.302316665649414\n",
            "g_norm = tensor(0.0832, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034324645996094\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302651882171631\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302581310272217\n",
            "g_norm = tensor(0.0917, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032479286193848\n",
            "g_norm = tensor(0.0931, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.51727294921875\n",
            "||∇_X meta|| = 0.0016993572935461998\n",
            "ΔX norm: 1.6993575627566315e-05\n",
            "Stage 6/10:  63%|██████████████████▏          | 188/300 [06:26<03:39,  1.96s/it]T Loss=2.3043220043182373\n",
            "g_norm = tensor(0.1218, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304668664932251\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040058612823486\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303864002227783\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304264545440674\n",
            "g_norm = tensor(0.1022, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.12693786621094\n",
            "||∇_X meta|| = 0.0016885005170479417\n",
            "ΔX norm: 1.6885012882994488e-05\n",
            "Stage 6/10:  63%|██████████████████▎          | 189/300 [06:28<03:46,  2.04s/it]T Loss=2.30416202545166\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037219047546387\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302746057510376\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034043312072754\n",
            "g_norm = tensor(0.0879, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020455837249756\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.39364624023438\n",
            "||∇_X meta|| = 0.0015245461836457253\n",
            "ΔX norm: 1.5245475879055448e-05\n",
            "Stage 6/10:  63%|██████████████████▎          | 190/300 [06:30<03:42,  2.02s/it]T Loss=2.3052103519439697\n",
            "g_norm = tensor(0.1465, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047256469726562\n",
            "g_norm = tensor(0.1660, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036417961120605\n",
            "g_norm = tensor(0.1919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304563045501709\n",
            "g_norm = tensor(0.1363, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042635917663574\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2903289794922\n",
            "||∇_X meta|| = 0.0013910062843933702\n",
            "ΔX norm: 1.391004570905352e-05\n",
            "Stage 6/10:  64%|██████████████████▍          | 191/300 [06:32<03:36,  1.99s/it]T Loss=2.3035244941711426\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303945779800415\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037877082824707\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304063558578491\n",
            "g_norm = tensor(0.0793, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041865825653076\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.24990844726562\n",
            "||∇_X meta|| = 0.0014497291995212436\n",
            "ΔX norm: 1.4497288248094264e-05\n",
            "Stage 6/10:  64%|██████████████████▌          | 192/300 [06:34<03:32,  1.97s/it]T Loss=2.3031277656555176\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041958808898926\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304302215576172\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303718328475952\n",
            "g_norm = tensor(0.0837, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044943809509277\n",
            "g_norm = tensor(0.1367, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5762176513672\n",
            "||∇_X meta|| = 0.0017498299712315202\n",
            "ΔX norm: 1.7498323359177448e-05\n",
            "Stage 6/10:  64%|██████████████████▋          | 193/300 [06:35<03:26,  1.93s/it]T Loss=2.3046889305114746\n",
            "g_norm = tensor(0.1465, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303544282913208\n",
            "g_norm = tensor(0.1655, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024301528930664\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044865131378174\n",
            "g_norm = tensor(0.1370, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048274517059326\n",
            "g_norm = tensor(0.1375, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.86936950683594\n",
            "||∇_X meta|| = 0.0014921686379238963\n",
            "ΔX norm: 1.4921686670277268e-05\n",
            "Stage 6/10:  65%|██████████████████▊          | 194/300 [06:38<03:29,  1.97s/it]T Loss=2.304133176803589\n",
            "g_norm = tensor(0.0860, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033812046051025\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028082847595215\n",
            "g_norm = tensor(0.0872, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303142786026001\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302739381790161\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.63397216796875\n",
            "||∇_X meta|| = 0.0015590513357892632\n",
            "ΔX norm: 1.5590512703056447e-05\n",
            "Stage 6/10:  65%|██████████████████▊          | 195/300 [06:39<03:22,  1.93s/it]T Loss=2.3034729957580566\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303312063217163\n",
            "g_norm = tensor(0.1691, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021302223205566\n",
            "g_norm = tensor(0.1380, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052256107330322\n",
            "g_norm = tensor(0.1479, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044075965881348\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.05230712890625\n",
            "||∇_X meta|| = 0.0015602321363985538\n",
            "ΔX norm: 1.5602285202476196e-05\n",
            "Stage 6/10:  65%|██████████████████▉          | 196/300 [06:41<03:20,  1.93s/it]T Loss=2.303525447845459\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043227195739746\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304900646209717\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304056167602539\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304250717163086\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.82577514648438\n",
            "||∇_X meta|| = 0.001570576336234808\n",
            "ΔX norm: 1.5705780242569745e-05\n",
            "Stage 6/10:  66%|███████████████████          | 197/300 [06:43<03:16,  1.91s/it]T Loss=2.303304672241211\n",
            "g_norm = tensor(0.1234, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304511308670044\n",
            "g_norm = tensor(0.1360, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303753614425659\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304652690887451\n",
            "g_norm = tensor(0.1575, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304187059402466\n",
            "g_norm = tensor(0.1216, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.24240112304688\n",
            "||∇_X meta|| = 0.0014293468557298183\n",
            "ΔX norm: 1.4293436834122986e-05\n",
            "Stage 6/10:  66%|███████████████████▏         | 198/300 [06:45<03:14,  1.90s/it]T Loss=2.302912712097168\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303077220916748\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30293607711792\n",
            "g_norm = tensor(0.1386, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046915531158447\n",
            "g_norm = tensor(0.1271, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029589653015137\n",
            "g_norm = tensor(0.1302, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.724609375\n",
            "||∇_X meta|| = 0.0016069207340478897\n",
            "ΔX norm: 1.606918522156775e-05\n",
            "Stage 6/10:  66%|███████████████████▏         | 199/300 [06:47<03:10,  1.88s/it]T Loss=2.3034002780914307\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303457260131836\n",
            "g_norm = tensor(0.0945, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034253120422363\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303226947784424\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30355167388916\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.98223876953125\n",
            "||∇_X meta|| = 0.0015061948215588927\n",
            "ΔX norm: 1.5061948943184689e-05\n",
            "Stage 6/10:  67%|███████████████████▎         | 200/300 [06:49<03:06,  1.87s/it]T Loss=2.30319881439209\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304812431335449\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303906202316284\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305121898651123\n",
            "g_norm = tensor(0.1234, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303997755050659\n",
            "g_norm = tensor(0.0850, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.31190490722656\n",
            "||∇_X meta|| = 0.0015040277503430843\n",
            "ΔX norm: 1.5040271136967931e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 6/10:  67%|███████████████████▍         | 201/300 [06:51<03:16,  1.98s/it]T Loss=2.304145336151123\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050625324249268\n",
            "g_norm = tensor(0.1414, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049075603485107\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3016865253448486\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035035133361816\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.80043029785156\n",
            "||∇_X meta|| = 0.0014571952633559704\n",
            "ΔX norm: 1.4571964129572734e-05\n",
            "Stage 6/10:  67%|███████████████████▌         | 202/300 [06:54<03:32,  2.16s/it]T Loss=2.303816080093384\n",
            "g_norm = tensor(0.1330, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020031452178955\n",
            "g_norm = tensor(0.1183, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302689790725708\n",
            "g_norm = tensor(0.1453, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303276538848877\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302809238433838\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4632568359375\n",
            "||∇_X meta|| = 0.0015768471639603376\n",
            "ΔX norm: 1.576848080730997e-05\n",
            "Stage 6/10:  68%|███████████████████▌         | 203/300 [06:55<03:23,  2.09s/it]T Loss=2.3034164905548096\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304246187210083\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027753829956055\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302926540374756\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030543327331543\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.20645141601562\n",
            "||∇_X meta|| = 0.0015658395132049918\n",
            "ΔX norm: 1.56584083015332e-05\n",
            "Stage 6/10:  68%|███████████████████▋         | 204/300 [06:57<03:16,  2.05s/it]T Loss=2.3042359352111816\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305636167526245\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044941425323486\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3060739040374756\n",
            "g_norm = tensor(0.1331, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026554584503174\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.75759887695312\n",
            "||∇_X meta|| = 0.0017131882486864924\n",
            "ΔX norm: 1.7131866115960293e-05\n",
            "Stage 6/10:  68%|███████████████████▊         | 205/300 [06:59<03:08,  1.98s/it]T Loss=2.303633213043213\n",
            "g_norm = tensor(0.0762, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031792640686035\n",
            "g_norm = tensor(0.0709, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035240173339844\n",
            "g_norm = tensor(0.0793, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302642345428467\n",
            "g_norm = tensor(0.0771, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303959608078003\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2366485595703\n",
            "||∇_X meta|| = 0.0015298647340387106\n",
            "ΔX norm: 1.5298646758310497e-05\n",
            "Stage 6/10:  69%|███████████████████▉         | 206/300 [07:01<03:00,  1.93s/it]T Loss=2.3014230728149414\n",
            "g_norm = tensor(0.1434, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036534786224365\n",
            "g_norm = tensor(0.1426, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021767139434814\n",
            "g_norm = tensor(0.1342, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302637815475464\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302454710006714\n",
            "g_norm = tensor(0.1429, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.3052520751953\n",
            "||∇_X meta|| = 0.0016753211384639144\n",
            "ΔX norm: 1.675321072980296e-05\n",
            "Stage 6/10:  69%|████████████████████         | 207/300 [07:03<02:57,  1.91s/it]T Loss=2.303431510925293\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031961917877197\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037519454956055\n",
            "g_norm = tensor(0.0814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027548789978027\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035712242126465\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.5610809326172\n",
            "||∇_X meta|| = 0.001566387014463544\n",
            "ΔX norm: 1.5663870726712048e-05\n",
            "Stage 6/10:  69%|████████████████████         | 208/300 [07:05<02:57,  1.92s/it]T Loss=2.3036487102508545\n",
            "g_norm = tensor(0.0706, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040592670440674\n",
            "g_norm = tensor(0.0697, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033366203308105\n",
            "g_norm = tensor(0.0627, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040480613708496\n",
            "g_norm = tensor(0.0735, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037402629852295\n",
            "g_norm = tensor(0.0732, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.34909057617188\n",
            "||∇_X meta|| = 0.0014526931336149573\n",
            "ΔX norm: 1.4526932318403851e-05\n",
            "Stage 6/10:  70%|████████████████████▏        | 209/300 [07:07<02:52,  1.89s/it]T Loss=2.3025505542755127\n",
            "g_norm = tensor(0.1288, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033108711242676\n",
            "g_norm = tensor(0.1689, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302943229675293\n",
            "g_norm = tensor(0.1577, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029134273529053\n",
            "g_norm = tensor(0.1581, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302490234375\n",
            "g_norm = tensor(0.1704, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7282257080078\n",
            "||∇_X meta|| = 0.0016449615359306335\n",
            "ΔX norm: 1.644962867430877e-05\n",
            "Stage 6/10:  70%|████████████████████▎        | 210/300 [07:09<03:01,  2.02s/it]T Loss=2.3046603202819824\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305388927459717\n",
            "g_norm = tensor(0.1075, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304302930831909\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049280643463135\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304943084716797\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9178466796875\n",
            "||∇_X meta|| = 0.0015974822454154491\n",
            "ΔX norm: 1.5974819689290598e-05\n",
            "Stage 6/10:  70%|████████████████████▍        | 211/300 [07:11<03:00,  2.03s/it]T Loss=2.3036587238311768\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303104877471924\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038506507873535\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304323196411133\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032054901123047\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4912872314453\n",
            "||∇_X meta|| = 0.0016032546991482377\n",
            "ΔX norm: 1.603251621418167e-05\n",
            "Stage 6/10:  71%|████████████████████▍        | 212/300 [07:13<03:04,  2.09s/it]T Loss=2.302619218826294\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302583694458008\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025150299072266\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040387630462646\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30417799949646\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6367645263672\n",
            "||∇_X meta|| = 0.0014911126345396042\n",
            "ΔX norm: 1.4911128346284386e-05\n",
            "Stage 6/10:  71%|████████████████████▌        | 213/300 [07:15<02:58,  2.05s/it]T Loss=2.3033180236816406\n",
            "g_norm = tensor(0.1330, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045029640197754\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303546667098999\n",
            "g_norm = tensor(0.1216, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303652048110962\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048837184906006\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.34616088867188\n",
            "||∇_X meta|| = 0.00156153563875705\n",
            "ΔX norm: 1.5615381926181726e-05\n",
            "Stage 6/10:  71%|████████████████████▋        | 214/300 [07:17<02:54,  2.03s/it]T Loss=2.302457332611084\n",
            "g_norm = tensor(0.1328, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034234046936035\n",
            "g_norm = tensor(0.1309, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303736925125122\n",
            "g_norm = tensor(0.1398, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302581310272217\n",
            "g_norm = tensor(0.1679, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302712917327881\n",
            "g_norm = tensor(0.1641, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.72500610351562\n",
            "||∇_X meta|| = 0.0015745825367048383\n",
            "ΔX norm: 1.5745818018331192e-05\n",
            "Stage 6/10:  72%|████████████████████▊        | 215/300 [07:19<02:49,  2.00s/it]T Loss=2.3032994270324707\n",
            "g_norm = tensor(0.1458, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303844928741455\n",
            "g_norm = tensor(0.1629, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043289184570312\n",
            "g_norm = tensor(0.1758, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045871257781982\n",
            "g_norm = tensor(0.1453, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30312180519104\n",
            "g_norm = tensor(0.1792, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.6080780029297\n",
            "||∇_X meta|| = 0.0015148685779422522\n",
            "ΔX norm: 1.5148692000366282e-05\n",
            "Stage 6/10:  72%|████████████████████▉        | 216/300 [07:21<02:44,  1.96s/it]T Loss=2.3025875091552734\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038830757141113\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303265333175659\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30393123626709\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304060697555542\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.95860290527344\n",
            "||∇_X meta|| = 0.0014272240223363042\n",
            "ΔX norm: 1.4272226508182939e-05\n",
            "Stage 6/10:  72%|████████████████████▉        | 217/300 [07:23<02:42,  1.96s/it]T Loss=2.304821252822876\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304325580596924\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037400245666504\n",
            "g_norm = tensor(0.1481, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30094313621521\n",
            "g_norm = tensor(0.1583, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041839599609375\n",
            "g_norm = tensor(0.1303, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.15711975097656\n",
            "||∇_X meta|| = 0.0016488016117364168\n",
            "ΔX norm: 1.6488032997585833e-05\n",
            "Stage 6/10:  73%|█████████████████████        | 218/300 [07:25<02:37,  1.92s/it]T Loss=2.3062214851379395\n",
            "g_norm = tensor(0.1385, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305907964706421\n",
            "g_norm = tensor(0.1270, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050124645233154\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304811477661133\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039562702178955\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.07888793945312\n",
            "||∇_X meta|| = 0.0014527026796713471\n",
            "ΔX norm: 1.4527029634336941e-05\n",
            "Stage 6/10:  73%|█████████████████████▏       | 219/300 [07:27<02:32,  1.89s/it]T Loss=2.3032519817352295\n",
            "g_norm = tensor(0.1566, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301955461502075\n",
            "g_norm = tensor(0.1441, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30361008644104\n",
            "g_norm = tensor(0.1510, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027539253234863\n",
            "g_norm = tensor(0.1342, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042521476745605\n",
            "g_norm = tensor(0.1584, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.17539978027344\n",
            "||∇_X meta|| = 0.0016108016716316342\n",
            "ΔX norm: 1.610800791240763e-05\n",
            "Stage 6/10:  73%|█████████████████████▎       | 220/300 [07:29<02:37,  1.96s/it]T Loss=2.3042454719543457\n",
            "g_norm = tensor(0.1927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3059639930725098\n",
            "g_norm = tensor(0.1645, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027377128601074\n",
            "g_norm = tensor(0.1863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038601875305176\n",
            "g_norm = tensor(0.1768, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053297996520996\n",
            "g_norm = tensor(0.1771, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.0730438232422\n",
            "||∇_X meta|| = 0.0015831488417461514\n",
            "ΔX norm: 1.583150151418522e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 6/10:  74%|█████████████████████▎       | 221/300 [07:31<02:36,  1.99s/it]T Loss=2.303352117538452\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031890392303467\n",
            "g_norm = tensor(0.0928, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303879499435425\n",
            "g_norm = tensor(0.0764, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304201602935791\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035457134246826\n",
            "g_norm = tensor(0.0865, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.24295043945312\n",
            "||∇_X meta|| = 0.0014969215262681246\n",
            "ΔX norm: 1.4969213225413114e-05\n",
            "Stage 6/10:  74%|█████████████████████▍       | 222/300 [07:33<02:49,  2.18s/it]T Loss=2.303706407546997\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042116165161133\n",
            "g_norm = tensor(0.0693, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046727180480957\n",
            "g_norm = tensor(0.0878, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033249378204346\n",
            "g_norm = tensor(0.0667, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303428888320923\n",
            "g_norm = tensor(0.0773, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3131103515625\n",
            "||∇_X meta|| = 0.001683683367446065\n",
            "ΔX norm: 1.6836853319546208e-05\n",
            "Stage 6/10:  74%|█████████████████████▌       | 223/300 [07:35<02:44,  2.14s/it]T Loss=2.304439067840576\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303173542022705\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030002117156982\n",
            "g_norm = tensor(0.0956, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040857315063477\n",
            "g_norm = tensor(0.1021, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303947687149048\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.42745971679688\n",
            "||∇_X meta|| = 0.0015322669642046094\n",
            "ΔX norm: 1.532266105641611e-05\n",
            "Stage 6/10:  75%|█████████████████████▋       | 224/300 [07:37<02:39,  2.10s/it]T Loss=2.3028290271759033\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304083824157715\n",
            "g_norm = tensor(0.1399, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018295764923096\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027679920196533\n",
            "g_norm = tensor(0.1304, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302715301513672\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1055145263672\n",
            "||∇_X meta|| = 0.0015379907563328743\n",
            "ΔX norm: 1.5379910109913908e-05\n",
            "Stage 6/10:  75%|█████████████████████▊       | 225/300 [07:39<02:30,  2.01s/it]T Loss=2.3038675785064697\n",
            "g_norm = tensor(0.0852, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303960084915161\n",
            "g_norm = tensor(0.0861, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303776979446411\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304877281188965\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304208755493164\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.29049682617188\n",
            "||∇_X meta|| = 0.0017988506006076932\n",
            "ΔX norm: 1.7988508261623792e-05\n",
            "Stage 6/10:  75%|█████████████████████▊       | 226/300 [07:41<02:24,  1.96s/it]T Loss=2.3036296367645264\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303750991821289\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049004077911377\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303520679473877\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303199291229248\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.93641662597656\n",
            "||∇_X meta|| = 0.0014829583233222365\n",
            "ΔX norm: 1.4829594874754548e-05\n",
            "Stage 6/10:  76%|█████████████████████▉       | 227/300 [07:43<02:29,  2.05s/it]T Loss=2.304058790206909\n",
            "g_norm = tensor(0.0856, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037760257720947\n",
            "g_norm = tensor(0.0768, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042409420013428\n",
            "g_norm = tensor(0.0787, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304124116897583\n",
            "g_norm = tensor(0.0931, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304328441619873\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.98406982421875\n",
            "||∇_X meta|| = 0.0016302511794492602\n",
            "ΔX norm: 1.6302517906296998e-05\n",
            "Stage 6/10:  76%|██████████████████████       | 228/300 [07:45<02:28,  2.06s/it]T Loss=2.30318284034729\n",
            "g_norm = tensor(0.0776, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035621643066406\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030285835266113\n",
            "g_norm = tensor(0.0812, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304035186767578\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043689727783203\n",
            "g_norm = tensor(0.0869, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.14599609375\n",
            "||∇_X meta|| = 0.0014873604523018003\n",
            "ΔX norm: 1.4873604413878638e-05\n",
            "Stage 6/10:  76%|██████████████████████▏      | 229/300 [07:47<02:24,  2.03s/it]T Loss=2.3029956817626953\n",
            "g_norm = tensor(0.0848, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035359382629395\n",
            "g_norm = tensor(0.0675, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036911487579346\n",
            "g_norm = tensor(0.0733, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032994270324707\n",
            "g_norm = tensor(0.0807, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303541660308838\n",
            "g_norm = tensor(0.0786, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.41708374023438\n",
            "||∇_X meta|| = 0.001614524400793016\n",
            "ΔX norm: 1.6145242625498213e-05\n",
            "Stage 6/10:  77%|██████████████████████▏      | 230/300 [07:49<02:17,  1.97s/it]T Loss=2.305060625076294\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034253120422363\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304614543914795\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050715923309326\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044116497039795\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5596923828125\n",
            "||∇_X meta|| = 0.0013177519431337714\n",
            "ΔX norm: 1.3177510481909849e-05\n",
            "Stage 6/10:  77%|██████████████████████▎      | 231/300 [07:51<02:18,  2.01s/it]T Loss=2.3058323860168457\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049349784851074\n",
            "g_norm = tensor(0.1275, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306234836578369\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3060476779937744\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305448532104492\n",
            "g_norm = tensor(0.1418, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.29673767089844\n",
            "||∇_X meta|| = 0.0016091630095615983\n",
            "ΔX norm: 1.609164428373333e-05\n",
            "Stage 6/10:  77%|██████████████████████▍      | 232/300 [07:53<02:17,  2.02s/it]T Loss=2.303098678588867\n",
            "g_norm = tensor(0.1541, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036816120147705\n",
            "g_norm = tensor(0.1487, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038880825042725\n",
            "g_norm = tensor(0.1400, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058040142059326\n",
            "g_norm = tensor(0.1508, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303776979446411\n",
            "g_norm = tensor(0.1502, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.9667510986328\n",
            "||∇_X meta|| = 0.0016709720948711038\n",
            "ΔX norm: 1.670971505518537e-05\n",
            "Stage 6/10:  78%|██████████████████████▌      | 233/300 [07:55<02:15,  2.02s/it]T Loss=2.303783893585205\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303685426712036\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047542572021484\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303724527359009\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046793937683105\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5255126953125\n",
            "||∇_X meta|| = 0.0016216675285249949\n",
            "ΔX norm: 1.6216717995121144e-05\n",
            "Stage 6/10:  78%|██████████████████████▌      | 234/300 [07:57<02:13,  2.03s/it]T Loss=2.304586887359619\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304671049118042\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30202054977417\n",
            "g_norm = tensor(0.1349, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036134243011475\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303865909576416\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.6821746826172\n",
            "||∇_X meta|| = 0.0015282067470252514\n",
            "ΔX norm: 1.5282066669897176e-05\n",
            "Stage 6/10:  78%|██████████████████████▋      | 235/300 [07:59<02:08,  1.98s/it]T Loss=2.304633855819702\n",
            "g_norm = tensor(0.0917, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038554191589355\n",
            "g_norm = tensor(0.0827, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036441802978516\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041625022888184\n",
            "g_norm = tensor(0.0778, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304169178009033\n",
            "g_norm = tensor(0.0746, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.59674072265625\n",
            "||∇_X meta|| = 0.0016265787417069077\n",
            "ΔX norm: 1.62657888722606e-05\n",
            "Stage 6/10:  79%|██████████████████████▊      | 236/300 [08:01<02:04,  1.95s/it]T Loss=2.303244113922119\n",
            "g_norm = tensor(0.1603, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029396533966064\n",
            "g_norm = tensor(0.1423, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303711414337158\n",
            "g_norm = tensor(0.1504, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029367923736572\n",
            "g_norm = tensor(0.1381, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034818172454834\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.99603271484375\n",
            "||∇_X meta|| = 0.0014951152261346579\n",
            "ΔX norm: 1.4951142475183588e-05\n",
            "Stage 6/10:  79%|██████████████████████▉      | 237/300 [08:03<02:00,  1.92s/it]T Loss=2.3027939796447754\n",
            "g_norm = tensor(0.1362, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044323921203613\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302772045135498\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303239345550537\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043487071990967\n",
            "g_norm = tensor(0.1140, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9864501953125\n",
            "||∇_X meta|| = 0.0014538285322487354\n",
            "ΔX norm: 1.4538286450260784e-05\n",
            "Stage 6/10:  79%|███████████████████████      | 238/300 [08:05<01:58,  1.92s/it]T Loss=2.303293228149414\n",
            "g_norm = tensor(0.1404, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020808696746826\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034584522247314\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302863359451294\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027548789978027\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5909881591797\n",
            "||∇_X meta|| = 0.0014905286952853203\n",
            "ΔX norm: 1.490530848968774e-05\n",
            "Stage 6/10:  80%|███████████████████████      | 239/300 [08:07<01:57,  1.93s/it]T Loss=2.30289888381958\n",
            "g_norm = tensor(0.1402, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043227195739746\n",
            "g_norm = tensor(0.1458, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303067684173584\n",
            "g_norm = tensor(0.1599, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043854236602783\n",
            "g_norm = tensor(0.1446, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034167289733887\n",
            "g_norm = tensor(0.1377, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4059295654297\n",
            "||∇_X meta|| = 0.0014788358239457011\n",
            "ΔX norm: 1.4788361113460269e-05\n",
            "Stage 6/10:  80%|███████████████████████▏     | 240/300 [08:10<02:07,  2.13s/it]T Loss=2.3037610054016113\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302809000015259\n",
            "g_norm = tensor(0.1359, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031980991363525\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027749061584473\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302436590194702\n",
            "g_norm = tensor(0.1474, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.35745239257812\n",
            "||∇_X meta|| = 0.0014998295810073614\n",
            "ΔX norm: 1.4998288861534093e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 6/10:  80%|███████████████████████▎     | 241/300 [08:12<02:03,  2.10s/it]T Loss=2.3030266761779785\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037824630737305\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031203746795654\n",
            "g_norm = tensor(0.1296, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304016590118408\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025400638580322\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.07476806640625\n",
            "||∇_X meta|| = 0.0014468819135800004\n",
            "ΔX norm: 1.4468835615844e-05\n",
            "Stage 6/10:  81%|███████████████████████▍     | 242/300 [08:14<02:11,  2.26s/it]T Loss=2.304068088531494\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302523374557495\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032126426696777\n",
            "g_norm = tensor(0.1271, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302382230758667\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039231300354004\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9384002685547\n",
            "||∇_X meta|| = 0.0016815009294077754\n",
            "ΔX norm: 1.681501635175664e-05\n",
            "Stage 6/10:  81%|███████████████████████▍     | 243/300 [08:16<02:02,  2.16s/it]T Loss=2.304722309112549\n",
            "g_norm = tensor(0.1600, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038477897644043\n",
            "g_norm = tensor(0.1739, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303752899169922\n",
            "g_norm = tensor(0.1637, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303917169570923\n",
            "g_norm = tensor(0.1420, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050942420959473\n",
            "g_norm = tensor(0.1815, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.77540588378906\n",
            "||∇_X meta|| = 0.0015457883710041642\n",
            "ΔX norm: 1.5457899280590937e-05\n",
            "Stage 6/10:  81%|███████████████████████▌     | 244/300 [08:18<01:56,  2.08s/it]T Loss=2.302983045578003\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303147792816162\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303614854812622\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303795337677002\n",
            "g_norm = tensor(0.0865, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30328106880188\n",
            "g_norm = tensor(0.0845, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.833984375\n",
            "||∇_X meta|| = 0.0014940605033189058\n",
            "ΔX norm: 1.4940594155632425e-05\n",
            "Stage 6/10:  82%|███████████████████████▋     | 245/300 [08:20<01:52,  2.04s/it]T Loss=2.303957223892212\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042964935302734\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044228553771973\n",
            "g_norm = tensor(0.0917, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303539752960205\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031890392303467\n",
            "g_norm = tensor(0.0833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.90769958496094\n",
            "||∇_X meta|| = 0.0015730706509202719\n",
            "ΔX norm: 1.5730711311334744e-05\n",
            "Stage 6/10:  82%|███████████████████████▊     | 246/300 [08:22<01:47,  2.00s/it]T Loss=2.3034396171569824\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039371967315674\n",
            "g_norm = tensor(0.1251, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302680492401123\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302841901779175\n",
            "g_norm = tensor(0.1367, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303917169570923\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.20297241210938\n",
            "||∇_X meta|| = 0.0015162053750827909\n",
            "ΔX norm: 1.51620388351148e-05\n",
            "Stage 6/10:  82%|███████████████████████▉     | 247/300 [08:24<01:47,  2.02s/it]T Loss=2.3030550479888916\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30263614654541\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030240535736084\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026909828186035\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027729988098145\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.208251953125\n",
            "||∇_X meta|| = 0.0016423903871327639\n",
            "ΔX norm: 1.642391725908965e-05\n",
            "Stage 6/10:  83%|███████████████████████▉     | 248/300 [08:26<01:42,  1.98s/it]T Loss=2.304318904876709\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304492712020874\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30515718460083\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053627014160156\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053646087646484\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8582000732422\n",
            "||∇_X meta|| = 0.001562913996167481\n",
            "ΔX norm: 1.562913712405134e-05\n",
            "Stage 6/10:  83%|████████████████████████     | 249/300 [08:28<01:39,  1.94s/it]T Loss=2.3017961978912354\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303175210952759\n",
            "g_norm = tensor(0.0937, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302731990814209\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303485631942749\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033719062805176\n",
            "g_norm = tensor(0.0933, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.06838989257812\n",
            "||∇_X meta|| = 0.001590143539942801\n",
            "ΔX norm: 1.5901428923825733e-05\n",
            "Stage 6/10:  83%|████████████████████████▏    | 250/300 [08:29<01:35,  1.91s/it]T Loss=2.3025598526000977\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303041934967041\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029043674468994\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031163215637207\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303053379058838\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9423828125\n",
            "||∇_X meta|| = 0.001735108788125217\n",
            "ΔX norm: 1.735109071887564e-05\n",
            "Stage 6/10:  84%|████████████████████████▎    | 251/300 [08:31<01:32,  1.89s/it]T Loss=2.304022789001465\n",
            "g_norm = tensor(0.1348, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022894859313965\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047103881835938\n",
            "g_norm = tensor(0.1413, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032445907592773\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303725481033325\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.15550231933594\n",
            "||∇_X meta|| = 0.0015602054772898555\n",
            "ΔX norm: 1.5602045095874928e-05\n",
            "Stage 6/10:  84%|████████████████████████▎    | 252/300 [08:34<01:35,  1.98s/it]T Loss=2.3037269115448\n",
            "g_norm = tensor(0.1441, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030405044555664\n",
            "g_norm = tensor(0.1420, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034005165100098\n",
            "g_norm = tensor(0.1502, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020498752593994\n",
            "g_norm = tensor(0.1507, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.300567150115967\n",
            "g_norm = tensor(0.1686, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.94091796875\n",
            "||∇_X meta|| = 0.00160078180488199\n",
            "ΔX norm: 1.6007843441911973e-05\n",
            "Stage 6/10:  84%|████████████████████████▍    | 253/300 [08:35<01:32,  1.98s/it]T Loss=2.3028368949890137\n",
            "g_norm = tensor(0.1163, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303931474685669\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302433967590332\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031527996063232\n",
            "g_norm = tensor(0.1342, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039658069610596\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.38629150390625\n",
            "||∇_X meta|| = 0.00155190983787179\n",
            "ΔX norm: 1.5519099179073237e-05\n",
            "Stage 6/10:  85%|████████████████████████▌    | 254/300 [08:37<01:30,  1.96s/it]T Loss=2.3041319847106934\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034543991088867\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033647537231445\n",
            "g_norm = tensor(0.1140, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030848503112793\n",
            "g_norm = tensor(0.1344, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047053813934326\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2113037109375\n",
            "||∇_X meta|| = 0.001632355502806604\n",
            "ΔX norm: 1.632353632885497e-05\n",
            "Stage 6/10:  85%|████████████████████████▋    | 255/300 [08:39<01:26,  1.93s/it]T Loss=2.3038010597229004\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302384614944458\n",
            "g_norm = tensor(0.1332, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303192138671875\n",
            "g_norm = tensor(0.1651, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034427165985107\n",
            "g_norm = tensor(0.1547, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037471771240234\n",
            "g_norm = tensor(0.1507, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.35580444335938\n",
            "||∇_X meta|| = 0.00147852988447994\n",
            "ΔX norm: 1.4785301573283505e-05\n",
            "Stage 6/10:  85%|████████████████████████▋    | 256/300 [08:41<01:23,  1.89s/it]T Loss=2.304656505584717\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034138679504395\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30454683303833\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041985034942627\n",
            "g_norm = tensor(0.0849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038077354431152\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.03170776367188\n",
            "||∇_X meta|| = 0.0015613171271979809\n",
            "ΔX norm: 1.561314275022596e-05\n",
            "Stage 6/10:  86%|████████████████████████▊    | 257/300 [08:43<01:25,  1.99s/it]T Loss=2.3055710792541504\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303661584854126\n",
            "g_norm = tensor(0.0821, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303054094314575\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043792247772217\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044369220733643\n",
            "g_norm = tensor(0.0865, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.5629119873047\n",
            "||∇_X meta|| = 0.0016277265967801213\n",
            "ΔX norm: 1.6277268514386378e-05\n",
            "Stage 6/10:  86%|████████████████████████▉    | 258/300 [08:45<01:22,  1.96s/it]T Loss=2.3049304485321045\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039002418518066\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053689002990723\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304225444793701\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30534029006958\n",
            "g_norm = tensor(0.1283, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8858642578125\n",
            "||∇_X meta|| = 0.001694009522907436\n",
            "ΔX norm: 1.694010461505968e-05\n",
            "Stage 6/10:  86%|█████████████████████████    | 259/300 [08:47<01:20,  1.96s/it]T Loss=2.3039615154266357\n",
            "g_norm = tensor(0.1266, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051412105560303\n",
            "g_norm = tensor(0.1426, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032379150390625\n",
            "g_norm = tensor(0.1427, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303924083709717\n",
            "g_norm = tensor(0.1297, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047854900360107\n",
            "g_norm = tensor(0.1469, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.96275329589844\n",
            "||∇_X meta|| = 0.001608395017683506\n",
            "ΔX norm: 1.6083955415524542e-05\n",
            "Stage 6/10:  87%|█████████████████████████▏   | 260/300 [08:49<01:17,  1.94s/it]T Loss=2.303408622741699\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3059616088867188\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305333137512207\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3060150146484375\n",
            "g_norm = tensor(0.1362, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305227279663086\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.8326416015625\n",
            "||∇_X meta|| = 0.0015165130607783794\n",
            "ΔX norm: 1.5165154763963073e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 6/10:  87%|█████████████████████████▏   | 261/300 [08:51<01:14,  1.92s/it]T Loss=2.307030200958252\n",
            "g_norm = tensor(0.1876, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304236888885498\n",
            "g_norm = tensor(0.1620, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.299804925918579\n",
            "g_norm = tensor(0.2155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302337646484375\n",
            "g_norm = tensor(0.1698, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306206703186035\n",
            "g_norm = tensor(0.1609, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8397674560547\n",
            "||∇_X meta|| = 0.001621845061890781\n",
            "ΔX norm: 1.6218464224948548e-05\n",
            "Stage 6/10:  87%|█████████████████████████▎   | 262/300 [08:53<01:18,  2.06s/it]T Loss=2.304516077041626\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026840686798096\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058934211730957\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304500102996826\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044285774230957\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.8817138671875\n",
            "||∇_X meta|| = 0.0015311186434701085\n",
            "ΔX norm: 1.531120142317377e-05\n",
            "Stage 6/10:  88%|█████████████████████████▍   | 263/300 [08:55<01:15,  2.05s/it]T Loss=2.3035292625427246\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304363965988159\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038172721862793\n",
            "g_norm = tensor(0.0947, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045389652252197\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304267406463623\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.35653686523438\n",
            "||∇_X meta|| = 0.0015741767128929496\n",
            "ΔX norm: 1.574178895680234e-05\n",
            "Stage 6/10:  88%|█████████████████████████▌   | 264/300 [08:57<01:12,  2.01s/it]T Loss=2.3035988807678223\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303626537322998\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305006980895996\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304351329803467\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037240505218506\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.05665588378906\n",
            "||∇_X meta|| = 0.0015623600920662284\n",
            "ΔX norm: 1.5623589206370525e-05\n",
            "Stage 6/10:  88%|█████████████████████████▌   | 265/300 [09:00<01:16,  2.19s/it]T Loss=2.3039567470550537\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306114912033081\n",
            "g_norm = tensor(0.1797, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044769763946533\n",
            "g_norm = tensor(0.1332, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032846450805664\n",
            "g_norm = tensor(0.1306, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051276206970215\n",
            "g_norm = tensor(0.1524, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.32696533203125\n",
            "||∇_X meta|| = 0.0015152619453147054\n",
            "ΔX norm: 1.5152650121308398e-05\n",
            "Stage 6/10:  89%|█████████████████████████▋   | 266/300 [09:02<01:18,  2.31s/it]T Loss=2.3029682636260986\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031764030456543\n",
            "g_norm = tensor(0.1021, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037540912628174\n",
            "g_norm = tensor(0.1216, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044228553771973\n",
            "g_norm = tensor(0.0795, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052444458007812\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.13400268554688\n",
            "||∇_X meta|| = 0.0016108573181554675\n",
            "ΔX norm: 1.610854633327108e-05\n",
            "Stage 6/10:  89%|█████████████████████████▊   | 267/300 [09:07<01:41,  3.07s/it]T Loss=2.303159236907959\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028807640075684\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032803535461426\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024964332580566\n",
            "g_norm = tensor(0.1110, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037164211273193\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.11383056640625\n",
            "||∇_X meta|| = 0.001395682105794549\n",
            "ΔX norm: 1.3956840120954439e-05\n",
            "Stage 6/10:  89%|█████████████████████████▉   | 268/300 [09:11<01:39,  3.11s/it]T Loss=2.3046820163726807\n",
            "g_norm = tensor(0.0897, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304842472076416\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046984672546387\n",
            "g_norm = tensor(0.0808, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304497241973877\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304090976715088\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9309844970703\n",
            "||∇_X meta|| = 0.0015188285615295172\n",
            "ΔX norm: 1.5188282304734457e-05\n",
            "Stage 6/10:  90%|██████████████████████████   | 269/300 [09:13<01:33,  3.02s/it]T Loss=2.3032498359680176\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023993968963623\n",
            "g_norm = tensor(0.1308, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038830757141113\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302964925765991\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30312180519104\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.10696411132812\n",
            "||∇_X meta|| = 0.0016285359160974622\n",
            "ΔX norm: 1.6285355741274543e-05\n",
            "Stage 6/10:  90%|██████████████████████████   | 270/300 [09:16<01:28,  2.95s/it]T Loss=2.3030238151550293\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033180236816406\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302616596221924\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30295729637146\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303798198699951\n",
            "g_norm = tensor(0.0867, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.49716186523438\n",
            "||∇_X meta|| = 0.001392042962834239\n",
            "ΔX norm: 1.3920439414505381e-05\n",
            "Stage 6/10:  90%|██████████████████████████▏  | 271/300 [09:18<01:18,  2.69s/it]T Loss=2.3031482696533203\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029568195343018\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031463623046875\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302827835083008\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038251399993896\n",
            "g_norm = tensor(0.0857, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3967742919922\n",
            "||∇_X meta|| = 0.0015140968607738614\n",
            "ΔX norm: 1.5140949471970089e-05\n",
            "Stage 6/10:  91%|██████████████████████████▎  | 272/300 [09:20<01:09,  2.50s/it]T Loss=2.3049468994140625\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30336856842041\n",
            "g_norm = tensor(0.1118, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304004430770874\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303452968597412\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058204650878906\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.55775451660156\n",
            "||∇_X meta|| = 0.0015347113367170095\n",
            "ΔX norm: 1.5347086446126923e-05\n",
            "Stage 6/10:  91%|██████████████████████████▍  | 273/300 [09:22<01:02,  2.32s/it]T Loss=2.3034369945526123\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039958477020264\n",
            "g_norm = tensor(0.0933, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303032398223877\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032546043395996\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021161556243896\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.79412841796875\n",
            "||∇_X meta|| = 0.001579608884640038\n",
            "ΔX norm: 1.5796071238582954e-05\n",
            "Stage 6/10:  91%|██████████████████████████▍  | 274/300 [09:24<00:57,  2.20s/it]T Loss=2.3062937259674072\n",
            "g_norm = tensor(0.1250, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303316593170166\n",
            "g_norm = tensor(0.1276, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019213676452637\n",
            "g_norm = tensor(0.1221, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036792278289795\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020365238189697\n",
            "g_norm = tensor(0.1411, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.66465759277344\n",
            "||∇_X meta|| = 0.0015800336841493845\n",
            "ΔX norm: 1.5800329492776655e-05\n",
            "Stage 6/10:  92%|██████████████████████████▌  | 275/300 [09:26<00:53,  2.16s/it]T Loss=2.303499937057495\n",
            "g_norm = tensor(0.0808, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302649974822998\n",
            "g_norm = tensor(0.0745, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030757904052734\n",
            "g_norm = tensor(0.0861, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303501844406128\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025286197662354\n",
            "g_norm = tensor(0.0861, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.26950073242188\n",
            "||∇_X meta|| = 0.0014489636523649096\n",
            "ΔX norm: 1.4489633940684143e-05\n",
            "Stage 6/10:  92%|██████████████████████████▋  | 276/300 [09:28<00:51,  2.14s/it]T Loss=2.304412364959717\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30363130569458\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303943634033203\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30391788482666\n",
            "g_norm = tensor(0.0983, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303281545639038\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6531219482422\n",
            "||∇_X meta|| = 0.0015053711831569672\n",
            "ΔX norm: 1.5053718016133644e-05\n",
            "Stage 6/10:  92%|██████████████████████████▊  | 277/300 [09:31<00:50,  2.20s/it]T Loss=2.3047614097595215\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304062604904175\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051838874816895\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044230937957764\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043735027313232\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.06822204589844\n",
            "||∇_X meta|| = 0.0015072831884026527\n",
            "ΔX norm: 1.507282468082849e-05\n",
            "Stage 6/10:  93%|██████████████████████████▊  | 278/300 [09:32<00:46,  2.11s/it]T Loss=2.3023953437805176\n",
            "g_norm = tensor(0.1253, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031468391418457\n",
            "g_norm = tensor(0.1268, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033859729766846\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040833473205566\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303551197052002\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.75877380371094\n",
            "||∇_X meta|| = 0.0014816413167864084\n",
            "ΔX norm: 1.4816413568041753e-05\n",
            "Stage 6/10:  93%|██████████████████████████▉  | 279/300 [09:35<00:44,  2.12s/it]T Loss=2.3044848442077637\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30375337600708\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035850524902344\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033182621002197\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304182529449463\n",
            "g_norm = tensor(0.1080, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5485382080078\n",
            "||∇_X meta|| = 0.0016610510647296906\n",
            "ΔX norm: 1.6610485545243137e-05\n",
            "Stage 6/10:  93%|███████████████████████████  | 280/300 [09:37<00:42,  2.11s/it]T Loss=2.3045380115509033\n",
            "g_norm = tensor(0.1475, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305978298187256\n",
            "g_norm = tensor(0.1659, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.307114839553833\n",
            "g_norm = tensor(0.1544, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054230213165283\n",
            "g_norm = tensor(0.1394, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305419445037842\n",
            "g_norm = tensor(0.1608, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.91908264160156\n",
            "||∇_X meta|| = 0.001591711537912488\n",
            "ΔX norm: 1.5917137716314755e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 6/10:  94%|███████████████████████████▏ | 281/300 [09:39<00:40,  2.13s/it]T Loss=2.303494930267334\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041183948516846\n",
            "g_norm = tensor(0.1378, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303422451019287\n",
            "g_norm = tensor(0.1613, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036999702453613\n",
            "g_norm = tensor(0.1644, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302539825439453\n",
            "g_norm = tensor(0.1278, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.05679321289062\n",
            "||∇_X meta|| = 0.0016666072187945247\n",
            "ΔX norm: 1.666609023232013e-05\n",
            "Stage 6/10:  94%|███████████████████████████▎ | 282/300 [09:42<00:45,  2.51s/it]T Loss=2.3036110401153564\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303828716278076\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304640293121338\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039352893829346\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041629791259766\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.09271240234375\n",
            "||∇_X meta|| = 0.0016432793345302343\n",
            "ΔX norm: 1.643281393626239e-05\n",
            "Stage 6/10:  94%|███████████████████████████▎ | 283/300 [09:45<00:42,  2.49s/it]T Loss=2.3037638664245605\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303497076034546\n",
            "g_norm = tensor(0.0778, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304774522781372\n",
            "g_norm = tensor(0.0923, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040575981140137\n",
            "g_norm = tensor(0.0827, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038382530212402\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.48031616210938\n",
            "||∇_X meta|| = 0.0014736498706042767\n",
            "ΔX norm: 1.4736499906575773e-05\n",
            "Stage 6/10:  95%|███████████████████████████▍ | 284/300 [09:47<00:36,  2.31s/it]T Loss=2.303046226501465\n",
            "g_norm = tensor(0.0695, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032448291778564\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034541606903076\n",
            "g_norm = tensor(0.0772, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30363392829895\n",
            "g_norm = tensor(0.0879, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029208183288574\n",
            "g_norm = tensor(0.0794, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.70680236816406\n",
            "||∇_X meta|| = 0.0014460766687989235\n",
            "ΔX norm: 1.4460752026934642e-05\n",
            "Stage 6/10:  95%|███████████████████████████▌ | 285/300 [09:49<00:33,  2.25s/it]T Loss=2.3042190074920654\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041224479675293\n",
            "g_norm = tensor(0.0922, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042001724243164\n",
            "g_norm = tensor(0.0835, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040270805358887\n",
            "g_norm = tensor(0.0869, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043479919433594\n",
            "g_norm = tensor(0.0843, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.07467651367188\n",
            "||∇_X meta|| = 0.0015308052534237504\n",
            "ΔX norm: 1.5308034562622197e-05\n",
            "Stage 6/10:  95%|███████████████████████████▋ | 286/300 [09:51<00:29,  2.13s/it]T Loss=2.3033292293548584\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040263652801514\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032283782958984\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303452968597412\n",
            "g_norm = tensor(0.1282, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042402267456055\n",
            "g_norm = tensor(0.1295, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.34127807617188\n",
            "||∇_X meta|| = 0.0016224985010921955\n",
            "ΔX norm: 1.6225012586801313e-05\n",
            "Stage 6/10:  96%|███████████████████████████▋ | 287/300 [09:52<00:26,  2.05s/it]T Loss=2.303764581680298\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303997755050659\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039467334747314\n",
            "g_norm = tensor(0.1354, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303628444671631\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055951595306396\n",
            "g_norm = tensor(0.1218, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4840087890625\n",
            "||∇_X meta|| = 0.0016907542012631893\n",
            "ΔX norm: 1.6907530152820982e-05\n",
            "Stage 6/10:  96%|███████████████████████████▊ | 288/300 [09:54<00:23,  1.98s/it]T Loss=2.3048534393310547\n",
            "g_norm = tensor(0.1251, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305182456970215\n",
            "g_norm = tensor(0.1234, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031771183013916\n",
            "g_norm = tensor(0.1658, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30523681640625\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304262638092041\n",
            "g_norm = tensor(0.1268, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.9991455078125\n",
            "||∇_X meta|| = 0.0016147347632795572\n",
            "ΔX norm: 1.61473399202805e-05\n",
            "Stage 6/10:  96%|███████████████████████████▉ | 289/300 [09:56<00:21,  1.95s/it]T Loss=2.3047125339508057\n",
            "g_norm = tensor(0.1536, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040943145751953\n",
            "g_norm = tensor(0.1550, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040995597839355\n",
            "g_norm = tensor(0.1585, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043124675750732\n",
            "g_norm = tensor(0.1269, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303985834121704\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.18902587890625\n",
            "||∇_X meta|| = 0.001507696695625782\n",
            "ΔX norm: 1.5076984709594399e-05\n",
            "Stage 6/10:  97%|████████████████████████████ | 290/300 [09:58<00:20,  2.07s/it]T Loss=2.3033089637756348\n",
            "g_norm = tensor(0.1494, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305715799331665\n",
            "g_norm = tensor(0.1356, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054521083831787\n",
            "g_norm = tensor(0.1560, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036599159240723\n",
            "g_norm = tensor(0.1428, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035900592803955\n",
            "g_norm = tensor(0.1380, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4065704345703\n",
            "||∇_X meta|| = 0.0015719010261818767\n",
            "ΔX norm: 1.5719020666438155e-05\n",
            "Stage 6/10:  97%|████████████████████████████▏| 291/300 [10:00<00:18,  2.02s/it]T Loss=2.3041939735412598\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040404319763184\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304835796356201\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038887977600098\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304518461227417\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.8970947265625\n",
            "||∇_X meta|| = 0.0015989780658856034\n",
            "ΔX norm: 1.598979542904999e-05\n",
            "Stage 6/10:  97%|████████████████████████████▏| 292/300 [10:02<00:16,  2.02s/it]T Loss=2.302650213241577\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034656047821045\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30407977104187\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030428886413574\n",
            "g_norm = tensor(0.1214, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033127784729004\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1650390625\n",
            "||∇_X meta|| = 0.0016115364851430058\n",
            "ΔX norm: 1.611536390555557e-05\n",
            "Stage 6/10:  98%|████████████████████████████▎| 293/300 [10:04<00:13,  1.99s/it]T Loss=2.3032004833221436\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040153980255127\n",
            "g_norm = tensor(0.1273, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304678440093994\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039519786834717\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303966522216797\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8282012939453\n",
            "||∇_X meta|| = 0.0016379798762500286\n",
            "ΔX norm: 1.6379806766053662e-05\n",
            "Stage 6/10:  98%|████████████████████████████▍| 294/300 [10:07<00:12,  2.12s/it]T Loss=2.303833246231079\n",
            "g_norm = tensor(0.1600, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304708957672119\n",
            "g_norm = tensor(0.1371, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302659273147583\n",
            "g_norm = tensor(0.1495, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303281784057617\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035659790039062\n",
            "g_norm = tensor(0.1763, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.09068298339844\n",
            "||∇_X meta|| = 0.001553531619720161\n",
            "ΔX norm: 1.5535335478489287e-05\n",
            "Stage 6/10:  98%|████████████████████████████▌| 295/300 [10:10<00:12,  2.43s/it]T Loss=2.3053181171417236\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304155111312866\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041610717773438\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302351236343384\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043994903564453\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.52447509765625\n",
            "||∇_X meta|| = 0.0016040722839534283\n",
            "ΔX norm: 1.604071439942345e-05\n",
            "Stage 6/10:  99%|████████████████████████████▌| 296/300 [10:12<00:09,  2.34s/it]T Loss=2.305478096008301\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304765224456787\n",
            "g_norm = tensor(0.1270, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304020404815674\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035361766815186\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039309978485107\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8439483642578\n",
            "||∇_X meta|| = 0.0016270607011392713\n",
            "ΔX norm: 1.6270638298010454e-05\n",
            "Stage 6/10:  99%|████████████████████████████▋| 297/300 [10:14<00:06,  2.20s/it]T Loss=2.3020806312561035\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033406734466553\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303579330444336\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025155067443848\n",
            "g_norm = tensor(0.1103, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302172899246216\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.94204711914062\n",
            "||∇_X meta|| = 0.0016040659975260496\n",
            "ΔX norm: 1.6040650734794326e-05\n",
            "Stage 6/10:  99%|████████████████████████████▊| 298/300 [10:16<00:04,  2.15s/it]T Loss=2.3042969703674316\n",
            "g_norm = tensor(0.0862, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303692102432251\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043370246887207\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304051399230957\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038954734802246\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.42037963867188\n",
            "||∇_X meta|| = 0.0015231349971145391\n",
            "ΔX norm: 1.5231353245326318e-05\n",
            "Stage 6/10: 100%|████████████████████████████▉| 299/300 [10:18<00:02,  2.21s/it]T Loss=2.303640842437744\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038089275360107\n",
            "g_norm = tensor(0.0821, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028206825256348\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036797046661377\n",
            "g_norm = tensor(0.0852, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033013343811035\n",
            "g_norm = tensor(0.0853, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.71144104003906\n",
            "||∇_X meta|| = 0.0016385078197345138\n",
            "ΔX norm: 1.638509456824977e-05\n",
            "Stage 5, class 0, loss 2.209                                                    \n",
            "Stage 5, class 1, loss 2.267\n",
            "Stage 5, class 2, loss 2.339\n",
            "Stage 5, class 3, loss 2.360\n",
            "Stage 5, class 4, loss 2.305\n",
            "Stage 5, class 5, loss 2.327\n",
            "Stage 5, class 6, loss 2.383\n",
            "Stage 5, class 7, loss 2.225\n",
            "Stage 5, class 8, loss 2.371\n",
            "Stage 5, class 9, loss 2.258\n",
            "Stage 7/10:   0%|                                       | 0/300 [00:00<?, ?it/s]T Loss=2.302375078201294\n",
            "g_norm = tensor(0.1708, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303264856338501\n",
            "g_norm = tensor(0.1863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019819259643555\n",
            "g_norm = tensor(0.1452, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027617931365967\n",
            "g_norm = tensor(0.1349, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304659366607666\n",
            "g_norm = tensor(0.1967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.69017028808594\n",
            "||∇_X meta|| = 0.003571353619918227\n",
            "ΔX norm: 3.5713554098038e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 7/10:   0%|                               | 1/300 [00:01<09:44,  1.95s/it]T Loss=2.303600311279297\n",
            "g_norm = tensor(0.1327, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044698238372803\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038747310638428\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040130138397217\n",
            "g_norm = tensor(0.1755, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031556606292725\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.8785400390625\n",
            "||∇_X meta|| = 0.004118290264159441\n",
            "ΔX norm: 4.1182902350556105e-05\n",
            "Stage 7/10:   1%|▏                              | 2/300 [00:04<11:56,  2.40s/it]T Loss=2.3025848865509033\n",
            "g_norm = tensor(0.1660, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036131858825684\n",
            "g_norm = tensor(0.1622, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30368709564209\n",
            "g_norm = tensor(0.1663, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30338978767395\n",
            "g_norm = tensor(0.1688, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022804260253906\n",
            "g_norm = tensor(0.1435, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.85232543945312\n",
            "||∇_X meta|| = 0.003937094938009977\n",
            "ΔX norm: 3.937096334993839e-05\n",
            "Stage 7/10:   1%|▎                              | 3/300 [00:06<11:19,  2.29s/it]T Loss=2.3033440113067627\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028810024261475\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037428855895996\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034560680389404\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039445877075195\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9874725341797\n",
            "||∇_X meta|| = 0.00317513570189476\n",
            "ΔX norm: 3.1751358619658276e-05\n",
            "Stage 7/10:   1%|▍                              | 4/300 [00:08<10:28,  2.12s/it]T Loss=2.3020834922790527\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026700019836426\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3016164302825928\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302499771118164\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301766872406006\n",
            "g_norm = tensor(0.1213, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.74073791503906\n",
            "||∇_X meta|| = 0.0036914190277457237\n",
            "ΔX norm: 3.691418532980606e-05\n",
            "Stage 7/10:   2%|▌                              | 5/300 [00:10<09:50,  2.00s/it]T Loss=2.303778648376465\n",
            "g_norm = tensor(0.1421, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305276393890381\n",
            "g_norm = tensor(0.1444, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044204711914062\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303806781768799\n",
            "g_norm = tensor(0.1550, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303961992263794\n",
            "g_norm = tensor(0.1664, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2863311767578\n",
            "||∇_X meta|| = 0.0037589706480503082\n",
            "ΔX norm: 3.7589728890452534e-05\n",
            "Stage 7/10:   2%|▌                              | 6/300 [00:12<10:33,  2.15s/it]T Loss=2.3040828704833984\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30424427986145\n",
            "g_norm = tensor(0.0821, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304384231567383\n",
            "g_norm = tensor(0.0803, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045098781585693\n",
            "g_norm = tensor(0.0848, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050827980041504\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.85240173339844\n",
            "||∇_X meta|| = 0.0033239724580198526\n",
            "ΔX norm: 3.323975033708848e-05\n",
            "Stage 7/10:   2%|▋                              | 7/300 [00:15<11:09,  2.29s/it]T Loss=2.304974317550659\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038926124572754\n",
            "g_norm = tensor(0.1053, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039824962615967\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304168701171875\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041110038757324\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.05690002441406\n",
            "||∇_X meta|| = 0.00378796155564487\n",
            "ΔX norm: 3.7879610317759216e-05\n",
            "Stage 7/10:   3%|▊                              | 8/300 [00:19<13:46,  2.83s/it]T Loss=2.305455446243286\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302712917327881\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044991493225098\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045170307159424\n",
            "g_norm = tensor(0.1307, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051140308380127\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.514892578125\n",
            "||∇_X meta|| = 0.003718216670677066\n",
            "ΔX norm: 3.718215521075763e-05\n",
            "Stage 7/10:   3%|▉                              | 9/300 [00:23<15:06,  3.11s/it]T Loss=2.3038601875305176\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303185224533081\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303237199783325\n",
            "g_norm = tensor(0.0711, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037619590759277\n",
            "g_norm = tensor(0.0682, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051276206970215\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.75735473632812\n",
            "||∇_X meta|| = 0.003533401060849428\n",
            "ΔX norm: 3.533398557920009e-05\n",
            "Stage 7/10:   3%|█                             | 10/300 [00:26<15:40,  3.24s/it]T Loss=2.303138017654419\n",
            "g_norm = tensor(0.0848, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042709827423096\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303069829940796\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043670654296875\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047332763671875\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.833251953125\n",
            "||∇_X meta|| = 0.0035877982154488564\n",
            "ΔX norm: 3.587799074011855e-05\n",
            "Stage 7/10:   4%|█                             | 11/300 [00:29<15:04,  3.13s/it]T Loss=2.3044097423553467\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033487796783447\n",
            "g_norm = tensor(0.0922, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035755157470703\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038718700408936\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037421703338623\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.14016723632812\n",
            "||∇_X meta|| = 0.003700479632243514\n",
            "ΔX norm: 3.700480374391191e-05\n",
            "Stage 7/10:   4%|█▏                            | 12/300 [00:31<13:33,  2.82s/it]T Loss=2.302189588546753\n",
            "g_norm = tensor(0.1275, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303121566772461\n",
            "g_norm = tensor(0.1473, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302584171295166\n",
            "g_norm = tensor(0.1417, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032619953155518\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303558826446533\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.91152954101562\n",
            "||∇_X meta|| = 0.0033572770189493895\n",
            "ΔX norm: 3.3572810934856534e-05\n",
            "Stage 7/10:   4%|█▎                            | 13/300 [00:33<12:19,  2.58s/it]T Loss=2.3047285079956055\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045473098754883\n",
            "g_norm = tensor(0.0840, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046040534973145\n",
            "g_norm = tensor(0.0748, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045923709869385\n",
            "g_norm = tensor(0.0866, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041062355041504\n",
            "g_norm = tensor(0.0738, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.51107788085938\n",
            "||∇_X meta|| = 0.00331476260907948\n",
            "ΔX norm: 3.314765126560815e-05\n",
            "Stage 7/10:   5%|█▍                            | 14/300 [00:35<11:36,  2.44s/it]T Loss=2.304647922515869\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045945167541504\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304368495941162\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304095506668091\n",
            "g_norm = tensor(0.1257, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031575679779053\n",
            "g_norm = tensor(0.1395, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.66465759277344\n",
            "||∇_X meta|| = 0.003807093482464552\n",
            "ΔX norm: 3.80709461751394e-05\n",
            "Stage 7/10:   5%|█▌                            | 15/300 [00:38<11:14,  2.37s/it]T Loss=2.3032352924346924\n",
            "g_norm = tensor(0.0801, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303558826446533\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302696466445923\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302574634552002\n",
            "g_norm = tensor(0.0810, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30340576171875\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.88470458984375\n",
            "||∇_X meta|| = 0.0035190084017813206\n",
            "ΔX norm: 3.519008896546438e-05\n",
            "Stage 7/10:   5%|█▌                            | 16/300 [00:40<10:54,  2.30s/it]T Loss=2.303326368331909\n",
            "g_norm = tensor(0.1355, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024885654449463\n",
            "g_norm = tensor(0.1497, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028101921081543\n",
            "g_norm = tensor(0.1452, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303723096847534\n",
            "g_norm = tensor(0.1512, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302245616912842\n",
            "g_norm = tensor(0.1842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.22735595703125\n",
            "||∇_X meta|| = 0.003573803696781397\n",
            "ΔX norm: 3.573798676370643e-05\n",
            "Stage 7/10:   6%|█▋                            | 17/300 [00:42<10:23,  2.20s/it]T Loss=2.303905487060547\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304320812225342\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033063411712646\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304475784301758\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046071529388428\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.27081298828125\n",
            "||∇_X meta|| = 0.0034646193962544203\n",
            "ΔX norm: 3.4646218409761786e-05\n",
            "Stage 7/10:   6%|█▊                            | 18/300 [00:44<10:08,  2.16s/it]T Loss=2.3049070835113525\n",
            "g_norm = tensor(0.1375, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043789863586426\n",
            "g_norm = tensor(0.1422, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041329383850098\n",
            "g_norm = tensor(0.1345, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303725004196167\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303478717803955\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.63433837890625\n",
            "||∇_X meta|| = 0.002910262206569314\n",
            "ΔX norm: 2.9102646294631995e-05\n",
            "Stage 7/10:   6%|█▉                            | 19/300 [00:46<10:08,  2.17s/it]T Loss=2.3030335903167725\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30389404296875\n",
            "g_norm = tensor(0.1250, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304396152496338\n",
            "g_norm = tensor(0.1099, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038668632507324\n",
            "g_norm = tensor(0.1218, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036627769470215\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.91685485839844\n",
            "||∇_X meta|| = 0.002863332163542509\n",
            "ΔX norm: 2.8633276087930426e-05\n",
            "Stage 7/10:   7%|██                            | 20/300 [00:48<09:55,  2.13s/it]T Loss=2.304611921310425\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049397468566895\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038742542266846\n",
            "g_norm = tensor(0.1372, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043103218078613\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303647041320801\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.00946044921875\n",
            "||∇_X meta|| = 0.0031949148979038\n",
            "ΔX norm: 3.194912278559059e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 7/10:   7%|██                            | 21/300 [00:50<09:33,  2.05s/it]T Loss=2.3013877868652344\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029916286468506\n",
            "g_norm = tensor(0.1157, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022918701171875\n",
            "g_norm = tensor(0.1257, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302727699279785\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303271770477295\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7135009765625\n",
            "||∇_X meta|| = 0.0032384232617914677\n",
            "ΔX norm: 3.238428689655848e-05\n",
            "Stage 7/10:   7%|██▏                           | 22/300 [00:52<09:58,  2.15s/it]T Loss=2.3045976161956787\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304853677749634\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040883541107178\n",
            "g_norm = tensor(0.0880, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042683601379395\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30372953414917\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.1819305419922\n",
            "||∇_X meta|| = 0.003233998315408826\n",
            "ΔX norm: 3.233999450458214e-05\n",
            "Stage 7/10:   8%|██▎                           | 23/300 [00:54<09:39,  2.09s/it]T Loss=2.305349111557007\n",
            "g_norm = tensor(0.1399, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041892051696777\n",
            "g_norm = tensor(0.1407, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304905414581299\n",
            "g_norm = tensor(0.1357, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304596424102783\n",
            "g_norm = tensor(0.1523, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026533126831055\n",
            "g_norm = tensor(0.1722, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1166534423828\n",
            "||∇_X meta|| = 0.002952289069071412\n",
            "ΔX norm: 2.9522929253289476e-05\n",
            "Stage 7/10:   8%|██▍                           | 24/300 [00:56<09:27,  2.06s/it]T Loss=2.302927017211914\n",
            "g_norm = tensor(0.0712, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303616523742676\n",
            "g_norm = tensor(0.0651, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031301498413086\n",
            "g_norm = tensor(0.0602, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035764694213867\n",
            "g_norm = tensor(0.0546, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303623676300049\n",
            "g_norm = tensor(0.0526, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.14610290527344\n",
            "||∇_X meta|| = 0.003166954731568694\n",
            "ΔX norm: 3.16695477522444e-05\n",
            "Stage 7/10:   8%|██▌                           | 25/300 [00:58<09:13,  2.01s/it]T Loss=2.3033649921417236\n",
            "g_norm = tensor(0.1322, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302762985229492\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044543266296387\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303889513015747\n",
            "g_norm = tensor(0.1403, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027243614196777\n",
            "g_norm = tensor(0.1275, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8452911376953\n",
            "||∇_X meta|| = 0.0027115640696138144\n",
            "ΔX norm: 2.7115624106954783e-05\n",
            "Stage 7/10:   9%|██▌                           | 26/300 [01:01<09:52,  2.16s/it]T Loss=2.303382635116577\n",
            "g_norm = tensor(0.1451, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030362129211426\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304318428039551\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302088499069214\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037078380584717\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3656005859375\n",
            "||∇_X meta|| = 0.0028382132295519114\n",
            "ΔX norm: 2.838213913491927e-05\n",
            "Stage 7/10:   9%|██▋                           | 27/300 [01:03<09:45,  2.14s/it]T Loss=2.3036036491394043\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303590774536133\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304851531982422\n",
            "g_norm = tensor(0.1275, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042752742767334\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039634227752686\n",
            "g_norm = tensor(0.1157, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5756378173828\n",
            "||∇_X meta|| = 0.003059282200410962\n",
            "ΔX norm: 3.059284790651873e-05\n",
            "Stage 7/10:   9%|██▊                           | 28/300 [01:05<09:25,  2.08s/it]T Loss=2.3029775619506836\n",
            "g_norm = tensor(0.1737, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042216300964355\n",
            "g_norm = tensor(0.1575, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050599098205566\n",
            "g_norm = tensor(0.1448, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304025173187256\n",
            "g_norm = tensor(0.1551, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035995960235596\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.21209716796875\n",
            "||∇_X meta|| = 0.00280385953374207\n",
            "ΔX norm: 2.8038564778398722e-05\n",
            "Stage 7/10:  10%|██▉                           | 29/300 [01:07<09:33,  2.12s/it]T Loss=2.304403781890869\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037617206573486\n",
            "g_norm = tensor(0.1334, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032360076904297\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041539192199707\n",
            "g_norm = tensor(0.1305, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041439056396484\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.39891052246094\n",
            "||∇_X meta|| = 0.002872166922315955\n",
            "ΔX norm: 2.872167169698514e-05\n",
            "Stage 7/10:  10%|███                           | 30/300 [01:09<09:13,  2.05s/it]T Loss=2.3045530319213867\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031394481658936\n",
            "g_norm = tensor(0.0898, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039565086364746\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040311336517334\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302834987640381\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.87342834472656\n",
            "||∇_X meta|| = 0.0029026009142398834\n",
            "ΔX norm: 2.902604865084868e-05\n",
            "Stage 7/10:  10%|███                           | 31/300 [01:11<09:10,  2.05s/it]T Loss=2.3044447898864746\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305208683013916\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032901287078857\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034868240356445\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306025743484497\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.79212951660156\n",
            "||∇_X meta|| = 0.002896946854889393\n",
            "ΔX norm: 2.896951809816528e-05\n",
            "Stage 7/10:  11%|███▏                          | 32/300 [01:13<09:01,  2.02s/it]T Loss=2.303847074508667\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302588701248169\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036513328552246\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3014872074127197\n",
            "g_norm = tensor(0.0852, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303229570388794\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.59593200683594\n",
            "||∇_X meta|| = 0.0028073592111468315\n",
            "ΔX norm: 2.807357486744877e-05\n",
            "Stage 7/10:  11%|███▎                          | 33/300 [01:15<08:56,  2.01s/it]T Loss=2.3051366806030273\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304121255874634\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304823160171509\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304274320602417\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304245948791504\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.92234802246094\n",
            "||∇_X meta|| = 0.0031173890456557274\n",
            "ΔX norm: 3.117388769169338e-05\n",
            "Stage 7/10:  11%|███▍                          | 34/300 [01:17<09:42,  2.19s/it]T Loss=2.3032686710357666\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033719062805176\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032031059265137\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303081750869751\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037543296813965\n",
            "g_norm = tensor(0.1235, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.41465759277344\n",
            "||∇_X meta|| = 0.0025027228984981775\n",
            "ΔX norm: 2.5027246010722592e-05\n",
            "Stage 7/10:  12%|███▌                          | 35/300 [01:19<09:35,  2.17s/it]T Loss=2.3044066429138184\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304935932159424\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040237426757812\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033499717712402\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304506778717041\n",
            "g_norm = tensor(0.0850, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.26080322265625\n",
            "||∇_X meta|| = 0.003114246064797044\n",
            "ΔX norm: 3.114244100288488e-05\n",
            "Stage 7/10:  12%|███▌                          | 36/300 [01:21<09:17,  2.11s/it]T Loss=2.304004430770874\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030734062194824\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036129474639893\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035435676574707\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045530319213867\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.32147216796875\n",
            "||∇_X meta|| = 0.0033151977695524693\n",
            "ΔX norm: 3.315192952868529e-05\n",
            "Stage 7/10:  12%|███▋                          | 37/300 [01:23<09:02,  2.06s/it]T Loss=2.3032782077789307\n",
            "g_norm = tensor(0.1454, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027050495147705\n",
            "g_norm = tensor(0.1662, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30381441116333\n",
            "g_norm = tensor(0.1408, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022422790527344\n",
            "g_norm = tensor(0.1554, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036296367645264\n",
            "g_norm = tensor(0.1556, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.66343688964844\n",
            "||∇_X meta|| = 0.002841787878423929\n",
            "ΔX norm: 2.8417887733667158e-05\n",
            "Stage 7/10:  13%|███▊                          | 38/300 [01:25<08:57,  2.05s/it]T Loss=2.3051483631134033\n",
            "g_norm = tensor(0.1140, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037428855895996\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304800510406494\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058464527130127\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051466941833496\n",
            "g_norm = tensor(0.1312, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.66763305664062\n",
            "||∇_X meta|| = 0.0028103680815547705\n",
            "ΔX norm: 2.8103650038246997e-05\n",
            "Stage 7/10:  13%|███▉                          | 39/300 [01:27<08:58,  2.06s/it]T Loss=2.3022665977478027\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303391933441162\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024070262908936\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027853965759277\n",
            "g_norm = tensor(0.0947, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304447889328003\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.16839599609375\n",
            "||∇_X meta|| = 0.0029522250406444073\n",
            "ΔX norm: 2.9522239856305532e-05\n",
            "Stage 7/10:  13%|████                          | 40/300 [01:30<08:55,  2.06s/it]T Loss=2.3036112785339355\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036370277404785\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035976886749268\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303926706314087\n",
            "g_norm = tensor(0.0923, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30322527885437\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.62269592285156\n",
            "||∇_X meta|| = 0.0026768664829432964\n",
            "ΔX norm: 2.6768650059239008e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 7/10:  14%|████                          | 41/300 [01:32<08:48,  2.04s/it]T Loss=2.3034563064575195\n",
            "g_norm = tensor(0.0811, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303738832473755\n",
            "g_norm = tensor(0.0802, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037807941436768\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303997755050659\n",
            "g_norm = tensor(0.0919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043365478515625\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.71131896972656\n",
            "||∇_X meta|| = 0.0026563117280602455\n",
            "ΔX norm: 2.6563093342701904e-05\n",
            "Stage 7/10:  14%|████▏                         | 42/300 [01:34<09:25,  2.19s/it]T Loss=2.3046302795410156\n",
            "g_norm = tensor(0.1400, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304020404815674\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040716648101807\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302861452102661\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032333850860596\n",
            "g_norm = tensor(0.1276, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.28285217285156\n",
            "||∇_X meta|| = 0.003171428805217147\n",
            "ΔX norm: 3.171422576997429e-05\n",
            "Stage 7/10:  14%|████▎                         | 43/300 [01:36<09:11,  2.14s/it]T Loss=2.303410053253174\n",
            "g_norm = tensor(0.0612, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304352283477783\n",
            "g_norm = tensor(0.0572, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033523559570312\n",
            "g_norm = tensor(0.0632, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304034471511841\n",
            "g_norm = tensor(0.0711, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303095579147339\n",
            "g_norm = tensor(0.0633, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.51492309570312\n",
            "||∇_X meta|| = 0.002457281108945608\n",
            "ΔX norm: 2.4572811526013538e-05\n",
            "Stage 7/10:  15%|████▍                         | 44/300 [01:38<08:58,  2.10s/it]T Loss=2.3043432235717773\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303807020187378\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303347587585449\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047194480895996\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305112361907959\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.24305725097656\n",
            "||∇_X meta|| = 0.0025901366025209427\n",
            "ΔX norm: 2.590132316981908e-05\n",
            "Stage 7/10:  15%|████▌                         | 45/300 [01:40<08:36,  2.03s/it]T Loss=2.3055129051208496\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3064191341400146\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039934635162354\n",
            "g_norm = tensor(0.1266, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304913282394409\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045830726623535\n",
            "g_norm = tensor(0.1296, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.01792907714844\n",
            "||∇_X meta|| = 0.0025551130529493093\n",
            "ΔX norm: 2.5551129510859028e-05\n",
            "Stage 7/10:  15%|████▌                         | 46/300 [01:42<08:22,  1.98s/it]T Loss=2.3040993213653564\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304091691970825\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037269115448\n",
            "g_norm = tensor(0.0837, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042798042297363\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303554058074951\n",
            "g_norm = tensor(0.0908, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6416778564453\n",
            "||∇_X meta|| = 0.002735614310950041\n",
            "ΔX norm: 2.7356130885891616e-05\n",
            "Stage 7/10:  16%|████▋                         | 47/300 [01:44<08:44,  2.07s/it]T Loss=2.303368091583252\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303135633468628\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034825325012207\n",
            "g_norm = tensor(0.1278, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037068843841553\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302927255630493\n",
            "g_norm = tensor(0.1406, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.498779296875\n",
            "||∇_X meta|| = 0.0024135152343660593\n",
            "ΔX norm: 2.4135137209668756e-05\n",
            "Stage 7/10:  16%|████▊                         | 48/300 [01:46<08:25,  2.01s/it]T Loss=2.303800344467163\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304999828338623\n",
            "g_norm = tensor(0.0853, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034138679504395\n",
            "g_norm = tensor(0.0908, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304138660430908\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044769763946533\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.013916015625\n",
            "||∇_X meta|| = 0.0025885524228215218\n",
            "ΔX norm: 2.588551797089167e-05\n",
            "Stage 7/10:  16%|████▉                         | 49/300 [01:48<08:15,  1.97s/it]T Loss=2.304318428039551\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021557331085205\n",
            "g_norm = tensor(0.1184, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031492233276367\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028969764709473\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303985595703125\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0662078857422\n",
            "||∇_X meta|| = 0.002601789543405175\n",
            "ΔX norm: 2.601793130452279e-05\n",
            "Stage 7/10:  17%|█████                         | 50/300 [01:50<08:05,  1.94s/it]T Loss=2.3043417930603027\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040573596954346\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303011178970337\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304377794265747\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045520782470703\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.86038208007812\n",
            "||∇_X meta|| = 0.0024304904509335756\n",
            "ΔX norm: 2.430489257676527e-05\n",
            "Stage 7/10:  17%|█████                         | 51/300 [01:52<07:54,  1.91s/it]T Loss=2.30328106880188\n",
            "g_norm = tensor(0.0733, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302717447280884\n",
            "g_norm = tensor(0.0869, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303577423095703\n",
            "g_norm = tensor(0.0763, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302690267562866\n",
            "g_norm = tensor(0.0847, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026814460754395\n",
            "g_norm = tensor(0.0725, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.94212341308594\n",
            "||∇_X meta|| = 0.0023325467482209206\n",
            "ΔX norm: 2.3325474103330635e-05\n",
            "Stage 7/10:  17%|█████▏                        | 52/300 [01:53<07:52,  1.91s/it]T Loss=2.3031468391418457\n",
            "g_norm = tensor(0.1528, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303070545196533\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032596111297607\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018009662628174\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3013195991516113\n",
            "g_norm = tensor(0.1410, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5794219970703\n",
            "||∇_X meta|| = 0.002637116704136133\n",
            "ΔX norm: 2.6371157218818553e-05\n",
            "Stage 7/10:  18%|█████▎                        | 53/300 [01:55<07:47,  1.89s/it]T Loss=2.304065465927124\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047709465026855\n",
            "g_norm = tensor(0.0864, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047232627868652\n",
            "g_norm = tensor(0.0839, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303842067718506\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041539192199707\n",
            "g_norm = tensor(0.0831, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.18453979492188\n",
            "||∇_X meta|| = 0.0026320619508624077\n",
            "ΔX norm: 2.6320609322283417e-05\n",
            "Stage 7/10:  18%|█████▍                        | 54/300 [01:57<07:39,  1.87s/it]T Loss=2.3044114112854004\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040060997009277\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303009510040283\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049545288085938\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303499698638916\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.40830993652344\n",
            "||∇_X meta|| = 0.0023547220043838024\n",
            "ΔX norm: 2.354722710151691e-05\n",
            "Stage 7/10:  18%|█████▌                        | 55/300 [01:59<07:36,  1.86s/it]T Loss=2.304691791534424\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30324387550354\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036017417907715\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303236484527588\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036704063415527\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.40968322753906\n",
            "||∇_X meta|| = 0.002059403108432889\n",
            "ΔX norm: 2.0594017769326456e-05\n",
            "Stage 7/10:  19%|█████▌                        | 56/300 [02:01<07:28,  1.84s/it]T Loss=2.3030307292938232\n",
            "g_norm = tensor(0.1355, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039093017578125\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039064407348633\n",
            "g_norm = tensor(0.1377, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023619651794434\n",
            "g_norm = tensor(0.1405, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042824268341064\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5145721435547\n",
            "||∇_X meta|| = 0.002391816582530737\n",
            "ΔX norm: 2.3918179067550227e-05\n",
            "Stage 7/10:  19%|█████▋                        | 57/300 [02:03<07:25,  1.83s/it]T Loss=2.3039965629577637\n",
            "g_norm = tensor(0.1276, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024673461914062\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030683994293213\n",
            "g_norm = tensor(0.1461, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025062084198\n",
            "g_norm = tensor(0.1389, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034210205078125\n",
            "g_norm = tensor(0.1358, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.45083618164062\n",
            "||∇_X meta|| = 0.002488549565896392\n",
            "ΔX norm: 2.4885508537408896e-05\n",
            "Stage 7/10:  19%|█████▊                        | 58/300 [02:04<07:22,  1.83s/it]T Loss=2.3038227558135986\n",
            "g_norm = tensor(0.0888, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048789501190186\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304509401321411\n",
            "g_norm = tensor(0.0845, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039379119873047\n",
            "g_norm = tensor(0.0884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042690753936768\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.77667236328125\n",
            "||∇_X meta|| = 0.002502236980944872\n",
            "ΔX norm: 2.50223765760893e-05\n",
            "Stage 7/10:  20%|█████▉                        | 59/300 [02:06<07:26,  1.85s/it]T Loss=2.30428147315979\n",
            "g_norm = tensor(0.0746, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304133892059326\n",
            "g_norm = tensor(0.0819, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046488761901855\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035085201263428\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040807247161865\n",
            "g_norm = tensor(0.0724, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.27865600585938\n",
            "||∇_X meta|| = 0.0026498783845454454\n",
            "ΔX norm: 2.6498761144466698e-05\n",
            "Stage 7/10:  20%|██████                        | 60/300 [02:08<07:21,  1.84s/it]T Loss=2.303968906402588\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303461790084839\n",
            "g_norm = tensor(0.1323, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038249015808105\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021225929260254\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302841901779175\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.0545196533203\n",
            "||∇_X meta|| = 0.001907983561977744\n",
            "ΔX norm: 1.9079825506196357e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 7/10:  20%|██████                        | 61/300 [02:10<07:27,  1.87s/it]T Loss=2.3025259971618652\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30226469039917\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028321266174316\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301743268966675\n",
            "g_norm = tensor(0.1251, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019542694091797\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9149169921875\n",
            "||∇_X meta|| = 0.0023578510154038668\n",
            "ΔX norm: 2.357851008127909e-05\n",
            "Stage 7/10:  21%|██████▏                       | 62/300 [02:13<08:17,  2.09s/it]T Loss=2.30389142036438\n",
            "g_norm = tensor(0.1430, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045833110809326\n",
            "g_norm = tensor(0.1326, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303054094314575\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304868459701538\n",
            "g_norm = tensor(0.1533, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042361736297607\n",
            "g_norm = tensor(0.1479, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.91310119628906\n",
            "||∇_X meta|| = 0.0022932158317416906\n",
            "ΔX norm: 2.2932128558750264e-05\n",
            "Stage 7/10:  21%|██████▎                       | 63/300 [02:15<08:16,  2.10s/it]T Loss=2.3058128356933594\n",
            "g_norm = tensor(0.1403, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047637939453125\n",
            "g_norm = tensor(0.1527, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304943323135376\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304816722869873\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304565906524658\n",
            "g_norm = tensor(0.1452, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3237762451172\n",
            "||∇_X meta|| = 0.0024045140016824007\n",
            "ΔX norm: 2.4045142708928324e-05\n",
            "Stage 7/10:  21%|██████▍                       | 64/300 [02:17<08:16,  2.11s/it]T Loss=2.3033645153045654\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303180456161499\n",
            "g_norm = tensor(0.0833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302720069885254\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30334734916687\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024375438690186\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.35972595214844\n",
            "||∇_X meta|| = 0.0025670481845736504\n",
            "ΔX norm: 2.5670502509456128e-05\n",
            "Stage 7/10:  22%|██████▌                       | 65/300 [02:19<08:40,  2.21s/it]T Loss=2.3039193153381348\n",
            "g_norm = tensor(0.1533, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036491870880127\n",
            "g_norm = tensor(0.1351, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054003715515137\n",
            "g_norm = tensor(0.1496, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305119037628174\n",
            "g_norm = tensor(0.1318, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052635192871094\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.82550048828125\n",
            "||∇_X meta|| = 0.002420522505417466\n",
            "ΔX norm: 2.4205204681493342e-05\n",
            "Stage 7/10:  22%|██████▌                       | 66/300 [02:22<08:48,  2.26s/it]T Loss=2.3040995597839355\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303788185119629\n",
            "g_norm = tensor(0.0781, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304049015045166\n",
            "g_norm = tensor(0.0800, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036551475524902\n",
            "g_norm = tensor(0.0849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30452299118042\n",
            "g_norm = tensor(0.0846, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.6040496826172\n",
            "||∇_X meta|| = 0.0023661621380597353\n",
            "ΔX norm: 2.3661621526116505e-05\n",
            "Stage 7/10:  22%|██████▋                       | 67/300 [02:24<08:31,  2.20s/it]T Loss=2.3028531074523926\n",
            "g_norm = tensor(0.1540, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034591674804688\n",
            "g_norm = tensor(0.1349, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037571907043457\n",
            "g_norm = tensor(0.1453, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304641008377075\n",
            "g_norm = tensor(0.1336, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046650886535645\n",
            "g_norm = tensor(0.1433, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.85153198242188\n",
            "||∇_X meta|| = 0.002188988495618105\n",
            "ΔX norm: 2.188986945839133e-05\n",
            "Stage 7/10:  23%|██████▊                       | 68/300 [02:26<08:14,  2.13s/it]T Loss=2.303896903991699\n",
            "g_norm = tensor(0.1368, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304856777191162\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305058240890503\n",
            "g_norm = tensor(0.1140, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304075241088867\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036813735961914\n",
            "g_norm = tensor(0.1333, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2201690673828\n",
            "||∇_X meta|| = 0.0022392701357603073\n",
            "ΔX norm: 2.2392734535969794e-05\n",
            "Stage 7/10:  23%|██████▉                       | 69/300 [02:28<08:02,  2.09s/it]T Loss=2.3037102222442627\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304152011871338\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303382158279419\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303197145462036\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303788185119629\n",
            "g_norm = tensor(0.0956, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1409454345703\n",
            "||∇_X meta|| = 0.0020414497703313828\n",
            "ΔX norm: 2.0414479877217673e-05\n",
            "Stage 7/10:  23%|███████                       | 70/300 [02:30<08:11,  2.14s/it]T Loss=2.3023524284362793\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041110038757324\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303781509399414\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020482063293457\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032543659210205\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7479705810547\n",
            "||∇_X meta|| = 0.002201242372393608\n",
            "ΔX norm: 2.2012454792275093e-05\n",
            "Stage 7/10:  24%|███████                       | 71/300 [02:32<07:56,  2.08s/it]T Loss=2.30393123626709\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303978443145752\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304854154586792\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304358959197998\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30410099029541\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.07493591308594\n",
            "||∇_X meta|| = 0.0027809729799628258\n",
            "ΔX norm: 2.7809730454464443e-05\n",
            "Stage 7/10:  24%|███████▏                      | 72/300 [02:34<07:45,  2.04s/it]T Loss=2.3042428493499756\n",
            "g_norm = tensor(0.1578, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032584190368652\n",
            "g_norm = tensor(0.1813, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305595874786377\n",
            "g_norm = tensor(0.1683, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042941093444824\n",
            "g_norm = tensor(0.1819, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045783042907715\n",
            "g_norm = tensor(0.1436, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.87351989746094\n",
            "||∇_X meta|| = 0.0021123236510902643\n",
            "ΔX norm: 2.1123238184372894e-05\n",
            "Stage 7/10:  24%|███████▎                      | 73/300 [02:36<07:39,  2.02s/it]T Loss=2.3030972480773926\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304453134536743\n",
            "g_norm = tensor(0.1345, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026983737945557\n",
            "g_norm = tensor(0.1449, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304553985595703\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30442476272583\n",
            "g_norm = tensor(0.1364, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.40040588378906\n",
            "||∇_X meta|| = 0.0024160968605428934\n",
            "ΔX norm: 2.4160950488294475e-05\n",
            "Stage 7/10:  25%|███████▍                      | 74/300 [02:38<07:52,  2.09s/it]T Loss=2.3030307292938232\n",
            "g_norm = tensor(0.0798, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30267333984375\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030505180358887\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029894828796387\n",
            "g_norm = tensor(0.0817, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303253650665283\n",
            "g_norm = tensor(0.0731, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.89060974121094\n",
            "||∇_X meta|| = 0.002055208431556821\n",
            "ΔX norm: 2.0552084606606513e-05\n",
            "Stage 7/10:  25%|███████▌                      | 75/300 [02:40<07:52,  2.10s/it]T Loss=2.3041794300079346\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304553508758545\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041865825653076\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303858518600464\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035876750946045\n",
            "g_norm = tensor(0.1325, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.33004760742188\n",
            "||∇_X meta|| = 0.0022381809540092945\n",
            "ΔX norm: 2.2381807866622694e-05\n",
            "Stage 7/10:  25%|███████▌                      | 76/300 [02:43<08:07,  2.18s/it]T Loss=2.3041434288024902\n",
            "g_norm = tensor(0.0866, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034114837646484\n",
            "g_norm = tensor(0.0878, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303525447845459\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032476902008057\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040452003479004\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.08055114746094\n",
            "||∇_X meta|| = 0.0021450291387736797\n",
            "ΔX norm: 2.145029247913044e-05\n",
            "Stage 7/10:  26%|███████▋                      | 77/300 [02:45<07:52,  2.12s/it]T Loss=2.30374813079834\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031365871429443\n",
            "g_norm = tensor(0.0769, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302868366241455\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302595615386963\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304180383682251\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2236328125\n",
            "||∇_X meta|| = 0.002312156604602933\n",
            "ΔX norm: 2.3121550839277916e-05\n",
            "Stage 7/10:  26%|███████▊                      | 78/300 [02:46<07:35,  2.05s/it]T Loss=2.3034310340881348\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038694858551025\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303809404373169\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046281337738037\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304630756378174\n",
            "g_norm = tensor(0.1157, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.45254516601562\n",
            "||∇_X meta|| = 0.0021166775841265917\n",
            "ΔX norm: 2.1166759324842133e-05\n",
            "Stage 7/10:  26%|███████▉                      | 79/300 [02:48<07:26,  2.02s/it]T Loss=2.303086757659912\n",
            "g_norm = tensor(0.1368, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30418062210083\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055202960968018\n",
            "g_norm = tensor(0.1671, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038299083709717\n",
            "g_norm = tensor(0.1368, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30238938331604\n",
            "g_norm = tensor(0.1402, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.81976318359375\n",
            "||∇_X meta|| = 0.001933779683895409\n",
            "ΔX norm: 1.9337770936544985e-05\n",
            "Stage 7/10:  27%|████████                      | 80/300 [02:50<07:16,  1.98s/it]T Loss=2.3031771183013916\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30202054977417\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026034832000732\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301363945007324\n",
            "g_norm = tensor(0.1423, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303583860397339\n",
            "g_norm = tensor(0.1178, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.06524658203125\n",
            "||∇_X meta|| = 0.002169743413105607\n",
            "ΔX norm: 2.1697442207369022e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 7/10:  27%|████████                      | 81/300 [02:52<07:05,  1.94s/it]T Loss=2.304339647293091\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044273853302\n",
            "g_norm = tensor(0.0806, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050527572631836\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049020767211914\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030669689178467\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.54005432128906\n",
            "||∇_X meta|| = 0.002277704421430826\n",
            "ΔX norm: 2.277703424624633e-05\n",
            "Stage 7/10:  27%|████████▏                     | 82/300 [02:55<07:35,  2.09s/it]T Loss=2.3037078380584717\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025877475738525\n",
            "g_norm = tensor(0.0983, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304110050201416\n",
            "g_norm = tensor(0.0937, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303205728530884\n",
            "g_norm = tensor(0.0919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033056259155273\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0364532470703\n",
            "||∇_X meta|| = 0.0020688772201538086\n",
            "ΔX norm: 2.0688747099484317e-05\n",
            "Stage 7/10:  28%|████████▎                     | 83/300 [02:57<07:33,  2.09s/it]T Loss=2.3043434619903564\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304810047149658\n",
            "g_norm = tensor(0.1530, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027656078338623\n",
            "g_norm = tensor(0.1563, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030858039855957\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038413524627686\n",
            "g_norm = tensor(0.1178, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.29122924804688\n",
            "||∇_X meta|| = 0.0020116963423788548\n",
            "ΔX norm: 2.011694959946908e-05\n",
            "Stage 7/10:  28%|████████▍                     | 84/300 [02:59<07:17,  2.03s/it]T Loss=2.3027162551879883\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303586483001709\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303773880004883\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033266067504883\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038439750671387\n",
            "g_norm = tensor(0.1479, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.75331115722656\n",
            "||∇_X meta|| = 0.002179492497816682\n",
            "ΔX norm: 2.1794892745674588e-05\n",
            "Stage 7/10:  28%|████████▌                     | 85/300 [03:00<07:01,  1.96s/it]T Loss=2.3024075031280518\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302940845489502\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035757541656494\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303109645843506\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304367780685425\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2317657470703\n",
            "||∇_X meta|| = 0.0020031474996358156\n",
            "ΔX norm: 2.0031471649417654e-05\n",
            "Stage 7/10:  29%|████████▌                     | 86/300 [03:02<06:52,  1.93s/it]T Loss=2.305215358734131\n",
            "g_norm = tensor(0.0937, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045456409454346\n",
            "g_norm = tensor(0.0808, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304833173751831\n",
            "g_norm = tensor(0.0744, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30497670173645\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047215938568115\n",
            "g_norm = tensor(0.0931, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.38531494140625\n",
            "||∇_X meta|| = 0.002082190243527293\n",
            "ΔX norm: 2.0821893485845067e-05\n",
            "Stage 7/10:  29%|████████▋                     | 87/300 [03:04<06:44,  1.90s/it]T Loss=2.3045554161071777\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028550148010254\n",
            "g_norm = tensor(0.0820, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302480459213257\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034162521362305\n",
            "g_norm = tensor(0.0697, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302527904510498\n",
            "g_norm = tensor(0.0764, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.60549926757812\n",
            "||∇_X meta|| = 0.0018571936525404453\n",
            "ΔX norm: 1.857192546594888e-05\n",
            "Stage 7/10:  29%|████████▊                     | 88/300 [03:06<06:43,  1.90s/it]T Loss=2.303769588470459\n",
            "g_norm = tensor(0.1426, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305288314819336\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051533699035645\n",
            "g_norm = tensor(0.1178, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304985761642456\n",
            "g_norm = tensor(0.1650, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30428409576416\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7025909423828\n",
            "||∇_X meta|| = 0.0020129221957176924\n",
            "ΔX norm: 2.0129218682995997e-05\n",
            "Stage 7/10:  30%|████████▉                     | 89/300 [03:08<06:59,  1.99s/it]T Loss=2.3032946586608887\n",
            "g_norm = tensor(0.0737, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037028312683105\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030190467834473\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031976222991943\n",
            "g_norm = tensor(0.0956, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303161859512329\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.95237731933594\n",
            "||∇_X meta|| = 0.0020037121139466763\n",
            "ΔX norm: 2.0037108697579242e-05\n",
            "Stage 7/10:  30%|█████████                     | 90/300 [03:10<06:50,  1.95s/it]T Loss=2.3031582832336426\n",
            "g_norm = tensor(0.0937, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031139373779297\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030858039855957\n",
            "g_norm = tensor(0.0767, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303952693939209\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029561042785645\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4940643310547\n",
            "||∇_X meta|| = 0.0019975537434220314\n",
            "ΔX norm: 1.9975524992332794e-05\n",
            "Stage 7/10:  30%|█████████                     | 91/300 [03:12<06:48,  1.96s/it]T Loss=2.3050076961517334\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055171966552734\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052802085876465\n",
            "g_norm = tensor(0.0888, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305328845977783\n",
            "g_norm = tensor(0.0833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305471181869507\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.37399291992188\n",
            "||∇_X meta|| = 0.0019375986885279417\n",
            "ΔX norm: 1.9375984265934676e-05\n",
            "Stage 7/10:  31%|█████████▏                    | 92/300 [03:14<07:03,  2.04s/it]T Loss=2.3029422760009766\n",
            "g_norm = tensor(0.0786, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303561210632324\n",
            "g_norm = tensor(0.0733, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040263652801514\n",
            "g_norm = tensor(0.0825, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041486740112305\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30311918258667\n",
            "g_norm = tensor(0.0766, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.80625915527344\n",
            "||∇_X meta|| = 0.002039366401731968\n",
            "ΔX norm: 2.0393657905515283e-05\n",
            "Stage 7/10:  31%|█████████▎                    | 93/300 [03:16<06:52,  1.99s/it]T Loss=2.3033382892608643\n",
            "g_norm = tensor(0.0737, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301584482192993\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035213947296143\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302823305130005\n",
            "g_norm = tensor(0.0821, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036694526672363\n",
            "g_norm = tensor(0.0888, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9725341796875\n",
            "||∇_X meta|| = 0.0019942298531532288\n",
            "ΔX norm: 1.994230660784524e-05\n",
            "Stage 7/10:  31%|█████████▍                    | 94/300 [03:18<07:02,  2.05s/it]T Loss=2.3031914234161377\n",
            "g_norm = tensor(0.0993, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304225206375122\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032612800598145\n",
            "g_norm = tensor(0.0816, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035895824432373\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30342435836792\n",
            "g_norm = tensor(0.0836, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.09242248535156\n",
            "||∇_X meta|| = 0.0017805765382945538\n",
            "ΔX norm: 1.780574348231312e-05\n",
            "Stage 7/10:  32%|█████████▌                    | 95/300 [03:20<06:53,  2.02s/it]T Loss=2.3043978214263916\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040270805358887\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033947944641113\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038668632507324\n",
            "g_norm = tensor(0.1257, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302476406097412\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.79251098632812\n",
            "||∇_X meta|| = 0.002004327019676566\n",
            "ΔX norm: 2.0043262338731438e-05\n",
            "Stage 7/10:  32%|█████████▌                    | 96/300 [03:22<06:42,  1.97s/it]T Loss=2.302302837371826\n",
            "g_norm = tensor(0.1337, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033204078674316\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027522563934326\n",
            "g_norm = tensor(0.1319, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303833484649658\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031556606292725\n",
            "g_norm = tensor(0.1378, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.44894409179688\n",
            "||∇_X meta|| = 0.0019511772552505136\n",
            "ΔX norm: 1.9511760910972953e-05\n",
            "Stage 7/10:  32%|█████████▋                    | 97/300 [03:24<06:32,  1.93s/it]T Loss=2.3033018112182617\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303264617919922\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303584575653076\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304586410522461\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304508686065674\n",
            "g_norm = tensor(0.0983, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.71353149414062\n",
            "||∇_X meta|| = 0.0018743191612884402\n",
            "ΔX norm: 1.87431724043563e-05\n",
            "Stage 7/10:  33%|█████████▊                    | 98/300 [03:26<06:28,  1.92s/it]T Loss=2.303581714630127\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024888038635254\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304039239883423\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035943508148193\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036608695983887\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.83856201171875\n",
            "||∇_X meta|| = 0.0019000067841261625\n",
            "ΔX norm: 1.900005736388266e-05\n",
            "Stage 7/10:  33%|█████████▉                    | 99/300 [03:28<06:26,  1.92s/it]T Loss=2.3039255142211914\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046767711639404\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304143190383911\n",
            "g_norm = tensor(0.0858, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041396141052246\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304671287536621\n",
            "g_norm = tensor(0.0832, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.13577270507812\n",
            "||∇_X meta|| = 0.0019745072349905968\n",
            "ΔX norm: 1.9745064491871744e-05\n",
            "Stage 7/10:  33%|█████████▋                   | 100/300 [03:30<06:34,  1.97s/it]T Loss=2.3037219047546387\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038406372070312\n",
            "g_norm = tensor(0.0993, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30399489402771\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037052154541016\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303715229034424\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.7510528564453\n",
            "||∇_X meta|| = 0.0019095496973022819\n",
            "ΔX norm: 1.9095510651823133e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 7/10:  34%|█████████▊                   | 101/300 [03:32<06:35,  1.99s/it]T Loss=2.305528163909912\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305102586746216\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050830364227295\n",
            "g_norm = tensor(0.0856, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044962882995605\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048510551452637\n",
            "g_norm = tensor(0.1110, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.47947692871094\n",
            "||∇_X meta|| = 0.0018569306703284383\n",
            "ΔX norm: 1.8569307940197177e-05\n",
            "Stage 7/10:  34%|█████████▊                   | 102/300 [03:34<07:07,  2.16s/it]T Loss=2.30358624458313\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303471803665161\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038716316223145\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047385215759277\n",
            "g_norm = tensor(0.0983, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303971767425537\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.95477294921875\n",
            "||∇_X meta|| = 0.0016916620079427958\n",
            "ΔX norm: 1.6916621461859904e-05\n",
            "Stage 7/10:  34%|█████████▉                   | 103/300 [03:36<06:56,  2.11s/it]T Loss=2.303382158279419\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039963245391846\n",
            "g_norm = tensor(0.0867, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041579723358154\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031258583068848\n",
            "g_norm = tensor(0.0848, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035945892333984\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.18545532226562\n",
            "||∇_X meta|| = 0.0019265968585386872\n",
            "ΔX norm: 1.9265971786808223e-05\n",
            "Stage 7/10:  35%|██████████                   | 104/300 [03:38<06:45,  2.07s/it]T Loss=2.303724765777588\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304997682571411\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302220106124878\n",
            "g_norm = tensor(0.1222, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303158760070801\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051791191101074\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9086151123047\n",
            "||∇_X meta|| = 0.0018012505024671555\n",
            "ΔX norm: 1.801249527488835e-05\n",
            "Stage 7/10:  35%|██████████▏                  | 105/300 [03:41<07:26,  2.29s/it]T Loss=2.3033993244171143\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303795099258423\n",
            "g_norm = tensor(0.0857, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041176795959473\n",
            "g_norm = tensor(0.0820, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303853750228882\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042330741882324\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.21047973632812\n",
            "||∇_X meta|| = 0.0018410955090075731\n",
            "ΔX norm: 1.8410946722724475e-05\n",
            "Stage 7/10:  35%|██████████▏                  | 106/300 [03:43<07:17,  2.25s/it]T Loss=2.302902936935425\n",
            "g_norm = tensor(0.1273, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303239583969116\n",
            "g_norm = tensor(0.1305, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302788734436035\n",
            "g_norm = tensor(0.1396, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033645153045654\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033833503723145\n",
            "g_norm = tensor(0.1356, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.33804321289062\n",
            "||∇_X meta|| = 0.0018285615369677544\n",
            "ΔX norm: 1.828560561989434e-05\n",
            "Stage 7/10:  36%|██████████▎                  | 107/300 [03:45<06:53,  2.14s/it]T Loss=2.305870532989502\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304579973220825\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043766021728516\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305302619934082\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029112815856934\n",
            "g_norm = tensor(0.1494, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.7021026611328\n",
            "||∇_X meta|| = 0.0017704975325614214\n",
            "ΔX norm: 1.770499875419773e-05\n",
            "Stage 7/10:  36%|██████████▍                  | 108/300 [03:47<06:39,  2.08s/it]T Loss=2.303581476211548\n",
            "g_norm = tensor(0.0772, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304018020629883\n",
            "g_norm = tensor(0.0796, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303990364074707\n",
            "g_norm = tensor(0.0689, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043439388275146\n",
            "g_norm = tensor(0.0673, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303591251373291\n",
            "g_norm = tensor(0.0828, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.057373046875\n",
            "||∇_X meta|| = 0.0018962275935336947\n",
            "ΔX norm: 1.8962289686896838e-05\n",
            "Stage 7/10:  36%|██████████▌                  | 109/300 [03:49<06:22,  2.01s/it]T Loss=2.3045859336853027\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304882287979126\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052124977111816\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046982288360596\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304321050643921\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.24923706054688\n",
            "||∇_X meta|| = 0.0019014222780242562\n",
            "ΔX norm: 1.9014221834368072e-05\n",
            "Stage 7/10:  37%|██████████▋                  | 110/300 [03:51<06:23,  2.02s/it]T Loss=2.3040666580200195\n",
            "g_norm = tensor(0.0854, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303884744644165\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30283522605896\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037173748016357\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033602237701416\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.768798828125\n",
            "||∇_X meta|| = 0.0018654607702046633\n",
            "ΔX norm: 1.8654585801414214e-05\n",
            "Stage 7/10:  37%|██████████▋                  | 111/300 [03:53<06:15,  1.99s/it]T Loss=2.3043313026428223\n",
            "g_norm = tensor(0.1362, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039143085479736\n",
            "g_norm = tensor(0.1335, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045082092285156\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046364784240723\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305337429046631\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.24685668945312\n",
            "||∇_X meta|| = 0.0015923341270536184\n",
            "ΔX norm: 1.5923333194223233e-05\n",
            "Stage 7/10:  37%|██████████▊                  | 112/300 [03:55<06:11,  1.97s/it]T Loss=2.3038394451141357\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040807247161865\n",
            "g_norm = tensor(0.1259, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036048412323\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034069538116455\n",
            "g_norm = tensor(0.1250, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041398525238037\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.15673828125\n",
            "||∇_X meta|| = 0.0017042523249983788\n",
            "ΔX norm: 1.7042499166564085e-05\n",
            "Stage 7/10:  38%|██████████▉                  | 113/300 [03:57<06:11,  1.99s/it]T Loss=2.3011281490325928\n",
            "g_norm = tensor(0.1362, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025002479553223\n",
            "g_norm = tensor(0.1367, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303967237472534\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3008291721343994\n",
            "g_norm = tensor(0.1499, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036961555480957\n",
            "g_norm = tensor(0.1235, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.23141479492188\n",
            "||∇_X meta|| = 0.0017897021025419235\n",
            "ΔX norm: 1.789700945664663e-05\n",
            "Stage 7/10:  38%|███████████                  | 114/300 [03:59<06:05,  1.96s/it]T Loss=2.3031744956970215\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023593425750732\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032662868499756\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035852909088135\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035848140716553\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.45301818847656\n",
            "||∇_X meta|| = 0.0018912057857960463\n",
            "ΔX norm: 1.891200736281462e-05\n",
            "Stage 7/10:  38%|███████████                  | 115/300 [04:01<05:54,  1.92s/it]T Loss=2.3047618865966797\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052940368652344\n",
            "g_norm = tensor(0.0888, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039915561676025\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034753799438477\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049747943878174\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1641387939453\n",
            "||∇_X meta|| = 0.0017834436148405075\n",
            "ΔX norm: 1.7834410755313e-05\n",
            "Stage 7/10:  39%|███████████▏                 | 116/300 [04:03<06:05,  1.99s/it]T Loss=2.304379940032959\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044042587280273\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036961555480957\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304804801940918\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304619073867798\n",
            "g_norm = tensor(0.0919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.17630004882812\n",
            "||∇_X meta|| = 0.0018868482438847423\n",
            "ΔX norm: 1.886846439447254e-05\n",
            "Stage 7/10:  39%|███████████▎                 | 117/300 [04:05<05:55,  1.94s/it]T Loss=2.304111957550049\n",
            "g_norm = tensor(0.1340, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050150871276855\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051319122314453\n",
            "g_norm = tensor(0.1426, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056459426879883\n",
            "g_norm = tensor(0.1476, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305819272994995\n",
            "g_norm = tensor(0.1345, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.18821716308594\n",
            "||∇_X meta|| = 0.0017620379803702235\n",
            "ΔX norm: 1.762040665198583e-05\n",
            "Stage 7/10:  39%|███████████▍                 | 118/300 [04:07<05:49,  1.92s/it]T Loss=2.303518772125244\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303001880645752\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304068088531494\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303710699081421\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042702674865723\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.77137756347656\n",
            "||∇_X meta|| = 0.001826844527386129\n",
            "ΔX norm: 1.826846164476592e-05\n",
            "Stage 7/10:  40%|███████████▌                 | 119/300 [04:08<05:45,  1.91s/it]T Loss=2.3047842979431152\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043246269226074\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3060965538024902\n",
            "g_norm = tensor(0.1441, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048200607299805\n",
            "g_norm = tensor(0.1424, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305422306060791\n",
            "g_norm = tensor(0.1571, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.81411743164062\n",
            "||∇_X meta|| = 0.0018434886587783694\n",
            "ΔX norm: 1.8434879166306928e-05\n",
            "Stage 7/10:  40%|███████████▌                 | 120/300 [04:10<05:41,  1.90s/it]T Loss=2.3046507835388184\n",
            "g_norm = tensor(0.1480, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301539421081543\n",
            "g_norm = tensor(0.1488, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305077314376831\n",
            "g_norm = tensor(0.1784, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017821311950684\n",
            "g_norm = tensor(0.1495, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303037166595459\n",
            "g_norm = tensor(0.1438, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.818115234375\n",
            "||∇_X meta|| = 0.0017894849879667163\n",
            "ΔX norm: 1.789486668712925e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 7/10:  40%|███████████▋                 | 121/300 [04:12<05:36,  1.88s/it]T Loss=2.3041720390319824\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302273750305176\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303037166595459\n",
            "g_norm = tensor(0.1422, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303685426712036\n",
            "g_norm = tensor(0.1354, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033416271209717\n",
            "g_norm = tensor(0.1561, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1722869873047\n",
            "||∇_X meta|| = 0.0016514064045622945\n",
            "ΔX norm: 1.6514062735950574e-05\n",
            "Stage 7/10:  41%|███████████▊                 | 122/300 [04:15<06:17,  2.12s/it]T Loss=2.3025965690612793\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303316593170166\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037774562835693\n",
            "g_norm = tensor(0.0814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303589344024658\n",
            "g_norm = tensor(0.0821, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302844762802124\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.72613525390625\n",
            "||∇_X meta|| = 0.0017430733423680067\n",
            "ΔX norm: 1.7430749721825123e-05\n",
            "Stage 7/10:  41%|███████████▉                 | 123/300 [04:18<07:02,  2.39s/it]T Loss=2.305457592010498\n",
            "g_norm = tensor(0.1467, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304413080215454\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040771484375\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053951263427734\n",
            "g_norm = tensor(0.1483, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305710792541504\n",
            "g_norm = tensor(0.1415, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.73623657226562\n",
            "||∇_X meta|| = 0.0016210913890972733\n",
            "ΔX norm: 1.6210917237913236e-05\n",
            "Stage 7/10:  41%|███████████▉                 | 124/300 [04:20<06:42,  2.28s/it]T Loss=2.3028206825256348\n",
            "g_norm = tensor(0.1608, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035144805908203\n",
            "g_norm = tensor(0.1538, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303574800491333\n",
            "g_norm = tensor(0.1326, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025615215301514\n",
            "g_norm = tensor(0.1443, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049683570861816\n",
            "g_norm = tensor(0.1624, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.30819702148438\n",
            "||∇_X meta|| = 0.0018156950827687979\n",
            "ΔX norm: 1.8156944861402735e-05\n",
            "Stage 7/10:  42%|████████████                 | 125/300 [04:22<06:22,  2.19s/it]T Loss=2.3045923709869385\n",
            "g_norm = tensor(0.0908, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042733669281006\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304095983505249\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035197257995605\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303492784500122\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0288543701172\n",
            "||∇_X meta|| = 0.0017095630755648017\n",
            "ΔX norm: 1.7095613657147624e-05\n",
            "Stage 7/10:  42%|████████████▏                | 126/300 [04:24<06:11,  2.14s/it]T Loss=2.3029301166534424\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303344249725342\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303757429122925\n",
            "g_norm = tensor(0.0841, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033699989318848\n",
            "g_norm = tensor(0.0888, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037526607513428\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.22686767578125\n",
            "||∇_X meta|| = 0.0017820930806919932\n",
            "ΔX norm: 1.7820924767875113e-05\n",
            "Stage 7/10:  42%|████████████▎                | 127/300 [04:26<06:04,  2.11s/it]T Loss=2.3042683601379395\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046090602874756\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033103942871094\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303065061569214\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045547008514404\n",
            "g_norm = tensor(0.1292, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4783477783203\n",
            "||∇_X meta|| = 0.001919848145917058\n",
            "ΔX norm: 1.9198469090042636e-05\n",
            "Stage 7/10:  43%|████████████▎                | 128/300 [04:28<06:05,  2.13s/it]T Loss=2.305631637573242\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035430908203125\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304506540298462\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304151773452759\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046107292175293\n",
            "g_norm = tensor(0.0724, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.27734375\n",
            "||∇_X meta|| = 0.0017719921888783574\n",
            "ΔX norm: 1.771992538124323e-05\n",
            "Stage 7/10:  43%|████████████▍                | 129/300 [04:30<06:13,  2.18s/it]T Loss=2.3027617931365967\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028459548950195\n",
            "g_norm = tensor(0.1404, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302788019180298\n",
            "g_norm = tensor(0.1441, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018581867218018\n",
            "g_norm = tensor(0.1269, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036255836486816\n",
            "g_norm = tensor(0.1614, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5717315673828\n",
            "||∇_X meta|| = 0.0016836399445310235\n",
            "ΔX norm: 1.6836394934216514e-05\n",
            "Stage 7/10:  43%|████████████▌                | 130/300 [04:32<05:58,  2.11s/it]T Loss=2.304921865463257\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304654598236084\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037781715393066\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033697605133057\n",
            "g_norm = tensor(0.1234, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046703338623047\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.92263793945312\n",
            "||∇_X meta|| = 0.001577765797264874\n",
            "ΔX norm: 1.577767397975549e-05\n",
            "Stage 7/10:  44%|████████████▋                | 131/300 [04:34<05:51,  2.08s/it]T Loss=2.3032116889953613\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036141395568848\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038909435272217\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049442768096924\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302858829498291\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5148162841797\n",
            "||∇_X meta|| = 0.0015622855862602592\n",
            "ΔX norm: 1.5622836144757457e-05\n",
            "Stage 7/10:  44%|████████████▊                | 132/300 [04:36<05:46,  2.07s/it]T Loss=2.304147958755493\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039708137512207\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304331064224243\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041625022888184\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029024600982666\n",
            "g_norm = tensor(0.0908, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.97451782226562\n",
            "||∇_X meta|| = 0.001487280591391027\n",
            "ΔX norm: 1.4872784959152341e-05\n",
            "Stage 7/10:  44%|████████████▊                | 133/300 [04:38<05:42,  2.05s/it]T Loss=2.3042001724243164\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303795337677002\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303332805633545\n",
            "g_norm = tensor(0.1140, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304046154022217\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024864196777344\n",
            "g_norm = tensor(0.1103, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.74899291992188\n",
            "||∇_X meta|| = 0.0016521838260814548\n",
            "ΔX norm: 1.652185346756596e-05\n",
            "Stage 7/10:  45%|████████████▉                | 134/300 [04:40<05:33,  2.01s/it]T Loss=2.3034889698028564\n",
            "g_norm = tensor(0.1714, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034491539001465\n",
            "g_norm = tensor(0.1581, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056931495666504\n",
            "g_norm = tensor(0.1682, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040170669555664\n",
            "g_norm = tensor(0.1639, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039872646331787\n",
            "g_norm = tensor(0.1477, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7619171142578\n",
            "||∇_X meta|| = 0.0018088771030306816\n",
            "ΔX norm: 1.808874003472738e-05\n",
            "Stage 7/10:  45%|█████████████                | 135/300 [04:42<05:27,  1.98s/it]T Loss=2.304250955581665\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303800582885742\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305201292037964\n",
            "g_norm = tensor(0.1440, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050076961517334\n",
            "g_norm = tensor(0.1366, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051609992980957\n",
            "g_norm = tensor(0.1395, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =226.73846435546875\n",
            "||∇_X meta|| = 0.0016196612268686295\n",
            "ΔX norm: 1.6196618162211962e-05\n",
            "Stage 7/10:  45%|█████████████▏               | 136/300 [04:44<05:26,  1.99s/it]T Loss=2.304948091506958\n",
            "g_norm = tensor(0.1360, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036437034606934\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303497552871704\n",
            "g_norm = tensor(0.1357, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053297996520996\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055615425109863\n",
            "g_norm = tensor(0.1622, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3494415283203\n",
            "||∇_X meta|| = 0.001852279296144843\n",
            "ΔX norm: 1.8522794562159106e-05\n",
            "Stage 7/10:  46%|█████████████▏               | 137/300 [04:46<05:22,  1.98s/it]T Loss=2.3047118186950684\n",
            "g_norm = tensor(0.1406, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032116889953613\n",
            "g_norm = tensor(0.1336, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304316759109497\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3013193607330322\n",
            "g_norm = tensor(0.1516, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301417350769043\n",
            "g_norm = tensor(0.1833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.85787963867188\n",
            "||∇_X meta|| = 0.001750831725075841\n",
            "ΔX norm: 1.7508305973024108e-05\n",
            "Stage 7/10:  46%|█████████████▎               | 138/300 [04:48<05:23,  2.00s/it]T Loss=2.304069995880127\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304471731185913\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303764581680298\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036208152770996\n",
            "g_norm = tensor(0.0793, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303849458694458\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.20797729492188\n",
            "||∇_X meta|| = 0.0016831625252962112\n",
            "ΔX norm: 1.6831618268042803e-05\n",
            "Stage 7/10:  46%|█████████████▍               | 139/300 [04:50<05:18,  1.98s/it]T Loss=2.3023362159729004\n",
            "g_norm = tensor(0.1412, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034462928771973\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025124073028564\n",
            "g_norm = tensor(0.1513, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030598163604736\n",
            "g_norm = tensor(0.1480, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302455186843872\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.93255615234375\n",
            "||∇_X meta|| = 0.001652236795052886\n",
            "ΔX norm: 1.652236642257776e-05\n",
            "Stage 7/10:  47%|█████████████▌               | 140/300 [04:52<05:13,  1.96s/it]T Loss=2.303786039352417\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031492233276367\n",
            "g_norm = tensor(0.0766, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036584854125977\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303382635116577\n",
            "g_norm = tensor(0.0769, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029885292053223\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1804962158203\n",
            "||∇_X meta|| = 0.001794136711396277\n",
            "ΔX norm: 1.7941370970220305e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 7/10:  47%|█████████████▋               | 141/300 [04:54<05:07,  1.93s/it]T Loss=2.3044707775115967\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304309129714966\n",
            "g_norm = tensor(0.0828, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304222822189331\n",
            "g_norm = tensor(0.0725, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303873300552368\n",
            "g_norm = tensor(0.0890, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026440143585205\n",
            "g_norm = tensor(0.0956, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.11007690429688\n",
            "||∇_X meta|| = 0.0016437943559139967\n",
            "ΔX norm: 1.643794348638039e-05\n",
            "Stage 7/10:  47%|█████████████▋               | 142/300 [04:57<05:38,  2.14s/it]T Loss=2.304222345352173\n",
            "g_norm = tensor(0.1369, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037662506103516\n",
            "g_norm = tensor(0.1292, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304159641265869\n",
            "g_norm = tensor(0.1275, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045318126678467\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050241470336914\n",
            "g_norm = tensor(0.1374, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.5472869873047\n",
            "||∇_X meta|| = 0.0015512289246544242\n",
            "ΔX norm: 1.5512281606788747e-05\n",
            "Stage 7/10:  48%|█████████████▊               | 143/300 [04:59<05:29,  2.10s/it]T Loss=2.303997039794922\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047051429748535\n",
            "g_norm = tensor(0.1289, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303204298019409\n",
            "g_norm = tensor(0.1384, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047702312469482\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050143718719482\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.266357421875\n",
            "||∇_X meta|| = 0.0017415584297850728\n",
            "ΔX norm: 1.741559935908299e-05\n",
            "Stage 7/10:  48%|█████████████▉               | 144/300 [05:00<05:13,  2.01s/it]T Loss=2.3035051822662354\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037524223327637\n",
            "g_norm = tensor(0.1481, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304443120956421\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024637699127197\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031158447265625\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.52308654785156\n",
            "||∇_X meta|| = 0.001628513215109706\n",
            "ΔX norm: 1.628513382456731e-05\n",
            "Stage 7/10:  48%|██████████████               | 145/300 [05:02<05:00,  1.94s/it]T Loss=2.3038673400878906\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046798706054688\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042640686035156\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304079532623291\n",
            "g_norm = tensor(0.1296, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031978607177734\n",
            "g_norm = tensor(0.0931, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.47164916992188\n",
            "||∇_X meta|| = 0.0017909572925418615\n",
            "ΔX norm: 1.7909576854435727e-05\n",
            "Stage 7/10:  49%|██████████████               | 146/300 [05:04<04:54,  1.91s/it]T Loss=2.3038735389709473\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304800033569336\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304358959197998\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036789894104004\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035728931427\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.6000518798828\n",
            "||∇_X meta|| = 0.001617836649529636\n",
            "ΔX norm: 1.6178386431420222e-05\n",
            "Stage 7/10:  49%|██████████████▏              | 147/300 [05:06<04:53,  1.92s/it]T Loss=2.3046059608459473\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304708242416382\n",
            "g_norm = tensor(0.0876, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041367530822754\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057360649108887\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051891326904297\n",
            "g_norm = tensor(0.0941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.53469848632812\n",
            "||∇_X meta|| = 0.0016381453024223447\n",
            "ΔX norm: 1.6381454770453274e-05\n",
            "Stage 7/10:  49%|██████████████▎              | 148/300 [05:08<05:01,  1.98s/it]T Loss=2.304154872894287\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302387237548828\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044679164886475\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030648231506348\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043181896209717\n",
            "g_norm = tensor(0.1391, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.63856506347656\n",
            "||∇_X meta|| = 0.0016811478417366743\n",
            "ΔX norm: 1.681148205534555e-05\n",
            "Stage 7/10:  50%|██████████████▍              | 149/300 [05:10<04:57,  1.97s/it]T Loss=2.304558277130127\n",
            "g_norm = tensor(0.1259, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303788661956787\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038136959075928\n",
            "g_norm = tensor(0.1392, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039002418518066\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304130792617798\n",
            "g_norm = tensor(0.1178, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.24417114257812\n",
            "||∇_X meta|| = 0.0015097798313945532\n",
            "ΔX norm: 1.5097784853423946e-05\n",
            "Stage 7/10:  50%|██████████████▌              | 150/300 [05:12<04:55,  1.97s/it]T Loss=2.304108142852783\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034827709198\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035149574279785\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035991191864014\n",
            "g_norm = tensor(0.0750, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033289909362793\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2278594970703\n",
            "||∇_X meta|| = 0.001442047650925815\n",
            "ΔX norm: 1.4420480511034839e-05\n",
            "Stage 7/10:  50%|██████████████▌              | 151/300 [05:14<04:49,  1.94s/it]T Loss=2.3030636310577393\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042705059051514\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303713083267212\n",
            "g_norm = tensor(0.0931, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30405592918396\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303370714187622\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.6803436279297\n",
            "||∇_X meta|| = 0.0016362760215997696\n",
            "ΔX norm: 1.6362755559384823e-05\n",
            "Stage 7/10:  51%|██████████████▋              | 152/300 [05:16<04:46,  1.94s/it]T Loss=2.304403066635132\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304311752319336\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305480480194092\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304530620574951\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048853874206543\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2242431640625\n",
            "||∇_X meta|| = 0.001615977264009416\n",
            "ΔX norm: 1.6159745428012684e-05\n",
            "Stage 7/10:  51%|██████████████▊              | 153/300 [05:18<04:55,  2.01s/it]T Loss=2.302361011505127\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302910089492798\n",
            "g_norm = tensor(0.0839, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023135662078857\n",
            "g_norm = tensor(0.0898, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036725521087646\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033251762390137\n",
            "g_norm = tensor(0.0861, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.88356018066406\n",
            "||∇_X meta|| = 0.0015606738161295652\n",
            "ΔX norm: 1.560672899358906e-05\n",
            "Stage 7/10:  51%|██████████████▉              | 154/300 [05:20<04:52,  2.00s/it]T Loss=2.304288387298584\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304689884185791\n",
            "g_norm = tensor(0.0876, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304718017578125\n",
            "g_norm = tensor(0.0860, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047187328338623\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050265312194824\n",
            "g_norm = tensor(0.0931, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.617431640625\n",
            "||∇_X meta|| = 0.0015105413040146232\n",
            "ΔX norm: 1.5105447346286383e-05\n",
            "Stage 7/10:  52%|██████████████▉              | 155/300 [05:22<04:54,  2.03s/it]T Loss=2.3042569160461426\n",
            "g_norm = tensor(0.1540, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044402599334717\n",
            "g_norm = tensor(0.1592, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302173376083374\n",
            "g_norm = tensor(0.1767, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303560733795166\n",
            "g_norm = tensor(0.1314, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304711103439331\n",
            "g_norm = tensor(0.1408, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7399444580078\n",
            "||∇_X meta|| = 0.0018456268589943647\n",
            "ΔX norm: 1.845624683483038e-05\n",
            "Stage 7/10:  52%|███████████████              | 156/300 [05:24<04:43,  1.97s/it]T Loss=2.304628849029541\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050336837768555\n",
            "g_norm = tensor(0.1250, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043665885925293\n",
            "g_norm = tensor(0.1225, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051304817199707\n",
            "g_norm = tensor(0.1384, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304497003555298\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.12799072265625\n",
            "||∇_X meta|| = 0.001561307697556913\n",
            "ΔX norm: 1.5613079085596837e-05\n",
            "Stage 7/10:  52%|███████████████▏             | 157/300 [05:26<04:32,  1.91s/it]T Loss=2.3025543689727783\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303670883178711\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302842378616333\n",
            "g_norm = tensor(0.0919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303065776824951\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303529977798462\n",
            "g_norm = tensor(0.0777, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.72885131835938\n",
            "||∇_X meta|| = 0.0016313189407810569\n",
            "ΔX norm: 1.6313208107021637e-05\n",
            "Stage 7/10:  53%|███████████████▎             | 158/300 [05:27<04:28,  1.89s/it]T Loss=2.303940534591675\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041024208068848\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052735328674316\n",
            "g_norm = tensor(0.1291, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050267696380615\n",
            "g_norm = tensor(0.1384, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303698778152466\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.80026245117188\n",
            "||∇_X meta|| = 0.0017087043961510062\n",
            "ΔX norm: 1.7087042579078116e-05\n",
            "Stage 7/10:  53%|███████████████▎             | 159/300 [05:29<04:24,  1.87s/it]T Loss=2.305800199508667\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304353713989258\n",
            "g_norm = tensor(0.0902, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303981304168701\n",
            "g_norm = tensor(0.0812, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304050922393799\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052597045898438\n",
            "g_norm = tensor(0.0797, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.13169860839844\n",
            "||∇_X meta|| = 0.0018024645978584886\n",
            "ΔX norm: 1.8024655219051056e-05\n",
            "Stage 7/10:  53%|███████████████▍             | 160/300 [05:31<04:21,  1.87s/it]T Loss=2.3041603565216064\n",
            "g_norm = tensor(0.1421, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030173778533936\n",
            "g_norm = tensor(0.1699, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303581476211548\n",
            "g_norm = tensor(0.1476, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034474849700928\n",
            "g_norm = tensor(0.1488, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304910182952881\n",
            "g_norm = tensor(0.1338, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.57192993164062\n",
            "||∇_X meta|| = 0.0016655565705150366\n",
            "ΔX norm: 1.6655592844472267e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 7/10:  54%|███████████████▌             | 161/300 [05:33<04:19,  1.87s/it]T Loss=2.304497241973877\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045382499694824\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035976886749268\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30448579788208\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303452730178833\n",
            "g_norm = tensor(0.0841, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1383514404297\n",
            "||∇_X meta|| = 0.0014976944075897336\n",
            "ΔX norm: 1.4976933925936464e-05\n",
            "Stage 7/10:  54%|███████████████▋             | 162/300 [05:36<04:43,  2.06s/it]T Loss=2.302811622619629\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303445339202881\n",
            "g_norm = tensor(0.1213, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304938793182373\n",
            "g_norm = tensor(0.1269, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034753799438477\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039567470550537\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8885040283203\n",
            "||∇_X meta|| = 0.0015274283941835165\n",
            "ΔX norm: 1.5274274119292386e-05\n",
            "Stage 7/10:  54%|███████████████▊             | 163/300 [05:38<04:44,  2.08s/it]T Loss=2.3042361736297607\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042895793914795\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303466796875\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031833171844482\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035120964050293\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.54705810546875\n",
            "||∇_X meta|| = 0.0015843977453187108\n",
            "ΔX norm: 1.584399797138758e-05\n",
            "Stage 7/10:  55%|███████████████▊             | 164/300 [05:40<04:45,  2.10s/it]T Loss=2.3040215969085693\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040077686309814\n",
            "g_norm = tensor(0.1410, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044495582580566\n",
            "g_norm = tensor(0.1323, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303457736968994\n",
            "g_norm = tensor(0.1219, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304797649383545\n",
            "g_norm = tensor(0.1080, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.47230529785156\n",
            "||∇_X meta|| = 0.001654524472542107\n",
            "ΔX norm: 1.6545256585231982e-05\n",
            "Stage 7/10:  55%|███████████████▉             | 165/300 [05:42<04:39,  2.07s/it]T Loss=2.3053135871887207\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047549724578857\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035085201263428\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304677963256836\n",
            "g_norm = tensor(0.1248, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304232120513916\n",
            "g_norm = tensor(0.1323, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2963409423828\n",
            "||∇_X meta|| = 0.0015614061849191785\n",
            "ΔX norm: 1.5614061339874752e-05\n",
            "Stage 7/10:  55%|████████████████             | 166/300 [05:44<04:30,  2.02s/it]T Loss=2.304065227508545\n",
            "g_norm = tensor(0.0827, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304537296295166\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303449869155884\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046231269836426\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039774894714355\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.90049743652344\n",
            "||∇_X meta|| = 0.0014404768589884043\n",
            "ΔX norm: 1.4404766261577606e-05\n",
            "Stage 7/10:  56%|████████████████▏            | 167/300 [05:46<04:57,  2.24s/it]T Loss=2.302842617034912\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027501106262207\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036651611328125\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026509284973145\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027215003967285\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3812713623047\n",
            "||∇_X meta|| = 0.0016059221234172583\n",
            "ΔX norm: 1.605922807357274e-05\n",
            "Stage 7/10:  56%|████████████████▏            | 168/300 [05:49<04:59,  2.27s/it]T Loss=2.3030788898468018\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302520751953125\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036959171295166\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034822940826416\n",
            "g_norm = tensor(0.1011, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035788536071777\n",
            "g_norm = tensor(0.0814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.68418884277344\n",
            "||∇_X meta|| = 0.0017675982089713216\n",
            "ΔX norm: 1.767598405422177e-05\n",
            "Stage 7/10:  56%|████████████████▎            | 169/300 [05:51<04:59,  2.29s/it]T Loss=2.3046181201934814\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305957794189453\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306147336959839\n",
            "g_norm = tensor(0.1481, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044137954711914\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043880462646484\n",
            "g_norm = tensor(0.1249, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =227.84336853027344\n",
            "||∇_X meta|| = 0.0016689267940819263\n",
            "ΔX norm: 1.6689273252268322e-05\n",
            "Stage 7/10:  57%|████████████████▍            | 170/300 [05:53<04:51,  2.25s/it]T Loss=2.3033738136291504\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034868240356445\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031582832336426\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039681911468506\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304572343826294\n",
            "g_norm = tensor(0.0937, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.00823974609375\n",
            "||∇_X meta|| = 0.0015958643052726984\n",
            "ΔX norm: 1.5958637959556654e-05\n",
            "Stage 7/10:  57%|████████████████▌            | 171/300 [05:55<04:46,  2.22s/it]T Loss=2.3044192790985107\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043997287750244\n",
            "g_norm = tensor(0.1286, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304300546646118\n",
            "g_norm = tensor(0.1295, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058154582977295\n",
            "g_norm = tensor(0.1423, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3059802055358887\n",
            "g_norm = tensor(0.1461, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.50582885742188\n",
            "||∇_X meta|| = 0.0017088945023715496\n",
            "ΔX norm: 1.7088910681195557e-05\n",
            "Stage 7/10:  57%|████████████████▋            | 172/300 [05:57<04:34,  2.15s/it]T Loss=2.3052947521209717\n",
            "g_norm = tensor(0.1419, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304687261581421\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036491870880127\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050014972686768\n",
            "g_norm = tensor(0.1362, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304980754852295\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.47354125976562\n",
            "||∇_X meta|| = 0.0016787843778729439\n",
            "ΔX norm: 1.678783883107826e-05\n",
            "Stage 7/10:  58%|████████████████▋            | 173/300 [05:59<04:22,  2.06s/it]T Loss=2.304224967956543\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304006814956665\n",
            "g_norm = tensor(0.0774, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040246963500977\n",
            "g_norm = tensor(0.0838, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043534755706787\n",
            "g_norm = tensor(0.0740, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041257858276367\n",
            "g_norm = tensor(0.0700, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2372283935547\n",
            "||∇_X meta|| = 0.0017953161150217056\n",
            "ΔX norm: 1.7953170754481107e-05\n",
            "Stage 7/10:  58%|████████████████▊            | 174/300 [06:01<04:17,  2.04s/it]T Loss=2.304715633392334\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304932117462158\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032970428466797\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036177158355713\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051114082336426\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9398193359375\n",
            "||∇_X meta|| = 0.0016624050913378596\n",
            "ΔX norm: 1.662404611124657e-05\n",
            "Stage 7/10:  58%|████████████████▉            | 175/300 [06:04<04:32,  2.18s/it]T Loss=2.306344509124756\n",
            "g_norm = tensor(0.1391, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305816888809204\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053596019744873\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054068088531494\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052315711975098\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.58702087402344\n",
            "||∇_X meta|| = 0.0018118220614269376\n",
            "ΔX norm: 1.8118214939022437e-05\n",
            "Stage 7/10:  59%|█████████████████            | 176/300 [06:06<04:31,  2.19s/it]T Loss=2.302889108657837\n",
            "g_norm = tensor(0.1567, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034679889678955\n",
            "g_norm = tensor(0.1529, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304316282272339\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037047386169434\n",
            "g_norm = tensor(0.1304, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033878803253174\n",
            "g_norm = tensor(0.1437, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.76138305664062\n",
            "||∇_X meta|| = 0.0015654468443244696\n",
            "ΔX norm: 1.5654481103410944e-05\n",
            "Stage 7/10:  59%|█████████████████            | 177/300 [06:08<04:26,  2.17s/it]T Loss=2.3043391704559326\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044159412384033\n",
            "g_norm = tensor(0.1453, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304412603378296\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303701877593994\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048462867736816\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.39852905273438\n",
            "||∇_X meta|| = 0.0016036484157666564\n",
            "ΔX norm: 1.603647251613438e-05\n",
            "Stage 7/10:  59%|█████████████████▏           | 178/300 [06:10<04:14,  2.09s/it]T Loss=2.303412437438965\n",
            "g_norm = tensor(0.1021, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303339958190918\n",
            "g_norm = tensor(0.0879, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026530742645264\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035783767700195\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303471803665161\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2963409423828\n",
            "||∇_X meta|| = 0.001538037438876927\n",
            "ΔX norm: 1.538037759019062e-05\n",
            "Stage 7/10:  60%|█████████████████▎           | 179/300 [06:12<04:06,  2.04s/it]T Loss=2.304731845855713\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037362098693848\n",
            "g_norm = tensor(0.1305, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042373657226562\n",
            "g_norm = tensor(0.1344, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304168224334717\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047823905944824\n",
            "g_norm = tensor(0.1579, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.67042541503906\n",
            "||∇_X meta|| = 0.0017059029778465629\n",
            "ΔX norm: 1.7059008314390667e-05\n",
            "Stage 7/10:  60%|█████████████████▍           | 180/300 [06:14<04:12,  2.10s/it]T Loss=2.3024888038635254\n",
            "g_norm = tensor(0.1573, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036675453186035\n",
            "g_norm = tensor(0.1325, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302628993988037\n",
            "g_norm = tensor(0.1704, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030107021331787\n",
            "g_norm = tensor(0.1574, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035733699798584\n",
            "g_norm = tensor(0.1575, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.7394256591797\n",
            "||∇_X meta|| = 0.0017080141697078943\n",
            "ΔX norm: 1.708012496237643e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 7/10:  60%|█████████████████▍           | 181/300 [06:16<04:10,  2.10s/it]T Loss=2.302654504776001\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033719062805176\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034119606018066\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040997982025146\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304425001144409\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.84857177734375\n",
            "||∇_X meta|| = 0.0015346953878179193\n",
            "ΔX norm: 1.534694092697464e-05\n",
            "Stage 7/10:  61%|█████████████████▌           | 182/300 [06:19<04:29,  2.29s/it]T Loss=2.30375599861145\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031058311462402\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026957511901855\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303210496902466\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302324056625366\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0924835205078\n",
            "||∇_X meta|| = 0.0014483776176348329\n",
            "ΔX norm: 1.4483765880868305e-05\n",
            "Stage 7/10:  61%|█████████████████▋           | 183/300 [06:21<04:22,  2.24s/it]T Loss=2.303537368774414\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049728870391846\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304429769515991\n",
            "g_norm = tensor(0.1312, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041396141052246\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303539514541626\n",
            "g_norm = tensor(0.1139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4166717529297\n",
            "||∇_X meta|| = 0.0016004323260858655\n",
            "ΔX norm: 1.6004290955606848e-05\n",
            "Stage 7/10:  61%|█████████████████▊           | 184/300 [06:23<04:10,  2.16s/it]T Loss=2.303422212600708\n",
            "g_norm = tensor(0.0806, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027291297912598\n",
            "g_norm = tensor(0.0922, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303976535797119\n",
            "g_norm = tensor(0.0806, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037517070770264\n",
            "g_norm = tensor(0.0831, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303410530090332\n",
            "g_norm = tensor(0.0728, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.36392211914062\n",
            "||∇_X meta|| = 0.0015552216209471226\n",
            "ΔX norm: 1.555222479510121e-05\n",
            "Stage 7/10:  62%|█████████████████▉           | 185/300 [06:25<04:05,  2.13s/it]T Loss=2.3025341033935547\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303502321243286\n",
            "g_norm = tensor(0.0781, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036670684814453\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036277294158936\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302741050720215\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.67788696289062\n",
            "||∇_X meta|| = 0.0015404362929984927\n",
            "ΔX norm: 1.5404393707285635e-05\n",
            "Stage 7/10:  62%|█████████████████▉           | 186/300 [06:27<04:04,  2.15s/it]T Loss=2.3037052154541016\n",
            "g_norm = tensor(0.0851, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034567832946777\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037614822387695\n",
            "g_norm = tensor(0.0773, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036270141601562\n",
            "g_norm = tensor(0.0803, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029866218566895\n",
            "g_norm = tensor(0.0858, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4488983154297\n",
            "||∇_X meta|| = 0.0015720769297331572\n",
            "ΔX norm: 1.5720770534244366e-05\n",
            "Stage 7/10:  62%|██████████████████           | 187/300 [06:30<04:08,  2.20s/it]T Loss=2.3052992820739746\n",
            "g_norm = tensor(0.1583, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3064823150634766\n",
            "g_norm = tensor(0.1302, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304908037185669\n",
            "g_norm = tensor(0.1309, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30484676361084\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303910970687866\n",
            "g_norm = tensor(0.1439, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.69268798828125\n",
            "||∇_X meta|| = 0.001593828434124589\n",
            "ΔX norm: 1.5938303477014415e-05\n",
            "Stage 7/10:  63%|██████████████████▏          | 188/300 [06:32<04:03,  2.18s/it]T Loss=2.3035056591033936\n",
            "g_norm = tensor(0.0765, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032877445220947\n",
            "g_norm = tensor(0.0883, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037617206573486\n",
            "g_norm = tensor(0.0789, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303577184677124\n",
            "g_norm = tensor(0.0716, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028666973114014\n",
            "g_norm = tensor(0.0846, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.95010375976562\n",
            "||∇_X meta|| = 0.0015826806193217635\n",
            "ΔX norm: 1.5826790331630036e-05\n",
            "Stage 7/10:  63%|██████████████████▎          | 189/300 [06:34<03:51,  2.08s/it]T Loss=2.3047573566436768\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3061447143554688\n",
            "g_norm = tensor(0.1358, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304978847503662\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305476665496826\n",
            "g_norm = tensor(0.1523, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050038814544678\n",
            "g_norm = tensor(0.1545, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7134246826172\n",
            "||∇_X meta|| = 0.0015292431926354766\n",
            "ΔX norm: 1.5292429452529177e-05\n",
            "Stage 7/10:  63%|██████████████████▎          | 190/300 [06:36<03:45,  2.05s/it]T Loss=2.3030314445495605\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041634559631348\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041188716888428\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038954734802246\n",
            "g_norm = tensor(0.0945, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303995132446289\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0000762939453\n",
            "||∇_X meta|| = 0.0017469837330281734\n",
            "ΔX norm: 1.7469841623096727e-05\n",
            "Stage 7/10:  64%|██████████████████▍          | 191/300 [06:38<03:41,  2.03s/it]T Loss=2.3029870986938477\n",
            "g_norm = tensor(0.1449, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303013801574707\n",
            "g_norm = tensor(0.1270, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303398370742798\n",
            "g_norm = tensor(0.1384, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302013635635376\n",
            "g_norm = tensor(0.1503, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034026622772217\n",
            "g_norm = tensor(0.1493, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.6380615234375\n",
            "||∇_X meta|| = 0.0016363965114578605\n",
            "ΔX norm: 1.636393972148653e-05\n",
            "Stage 7/10:  64%|██████████████████▌          | 192/300 [06:40<03:37,  2.01s/it]T Loss=2.3035600185394287\n",
            "g_norm = tensor(0.0740, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035919666290283\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028175830841064\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040387630462646\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043861389160156\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.49755859375\n",
            "||∇_X meta|| = 0.0016295121749863029\n",
            "ΔX norm: 1.6295118257403374e-05\n",
            "Stage 7/10:  64%|██████████████████▋          | 193/300 [06:42<03:34,  2.01s/it]T Loss=2.3044075965881348\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304368495941162\n",
            "g_norm = tensor(0.0844, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044333457946777\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303833246231079\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039844036102295\n",
            "g_norm = tensor(0.0884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8553009033203\n",
            "||∇_X meta|| = 0.001616676920093596\n",
            "ΔX norm: 1.6166779460036196e-05\n",
            "Stage 7/10:  65%|██████████████████▊          | 194/300 [06:44<03:39,  2.07s/it]T Loss=2.3034958839416504\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023104667663574\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031792640686035\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034424781799316\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302569627761841\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.41278076171875\n",
            "||∇_X meta|| = 0.0014513940550386906\n",
            "ΔX norm: 1.4513953829009552e-05\n",
            "Stage 7/10:  65%|██████████████████▊          | 195/300 [06:46<03:37,  2.07s/it]T Loss=2.304060459136963\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044545650482178\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046371936798096\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027796745300293\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037288188934326\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4630889892578\n",
            "||∇_X meta|| = 0.0016519584460183978\n",
            "ΔX norm: 1.651959064474795e-05\n",
            "Stage 7/10:  65%|██████████████████▉          | 196/300 [06:48<03:42,  2.14s/it]T Loss=2.3025548458099365\n",
            "g_norm = tensor(0.1248, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032455444335938\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30320143699646\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039042949676514\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044047355651855\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.48841857910156\n",
            "||∇_X meta|| = 0.001574511406943202\n",
            "ΔX norm: 1.5745126802357845e-05\n",
            "Stage 7/10:  66%|███████████████████          | 197/300 [06:50<03:34,  2.09s/it]T Loss=2.3035566806793213\n",
            "g_norm = tensor(0.1447, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035101890563965\n",
            "g_norm = tensor(0.1557, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040361404418945\n",
            "g_norm = tensor(0.1326, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303035020828247\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30299711227417\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.23291015625\n",
            "||∇_X meta|| = 0.001767908688634634\n",
            "ΔX norm: 1.767908725014422e-05\n",
            "Stage 7/10:  66%|███████████████████▏         | 198/300 [06:52<03:30,  2.07s/it]T Loss=2.303419589996338\n",
            "g_norm = tensor(0.0714, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303262233734131\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033900260925293\n",
            "g_norm = tensor(0.0688, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036482334136963\n",
            "g_norm = tensor(0.0815, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304556369781494\n",
            "g_norm = tensor(0.0811, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.34262084960938\n",
            "||∇_X meta|| = 0.0016760758589953184\n",
            "ΔX norm: 1.6760785001679324e-05\n",
            "Stage 7/10:  66%|███████████████████▏         | 199/300 [06:54<03:30,  2.08s/it]T Loss=2.3044466972351074\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046374320983887\n",
            "g_norm = tensor(0.0993, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303795337677002\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047573566436768\n",
            "g_norm = tensor(0.0862, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037593364715576\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.44935607910156\n",
            "||∇_X meta|| = 0.001631635008379817\n",
            "ΔX norm: 1.6316347682732157e-05\n",
            "Stage 7/10:  67%|███████████████████▎         | 200/300 [06:56<03:23,  2.03s/it]T Loss=2.3027408123016357\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019261360168457\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302917718887329\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042969703674316\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038196563720703\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5707550048828\n",
            "||∇_X meta|| = 0.0015924195758998394\n",
            "ΔX norm: 1.5924200852168724e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 7/10:  67%|███████████████████▍         | 201/300 [06:58<03:22,  2.04s/it]T Loss=2.3033432960510254\n",
            "g_norm = tensor(0.1514, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302551746368408\n",
            "g_norm = tensor(0.1606, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303586483001709\n",
            "g_norm = tensor(0.1431, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303109884262085\n",
            "g_norm = tensor(0.1945, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035128116607666\n",
            "g_norm = tensor(0.1564, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7149200439453\n",
            "||∇_X meta|| = 0.0017123282887041569\n",
            "ΔX norm: 1.71233023138484e-05\n",
            "Stage 7/10:  67%|███████████████████▌         | 202/300 [07:01<03:28,  2.13s/it]T Loss=2.304058790206909\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031187057495117\n",
            "g_norm = tensor(0.1297, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305248975753784\n",
            "g_norm = tensor(0.1462, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302809953689575\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034870624542236\n",
            "g_norm = tensor(0.1447, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1226806640625\n",
            "||∇_X meta|| = 0.0018804601859301329\n",
            "ΔX norm: 1.8804588762577623e-05\n",
            "Stage 7/10:  68%|███████████████████▌         | 203/300 [07:03<03:24,  2.11s/it]T Loss=2.3038158416748047\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303466320037842\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303466320037842\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303455352783203\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032548427581787\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.24090576171875\n",
            "||∇_X meta|| = 0.0015764175914227962\n",
            "ΔX norm: 1.576417162141297e-05\n",
            "Stage 7/10:  68%|███████████████████▋         | 204/300 [07:05<03:31,  2.21s/it]T Loss=2.3025989532470703\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033597469329834\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304896831512451\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053016662597656\n",
            "g_norm = tensor(0.1307, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036623001098633\n",
            "g_norm = tensor(0.1443, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.91897583007812\n",
            "||∇_X meta|| = 0.0015759102534502745\n",
            "ΔX norm: 1.5759078451083042e-05\n",
            "Stage 7/10:  68%|███████████████████▊         | 205/300 [07:07<03:30,  2.21s/it]T Loss=2.303684711456299\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305159091949463\n",
            "g_norm = tensor(0.1258, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043837547302246\n",
            "g_norm = tensor(0.1550, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306647539138794\n",
            "g_norm = tensor(0.1387, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054447174072266\n",
            "g_norm = tensor(0.1510, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.47157287597656\n",
            "||∇_X meta|| = 0.001557776820845902\n",
            "ΔX norm: 1.5577788872178644e-05\n",
            "Stage 7/10:  69%|███████████████████▉         | 206/300 [07:10<03:35,  2.29s/it]T Loss=2.302905559539795\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041789531707764\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040099143981934\n",
            "g_norm = tensor(0.1369, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039848804473877\n",
            "g_norm = tensor(0.1498, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027796745300293\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.54083251953125\n",
            "||∇_X meta|| = 0.0016153721371665597\n",
            "ΔX norm: 1.615376277186442e-05\n",
            "Stage 7/10:  69%|████████████████████         | 207/300 [07:12<03:22,  2.18s/it]T Loss=2.3036437034606934\n",
            "g_norm = tensor(0.0751, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304124355316162\n",
            "g_norm = tensor(0.0766, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033671379089355\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039889335632324\n",
            "g_norm = tensor(0.0728, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3015637397766113\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.7324981689453\n",
            "||∇_X meta|| = 0.0016517783515155315\n",
            "ΔX norm: 1.6517766198376194e-05\n",
            "Stage 7/10:  69%|████████████████████         | 208/300 [07:14<03:12,  2.10s/it]T Loss=2.3029942512512207\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048934936523438\n",
            "g_norm = tensor(0.1251, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039803504943848\n",
            "g_norm = tensor(0.1262, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30357027053833\n",
            "g_norm = tensor(0.1418, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031845092773438\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1005401611328\n",
            "||∇_X meta|| = 0.0015038030687719584\n",
            "ΔX norm: 1.5038037417980377e-05\n",
            "Stage 7/10:  70%|████████████████████▏        | 209/300 [07:15<03:04,  2.03s/it]T Loss=2.3019461631774902\n",
            "g_norm = tensor(0.1771, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025918006896973\n",
            "g_norm = tensor(0.1572, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031222820281982\n",
            "g_norm = tensor(0.1365, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025898933410645\n",
            "g_norm = tensor(0.1508, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028721809387207\n",
            "g_norm = tensor(0.1493, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.9931182861328\n",
            "||∇_X meta|| = 0.0016207793960347772\n",
            "ΔX norm: 1.6207812223001383e-05\n",
            "Stage 7/10:  70%|████████████████████▎        | 210/300 [07:18<03:08,  2.09s/it]T Loss=2.303297519683838\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027234077453613\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026230335235596\n",
            "g_norm = tensor(0.1273, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304056406021118\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039116859436035\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.41311645507812\n",
            "||∇_X meta|| = 0.0015322258695960045\n",
            "ΔX norm: 1.5322257240768522e-05\n",
            "Stage 7/10:  70%|████████████████████▍        | 211/300 [07:20<03:12,  2.16s/it]T Loss=2.3037543296813965\n",
            "g_norm = tensor(0.1318, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303534984588623\n",
            "g_norm = tensor(0.1360, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036606311798096\n",
            "g_norm = tensor(0.0983, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3063418865203857\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038251399993896\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4834747314453\n",
            "||∇_X meta|| = 0.001487461500801146\n",
            "ΔX norm: 1.4874613043502904e-05\n",
            "Stage 7/10:  71%|████████████████████▍        | 212/300 [07:22<03:03,  2.08s/it]T Loss=2.3039870262145996\n",
            "g_norm = tensor(0.0856, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036954402923584\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033194541931152\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303748607635498\n",
            "g_norm = tensor(0.0853, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30444598197937\n",
            "g_norm = tensor(0.0884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.653564453125\n",
            "||∇_X meta|| = 0.0014879795489832759\n",
            "ΔX norm: 1.4879789887345396e-05\n",
            "Stage 7/10:  71%|████████████████████▌        | 213/300 [07:24<02:56,  2.03s/it]T Loss=2.30383563041687\n",
            "g_norm = tensor(0.1022, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025448322296143\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037123680114746\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030450344085693\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303434371948242\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.9080047607422\n",
            "||∇_X meta|| = 0.0015381085686385632\n",
            "ΔX norm: 1.5381094272015616e-05\n",
            "Stage 7/10:  71%|████████████████████▋        | 214/300 [07:26<02:53,  2.01s/it]T Loss=2.3044345378875732\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026938438415527\n",
            "g_norm = tensor(0.1299, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037326335906982\n",
            "g_norm = tensor(0.1139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032164573669434\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048079013824463\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.39976501464844\n",
            "||∇_X meta|| = 0.0014300758484750986\n",
            "ΔX norm: 1.4300758266472258e-05\n",
            "Stage 7/10:  72%|████████████████████▊        | 215/300 [07:28<02:56,  2.07s/it]T Loss=2.303171396255493\n",
            "g_norm = tensor(0.1405, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049685955047607\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028993606567383\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303440809249878\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303494930267334\n",
            "g_norm = tensor(0.1257, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.13424682617188\n",
            "||∇_X meta|| = 0.0017595116514712572\n",
            "ΔX norm: 1.7595117242308334e-05\n",
            "Stage 7/10:  72%|████████████████████▉        | 216/300 [07:30<02:57,  2.12s/it]T Loss=2.3030025959014893\n",
            "g_norm = tensor(0.1397, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035402297973633\n",
            "g_norm = tensor(0.1413, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305222749710083\n",
            "g_norm = tensor(0.1295, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305849313735962\n",
            "g_norm = tensor(0.1847, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044490814208984\n",
            "g_norm = tensor(0.1628, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.771484375\n",
            "||∇_X meta|| = 0.0016176429344341159\n",
            "ΔX norm: 1.617641100892797e-05\n",
            "Stage 7/10:  72%|████████████████████▉        | 217/300 [07:33<03:01,  2.18s/it]T Loss=2.303046226501465\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302541971206665\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032639026641846\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026320934295654\n",
            "g_norm = tensor(0.0855, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027281761169434\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5785369873047\n",
            "||∇_X meta|| = 0.0016128902789205313\n",
            "ΔX norm: 1.6128906281664968e-05\n",
            "Stage 7/10:  73%|█████████████████████        | 218/300 [07:35<02:58,  2.18s/it]T Loss=2.3026719093322754\n",
            "g_norm = tensor(0.0847, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031153678894043\n",
            "g_norm = tensor(0.0749, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302812099456787\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028745651245117\n",
            "g_norm = tensor(0.0873, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302896738052368\n",
            "g_norm = tensor(0.0835, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.92356872558594\n",
            "||∇_X meta|| = 0.0015867549227550626\n",
            "ΔX norm: 1.5867546608205885e-05\n",
            "Stage 7/10:  73%|█████████████████████▏       | 219/300 [07:37<02:54,  2.16s/it]T Loss=2.3043603897094727\n",
            "g_norm = tensor(0.1447, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303222894668579\n",
            "g_norm = tensor(0.1561, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302652359008789\n",
            "g_norm = tensor(0.1369, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041725158691406\n",
            "g_norm = tensor(0.1576, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304128646850586\n",
            "g_norm = tensor(0.1615, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.76364135742188\n",
            "||∇_X meta|| = 0.001553292851895094\n",
            "ΔX norm: 1.553292531752959e-05\n",
            "Stage 7/10:  73%|█████████████████████▎       | 220/300 [07:39<02:48,  2.11s/it]T Loss=2.3048129081726074\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3061110973358154\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046278953552246\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304877996444702\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304588556289673\n",
            "g_norm = tensor(0.1103, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.34555053710938\n",
            "||∇_X meta|| = 0.0014726442750543356\n",
            "ΔX norm: 1.4726429981237743e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 7/10:  74%|█████████████████████▎       | 221/300 [07:41<02:44,  2.08s/it]T Loss=2.3032455444335938\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302163600921631\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021960258483887\n",
            "g_norm = tensor(0.0917, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017609119415283\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30357027053833\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2869415283203\n",
            "||∇_X meta|| = 0.0015147881349548697\n",
            "ΔX norm: 1.5147901649470441e-05\n",
            "Stage 7/10:  74%|█████████████████████▍       | 222/300 [07:43<02:52,  2.21s/it]T Loss=2.3030030727386475\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053410053253174\n",
            "g_norm = tensor(0.1348, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035101890563965\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036551475524902\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302206516265869\n",
            "g_norm = tensor(0.1539, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.505126953125\n",
            "||∇_X meta|| = 0.0016807186184450984\n",
            "ΔX norm: 1.680718742136378e-05\n",
            "Stage 7/10:  74%|█████████████████████▌       | 223/300 [07:45<02:46,  2.17s/it]T Loss=2.3039584159851074\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048315048217773\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303286075592041\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043370246887207\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039355278015137\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.98536682128906\n",
            "||∇_X meta|| = 0.0017483002739027143\n",
            "ΔX norm: 1.748299655446317e-05\n",
            "Stage 7/10:  75%|█████████████████████▋       | 224/300 [07:48<02:59,  2.36s/it]T Loss=2.3037426471710205\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304759979248047\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049099445343018\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304114818572998\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305398464202881\n",
            "g_norm = tensor(0.1384, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9760284423828\n",
            "||∇_X meta|| = 0.001582245109602809\n",
            "ΔX norm: 1.582243748998735e-05\n",
            "Stage 7/10:  75%|█████████████████████▊       | 225/300 [07:51<02:57,  2.36s/it]T Loss=2.3060107231140137\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306098222732544\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044583797454834\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3072845935821533\n",
            "g_norm = tensor(0.1378, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306138038635254\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.35101318359375\n",
            "||∇_X meta|| = 0.0015779591631144285\n",
            "ΔX norm: 1.5779580280650407e-05\n",
            "Stage 7/10:  75%|█████████████████████▊       | 226/300 [07:53<02:51,  2.32s/it]T Loss=2.304694414138794\n",
            "g_norm = tensor(0.0787, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051609992980957\n",
            "g_norm = tensor(0.0734, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304332733154297\n",
            "g_norm = tensor(0.0860, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304487466812134\n",
            "g_norm = tensor(0.0861, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30438232421875\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.95555114746094\n",
            "||∇_X meta|| = 0.0015070692170411348\n",
            "ΔX norm: 1.5070695553731639e-05\n",
            "Stage 7/10:  76%|█████████████████████▉       | 227/300 [07:55<02:53,  2.37s/it]T Loss=2.3037912845611572\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025712966918945\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042445182800293\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033993244171143\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032031059265137\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.96804809570312\n",
            "||∇_X meta|| = 0.0015613012947142124\n",
            "ΔX norm: 1.5613020877935924e-05\n",
            "Stage 7/10:  76%|██████████████████████       | 228/300 [07:58<02:59,  2.49s/it]T Loss=2.303506374359131\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303384304046631\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031082153320312\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30421781539917\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304018497467041\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.33297729492188\n",
            "||∇_X meta|| = 0.001730969874188304\n",
            "ΔX norm: 1.7309710528934374e-05\n",
            "Stage 7/10:  76%|██████████████████████▏      | 229/300 [08:00<02:52,  2.43s/it]T Loss=2.3041977882385254\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304915189743042\n",
            "g_norm = tensor(0.0715, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043606281280518\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304245710372925\n",
            "g_norm = tensor(0.0941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038432598114014\n",
            "g_norm = tensor(0.0774, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.90545654296875\n",
            "||∇_X meta|| = 0.001653504092246294\n",
            "ΔX norm: 1.6535039321752265e-05\n",
            "Stage 7/10:  77%|██████████████████████▏      | 230/300 [08:02<02:40,  2.29s/it]T Loss=2.3040497303009033\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041701316833496\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040175437927246\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304166078567505\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303654670715332\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5216827392578\n",
            "||∇_X meta|| = 0.0014364401577040553\n",
            "ΔX norm: 1.4364415619638748e-05\n",
            "Stage 7/10:  77%|██████████████████████▎      | 231/300 [08:04<02:31,  2.19s/it]T Loss=2.3029286861419678\n",
            "g_norm = tensor(0.0781, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303997755050659\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033089637756348\n",
            "g_norm = tensor(0.0883, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030242919921875\n",
            "g_norm = tensor(0.0838, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305110454559326\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.39584350585938\n",
            "||∇_X meta|| = 0.0015994837740436196\n",
            "ΔX norm: 1.5994824934750795e-05\n",
            "Stage 7/10:  77%|██████████████████████▍      | 232/300 [08:06<02:21,  2.08s/it]T Loss=2.3047850131988525\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054375648498535\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304304838180542\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050200939178467\n",
            "g_norm = tensor(0.1307, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042144775390625\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.37472534179688\n",
            "||∇_X meta|| = 0.001461306936107576\n",
            "ΔX norm: 1.4613070561608765e-05\n",
            "Stage 7/10:  78%|██████████████████████▌      | 233/300 [08:08<02:19,  2.08s/it]T Loss=2.304335117340088\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037943840026855\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304267406463623\n",
            "g_norm = tensor(0.0823, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304497241973877\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035788536071777\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.17857360839844\n",
            "||∇_X meta|| = 0.001467150985263288\n",
            "ΔX norm: 1.4671493772766553e-05\n",
            "Stage 7/10:  78%|██████████████████████▌      | 234/300 [08:10<02:15,  2.05s/it]T Loss=2.305387020111084\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036913871765137\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037352561950684\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037781715393066\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048927783966064\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.77337646484375\n",
            "||∇_X meta|| = 0.0016342580784112215\n",
            "ΔX norm: 1.634257387195248e-05\n",
            "Stage 7/10:  78%|██████████████████████▋      | 235/300 [08:12<02:10,  2.00s/it]T Loss=2.303819179534912\n",
            "g_norm = tensor(0.0836, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303893566131592\n",
            "g_norm = tensor(0.0738, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304047107696533\n",
            "g_norm = tensor(0.0764, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303753137588501\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303504705429077\n",
            "g_norm = tensor(0.0761, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.34017944335938\n",
            "||∇_X meta|| = 0.0015504069160670042\n",
            "ΔX norm: 1.550405977468472e-05\n",
            "Stage 7/10:  79%|██████████████████████▊      | 236/300 [08:14<02:07,  1.99s/it]T Loss=2.3058040142059326\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304311990737915\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304394245147705\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053457736968994\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048901557922363\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.11770629882812\n",
            "||∇_X meta|| = 0.0016531376168131828\n",
            "ΔX norm: 1.6531350411241874e-05\n",
            "Stage 7/10:  79%|██████████████████████▉      | 237/300 [08:16<02:04,  1.97s/it]T Loss=2.3034181594848633\n",
            "g_norm = tensor(0.1594, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021554946899414\n",
            "g_norm = tensor(0.1327, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3014562129974365\n",
            "g_norm = tensor(0.1416, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.300307512283325\n",
            "g_norm = tensor(0.1451, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022921085357666\n",
            "g_norm = tensor(0.1394, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.73965454101562\n",
            "||∇_X meta|| = 0.0014698768500238657\n",
            "ΔX norm: 1.4698770428367425e-05\n",
            "Stage 7/10:  79%|███████████████████████      | 238/300 [08:18<02:08,  2.07s/it]T Loss=2.3033688068389893\n",
            "g_norm = tensor(0.1222, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027892112731934\n",
            "g_norm = tensor(0.1306, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036084175109863\n",
            "g_norm = tensor(0.1268, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046207427978516\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030142784118652\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9133758544922\n",
            "||∇_X meta|| = 0.0013681079726666212\n",
            "ΔX norm: 1.3681069503945764e-05\n",
            "Stage 7/10:  80%|███████████████████████      | 239/300 [08:20<02:04,  2.04s/it]T Loss=2.302271604537964\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030447959899902\n",
            "g_norm = tensor(0.0829, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303131580352783\n",
            "g_norm = tensor(0.0855, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034794330596924\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031575679779053\n",
            "g_norm = tensor(0.0861, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.6021728515625\n",
            "||∇_X meta|| = 0.001551973633468151\n",
            "ΔX norm: 1.5519734006375074e-05\n",
            "Stage 7/10:  80%|███████████████████████▏     | 240/300 [08:23<02:07,  2.12s/it]T Loss=2.302947521209717\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30379319190979\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034274578094482\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034439086914062\n",
            "g_norm = tensor(0.0919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036017417907715\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.41888427734375\n",
            "||∇_X meta|| = 0.0015254344325512648\n",
            "ΔX norm: 1.5254347999871243e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 7/10:  80%|███████████████████████▎     | 241/300 [08:25<02:04,  2.11s/it]T Loss=2.3032753467559814\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30527925491333\n",
            "g_norm = tensor(0.1439, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30385684967041\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039469718933105\n",
            "g_norm = tensor(0.1544, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029298782348633\n",
            "g_norm = tensor(0.1360, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.44412231445312\n",
            "||∇_X meta|| = 0.001599083305336535\n",
            "ΔX norm: 1.5990817701094784e-05\n",
            "Stage 7/10:  81%|███████████████████████▍     | 242/300 [08:27<02:11,  2.27s/it]T Loss=2.303557872772217\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037149906158447\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303920269012451\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038930892944336\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302960157394409\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.43466186523438\n",
            "||∇_X meta|| = 0.0015156222507357597\n",
            "ΔX norm: 1.5156270819716156e-05\n",
            "Stage 7/10:  81%|███████████████████████▍     | 243/300 [08:29<02:07,  2.24s/it]T Loss=2.3022422790527344\n",
            "g_norm = tensor(0.1402, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027076721191406\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039848804473877\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040518760681152\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034868240356445\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.79624938964844\n",
            "||∇_X meta|| = 0.0016421977197751403\n",
            "ΔX norm: 1.642196912143845e-05\n",
            "Stage 7/10:  81%|███████████████████████▌     | 244/300 [08:31<02:00,  2.15s/it]T Loss=2.3048853874206543\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303499698638916\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046233654022217\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30517315864563\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034658432006836\n",
            "g_norm = tensor(0.0956, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.66578674316406\n",
            "||∇_X meta|| = 0.0017273471457883716\n",
            "ΔX norm: 1.7273447156185284e-05\n",
            "Stage 7/10:  82%|███████████████████████▋     | 245/300 [08:33<01:53,  2.06s/it]T Loss=2.304007053375244\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302664041519165\n",
            "g_norm = tensor(0.1512, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303537368774414\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038244247436523\n",
            "g_norm = tensor(0.1437, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304361343383789\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.3066864013672\n",
            "||∇_X meta|| = 0.0015450194478034973\n",
            "ΔX norm: 1.5450204955413938e-05\n",
            "Stage 7/10:  82%|███████████████████████▊     | 246/300 [08:35<01:49,  2.03s/it]T Loss=2.3040785789489746\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049728870391846\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304698944091797\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050894737243652\n",
            "g_norm = tensor(0.1316, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049099445343018\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.32374572753906\n",
            "||∇_X meta|| = 0.001591154607012868\n",
            "ΔX norm: 1.5911544323898852e-05\n",
            "Stage 7/10:  82%|███████████████████████▉     | 247/300 [08:37<01:45,  1.99s/it]T Loss=2.304030656814575\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038454055786133\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043880462646484\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037030696868896\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034558296203613\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2607421875\n",
            "||∇_X meta|| = 0.001504664309322834\n",
            "ΔX norm: 1.5046641237859149e-05\n",
            "Stage 7/10:  83%|███████████████████████▉     | 248/300 [08:39<01:42,  1.97s/it]T Loss=2.3041114807128906\n",
            "g_norm = tensor(0.1219, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044395446777344\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304074764251709\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304036855697632\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048958778381348\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0594940185547\n",
            "||∇_X meta|| = 0.0015496868873015046\n",
            "ΔX norm: 1.549687840451952e-05\n",
            "Stage 7/10:  83%|████████████████████████     | 249/300 [08:41<01:44,  2.05s/it]T Loss=2.30393385887146\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304208278656006\n",
            "g_norm = tensor(0.0818, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032937049865723\n",
            "g_norm = tensor(0.0869, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042445182800293\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30338978767395\n",
            "g_norm = tensor(0.0890, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0850830078125\n",
            "||∇_X meta|| = 0.0016994019970297813\n",
            "ΔX norm: 1.6994026736938395e-05\n",
            "Stage 7/10:  83%|████████████████████████▏    | 250/300 [08:43<01:44,  2.10s/it]T Loss=2.304231643676758\n",
            "g_norm = tensor(0.1415, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306201457977295\n",
            "g_norm = tensor(0.1566, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302366256713867\n",
            "g_norm = tensor(0.1304, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303650379180908\n",
            "g_norm = tensor(0.1488, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303164005279541\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2886199951172\n",
            "||∇_X meta|| = 0.0015085515333339572\n",
            "ΔX norm: 1.5085481209098361e-05\n",
            "Stage 7/10:  84%|████████████████████████▎    | 251/300 [08:46<01:43,  2.11s/it]T Loss=2.3044705390930176\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023674488067627\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048408031463623\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034138679504395\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043160438537598\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.04910278320312\n",
            "||∇_X meta|| = 0.0016676601953804493\n",
            "ΔX norm: 1.6676638551871292e-05\n",
            "Stage 7/10:  84%|████████████████████████▎    | 252/300 [08:48<01:41,  2.11s/it]T Loss=2.30527925491333\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042380809783936\n",
            "g_norm = tensor(0.1355, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039298057556152\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057286739349365\n",
            "g_norm = tensor(0.1299, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305893898010254\n",
            "g_norm = tensor(0.1337, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.47607421875\n",
            "||∇_X meta|| = 0.0017493857303634286\n",
            "ΔX norm: 1.7493875930085778e-05\n",
            "Stage 7/10:  84%|████████████████████████▍    | 253/300 [08:50<01:36,  2.06s/it]T Loss=2.303375005722046\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032894134521484\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032069206237793\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302767276763916\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041043281555176\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9038543701172\n",
            "||∇_X meta|| = 0.0015690423315390944\n",
            "ΔX norm: 1.5690409782109782e-05\n",
            "Stage 7/10:  85%|████████████████████████▌    | 254/300 [08:52<01:32,  2.00s/it]T Loss=2.304047107696533\n",
            "g_norm = tensor(0.1466, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041625022888184\n",
            "g_norm = tensor(0.1367, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049726486206055\n",
            "g_norm = tensor(0.1481, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026299476623535\n",
            "g_norm = tensor(0.1392, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049569129943848\n",
            "g_norm = tensor(0.1470, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.73117065429688\n",
            "||∇_X meta|| = 0.0016429803799837828\n",
            "ΔX norm: 1.6429774404969066e-05\n",
            "Stage 7/10:  85%|████████████████████████▋    | 255/300 [08:54<01:33,  2.08s/it]T Loss=2.304337501525879\n",
            "g_norm = tensor(0.1184, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038387298583984\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034753799438477\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304584503173828\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039193153381348\n",
            "g_norm = tensor(0.1327, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.27162170410156\n",
            "||∇_X meta|| = 0.0016253967769443989\n",
            "ΔX norm: 1.6253952708211727e-05\n",
            "Stage 7/10:  85%|████████████████████████▋    | 256/300 [08:56<01:30,  2.05s/it]T Loss=2.3022990226745605\n",
            "g_norm = tensor(0.1516, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023171424865723\n",
            "g_norm = tensor(0.1791, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304361343383789\n",
            "g_norm = tensor(0.1776, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045711517333984\n",
            "g_norm = tensor(0.1475, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30255126953125\n",
            "g_norm = tensor(0.1536, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.8760528564453\n",
            "||∇_X meta|| = 0.0014531179331243038\n",
            "ΔX norm: 1.4531176020682324e-05\n",
            "Stage 7/10:  86%|████████████████████████▊    | 257/300 [08:58<01:29,  2.08s/it]T Loss=2.3036770820617676\n",
            "g_norm = tensor(0.1396, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037824630737305\n",
            "g_norm = tensor(0.1362, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035292625427246\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304016351699829\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033084869384766\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.58145141601562\n",
            "||∇_X meta|| = 0.0015137133887037635\n",
            "ΔX norm: 1.5137126865738537e-05\n",
            "Stage 7/10:  86%|████████████████████████▉    | 258/300 [09:00<01:28,  2.11s/it]T Loss=2.3061928749084473\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050479888916016\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043198585510254\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036484718322754\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049733638763428\n",
            "g_norm = tensor(0.1351, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.99884033203125\n",
            "||∇_X meta|| = 0.001574837719090283\n",
            "ΔX norm: 1.5748413716210052e-05\n",
            "Stage 7/10:  86%|█████████████████████████    | 259/300 [09:03<01:36,  2.36s/it]T Loss=2.3022642135620117\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037335872650146\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032476902008057\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303162097930908\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303260087966919\n",
            "g_norm = tensor(0.0838, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4423828125\n",
            "||∇_X meta|| = 0.001443317742086947\n",
            "ΔX norm: 1.4433194337470923e-05\n",
            "Stage 7/10:  87%|█████████████████████████▏   | 260/300 [09:05<01:32,  2.31s/it]T Loss=2.303985118865967\n",
            "g_norm = tensor(0.1305, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303527355194092\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029987812042236\n",
            "g_norm = tensor(0.1303, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302351474761963\n",
            "g_norm = tensor(0.1411, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303183078765869\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.44529724121094\n",
            "||∇_X meta|| = 0.0016127090202644467\n",
            "ΔX norm: 1.6127110939123668e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 7/10:  87%|█████████████████████████▏   | 261/300 [09:07<01:27,  2.25s/it]T Loss=2.302222490310669\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303647518157959\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302489757537842\n",
            "g_norm = tensor(0.1276, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303623676300049\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3015918731689453\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.62713623046875\n",
            "||∇_X meta|| = 0.0014944721478968859\n",
            "ΔX norm: 1.4944689610274509e-05\n",
            "Stage 7/10:  87%|█████████████████████████▎   | 262/300 [09:10<01:28,  2.33s/it]T Loss=2.303239345550537\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303654909133911\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303687572479248\n",
            "g_norm = tensor(0.1183, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302795886993408\n",
            "g_norm = tensor(0.1157, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304323673248291\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2253875732422\n",
            "||∇_X meta|| = 0.0015791186597198248\n",
            "ΔX norm: 1.5791212717886083e-05\n",
            "Stage 7/10:  88%|█████████████████████████▍   | 263/300 [09:12<01:22,  2.22s/it]T Loss=2.30424165725708\n",
            "g_norm = tensor(0.0860, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304750442504883\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304466724395752\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048577308654785\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046514987945557\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.92910766601562\n",
            "||∇_X meta|| = 0.0015535189304500818\n",
            "ΔX norm: 1.5535191778326407e-05\n",
            "Stage 7/10:  88%|█████████████████████████▌   | 264/300 [09:14<01:16,  2.13s/it]T Loss=2.3049464225769043\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305100440979004\n",
            "g_norm = tensor(0.1565, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304656505584717\n",
            "g_norm = tensor(0.1235, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304396152496338\n",
            "g_norm = tensor(0.1435, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039402961730957\n",
            "g_norm = tensor(0.1359, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.71363830566406\n",
            "||∇_X meta|| = 0.0015330209862440825\n",
            "ΔX norm: 1.5330224414356053e-05\n",
            "Stage 7/10:  88%|█████████████████████████▌   | 265/300 [09:16<01:11,  2.05s/it]T Loss=2.3030543327331543\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303799867630005\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021106719970703\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030362129211426\n",
            "g_norm = tensor(0.1053, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038997650146484\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.347412109375\n",
            "||∇_X meta|| = 0.0015867744805291295\n",
            "ΔX norm: 1.586777034390252e-05\n",
            "Stage 7/10:  89%|█████████████████████████▋   | 266/300 [09:18<01:10,  2.08s/it]T Loss=2.3049256801605225\n",
            "g_norm = tensor(0.1403, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303750514984131\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028693199157715\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3065719604492188\n",
            "g_norm = tensor(0.1371, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050475120544434\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.41493225097656\n",
            "||∇_X meta|| = 0.0015447279438376427\n",
            "ΔX norm: 1.544732913316693e-05\n",
            "Stage 7/10:  89%|█████████████████████████▊   | 267/300 [09:20<01:08,  2.08s/it]T Loss=2.3039469718933105\n",
            "g_norm = tensor(0.0789, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303962469100952\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039233684539795\n",
            "g_norm = tensor(0.0789, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303417921066284\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304474115371704\n",
            "g_norm = tensor(0.0775, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.6673583984375\n",
            "||∇_X meta|| = 0.0014571042265743017\n",
            "ΔX norm: 1.457103826396633e-05\n",
            "Stage 7/10:  89%|█████████████████████████▉   | 268/300 [09:22<01:04,  2.02s/it]T Loss=2.3048129081726074\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303300142288208\n",
            "g_norm = tensor(0.0947, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303649425506592\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051915168762207\n",
            "g_norm = tensor(0.0767, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30419921875\n",
            "g_norm = tensor(0.0835, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.82296752929688\n",
            "||∇_X meta|| = 0.0016549364663660526\n",
            "ΔX norm: 1.6549342035432346e-05\n",
            "Stage 7/10:  90%|██████████████████████████   | 269/300 [09:24<01:04,  2.07s/it]T Loss=2.303783893585205\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030967712402344\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303600788116455\n",
            "g_norm = tensor(0.0790, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303854465484619\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303607225418091\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.26222229003906\n",
            "||∇_X meta|| = 0.0016626125434413552\n",
            "ΔX norm: 1.6626132492092438e-05\n",
            "Stage 7/10:  90%|██████████████████████████   | 270/300 [09:26<01:00,  2.01s/it]T Loss=2.3028697967529297\n",
            "g_norm = tensor(0.1699, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034112453460693\n",
            "g_norm = tensor(0.1530, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302522659301758\n",
            "g_norm = tensor(0.1368, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303532361984253\n",
            "g_norm = tensor(0.1999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020825386047363\n",
            "g_norm = tensor(0.1624, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.71621704101562\n",
            "||∇_X meta|| = 0.0015173284336924553\n",
            "ΔX norm: 1.5173327483353205e-05\n",
            "Stage 7/10:  90%|██████████████████████████▏  | 271/300 [09:28<00:58,  2.03s/it]T Loss=2.3033554553985596\n",
            "g_norm = tensor(0.0762, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303485155105591\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029043674468994\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030009269714355\n",
            "g_norm = tensor(0.0829, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028342723846436\n",
            "g_norm = tensor(0.0814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.26461791992188\n",
            "||∇_X meta|| = 0.001497724442742765\n",
            "ΔX norm: 1.4977259525039699e-05\n",
            "Stage 7/10:  91%|██████████████████████████▎  | 272/300 [09:30<01:01,  2.19s/it]T Loss=2.3027234077453613\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035616874694824\n",
            "g_norm = tensor(0.1382, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027069568634033\n",
            "g_norm = tensor(0.1427, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302314519882202\n",
            "g_norm = tensor(0.1463, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303457260131836\n",
            "g_norm = tensor(0.1214, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.71633911132812\n",
            "||∇_X meta|| = 0.0015320978127419949\n",
            "ΔX norm: 1.532098394818604e-05\n",
            "Stage 7/10:  91%|██████████████████████████▍  | 273/300 [09:33<01:00,  2.23s/it]T Loss=2.3040759563446045\n",
            "g_norm = tensor(0.0701, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041012287139893\n",
            "g_norm = tensor(0.0766, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041648864746094\n",
            "g_norm = tensor(0.0795, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045756816864014\n",
            "g_norm = tensor(0.0782, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037827014923096\n",
            "g_norm = tensor(0.0761, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.36412048339844\n",
            "||∇_X meta|| = 0.0015686680562794209\n",
            "ΔX norm: 1.568667903484311e-05\n",
            "Stage 7/10:  91%|██████████████████████████▍  | 274/300 [09:35<01:01,  2.37s/it]T Loss=2.302302360534668\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301905632019043\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019418716430664\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302626132965088\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029544353485107\n",
            "g_norm = tensor(0.1495, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.59518432617188\n",
            "||∇_X meta|| = 0.0015256005572155118\n",
            "ΔX norm: 1.5256026927090716e-05\n",
            "Stage 7/10:  92%|██████████████████████████▌  | 275/300 [09:38<00:57,  2.30s/it]T Loss=2.305060863494873\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305908203125\n",
            "g_norm = tensor(0.1255, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303879499435425\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043529987335205\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306852102279663\n",
            "g_norm = tensor(0.1268, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.89739990234375\n",
            "||∇_X meta|| = 0.0016184021951630712\n",
            "ΔX norm: 1.618402347958181e-05\n",
            "Stage 7/10:  92%|██████████████████████████▋  | 276/300 [09:40<00:52,  2.19s/it]T Loss=2.3053982257843018\n",
            "g_norm = tensor(0.1519, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042824268341064\n",
            "g_norm = tensor(0.1259, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033812046051025\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031973838806152\n",
            "g_norm = tensor(0.1382, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305408239364624\n",
            "g_norm = tensor(0.1356, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.108154296875\n",
            "||∇_X meta|| = 0.0014901761896908283\n",
            "ΔX norm: 1.490175327489851e-05\n",
            "Stage 7/10:  92%|██████████████████████████▊  | 277/300 [09:42<00:49,  2.15s/it]T Loss=2.302706241607666\n",
            "g_norm = tensor(0.0867, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302933931350708\n",
            "g_norm = tensor(0.0758, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032166957855225\n",
            "g_norm = tensor(0.0811, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029417991638184\n",
            "g_norm = tensor(0.0797, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025588989257812\n",
            "g_norm = tensor(0.0719, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8083953857422\n",
            "||∇_X meta|| = 0.001461458159610629\n",
            "ΔX norm: 1.4614579413319007e-05\n",
            "Stage 7/10:  93%|██████████████████████████▊  | 278/300 [09:44<00:47,  2.16s/it]T Loss=2.3023648262023926\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042807579040527\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031299114227295\n",
            "g_norm = tensor(0.1496, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303771495819092\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036701679229736\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.71429443359375\n",
            "||∇_X meta|| = 0.0015259843785315752\n",
            "ΔX norm: 1.5259862266248092e-05\n",
            "Stage 7/10:  93%|██████████████████████████▉  | 279/300 [09:46<00:44,  2.12s/it]T Loss=2.3046913146972656\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303701877593994\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304100275039673\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304979085922241\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305083990097046\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1612091064453\n",
            "||∇_X meta|| = 0.0014610637445002794\n",
            "ΔX norm: 1.461064675822854e-05\n",
            "Stage 7/10:  93%|███████████████████████████  | 280/300 [09:48<00:41,  2.07s/it]T Loss=2.3036556243896484\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052725791931152\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30440092086792\n",
            "g_norm = tensor(0.0832, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302685260772705\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304076671600342\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5538787841797\n",
            "||∇_X meta|| = 0.001569952699355781\n",
            "ΔX norm: 1.569950836710632e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 7/10:  94%|███████████████████████████▏ | 281/300 [09:50<00:39,  2.06s/it]T Loss=2.3042521476745605\n",
            "g_norm = tensor(0.1530, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036842346191406\n",
            "g_norm = tensor(0.1599, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046088218688965\n",
            "g_norm = tensor(0.1580, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302201271057129\n",
            "g_norm = tensor(0.1608, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303370475769043\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.56069946289062\n",
            "||∇_X meta|| = 0.0016669302713125944\n",
            "ΔX norm: 1.666932257649023e-05\n",
            "Stage 7/10:  94%|███████████████████████████▎ | 282/300 [09:53<00:42,  2.35s/it]T Loss=2.302645206451416\n",
            "g_norm = tensor(0.0917, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302889347076416\n",
            "g_norm = tensor(0.0796, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30391263961792\n",
            "g_norm = tensor(0.0846, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031575679779053\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304335117340088\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.5707550048828\n",
            "||∇_X meta|| = 0.0015540153253823519\n",
            "ΔX norm: 1.5540146705461666e-05\n",
            "Stage 7/10:  94%|███████████████████████████▎ | 283/300 [09:55<00:38,  2.26s/it]T Loss=2.303290843963623\n",
            "g_norm = tensor(0.1618, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303863525390625\n",
            "g_norm = tensor(0.1631, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021347522735596\n",
            "g_norm = tensor(0.1565, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303410053253174\n",
            "g_norm = tensor(0.1546, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030686378479004\n",
            "g_norm = tensor(0.1850, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3917694091797\n",
            "||∇_X meta|| = 0.0017046643188223243\n",
            "ΔX norm: 1.704667192825582e-05\n",
            "Stage 7/10:  95%|███████████████████████████▍ | 284/300 [09:57<00:34,  2.18s/it]T Loss=2.303436756134033\n",
            "g_norm = tensor(0.0836, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302974224090576\n",
            "g_norm = tensor(0.0922, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303694248199463\n",
            "g_norm = tensor(0.0784, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038923740386963\n",
            "g_norm = tensor(0.0828, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030622005462646\n",
            "g_norm = tensor(0.0897, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.84593200683594\n",
            "||∇_X meta|| = 0.0015295767225325108\n",
            "ΔX norm: 1.5295814591809176e-05\n",
            "Stage 7/10:  95%|███████████████████████████▌ | 285/300 [09:59<00:31,  2.08s/it]T Loss=2.304421901702881\n",
            "g_norm = tensor(0.1364, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302150249481201\n",
            "g_norm = tensor(0.1318, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047094345092773\n",
            "g_norm = tensor(0.1326, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303450107574463\n",
            "g_norm = tensor(0.1457, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301318407058716\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.79261779785156\n",
            "||∇_X meta|| = 0.0015737834619358182\n",
            "ΔX norm: 1.5737825378892012e-05\n",
            "Stage 7/10:  95%|███████████████████████████▋ | 286/300 [10:01<00:28,  2.04s/it]T Loss=2.3031840324401855\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302478313446045\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028063774108887\n",
            "g_norm = tensor(0.0868, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024308681488037\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303203821182251\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.16404724121094\n",
            "||∇_X meta|| = 0.0014247307553887367\n",
            "ΔX norm: 1.4247276340029202e-05\n",
            "Stage 7/10:  96%|███████████████████████████▋ | 287/300 [10:03<00:26,  2.02s/it]T Loss=2.305379867553711\n",
            "g_norm = tensor(0.1421, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304263114929199\n",
            "g_norm = tensor(0.1514, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036506175994873\n",
            "g_norm = tensor(0.1251, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048512935638428\n",
            "g_norm = tensor(0.1357, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303969383239746\n",
            "g_norm = tensor(0.1396, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.31622314453125\n",
            "||∇_X meta|| = 0.0016168579459190369\n",
            "ΔX norm: 1.6168589354492724e-05\n",
            "Stage 7/10:  96%|███████████████████████████▊ | 288/300 [10:05<00:24,  2.03s/it]T Loss=2.3035359382629395\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052542209625244\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039658069610596\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304260730743408\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035149574279785\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.67898559570312\n",
            "||∇_X meta|| = 0.00157149787992239\n",
            "ΔX norm: 1.571497523400467e-05\n",
            "Stage 7/10:  96%|███████████████████████████▉ | 289/300 [10:07<00:21,  1.99s/it]T Loss=2.3043370246887207\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039944171905518\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041436672210693\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035194873809814\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304389476776123\n",
            "g_norm = tensor(0.0845, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.96192932128906\n",
            "||∇_X meta|| = 0.0015101645840331912\n",
            "ΔX norm: 1.5101643839443568e-05\n",
            "Stage 7/10:  97%|████████████████████████████ | 290/300 [10:09<00:19,  1.99s/it]T Loss=2.3042709827423096\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303886890411377\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303065299987793\n",
            "g_norm = tensor(0.0836, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038597106933594\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031363487243652\n",
            "g_norm = tensor(0.1022, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =227.6788787841797\n",
            "||∇_X meta|| = 0.0015980030875653028\n",
            "ΔX norm: 1.598003836988937e-05\n",
            "Stage 7/10:  97%|████████████████████████████▏| 291/300 [10:10<00:17,  1.95s/it]T Loss=2.3037025928497314\n",
            "g_norm = tensor(0.0621, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032760620117188\n",
            "g_norm = tensor(0.0804, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032925128936768\n",
            "g_norm = tensor(0.0707, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032138347625732\n",
            "g_norm = tensor(0.0707, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034579753875732\n",
            "g_norm = tensor(0.0696, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.11526489257812\n",
            "||∇_X meta|| = 0.0016627437435090542\n",
            "ΔX norm: 1.6627434888505377e-05\n",
            "Stage 7/10:  97%|████████████████████████████▏| 292/300 [10:12<00:15,  1.94s/it]T Loss=2.3041584491729736\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303854465484619\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036911487579346\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30369234085083\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036274909973145\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8657989501953\n",
            "||∇_X meta|| = 0.0014277845621109009\n",
            "ΔX norm: 1.4277829905040562e-05\n",
            "Stage 7/10:  98%|████████████████████████████▎| 293/300 [10:14<00:13,  1.91s/it]T Loss=2.3042824268341064\n",
            "g_norm = tensor(0.1534, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028664588928223\n",
            "g_norm = tensor(0.1596, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3012332916259766\n",
            "g_norm = tensor(0.1642, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036062717437744\n",
            "g_norm = tensor(0.1869, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30436372756958\n",
            "g_norm = tensor(0.1495, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.71376037597656\n",
            "||∇_X meta|| = 0.001425538444891572\n",
            "ΔX norm: 1.4255371752369683e-05\n",
            "Stage 7/10:  98%|████████████████████████████▍| 294/300 [10:16<00:11,  1.89s/it]T Loss=2.303327798843384\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038864135742188\n",
            "g_norm = tensor(0.1366, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30325984954834\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045268058776855\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303516387939453\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2861785888672\n",
            "||∇_X meta|| = 0.001681300811469555\n",
            "ΔX norm: 1.6813030015327968e-05\n",
            "Stage 7/10:  98%|████████████████████████████▌| 295/300 [10:18<00:09,  2.00s/it]T Loss=2.3043437004089355\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041741847991943\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041367530822754\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303842067718506\n",
            "g_norm = tensor(0.0813, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303847312927246\n",
            "g_norm = tensor(0.0750, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.93536376953125\n",
            "||∇_X meta|| = 0.0014301431365311146\n",
            "ΔX norm: 1.4301430383056868e-05\n",
            "Stage 7/10:  99%|████████████████████████████▌| 296/300 [10:20<00:07,  1.98s/it]T Loss=2.303687334060669\n",
            "g_norm = tensor(0.1601, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040096759796143\n",
            "g_norm = tensor(0.1653, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305434226989746\n",
            "g_norm = tensor(0.1823, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305075168609619\n",
            "g_norm = tensor(0.1480, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030622005462646\n",
            "g_norm = tensor(0.1897, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4023895263672\n",
            "||∇_X meta|| = 0.0014988759066909552\n",
            "ΔX norm: 1.4988773727964144e-05\n",
            "Stage 7/10:  99%|████████████████████████████▋| 297/300 [10:22<00:06,  2.03s/it]T Loss=2.3043053150177\n",
            "g_norm = tensor(0.1388, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304387331008911\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304002285003662\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036417961120605\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047215938568115\n",
            "g_norm = tensor(0.1289, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.26083374023438\n",
            "||∇_X meta|| = 0.0016250493936240673\n",
            "ΔX norm: 1.625053300813306e-05\n",
            "Stage 7/10:  99%|████████████████████████████▊| 298/300 [10:25<00:04,  2.07s/it]T Loss=2.3026740550994873\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028464317321777\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048954010009766\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033854961395264\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3061258792877197\n",
            "g_norm = tensor(0.1214, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.27647399902344\n",
            "||∇_X meta|| = 0.00156795559450984\n",
            "ΔX norm: 1.5679583157179877e-05\n",
            "Stage 7/10: 100%|████████████████████████████▉| 299/300 [10:26<00:02,  2.03s/it]T Loss=2.3024985790252686\n",
            "g_norm = tensor(0.1324, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3069088459014893\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037028312683105\n",
            "g_norm = tensor(0.1522, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045451641082764\n",
            "g_norm = tensor(0.2010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305924892425537\n",
            "g_norm = tensor(0.1419, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.7079315185547\n",
            "||∇_X meta|| = 0.0015526650240644813\n",
            "ΔX norm: 1.5526647985097952e-05\n",
            "Stage 6, class 0, loss 2.204                                                    \n",
            "Stage 6, class 1, loss 2.269\n",
            "Stage 6, class 2, loss 2.340\n",
            "Stage 6, class 3, loss 2.359\n",
            "Stage 6, class 4, loss 2.306\n",
            "Stage 6, class 5, loss 2.328\n",
            "Stage 6, class 6, loss 2.383\n",
            "Stage 6, class 7, loss 2.227\n",
            "Stage 6, class 8, loss 2.369\n",
            "Stage 6, class 9, loss 2.256\n",
            "Stage 8/10:   0%|                                       | 0/300 [00:00<?, ?it/s]T Loss=2.304922580718994\n",
            "g_norm = tensor(0.1486, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3006653785705566\n",
            "g_norm = tensor(0.1995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304044723510742\n",
            "g_norm = tensor(0.1731, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053078651428223\n",
            "g_norm = tensor(0.1919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3066506385803223\n",
            "g_norm = tensor(0.1916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0377197265625\n",
            "||∇_X meta|| = 0.0037146301474422216\n",
            "ΔX norm: 3.714631748152897e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 8/10:   0%|                               | 1/300 [00:02<14:37,  2.93s/it]T Loss=2.3038744926452637\n",
            "g_norm = tensor(0.0736, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303990125656128\n",
            "g_norm = tensor(0.0707, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303602457046509\n",
            "g_norm = tensor(0.0708, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036742210388184\n",
            "g_norm = tensor(0.0720, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036694526672363\n",
            "g_norm = tensor(0.0802, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.292724609375\n",
            "||∇_X meta|| = 0.0036410195752978325\n",
            "ΔX norm: 3.6410179745871574e-05\n",
            "Stage 8/10:   1%|▏                              | 2/300 [00:06<15:01,  3.03s/it]T Loss=2.3053669929504395\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305004119873047\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3059945106506348\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30507493019104\n",
            "g_norm = tensor(0.1053, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30556058883667\n",
            "g_norm = tensor(0.1283, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.71731567382812\n",
            "||∇_X meta|| = 0.003993622027337551\n",
            "ΔX norm: 3.9936228859005496e-05\n",
            "Stage 8/10:   1%|▎                              | 3/300 [00:08<12:58,  2.62s/it]T Loss=2.3046715259552\n",
            "g_norm = tensor(0.0578, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303534746170044\n",
            "g_norm = tensor(0.0620, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046233654022217\n",
            "g_norm = tensor(0.0679, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042922019958496\n",
            "g_norm = tensor(0.0608, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039278984069824\n",
            "g_norm = tensor(0.0851, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.51585388183594\n",
            "||∇_X meta|| = 0.0034210369922220707\n",
            "ΔX norm: 3.421036308282055e-05\n",
            "Stage 8/10:   1%|▍                              | 4/300 [00:10<11:31,  2.33s/it]T Loss=2.3029301166534424\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304621934890747\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303318500518799\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302645206451416\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031535148620605\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.27166748046875\n",
            "||∇_X meta|| = 0.004696123767644167\n",
            "ΔX norm: 4.6961271436885e-05\n",
            "Stage 8/10:   2%|▌                              | 5/300 [00:11<10:42,  2.18s/it]T Loss=2.303499698638916\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037350177764893\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036935329437256\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042702674865723\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304450511932373\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.79820251464844\n",
            "||∇_X meta|| = 0.003617394482716918\n",
            "ΔX norm: 3.617394031607546e-05\n",
            "Stage 8/10:   2%|▌                              | 6/300 [00:13<10:22,  2.12s/it]T Loss=2.3032314777374268\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034331798553467\n",
            "g_norm = tensor(0.1588, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304048538208008\n",
            "g_norm = tensor(0.1235, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044424057006836\n",
            "g_norm = tensor(0.1814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30485200881958\n",
            "g_norm = tensor(0.1344, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9303741455078\n",
            "||∇_X meta|| = 0.003530648536980152\n",
            "ΔX norm: 3.5306456993566826e-05\n",
            "Stage 8/10:   2%|▋                              | 7/300 [00:16<10:27,  2.14s/it]T Loss=2.302175998687744\n",
            "g_norm = tensor(0.1257, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032047748565674\n",
            "g_norm = tensor(0.1230, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039374351501465\n",
            "g_norm = tensor(0.1413, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033204078674316\n",
            "g_norm = tensor(0.1466, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038926124572754\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.23553466796875\n",
            "||∇_X meta|| = 0.0038965558633208275\n",
            "ΔX norm: 3.896553607773967e-05\n",
            "Stage 8/10:   3%|▊                              | 8/300 [00:18<10:23,  2.14s/it]T Loss=2.3033995628356934\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049087524414062\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304149627685547\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035597801208496\n",
            "g_norm = tensor(0.0865, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043174743652344\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.97691345214844\n",
            "||∇_X meta|| = 0.0034130567219108343\n",
            "ΔX norm: 3.413059312151745e-05\n",
            "Stage 8/10:   3%|▉                              | 9/300 [00:20<10:05,  2.08s/it]T Loss=2.3045127391815186\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303760290145874\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303955554962158\n",
            "g_norm = tensor(0.0872, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30348801612854\n",
            "g_norm = tensor(0.0902, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303511381149292\n",
            "g_norm = tensor(0.0750, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.71820068359375\n",
            "||∇_X meta|| = 0.003597160568460822\n",
            "ΔX norm: 3.597160684876144e-05\n",
            "Stage 8/10:   3%|█                             | 10/300 [00:22<10:02,  2.08s/it]T Loss=2.3039486408233643\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029849529266357\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303107976913452\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031225204467773\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039422035217285\n",
            "g_norm = tensor(0.1221, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.0168914794922\n",
            "||∇_X meta|| = 0.003659200621768832\n",
            "ΔX norm: 3.659195135696791e-05\n",
            "Stage 8/10:   4%|█                             | 11/300 [00:24<09:47,  2.03s/it]T Loss=2.3042309284210205\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304140567779541\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303642749786377\n",
            "g_norm = tensor(0.0919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049728870391846\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023874759674072\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.48275756835938\n",
            "||∇_X meta|| = 0.0036292830482125282\n",
            "ΔX norm: 3.6292854929342866e-05\n",
            "Stage 8/10:   4%|█▏                            | 12/300 [00:26<10:13,  2.13s/it]T Loss=2.3039374351501465\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031463623046875\n",
            "g_norm = tensor(0.1385, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303410291671753\n",
            "g_norm = tensor(0.1250, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303246021270752\n",
            "g_norm = tensor(0.1481, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026764392852783\n",
            "g_norm = tensor(0.1342, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.51036071777344\n",
            "||∇_X meta|| = 0.003922972362488508\n",
            "ΔX norm: 3.9229733374668285e-05\n",
            "Stage 8/10:   4%|█▎                            | 13/300 [00:28<09:50,  2.06s/it]T Loss=2.3049237728118896\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049187660217285\n",
            "g_norm = tensor(0.1312, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039753437042236\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305978298187256\n",
            "g_norm = tensor(0.1622, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30446195602417\n",
            "g_norm = tensor(0.1431, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.47027587890625\n",
            "||∇_X meta|| = 0.003421130357310176\n",
            "ΔX norm: 3.421127621550113e-05\n",
            "Stage 8/10:   5%|█▍                            | 14/300 [00:30<09:38,  2.02s/it]T Loss=2.303147077560425\n",
            "g_norm = tensor(0.1304, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304220676422119\n",
            "g_norm = tensor(0.1401, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032679557800293\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037614822387695\n",
            "g_norm = tensor(0.1464, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303640127182007\n",
            "g_norm = tensor(0.1372, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.72335815429688\n",
            "||∇_X meta|| = 0.0032761681359261274\n",
            "ΔX norm: 3.2761650800239295e-05\n",
            "Stage 8/10:   5%|█▌                            | 15/300 [00:32<09:33,  2.01s/it]T Loss=2.3045432567596436\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051953315734863\n",
            "g_norm = tensor(0.1465, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043668270111084\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031551837921143\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030662536621094\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.46917724609375\n",
            "||∇_X meta|| = 0.003550394903868437\n",
            "ΔX norm: 3.5503977414919063e-05\n",
            "Stage 8/10:   5%|█▌                            | 16/300 [00:34<09:27,  2.00s/it]T Loss=2.3059773445129395\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304625988006592\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305478572845459\n",
            "g_norm = tensor(0.1366, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301942825317383\n",
            "g_norm = tensor(0.1419, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041834831237793\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5469970703125\n",
            "||∇_X meta|| = 0.0040160054340958595\n",
            "ΔX norm: 4.0160066419048235e-05\n",
            "Stage 8/10:   6%|█▋                            | 17/300 [00:36<09:31,  2.02s/it]T Loss=2.302819013595581\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034088611602783\n",
            "g_norm = tensor(0.1429, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304089307785034\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031883239746094\n",
            "g_norm = tensor(0.1524, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303840160369873\n",
            "g_norm = tensor(0.1361, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.44692993164062\n",
            "||∇_X meta|| = 0.0030852353665977716\n",
            "ΔX norm: 3.085234493482858e-05\n",
            "Stage 8/10:   6%|█▊                            | 18/300 [00:38<09:28,  2.02s/it]T Loss=2.3020706176757812\n",
            "g_norm = tensor(0.1373, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044638633728027\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047592639923096\n",
            "g_norm = tensor(0.1367, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303701162338257\n",
            "g_norm = tensor(0.1460, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041110038757324\n",
            "g_norm = tensor(0.1406, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.48167419433594\n",
            "||∇_X meta|| = 0.0036032807547599077\n",
            "ΔX norm: 3.603280856623314e-05\n",
            "Stage 8/10:   6%|█▉                            | 19/300 [00:40<09:32,  2.04s/it]T Loss=2.305534839630127\n",
            "g_norm = tensor(0.0848, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046376705169678\n",
            "g_norm = tensor(0.0696, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305048942565918\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304138660430908\n",
            "g_norm = tensor(0.0756, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042831420898438\n",
            "g_norm = tensor(0.0809, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.14739990234375\n",
            "||∇_X meta|| = 0.0035324902273714542\n",
            "ΔX norm: 3.532487971824594e-05\n",
            "Stage 8/10:   7%|██                            | 20/300 [00:42<09:36,  2.06s/it]T Loss=2.302016019821167\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302859306335449\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302694797515869\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020713329315186\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025355339050293\n",
            "g_norm = tensor(0.0993, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.11441040039062\n",
            "||∇_X meta|| = 0.0029761837795376778\n",
            "ΔX norm: 2.976186078740284e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 8/10:   7%|██                            | 21/300 [00:44<09:29,  2.04s/it]T Loss=2.3050148487091064\n",
            "g_norm = tensor(0.1401, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034708499908447\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301565170288086\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032491207122803\n",
            "g_norm = tensor(0.1210, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303999423980713\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4624481201172\n",
            "||∇_X meta|| = 0.0030856425873935223\n",
            "ΔX norm: 3.085645585088059e-05\n",
            "Stage 8/10:   7%|██▏                           | 22/300 [00:47<10:19,  2.23s/it]T Loss=2.303417921066284\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033013343811035\n",
            "g_norm = tensor(0.0821, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036561012268066\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043174743652344\n",
            "g_norm = tensor(0.0890, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034799098968506\n",
            "g_norm = tensor(0.0770, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8111114501953\n",
            "||∇_X meta|| = 0.003008877858519554\n",
            "ΔX norm: 3.0088787752902135e-05\n",
            "Stage 8/10:   8%|██▎                           | 23/300 [00:49<10:02,  2.17s/it]T Loss=2.3041486740112305\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303269863128662\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034839630126953\n",
            "g_norm = tensor(0.1407, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039562702178955\n",
            "g_norm = tensor(0.1349, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303605318069458\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.77171325683594\n",
            "||∇_X meta|| = 0.0034889383241534233\n",
            "ΔX norm: 3.488936272333376e-05\n",
            "Stage 8/10:   8%|██▍                           | 24/300 [00:51<09:58,  2.17s/it]T Loss=2.3028409481048584\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302340030670166\n",
            "g_norm = tensor(0.1367, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3011741638183594\n",
            "g_norm = tensor(0.1309, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026621341705322\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021819591522217\n",
            "g_norm = tensor(0.1403, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.37489318847656\n",
            "||∇_X meta|| = 0.0031256237998604774\n",
            "ΔX norm: 3.1256229704013094e-05\n",
            "Stage 8/10:   8%|██▌                           | 25/300 [00:53<09:44,  2.13s/it]T Loss=2.3035666942596436\n",
            "g_norm = tensor(0.1263, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30326509475708\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021724224090576\n",
            "g_norm = tensor(0.1336, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303131341934204\n",
            "g_norm = tensor(0.1297, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042078018188477\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.43722534179688\n",
            "||∇_X meta|| = 0.0030551881063729525\n",
            "ΔX norm: 3.055188790312968e-05\n",
            "Stage 8/10:   9%|██▌                           | 26/300 [00:55<09:25,  2.07s/it]T Loss=2.303370952606201\n",
            "g_norm = tensor(0.1402, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030457496643066\n",
            "g_norm = tensor(0.1702, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035945892333984\n",
            "g_norm = tensor(0.1688, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029580116271973\n",
            "g_norm = tensor(0.1541, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30322003364563\n",
            "g_norm = tensor(0.1589, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7953338623047\n",
            "||∇_X meta|| = 0.003124168375506997\n",
            "ΔX norm: 3.124161594314501e-05\n",
            "Stage 8/10:   9%|██▋                           | 27/300 [00:57<09:10,  2.02s/it]T Loss=2.3030571937561035\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036513328552246\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303593873977661\n",
            "g_norm = tensor(0.1362, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040177822113037\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036789894104004\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9907684326172\n",
            "||∇_X meta|| = 0.0029200755525380373\n",
            "ΔX norm: 2.9200771678006276e-05\n",
            "Stage 8/10:   9%|██▊                           | 28/300 [00:59<09:00,  1.99s/it]T Loss=2.304569959640503\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304215431213379\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045268058776855\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035922050476074\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040895462036133\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.583984375\n",
            "||∇_X meta|| = 0.0027994003612548113\n",
            "ΔX norm: 2.7994001357001252e-05\n",
            "Stage 8/10:  10%|██▉                           | 29/300 [01:01<08:47,  1.95s/it]T Loss=2.3060786724090576\n",
            "g_norm = tensor(0.1451, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041470050811768\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047263622283936\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048648834228516\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3066043853759766\n",
            "g_norm = tensor(0.1580, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0113983154297\n",
            "||∇_X meta|| = 0.003078888403251767\n",
            "ΔX norm: 3.078892768826336e-05\n",
            "Stage 8/10:  10%|███                           | 30/300 [01:03<08:45,  1.95s/it]T Loss=2.304140090942383\n",
            "g_norm = tensor(0.0647, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047103881835938\n",
            "g_norm = tensor(0.0657, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304793119430542\n",
            "g_norm = tensor(0.0765, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304335117340088\n",
            "g_norm = tensor(0.0692, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044517040252686\n",
            "g_norm = tensor(0.0649, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.14088439941406\n",
            "||∇_X meta|| = 0.0033980400767177343\n",
            "ΔX norm: 3.398038825253025e-05\n",
            "Stage 8/10:  10%|███                           | 31/300 [01:04<08:35,  1.92s/it]T Loss=2.303581714630127\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040473461151123\n",
            "g_norm = tensor(0.1285, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035101890563965\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035011291503906\n",
            "g_norm = tensor(0.1394, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033595085144043\n",
            "g_norm = tensor(0.1433, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.52719116210938\n",
            "||∇_X meta|| = 0.0029057953506708145\n",
            "ΔX norm: 2.90579664579127e-05\n",
            "Stage 8/10:  11%|███▏                          | 32/300 [01:06<08:41,  1.95s/it]T Loss=2.303915500640869\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034276962280273\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303863048553467\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046913146972656\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305189609527588\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3376922607422\n",
            "||∇_X meta|| = 0.00296741328202188\n",
            "ΔX norm: 2.9674123652512208e-05\n",
            "Stage 8/10:  11%|███▎                          | 33/300 [01:08<08:44,  1.96s/it]T Loss=2.303201675415039\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039660453796387\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030014038085938\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302603006362915\n",
            "g_norm = tensor(0.0833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046469688415527\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.01052856445312\n",
            "||∇_X meta|| = 0.003113362705335021\n",
            "ΔX norm: 3.1133640732150525e-05\n",
            "Stage 8/10:  11%|███▍                          | 34/300 [01:11<08:54,  2.01s/it]T Loss=2.303797483444214\n",
            "g_norm = tensor(0.0837, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037867546081543\n",
            "g_norm = tensor(0.0751, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044052124023438\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30440092086792\n",
            "g_norm = tensor(0.0876, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047666549682617\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.66815185546875\n",
            "||∇_X meta|| = 0.0025991310831159353\n",
            "ΔX norm: 2.599132312752772e-05\n",
            "Stage 8/10:  12%|███▌                          | 35/300 [01:13<09:14,  2.09s/it]T Loss=2.304201126098633\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305055856704712\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034987449645996\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304534912109375\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043901920318604\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.88270568847656\n",
            "||∇_X meta|| = 0.002657087054103613\n",
            "ΔX norm: 2.6570922273094766e-05\n",
            "Stage 8/10:  12%|███▌                          | 36/300 [01:15<09:17,  2.11s/it]T Loss=2.305856466293335\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054428100585938\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304616689682007\n",
            "g_norm = tensor(0.1326, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042819499969482\n",
            "g_norm = tensor(0.1335, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043198585510254\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.39324951171875\n",
            "||∇_X meta|| = 0.0028611202724277973\n",
            "ΔX norm: 2.861117354768794e-05\n",
            "Stage 8/10:  12%|███▋                          | 37/300 [01:17<09:15,  2.11s/it]T Loss=2.3018500804901123\n",
            "g_norm = tensor(0.0897, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026914596557617\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032116889953613\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029050827026367\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034300804138184\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.37387084960938\n",
            "||∇_X meta|| = 0.0028936397284269333\n",
            "ΔX norm: 2.893643431889359e-05\n",
            "Stage 8/10:  13%|███▊                          | 38/300 [01:20<09:39,  2.21s/it]T Loss=2.304483413696289\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045246601104736\n",
            "g_norm = tensor(0.1432, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30503249168396\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045005798339844\n",
            "g_norm = tensor(0.1579, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305704116821289\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.85667419433594\n",
            "||∇_X meta|| = 0.002827851101756096\n",
            "ΔX norm: 2.8278500394662842e-05\n",
            "Stage 8/10:  13%|███▉                          | 39/300 [01:22<09:16,  2.13s/it]T Loss=2.302680492401123\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037118911743164\n",
            "g_norm = tensor(0.0839, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027846813201904\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041815757751465\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023228645324707\n",
            "g_norm = tensor(0.1331, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2793426513672\n",
            "||∇_X meta|| = 0.0023618575651198626\n",
            "ΔX norm: 2.361857332289219e-05\n",
            "Stage 8/10:  13%|████                          | 40/300 [01:23<09:01,  2.08s/it]T Loss=2.3047361373901367\n",
            "g_norm = tensor(0.1372, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301968574523926\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045337200164795\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305201768875122\n",
            "g_norm = tensor(0.1341, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042116165161133\n",
            "g_norm = tensor(0.1429, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5821075439453\n",
            "||∇_X meta|| = 0.0029943527188152075\n",
            "ΔX norm: 2.994357782881707e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 8/10:  14%|████                          | 41/300 [01:26<08:59,  2.08s/it]T Loss=2.304840326309204\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304206371307373\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304086446762085\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039188385009766\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302338123321533\n",
            "g_norm = tensor(0.1257, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.71742248535156\n",
            "||∇_X meta|| = 0.0025918269529938698\n",
            "ΔX norm: 2.5918259780155495e-05\n",
            "Stage 8/10:  14%|████▏                         | 42/300 [01:28<09:36,  2.23s/it]T Loss=2.3041882514953613\n",
            "g_norm = tensor(0.1206, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305098056793213\n",
            "g_norm = tensor(0.1516, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304091215133667\n",
            "g_norm = tensor(0.1351, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304564952850342\n",
            "g_norm = tensor(0.1319, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304649591445923\n",
            "g_norm = tensor(0.1354, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.04766845703125\n",
            "||∇_X meta|| = 0.0026368603575974703\n",
            "ΔX norm: 2.6368605176685378e-05\n",
            "Stage 8/10:  14%|████▎                         | 43/300 [01:31<10:40,  2.49s/it]T Loss=2.303321361541748\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032069206237793\n",
            "g_norm = tensor(0.0947, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303743839263916\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038477897644043\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026609420776367\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.27615356445312\n",
            "||∇_X meta|| = 0.0023630429059267044\n",
            "ΔX norm: 2.3630422219866887e-05\n",
            "Stage 8/10:  15%|████▍                         | 44/300 [01:34<11:18,  2.65s/it]T Loss=2.304380178451538\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050248622894287\n",
            "g_norm = tensor(0.0942, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305335760116577\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304713249206543\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305431842803955\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.27879333496094\n",
            "||∇_X meta|| = 0.002795172156766057\n",
            "ΔX norm: 2.7951722586294636e-05\n",
            "Stage 8/10:  15%|████▌                         | 45/300 [01:37<11:05,  2.61s/it]T Loss=2.30357027053833\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303011178970337\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030381202697754\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037009239196777\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036205768585205\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.49476623535156\n",
            "||∇_X meta|| = 0.0026759838219732046\n",
            "ΔX norm: 2.6759846150525846e-05\n",
            "Stage 8/10:  15%|████▌                         | 46/300 [01:39<10:32,  2.49s/it]T Loss=2.3033993244171143\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302427291870117\n",
            "g_norm = tensor(0.1222, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304508686065674\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023409843444824\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047709465026855\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.96694946289062\n",
            "||∇_X meta|| = 0.002729066414758563\n",
            "ΔX norm: 2.729065454332158e-05\n",
            "Stage 8/10:  16%|████▋                         | 47/300 [01:41<10:07,  2.40s/it]T Loss=2.3016459941864014\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031864166259766\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301818609237671\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028807640075684\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027100563049316\n",
            "g_norm = tensor(0.1448, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.3662109375\n",
            "||∇_X meta|| = 0.0028116556350141764\n",
            "ΔX norm: 2.811656850099098e-05\n",
            "Stage 8/10:  16%|████▊                         | 48/300 [01:43<09:42,  2.31s/it]T Loss=2.3046875\n",
            "g_norm = tensor(0.1213, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053324222564697\n",
            "g_norm = tensor(0.1206, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048527240753174\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304675340652466\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044393062591553\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4552001953125\n",
            "||∇_X meta|| = 0.002365668537095189\n",
            "ΔX norm: 2.3656715711695142e-05\n",
            "Stage 8/10:  16%|████▉                         | 49/300 [01:45<09:30,  2.27s/it]T Loss=2.304630994796753\n",
            "g_norm = tensor(0.0841, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304638147354126\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304543972015381\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043439388275146\n",
            "g_norm = tensor(0.0831, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041768074035645\n",
            "g_norm = tensor(0.0846, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4635772705078\n",
            "||∇_X meta|| = 0.0026287909131497145\n",
            "ΔX norm: 2.6287916625733487e-05\n",
            "Stage 8/10:  17%|█████                         | 50/300 [01:48<09:24,  2.26s/it]T Loss=2.303157329559326\n",
            "g_norm = tensor(0.1291, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037407398223877\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303612232208252\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021631240844727\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303889513015747\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.84304809570312\n",
            "||∇_X meta|| = 0.0024203623179346323\n",
            "ΔX norm: 2.4203658540500328e-05\n",
            "Stage 8/10:  17%|█████                         | 51/300 [01:50<09:36,  2.32s/it]T Loss=2.3028674125671387\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303234577178955\n",
            "g_norm = tensor(0.0878, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033666610717773\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028922080993652\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302947521209717\n",
            "g_norm = tensor(0.1139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4913787841797\n",
            "||∇_X meta|| = 0.0024401743430644274\n",
            "ΔX norm: 2.4401773771387525e-05\n",
            "Stage 8/10:  17%|█████▏                        | 52/300 [01:52<09:23,  2.27s/it]T Loss=2.302014112472534\n",
            "g_norm = tensor(0.0751, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024227619171143\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030004501342773\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302729368209839\n",
            "g_norm = tensor(0.0898, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301274061203003\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.63369750976562\n",
            "||∇_X meta|| = 0.0025643648114055395\n",
            "ΔX norm: 2.5643641492933966e-05\n",
            "Stage 8/10:  18%|█████▎                        | 53/300 [01:54<09:09,  2.23s/it]T Loss=2.3037171363830566\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303356170654297\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302694797515869\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303514003753662\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032326698303223\n",
            "g_norm = tensor(0.0983, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.02317810058594\n",
            "||∇_X meta|| = 0.002491178922355175\n",
            "ΔX norm: 2.491178565833252e-05\n",
            "Stage 8/10:  18%|█████▍                        | 54/300 [01:57<08:58,  2.19s/it]T Loss=2.3040943145751953\n",
            "g_norm = tensor(0.0823, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044848442077637\n",
            "g_norm = tensor(0.0777, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304158926010132\n",
            "g_norm = tensor(0.0797, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304382801055908\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033928871154785\n",
            "g_norm = tensor(0.0635, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4757537841797\n",
            "||∇_X meta|| = 0.0024163287598639727\n",
            "ΔX norm: 2.4163280613720417e-05\n",
            "Stage 8/10:  18%|█████▌                        | 55/300 [01:59<08:51,  2.17s/it]T Loss=2.303898811340332\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033363819122314\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040449619293213\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303677558898926\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304453134536743\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.46908569335938\n",
            "||∇_X meta|| = 0.0023982878774404526\n",
            "ΔX norm: 2.398287870164495e-05\n",
            "Stage 8/10:  19%|█████▌                        | 56/300 [02:01<09:15,  2.27s/it]T Loss=2.3051085472106934\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3061373233795166\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305049419403076\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305567502975464\n",
            "g_norm = tensor(0.0817, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048503398895264\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.43954467773438\n",
            "||∇_X meta|| = 0.0023085486609488726\n",
            "ΔX norm: 2.3085476641426794e-05\n",
            "Stage 8/10:  19%|█████▋                        | 57/300 [02:04<09:19,  2.30s/it]T Loss=2.302875280380249\n",
            "g_norm = tensor(0.1503, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304159164428711\n",
            "g_norm = tensor(0.1478, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046610355377197\n",
            "g_norm = tensor(0.1323, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029026985168457\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304985761642456\n",
            "g_norm = tensor(0.1282, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.49810791015625\n",
            "||∇_X meta|| = 0.0022089979611337185\n",
            "ΔX norm: 2.208996556873899e-05\n",
            "Stage 8/10:  19%|█████▊                        | 58/300 [02:06<09:11,  2.28s/it]T Loss=2.303492307662964\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303807258605957\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031466007232666\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022382259368896\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301971912384033\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0584259033203\n",
            "||∇_X meta|| = 0.0027512297965586185\n",
            "ΔX norm: 2.751229294517543e-05\n",
            "Stage 8/10:  20%|█████▉                        | 59/300 [02:08<09:09,  2.28s/it]T Loss=2.3052148818969727\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043956756591797\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055872917175293\n",
            "g_norm = tensor(0.0884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039355278015137\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304029941558838\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.60260009765625\n",
            "||∇_X meta|| = 0.002282543806359172\n",
            "ΔX norm: 2.2825435735285282e-05\n",
            "Stage 8/10:  20%|██████                        | 60/300 [02:10<09:05,  2.27s/it]T Loss=2.3032193183898926\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024797439575195\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302778720855713\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023781776428223\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026645183563232\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.19741821289062\n",
            "||∇_X meta|| = 0.002304429654031992\n",
            "ΔX norm: 2.304431654920336e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 8/10:  20%|██████                        | 61/300 [02:13<09:12,  2.31s/it]T Loss=2.303131103515625\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034298419952393\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304591178894043\n",
            "g_norm = tensor(0.1448, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303981304168701\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306011915206909\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.65599060058594\n",
            "||∇_X meta|| = 0.002815536456182599\n",
            "ΔX norm: 2.8155385734862648e-05\n",
            "Stage 8/10:  21%|██████▏                       | 62/300 [02:15<09:42,  2.45s/it]T Loss=2.303969383239746\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305074453353882\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303795576095581\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303969621658325\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034322261810303\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.79534912109375\n",
            "||∇_X meta|| = 0.002310970099642873\n",
            "ΔX norm: 2.3109736503101885e-05\n",
            "Stage 8/10:  21%|██████▎                       | 63/300 [02:18<09:42,  2.46s/it]T Loss=2.3026089668273926\n",
            "g_norm = tensor(0.0662, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027021884918213\n",
            "g_norm = tensor(0.0655, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029379844665527\n",
            "g_norm = tensor(0.0702, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026633262634277\n",
            "g_norm = tensor(0.0644, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302809238433838\n",
            "g_norm = tensor(0.0725, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0270233154297\n",
            "||∇_X meta|| = 0.002162633929401636\n",
            "ΔX norm: 2.1626348825520836e-05\n",
            "Stage 8/10:  21%|██████▍                       | 64/300 [02:20<09:19,  2.37s/it]T Loss=2.3047499656677246\n",
            "g_norm = tensor(0.1470, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051891326904297\n",
            "g_norm = tensor(0.1653, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043088912963867\n",
            "g_norm = tensor(0.1712, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050811290740967\n",
            "g_norm = tensor(0.1541, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042125701904297\n",
            "g_norm = tensor(0.1336, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.27679443359375\n",
            "||∇_X meta|| = 0.0020243632607162\n",
            "ΔX norm: 2.024365858233068e-05\n",
            "Stage 8/10:  22%|██████▌                       | 65/300 [02:22<09:13,  2.36s/it]T Loss=2.304119110107422\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038978576660156\n",
            "g_norm = tensor(0.1297, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035635948181152\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303178310394287\n",
            "g_norm = tensor(0.1347, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30536150932312\n",
            "g_norm = tensor(0.1278, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1694793701172\n",
            "||∇_X meta|| = 0.0021713832393288612\n",
            "ΔX norm: 2.1713833120884374e-05\n",
            "Stage 8/10:  22%|██████▌                       | 66/300 [02:25<09:28,  2.43s/it]T Loss=2.303093910217285\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028459548950195\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038902282714844\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304088830947876\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041915893554688\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5436248779297\n",
            "||∇_X meta|| = 0.0024026562459766865\n",
            "ΔX norm: 2.402655445621349e-05\n",
            "Stage 8/10:  22%|██████▋                       | 67/300 [02:27<09:10,  2.36s/it]T Loss=2.3029239177703857\n",
            "g_norm = tensor(0.1721, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038196563720703\n",
            "g_norm = tensor(0.1604, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303558826446533\n",
            "g_norm = tensor(0.1964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304140567779541\n",
            "g_norm = tensor(0.1839, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038220405578613\n",
            "g_norm = tensor(0.1355, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2857666015625\n",
            "||∇_X meta|| = 0.002296114806085825\n",
            "ΔX norm: 2.296115599165205e-05\n",
            "Stage 8/10:  23%|██████▊                       | 68/300 [02:30<09:04,  2.35s/it]T Loss=2.303882122039795\n",
            "g_norm = tensor(0.0813, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039584159851074\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040804862976074\n",
            "g_norm = tensor(0.0787, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037521839141846\n",
            "g_norm = tensor(0.0791, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304522752761841\n",
            "g_norm = tensor(0.0659, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5615234375\n",
            "||∇_X meta|| = 0.002560555934906006\n",
            "ΔX norm: 2.5605550035834312e-05\n",
            "Stage 8/10:  23%|██████▉                       | 69/300 [02:32<08:51,  2.30s/it]T Loss=2.303447723388672\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057985305786133\n",
            "g_norm = tensor(0.1250, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038992881774902\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037779331207275\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035836219787598\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3521728515625\n",
            "||∇_X meta|| = 0.0023432413581758738\n",
            "ΔX norm: 2.3432472517015412e-05\n",
            "Stage 8/10:  23%|███████                       | 70/300 [02:34<08:36,  2.25s/it]T Loss=2.30328106880188\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024468421936035\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304673671722412\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302147626876831\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303380250930786\n",
            "g_norm = tensor(0.1460, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9783477783203\n",
            "||∇_X meta|| = 0.0022155637852847576\n",
            "ΔX norm: 2.2155614715302363e-05\n",
            "Stage 8/10:  24%|███████                       | 71/300 [02:36<08:37,  2.26s/it]T Loss=2.303558588027954\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042893409729004\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302550792694092\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035385608673096\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039164543151855\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.0983123779297\n",
            "||∇_X meta|| = 0.0022402384784072638\n",
            "ΔX norm: 2.2402398826670833e-05\n",
            "Stage 8/10:  24%|███████▏                      | 72/300 [02:38<08:34,  2.26s/it]T Loss=2.304208993911743\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035836219787598\n",
            "g_norm = tensor(0.0919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039655685424805\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043155670166016\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306699752807617\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.44447326660156\n",
            "||∇_X meta|| = 0.002372969873249531\n",
            "ΔX norm: 2.372968810959719e-05\n",
            "Stage 8/10:  24%|███████▎                      | 73/300 [02:41<08:29,  2.25s/it]T Loss=2.3048224449157715\n",
            "g_norm = tensor(0.1322, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037123680114746\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304023265838623\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30505633354187\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305004835128784\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.49925231933594\n",
            "||∇_X meta|| = 0.002222946612164378\n",
            "ΔX norm: 2.2229460228118114e-05\n",
            "Stage 8/10:  25%|███████▍                      | 74/300 [02:43<08:31,  2.26s/it]T Loss=2.304940700531006\n",
            "g_norm = tensor(0.1103, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303804874420166\n",
            "g_norm = tensor(0.1428, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044281005859375\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032386302948\n",
            "g_norm = tensor(0.1557, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041064739227295\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.57310485839844\n",
            "||∇_X meta|| = 0.002132259774953127\n",
            "ΔX norm: 2.1322581233107485e-05\n",
            "Stage 8/10:  25%|███████▌                      | 75/300 [02:45<08:45,  2.34s/it]T Loss=2.302868604660034\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026421070098877\n",
            "g_norm = tensor(0.0749, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036155700683594\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303860664367676\n",
            "g_norm = tensor(0.0838, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302250385284424\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.80812072753906\n",
            "||∇_X meta|| = 0.0021202571224421263\n",
            "ΔX norm: 2.1202578864176758e-05\n",
            "Stage 8/10:  25%|███████▌                      | 76/300 [02:48<08:47,  2.36s/it]T Loss=2.3027987480163574\n",
            "g_norm = tensor(0.1424, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303868055343628\n",
            "g_norm = tensor(0.1552, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3016891479492188\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025128841400146\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303889274597168\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1656494140625\n",
            "||∇_X meta|| = 0.0021198687609285116\n",
            "ΔX norm: 2.119868622685317e-05\n",
            "Stage 8/10:  26%|███████▋                      | 77/300 [02:50<08:50,  2.38s/it]T Loss=2.3032925128936768\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053576946258545\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035881519317627\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303297519683838\n",
            "g_norm = tensor(0.1308, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047494888305664\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.39329528808594\n",
            "||∇_X meta|| = 0.0020726497750729322\n",
            "ΔX norm: 2.072651477647014e-05\n",
            "Stage 8/10:  26%|███████▊                      | 78/300 [02:53<08:46,  2.37s/it]T Loss=2.3033266067504883\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304051637649536\n",
            "g_norm = tensor(0.0879, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032386302948\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036398887634277\n",
            "g_norm = tensor(0.0851, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034067153930664\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.93812561035156\n",
            "||∇_X meta|| = 0.0021197921596467495\n",
            "ΔX norm: 2.1197920432314277e-05\n",
            "Stage 8/10:  26%|███████▉                      | 79/300 [02:55<08:49,  2.40s/it]T Loss=2.3049476146698\n",
            "g_norm = tensor(0.1187, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304485321044922\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30403470993042\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048806190490723\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045504093170166\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1170196533203\n",
            "||∇_X meta|| = 0.001917651272378862\n",
            "ΔX norm: 1.9176508430973627e-05\n",
            "Stage 8/10:  27%|████████                      | 80/300 [02:57<08:35,  2.34s/it]T Loss=2.3043665885925293\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043999671936035\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303736448287964\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30450439453125\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050856590270996\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.64501953125\n",
            "||∇_X meta|| = 0.0023008151911199093\n",
            "ΔX norm: 2.3008155039860867e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 8/10:  27%|████████                      | 81/300 [03:00<08:48,  2.41s/it]T Loss=2.3040597438812256\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037331104278564\n",
            "g_norm = tensor(0.1369, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303544759750366\n",
            "g_norm = tensor(0.1302, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304152250289917\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303981304168701\n",
            "g_norm = tensor(0.1325, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.80929565429688\n",
            "||∇_X meta|| = 0.0023943972773849964\n",
            "ΔX norm: 2.3944006898091175e-05\n",
            "Stage 8/10:  27%|████████▏                     | 82/300 [03:02<08:47,  2.42s/it]T Loss=2.304105281829834\n",
            "g_norm = tensor(0.0834, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040552139282227\n",
            "g_norm = tensor(0.0789, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033204078674316\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039894104003906\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303854465484619\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5903778076172\n",
            "||∇_X meta|| = 0.0020043461117893457\n",
            "ΔX norm: 2.004346788453404e-05\n",
            "Stage 8/10:  28%|████████▎                     | 83/300 [03:05<08:38,  2.39s/it]T Loss=2.303345203399658\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302201509475708\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042194843292236\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302156925201416\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301687717437744\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.9873046875\n",
            "||∇_X meta|| = 0.0020083270501345396\n",
            "ΔX norm: 2.0083305571461096e-05\n",
            "Stage 8/10:  28%|████████▍                     | 84/300 [03:07<08:36,  2.39s/it]T Loss=2.3044381141662598\n",
            "g_norm = tensor(0.1444, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305837869644165\n",
            "g_norm = tensor(0.1243, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303959369659424\n",
            "g_norm = tensor(0.1399, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038036823272705\n",
            "g_norm = tensor(0.1306, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040401935577393\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.22427368164062\n",
            "||∇_X meta|| = 0.002343209460377693\n",
            "ΔX norm: 2.3432074158336036e-05\n",
            "Stage 8/10:  28%|████████▌                     | 85/300 [03:09<08:22,  2.34s/it]T Loss=2.3029868602752686\n",
            "g_norm = tensor(0.1269, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034729957580566\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032634258270264\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302867889404297\n",
            "g_norm = tensor(0.1184, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019323348999023\n",
            "g_norm = tensor(0.1397, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8070068359375\n",
            "||∇_X meta|| = 0.0021276259794831276\n",
            "ΔX norm: 2.1276262486935593e-05\n",
            "Stage 8/10:  29%|████████▌                     | 86/300 [03:11<08:07,  2.28s/it]T Loss=2.3046956062316895\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038763999938965\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057987689971924\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052470684051514\n",
            "g_norm = tensor(0.0822, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048453330993652\n",
            "g_norm = tensor(0.0885, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0724639892578\n",
            "||∇_X meta|| = 0.00176246149931103\n",
            "ΔX norm: 1.7624613974476233e-05\n",
            "Stage 8/10:  29%|████████▋                     | 87/300 [03:14<08:41,  2.45s/it]T Loss=2.3032798767089844\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041818141937256\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303831100463867\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304415225982666\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043737411499023\n",
            "g_norm = tensor(0.1216, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.45468139648438\n",
            "||∇_X meta|| = 0.0022143106907606125\n",
            "ΔX norm: 2.2143118258100003e-05\n",
            "Stage 8/10:  29%|████████▊                     | 88/300 [03:17<09:15,  2.62s/it]T Loss=2.3042311668395996\n",
            "g_norm = tensor(0.1374, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040530681610107\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037827014923096\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055548667907715\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035659790039062\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.15817260742188\n",
            "||∇_X meta|| = 0.0021128521766513586\n",
            "ΔX norm: 2.1128496882738546e-05\n",
            "Stage 8/10:  30%|████████▉                     | 89/300 [03:20<09:39,  2.75s/it]T Loss=2.3025715351104736\n",
            "g_norm = tensor(0.1268, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037025928497314\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304847478866577\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035008907318115\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303877830505371\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3415985107422\n",
            "||∇_X meta|| = 0.001977107021957636\n",
            "ΔX norm: 1.9771059669437818e-05\n",
            "Stage 8/10:  30%|█████████                     | 90/300 [03:23<09:36,  2.74s/it]T Loss=2.3052172660827637\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306093454360962\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304225206375122\n",
            "g_norm = tensor(0.1496, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304021120071411\n",
            "g_norm = tensor(0.1522, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304419994354248\n",
            "g_norm = tensor(0.1250, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5384521484375\n",
            "||∇_X meta|| = 0.0020856005139648914\n",
            "ΔX norm: 2.0856043192907237e-05\n",
            "Stage 8/10:  30%|█████████                     | 91/300 [03:26<09:21,  2.69s/it]T Loss=2.30311918258667\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302579641342163\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301975727081299\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303786516189575\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030152320861816\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.027099609375\n",
            "||∇_X meta|| = 0.0019155021291226149\n",
            "ΔX norm: 1.915502070914954e-05\n",
            "Stage 8/10:  31%|█████████▏                    | 92/300 [03:28<09:10,  2.64s/it]T Loss=2.304561138153076\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303199529647827\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025717735290527\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305049180984497\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049824237823486\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8917236328125\n",
            "||∇_X meta|| = 0.0018699760548770428\n",
            "ΔX norm: 1.8699754946283065e-05\n",
            "Stage 8/10:  31%|█████████▎                    | 93/300 [03:31<08:56,  2.59s/it]T Loss=2.3039188385009766\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032824993133545\n",
            "g_norm = tensor(0.1140, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304142475128174\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038039207458496\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034443855285645\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.60601806640625\n",
            "||∇_X meta|| = 0.0018448096234351397\n",
            "ΔX norm: 1.8448097762302496e-05\n",
            "Stage 8/10:  31%|█████████▍                    | 94/300 [03:33<08:38,  2.52s/it]T Loss=2.303884983062744\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052377700805664\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039097785949707\n",
            "g_norm = tensor(0.1080, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035242557525635\n",
            "g_norm = tensor(0.0937, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303114652633667\n",
            "g_norm = tensor(0.1292, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.78846740722656\n",
            "||∇_X meta|| = 0.0023257723078131676\n",
            "ΔX norm: 2.3257653083419427e-05\n",
            "Stage 8/10:  32%|█████████▌                    | 95/300 [03:35<08:27,  2.48s/it]T Loss=2.303614854812622\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030765056610107\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303617000579834\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304297685623169\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302372455596924\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5273895263672\n",
            "||∇_X meta|| = 0.002064380794763565\n",
            "ΔX norm: 2.0643823518184945e-05\n",
            "Stage 8/10:  32%|█████████▌                    | 96/300 [03:38<08:10,  2.41s/it]T Loss=2.302548885345459\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303016185760498\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30383038520813\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037376403808594\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025145530700684\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.21266174316406\n",
            "||∇_X meta|| = 0.002147458493709564\n",
            "ΔX norm: 2.1474599634530023e-05\n",
            "Stage 8/10:  32%|█████████▋                    | 97/300 [03:40<08:23,  2.48s/it]T Loss=2.3018860816955566\n",
            "g_norm = tensor(0.1390, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305119514465332\n",
            "g_norm = tensor(0.1338, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039746284484863\n",
            "g_norm = tensor(0.1477, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304046154022217\n",
            "g_norm = tensor(0.1605, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302607297897339\n",
            "g_norm = tensor(0.1525, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2012176513672\n",
            "||∇_X meta|| = 0.001996140694245696\n",
            "ΔX norm: 1.996142600546591e-05\n",
            "Stage 8/10:  33%|█████████▊                    | 98/300 [03:43<08:14,  2.45s/it]T Loss=2.3056461811065674\n",
            "g_norm = tensor(0.1619, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054559230804443\n",
            "g_norm = tensor(0.1365, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305341958999634\n",
            "g_norm = tensor(0.1243, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303297758102417\n",
            "g_norm = tensor(0.1539, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043408393859863\n",
            "g_norm = tensor(0.1352, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.19192504882812\n",
            "||∇_X meta|| = 0.0022048805840313435\n",
            "ΔX norm: 2.204880911449436e-05\n",
            "Stage 8/10:  33%|█████████▉                    | 99/300 [03:45<08:06,  2.42s/it]T Loss=2.30464768409729\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304506301879883\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036251068115234\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036887645721436\n",
            "g_norm = tensor(0.0852, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047115802764893\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.91351318359375\n",
            "||∇_X meta|| = 0.0018522815080359578\n",
            "ΔX norm: 1.852280729508493e-05\n",
            "Stage 8/10:  33%|█████████▋                   | 100/300 [03:47<08:01,  2.41s/it]T Loss=2.3041746616363525\n",
            "g_norm = tensor(0.0822, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039586544036865\n",
            "g_norm = tensor(0.0825, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041679859161377\n",
            "g_norm = tensor(0.0856, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045032024383545\n",
            "g_norm = tensor(0.0704, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046040534973145\n",
            "g_norm = tensor(0.0763, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.78575134277344\n",
            "||∇_X meta|| = 0.001946082105860114\n",
            "ΔX norm: 1.946081465575844e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 8/10:  34%|█████████▊                   | 101/300 [03:50<07:49,  2.36s/it]T Loss=2.3039438724517822\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304769992828369\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303224802017212\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30531644821167\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048629760742188\n",
            "g_norm = tensor(0.1234, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.47206115722656\n",
            "||∇_X meta|| = 0.0019084254745393991\n",
            "ΔX norm: 1.908424383145757e-05\n",
            "Stage 8/10:  34%|█████████▊                   | 102/300 [03:52<08:08,  2.47s/it]T Loss=2.303929567337036\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052821159362793\n",
            "g_norm = tensor(0.1452, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305931329727173\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039727210998535\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303271532058716\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.92221069335938\n",
            "||∇_X meta|| = 0.001751575618982315\n",
            "ΔX norm: 1.7515749277663417e-05\n",
            "Stage 8/10:  34%|█████████▉                   | 103/300 [03:55<07:53,  2.40s/it]T Loss=2.3048174381256104\n",
            "g_norm = tensor(0.1647, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058454990386963\n",
            "g_norm = tensor(0.1374, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051204681396484\n",
            "g_norm = tensor(0.1726, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302966594696045\n",
            "g_norm = tensor(0.1497, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303618907928467\n",
            "g_norm = tensor(0.1411, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.99046325683594\n",
            "||∇_X meta|| = 0.0018591280095279217\n",
            "ΔX norm: 1.859125950431917e-05\n",
            "Stage 8/10:  35%|██████████                   | 104/300 [03:57<07:42,  2.36s/it]T Loss=2.304187536239624\n",
            "g_norm = tensor(0.1507, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039932250976562\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019158840179443\n",
            "g_norm = tensor(0.1484, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301334857940674\n",
            "g_norm = tensor(0.1314, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024158477783203\n",
            "g_norm = tensor(0.1184, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.445068359375\n",
            "||∇_X meta|| = 0.001965619157999754\n",
            "ΔX norm: 1.965618139365688e-05\n",
            "Stage 8/10:  35%|██████████▏                  | 105/300 [03:59<07:32,  2.32s/it]T Loss=2.3045547008514404\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30413818359375\n",
            "g_norm = tensor(0.1257, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039791584014893\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043975830078125\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041324615478516\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.62625122070312\n",
            "||∇_X meta|| = 0.001888205180875957\n",
            "ΔX norm: 1.8882030417444184e-05\n",
            "Stage 8/10:  35%|██████████▏                  | 106/300 [04:01<07:36,  2.35s/it]T Loss=2.3036205768585205\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036396503448486\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304213762283325\n",
            "g_norm = tensor(0.1299, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304992914199829\n",
            "g_norm = tensor(0.1371, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036108016967773\n",
            "g_norm = tensor(0.1283, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.9834747314453\n",
            "||∇_X meta|| = 0.0019292160868644714\n",
            "ΔX norm: 1.9292167053208686e-05\n",
            "Stage 8/10:  36%|██████████▎                  | 107/300 [04:04<07:35,  2.36s/it]T Loss=2.3039658069610596\n",
            "g_norm = tensor(0.1398, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051114082336426\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303734064102173\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304344892501831\n",
            "g_norm = tensor(0.1325, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304713249206543\n",
            "g_norm = tensor(0.1609, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.61399841308594\n",
            "||∇_X meta|| = 0.001927297213114798\n",
            "ΔX norm: 1.9272980352980085e-05\n",
            "Stage 8/10:  36%|██████████▍                  | 108/300 [04:06<07:38,  2.39s/it]T Loss=2.3037304878234863\n",
            "g_norm = tensor(0.1321, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304259777069092\n",
            "g_norm = tensor(0.1316, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036627769470215\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019983768463135\n",
            "g_norm = tensor(0.1248, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304051160812378\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.08888244628906\n",
            "||∇_X meta|| = 0.001671639154665172\n",
            "ΔX norm: 1.6716376194381155e-05\n",
            "Stage 8/10:  36%|██████████▌                  | 109/300 [04:09<07:35,  2.39s/it]T Loss=2.3041253089904785\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027634620666504\n",
            "g_norm = tensor(0.1283, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044097423553467\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039376735687256\n",
            "g_norm = tensor(0.1230, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303743362426758\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.61534118652344\n",
            "||∇_X meta|| = 0.001952335238456726\n",
            "ΔX norm: 1.9523366063367575e-05\n",
            "Stage 8/10:  37%|██████████▋                  | 110/300 [04:11<07:54,  2.50s/it]T Loss=2.303617000579834\n",
            "g_norm = tensor(0.1184, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041634559631348\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3011667728424072\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041107654571533\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019297122955322\n",
            "g_norm = tensor(0.1422, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.42974853515625\n",
            "||∇_X meta|| = 0.0020416986662894487\n",
            "ΔX norm: 2.0416964616742916e-05\n",
            "Stage 8/10:  37%|██████████▋                  | 111/300 [04:14<07:45,  2.46s/it]T Loss=2.304168224334717\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302999973297119\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043112754821777\n",
            "g_norm = tensor(0.1296, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043739795684814\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303487777709961\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6278839111328\n",
            "||∇_X meta|| = 0.0016013879794627428\n",
            "ΔX norm: 1.6013882486731745e-05\n",
            "Stage 8/10:  37%|██████████▊                  | 112/300 [04:16<07:54,  2.52s/it]T Loss=2.3042454719543457\n",
            "g_norm = tensor(0.0853, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030202388763428\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030076026916504\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027713298797607\n",
            "g_norm = tensor(0.0862, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302802324295044\n",
            "g_norm = tensor(0.0704, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.46157836914062\n",
            "||∇_X meta|| = 0.0018011762294918299\n",
            "ΔX norm: 1.8011756765190512e-05\n",
            "Stage 8/10:  38%|██████████▉                  | 113/300 [04:19<07:39,  2.46s/it]T Loss=2.3021106719970703\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025405406951904\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302894115447998\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036415576934814\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302342176437378\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.18338012695312\n",
            "||∇_X meta|| = 0.001667181495577097\n",
            "ΔX norm: 1.6671801859047264e-05\n",
            "Stage 8/10:  38%|███████████                  | 114/300 [04:21<07:29,  2.41s/it]T Loss=2.3033437728881836\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303471088409424\n",
            "g_norm = tensor(0.1330, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034350872039795\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303323745727539\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303926944732666\n",
            "g_norm = tensor(0.0855, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1962432861328\n",
            "||∇_X meta|| = 0.001871230429969728\n",
            "ΔX norm: 1.871229505923111e-05\n",
            "Stage 8/10:  38%|███████████                  | 115/300 [04:24<07:26,  2.41s/it]T Loss=2.3022875785827637\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035478591918945\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303539991378784\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303947687149048\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032212257385254\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.02915954589844\n",
            "||∇_X meta|| = 0.001738381921313703\n",
            "ΔX norm: 1.7383807062287815e-05\n",
            "Stage 8/10:  39%|███████████▏                 | 116/300 [04:26<07:41,  2.51s/it]T Loss=2.3027398586273193\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3016622066497803\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034744262695312\n",
            "g_norm = tensor(0.0788, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302414655685425\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035712242126465\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7941436767578\n",
            "||∇_X meta|| = 0.001780753256753087\n",
            "ΔX norm: 1.780751881597098e-05\n",
            "Stage 8/10:  39%|███████████▎                 | 117/300 [04:29<07:35,  2.49s/it]T Loss=2.303597927093506\n",
            "g_norm = tensor(0.1466, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022913932800293\n",
            "g_norm = tensor(0.1416, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30353045463562\n",
            "g_norm = tensor(0.1354, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033180236816406\n",
            "g_norm = tensor(0.1380, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031020164489746\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.90208435058594\n",
            "||∇_X meta|| = 0.0019360127625986934\n",
            "ΔX norm: 1.9360133592272177e-05\n",
            "Stage 8/10:  39%|███████████▍                 | 118/300 [04:31<07:23,  2.44s/it]T Loss=2.303915023803711\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032479286193848\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303208827972412\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303799629211426\n",
            "g_norm = tensor(0.1184, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050265312194824\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.03050231933594\n",
            "||∇_X meta|| = 0.0019406374776735902\n",
            "ΔX norm: 1.9406357750995085e-05\n",
            "Stage 8/10:  40%|███████████▌                 | 119/300 [04:33<07:21,  2.44s/it]T Loss=2.303868532180786\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030247688293457\n",
            "g_norm = tensor(0.1438, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303270101547241\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302903890609741\n",
            "g_norm = tensor(0.1302, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041367530822754\n",
            "g_norm = tensor(0.1447, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.65220642089844\n",
            "||∇_X meta|| = 0.0018880482530221343\n",
            "ΔX norm: 1.8880480638472363e-05\n",
            "Stage 8/10:  40%|███████████▌                 | 120/300 [04:36<07:19,  2.44s/it]T Loss=2.3040452003479004\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029112815856934\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028998374938965\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040475845336914\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031249046325684\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3397979736328\n",
            "||∇_X meta|| = 0.0018886411562561989\n",
            "ΔX norm: 1.888640872493852e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 8/10:  40%|███████████▋                 | 121/300 [04:39<07:26,  2.49s/it]T Loss=2.304622173309326\n",
            "g_norm = tensor(0.1581, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305828809738159\n",
            "g_norm = tensor(0.1616, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044848442077637\n",
            "g_norm = tensor(0.1494, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039581775665283\n",
            "g_norm = tensor(0.1558, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050076961517334\n",
            "g_norm = tensor(0.1453, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7310028076172\n",
            "||∇_X meta|| = 0.0018577156588435173\n",
            "ΔX norm: 1.8577140508568846e-05\n",
            "Stage 8/10:  41%|███████████▊                 | 122/300 [04:41<07:48,  2.63s/it]T Loss=2.3035178184509277\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304020643234253\n",
            "g_norm = tensor(0.1295, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040335178375244\n",
            "g_norm = tensor(0.1407, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038668632507324\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303597927093506\n",
            "g_norm = tensor(0.1550, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.98326110839844\n",
            "||∇_X meta|| = 0.0019520435016602278\n",
            "ΔX norm: 1.9520412024576217e-05\n",
            "Stage 8/10:  41%|███████████▉                 | 123/300 [04:44<07:37,  2.59s/it]T Loss=2.304072856903076\n",
            "g_norm = tensor(0.1668, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304863214492798\n",
            "g_norm = tensor(0.1412, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036553859710693\n",
            "g_norm = tensor(0.1484, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038909435272217\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037142753601074\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6240234375\n",
            "||∇_X meta|| = 0.001686088158749044\n",
            "ΔX norm: 1.6860854884725995e-05\n",
            "Stage 8/10:  41%|███████████▉                 | 124/300 [04:46<07:23,  2.52s/it]T Loss=2.3037655353546143\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026511669158936\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040661811828613\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038220405578613\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028385639190674\n",
            "g_norm = tensor(0.1306, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.45875549316406\n",
            "||∇_X meta|| = 0.0016973359743133187\n",
            "ΔX norm: 1.697337211226113e-05\n",
            "Stage 8/10:  42%|████████████                 | 125/300 [04:49<07:11,  2.46s/it]T Loss=2.3049957752227783\n",
            "g_norm = tensor(0.1401, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052427768707275\n",
            "g_norm = tensor(0.1521, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044040203094482\n",
            "g_norm = tensor(0.1456, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053908348083496\n",
            "g_norm = tensor(0.1362, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038573265075684\n",
            "g_norm = tensor(0.1491, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.74537658691406\n",
            "||∇_X meta|| = 0.0016408513765782118\n",
            "ΔX norm: 1.6408521332778037e-05\n",
            "Stage 8/10:  42%|████████████▏                | 126/300 [04:51<06:59,  2.41s/it]T Loss=2.304738998413086\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304304599761963\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303436756134033\n",
            "g_norm = tensor(0.1053, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041274547576904\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038506507873535\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9937286376953\n",
            "||∇_X meta|| = 0.001818773802369833\n",
            "ΔX norm: 1.8187720343121327e-05\n",
            "Stage 8/10:  42%|████████████▎                | 127/300 [04:53<06:51,  2.38s/it]T Loss=2.3035635948181152\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038530349731445\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038742542266846\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044142723083496\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035783767700195\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0755157470703\n",
            "||∇_X meta|| = 0.001702727167867124\n",
            "ΔX norm: 1.7027297872118652e-05\n",
            "Stage 8/10:  43%|████████████▎                | 128/300 [04:56<06:47,  2.37s/it]T Loss=2.301938533782959\n",
            "g_norm = tensor(0.1333, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023812770843506\n",
            "g_norm = tensor(0.1359, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027591705322266\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027849197387695\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30444598197937\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.55740356445312\n",
            "||∇_X meta|| = 0.0015533146215602756\n",
            "ΔX norm: 1.5533149053226225e-05\n",
            "Stage 8/10:  43%|████████████▍                | 129/300 [04:58<06:40,  2.34s/it]T Loss=2.304577350616455\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304964542388916\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034729957580566\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056132793426514\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052937984466553\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.98841857910156\n",
            "||∇_X meta|| = 0.0017420380609109998\n",
            "ΔX norm: 1.7420366930309683e-05\n",
            "Stage 8/10:  43%|████████████▌                | 130/300 [05:00<06:47,  2.39s/it]T Loss=2.305783987045288\n",
            "g_norm = tensor(0.1677, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039844036102295\n",
            "g_norm = tensor(0.1451, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037712574005127\n",
            "g_norm = tensor(0.1513, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041036128997803\n",
            "g_norm = tensor(0.1590, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051276206970215\n",
            "g_norm = tensor(0.1547, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4006805419922\n",
            "||∇_X meta|| = 0.0017026423010975122\n",
            "ΔX norm: 1.7026406567310914e-05\n",
            "Stage 8/10:  44%|████████████▋                | 131/300 [05:03<06:55,  2.46s/it]T Loss=2.302785873413086\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304016351699829\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302995204925537\n",
            "g_norm = tensor(0.1332, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020007610321045\n",
            "g_norm = tensor(0.1404, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303361415863037\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.07369995117188\n",
            "||∇_X meta|| = 0.001556901726871729\n",
            "ΔX norm: 1.556902498123236e-05\n",
            "Stage 8/10:  44%|████████████▊                | 132/300 [05:05<06:50,  2.44s/it]T Loss=2.303048610687256\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025362491607666\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303056478500366\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042757511138916\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048062324523926\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.46243286132812\n",
            "||∇_X meta|| = 0.0018334557535126805\n",
            "ΔX norm: 1.833454371080734e-05\n",
            "Stage 8/10:  44%|████████████▊                | 133/300 [05:08<06:37,  2.38s/it]T Loss=2.3043196201324463\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305492401123047\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304077625274658\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047142028808594\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045926094055176\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.47801208496094\n",
            "||∇_X meta|| = 0.0017312237760052085\n",
            "ΔX norm: 1.7312235286226496e-05\n",
            "Stage 8/10:  45%|████████████▉                | 134/300 [05:10<06:28,  2.34s/it]T Loss=2.304227113723755\n",
            "g_norm = tensor(0.0797, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304798126220703\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045575618743896\n",
            "g_norm = tensor(0.0765, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304513454437256\n",
            "g_norm = tensor(0.0866, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054697513580322\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.55177307128906\n",
            "||∇_X meta|| = 0.001743262866511941\n",
            "ΔX norm: 1.743264147080481e-05\n",
            "Stage 8/10:  45%|█████████████                | 135/300 [05:12<06:17,  2.29s/it]T Loss=2.3036739826202393\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302868366241455\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039989471435547\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303004741668701\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303515672683716\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.02923583984375\n",
            "||∇_X meta|| = 0.0016020698240026832\n",
            "ΔX norm: 1.6020705515984446e-05\n",
            "Stage 8/10:  45%|█████████████▏               | 136/300 [05:14<06:16,  2.30s/it]T Loss=2.305729389190674\n",
            "g_norm = tensor(0.1323, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304124116897583\n",
            "g_norm = tensor(0.1564, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3062868118286133\n",
            "g_norm = tensor(0.1314, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302922010421753\n",
            "g_norm = tensor(0.1153, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3066353797912598\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.00579833984375\n",
            "||∇_X meta|| = 0.0015456494875252247\n",
            "ΔX norm: 1.545651684864424e-05\n",
            "Stage 8/10:  46%|█████████████▏               | 137/300 [05:17<06:24,  2.36s/it]T Loss=2.303473711013794\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302306652069092\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302490234375\n",
            "g_norm = tensor(0.1276, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023781776428223\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042359352111816\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.62535095214844\n",
            "||∇_X meta|| = 0.0016564811812713742\n",
            "ΔX norm: 1.6564803445362486e-05\n",
            "Stage 8/10:  46%|█████████████▎               | 138/300 [05:19<06:26,  2.39s/it]T Loss=2.3046228885650635\n",
            "g_norm = tensor(0.1468, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028204441070557\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304126739501953\n",
            "g_norm = tensor(0.1574, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.300779342651367\n",
            "g_norm = tensor(0.1382, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302938461303711\n",
            "g_norm = tensor(0.1380, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.24183654785156\n",
            "||∇_X meta|| = 0.0017280069878324866\n",
            "ΔX norm: 1.7280059182667173e-05\n",
            "Stage 8/10:  46%|█████████████▍               | 139/300 [05:22<06:21,  2.37s/it]T Loss=2.3041656017303467\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304680347442627\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032188415527344\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040614128112793\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040878772735596\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.952392578125\n",
            "||∇_X meta|| = 0.0015318560181185603\n",
            "ΔX norm: 1.531857742520515e-05\n",
            "Stage 8/10:  47%|█████████████▌               | 140/300 [05:24<06:17,  2.36s/it]T Loss=2.304381847381592\n",
            "g_norm = tensor(0.0822, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031158447265625\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041698932647705\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304565906524658\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033504486083984\n",
            "g_norm = tensor(0.1219, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.26222229003906\n",
            "||∇_X meta|| = 0.001745783258229494\n",
            "ΔX norm: 1.7457845387980342e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 8/10:  47%|█████████████▋               | 141/300 [05:26<06:16,  2.37s/it]T Loss=2.3050756454467773\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031458854675293\n",
            "g_norm = tensor(0.1465, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027427196502686\n",
            "g_norm = tensor(0.1386, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302563190460205\n",
            "g_norm = tensor(0.1550, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303156614303589\n",
            "g_norm = tensor(0.1345, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.445068359375\n",
            "||∇_X meta|| = 0.0016485733212903142\n",
            "ΔX norm: 1.6485755622852594e-05\n",
            "Stage 8/10:  47%|█████████████▋               | 142/300 [05:29<06:24,  2.43s/it]T Loss=2.305055618286133\n",
            "g_norm = tensor(0.1325, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3064773082733154\n",
            "g_norm = tensor(0.1435, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305105209350586\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303441286087036\n",
            "g_norm = tensor(0.1278, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3061110973358154\n",
            "g_norm = tensor(0.1321, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.81011962890625\n",
            "||∇_X meta|| = 0.0014886665157973766\n",
            "ΔX norm: 1.4886656572343782e-05\n",
            "Stage 8/10:  48%|█████████████▊               | 143/300 [05:32<06:38,  2.54s/it]T Loss=2.302316188812256\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023574352264404\n",
            "g_norm = tensor(0.1262, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024790287017822\n",
            "g_norm = tensor(0.1303, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022918701171875\n",
            "g_norm = tensor(0.1341, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302154064178467\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7464141845703\n",
            "||∇_X meta|| = 0.0017909061862155795\n",
            "ΔX norm: 1.790906571841333e-05\n",
            "Stage 8/10:  48%|█████████████▉               | 144/300 [05:34<06:23,  2.46s/it]T Loss=2.3047561645507812\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304283857345581\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043365478515625\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304161548614502\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033523559570312\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.17828369140625\n",
            "||∇_X meta|| = 0.001731416443362832\n",
            "ΔX norm: 1.731416159600485e-05\n",
            "Stage 8/10:  48%|██████████████               | 145/300 [05:37<06:34,  2.55s/it]T Loss=2.30350399017334\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303250312805176\n",
            "g_norm = tensor(0.1337, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302948236465454\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043036460876465\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303819179534912\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.21620178222656\n",
            "||∇_X meta|| = 0.0017902066465467215\n",
            "ΔX norm: 1.790203168638982e-05\n",
            "Stage 8/10:  49%|██████████████               | 146/300 [05:39<06:31,  2.54s/it]T Loss=2.3053035736083984\n",
            "g_norm = tensor(0.1258, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054308891296387\n",
            "g_norm = tensor(0.1473, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055121898651123\n",
            "g_norm = tensor(0.1450, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306342601776123\n",
            "g_norm = tensor(0.1632, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305957794189453\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.44863891601562\n",
            "||∇_X meta|| = 0.0017366806278005242\n",
            "ΔX norm: 1.736679951136466e-05\n",
            "Stage 8/10:  49%|██████████████▏              | 147/300 [05:42<06:18,  2.47s/it]T Loss=2.3042609691619873\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038299083709717\n",
            "g_norm = tensor(0.1326, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034520149230957\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019280433654785\n",
            "g_norm = tensor(0.1603, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303849697113037\n",
            "g_norm = tensor(0.1324, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1438751220703\n",
            "||∇_X meta|| = 0.001690076314844191\n",
            "ΔX norm: 1.6900745322345756e-05\n",
            "Stage 8/10:  49%|██████████████▎              | 148/300 [05:44<06:15,  2.47s/it]T Loss=2.3021960258483887\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040454387664795\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303483486175537\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036513328552246\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303069591522217\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.713623046875\n",
            "||∇_X meta|| = 0.0015254023019224405\n",
            "ΔX norm: 1.5254036952683236e-05\n",
            "Stage 8/10:  50%|██████████████▍              | 149/300 [05:46<06:05,  2.42s/it]T Loss=2.302598476409912\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041059970855713\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303804397583008\n",
            "g_norm = tensor(0.1249, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037145137786865\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303220272064209\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.156494140625\n",
            "||∇_X meta|| = 0.0016718736151233315\n",
            "ΔX norm: 1.6718737242626958e-05\n",
            "Stage 8/10:  50%|██████████████▌              | 150/300 [05:49<05:58,  2.39s/it]T Loss=2.303687572479248\n",
            "g_norm = tensor(0.0871, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036727905273438\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038995265960693\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303290843963623\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304311752319336\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.62557983398438\n",
            "||∇_X meta|| = 0.001558478455990553\n",
            "ΔX norm: 1.5584790162392892e-05\n",
            "Stage 8/10:  50%|██████████████▌              | 151/300 [05:51<06:06,  2.46s/it]T Loss=2.3046231269836426\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038330078125\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304558753967285\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030107021331787\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303452968597412\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.75645446777344\n",
            "||∇_X meta|| = 0.0017085541039705276\n",
            "ΔX norm: 1.708556192170363e-05\n",
            "Stage 8/10:  51%|██████████████▋              | 152/300 [05:54<05:53,  2.39s/it]T Loss=2.303637981414795\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303908586502075\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034160137176514\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303981304168701\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042497634887695\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.58473205566406\n",
            "||∇_X meta|| = 0.0017565106973052025\n",
            "ΔX norm: 1.756508572725579e-05\n",
            "Stage 8/10:  51%|██████████████▊              | 153/300 [05:56<05:46,  2.36s/it]T Loss=2.3030521869659424\n",
            "g_norm = tensor(0.1143, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302821636199951\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029799461364746\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025155067443848\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038508892059326\n",
            "g_norm = tensor(0.1221, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1442108154297\n",
            "||∇_X meta|| = 0.0014704809291288257\n",
            "ΔX norm: 1.4704810382681899e-05\n",
            "Stage 8/10:  51%|██████████████▉              | 154/300 [05:58<05:39,  2.33s/it]T Loss=2.3048408031463623\n",
            "g_norm = tensor(0.0833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305218458175659\n",
            "g_norm = tensor(0.0788, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304410457611084\n",
            "g_norm = tensor(0.0704, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304863691329956\n",
            "g_norm = tensor(0.0785, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047657012939453\n",
            "g_norm = tensor(0.0636, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.32333374023438\n",
            "||∇_X meta|| = 0.0015162226045504212\n",
            "ΔX norm: 1.516222891950747e-05\n",
            "Stage 8/10:  52%|██████████████▉              | 155/300 [06:00<05:34,  2.30s/it]T Loss=2.3042068481445312\n",
            "g_norm = tensor(0.0851, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304569959640503\n",
            "g_norm = tensor(0.0832, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303175687789917\n",
            "g_norm = tensor(0.0828, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035149574279785\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026747703552246\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2027130126953\n",
            "||∇_X meta|| = 0.0015201596543192863\n",
            "ΔX norm: 1.520158548373729e-05\n",
            "Stage 8/10:  52%|███████████████              | 156/300 [06:03<05:39,  2.36s/it]T Loss=2.3038241863250732\n",
            "g_norm = tensor(0.0772, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303866147994995\n",
            "g_norm = tensor(0.0766, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302893877029419\n",
            "g_norm = tensor(0.0867, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304382801055908\n",
            "g_norm = tensor(0.0703, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036556243896484\n",
            "g_norm = tensor(0.0832, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.53912353515625\n",
            "||∇_X meta|| = 0.0015931724337860942\n",
            "ΔX norm: 1.593172964931e-05\n",
            "Stage 8/10:  52%|███████████████▏             | 157/300 [06:05<05:36,  2.35s/it]T Loss=2.3035144805908203\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020031452178955\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031396865844727\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034636974334717\n",
            "g_norm = tensor(0.1334, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302385091781616\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.46994018554688\n",
            "||∇_X meta|| = 0.0017545201117172837\n",
            "ΔX norm: 1.754520599206444e-05\n",
            "Stage 8/10:  53%|███████████████▎             | 158/300 [06:08<05:33,  2.35s/it]T Loss=2.304321527481079\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046793937683105\n",
            "g_norm = tensor(0.1011, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304593563079834\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051700592041016\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036510944366455\n",
            "g_norm = tensor(0.0866, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.66708374023438\n",
            "||∇_X meta|| = 0.0014802197692915797\n",
            "ΔX norm: 1.4802195437368937e-05\n",
            "Stage 8/10:  53%|███████████████▎             | 159/300 [06:10<05:41,  2.42s/it]T Loss=2.305535316467285\n",
            "g_norm = tensor(0.1384, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304203510284424\n",
            "g_norm = tensor(0.1472, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041019439697266\n",
            "g_norm = tensor(0.1620, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303983211517334\n",
            "g_norm = tensor(0.1377, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050332069396973\n",
            "g_norm = tensor(0.1516, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.35211181640625\n",
            "||∇_X meta|| = 0.0017409076681360602\n",
            "ΔX norm: 1.7409072825103067e-05\n",
            "Stage 8/10:  53%|███████████████▍             | 160/300 [06:12<05:31,  2.37s/it]T Loss=2.30428147315979\n",
            "g_norm = tensor(0.1358, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303576946258545\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040928840637207\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038763999938965\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044347763061523\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.48095703125\n",
            "||∇_X meta|| = 0.001679785898886621\n",
            "ΔX norm: 1.6797854186734185e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 8/10:  54%|███████████████▌             | 161/300 [06:15<05:28,  2.36s/it]T Loss=2.304670572280884\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304257392883301\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045356273651123\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042242527008057\n",
            "g_norm = tensor(0.0868, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039889335632324\n",
            "g_norm = tensor(0.1080, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.60057067871094\n",
            "||∇_X meta|| = 0.0016271363710984588\n",
            "ΔX norm: 1.627133860893082e-05\n",
            "Stage 8/10:  54%|███████████████▋             | 162/300 [06:18<05:51,  2.55s/it]T Loss=2.3048603534698486\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304570436477661\n",
            "g_norm = tensor(0.1157, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305058002471924\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305842876434326\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3066763877868652\n",
            "g_norm = tensor(0.1465, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.12596130371094\n",
            "||∇_X meta|| = 0.0016168804140761495\n",
            "ΔX norm: 1.61688330990728e-05\n",
            "Stage 8/10:  54%|███████████████▊             | 163/300 [06:20<05:41,  2.49s/it]T Loss=2.3048667907714844\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032469749450684\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303323268890381\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303610324859619\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033640384674072\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.00555419921875\n",
            "||∇_X meta|| = 0.001594611327163875\n",
            "ΔX norm: 1.5946105122566223e-05\n",
            "Stage 8/10:  55%|███████████████▊             | 164/300 [06:22<05:29,  2.42s/it]T Loss=2.3037874698638916\n",
            "g_norm = tensor(0.0819, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304168224334717\n",
            "g_norm = tensor(0.0806, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304412364959717\n",
            "g_norm = tensor(0.0864, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035480976104736\n",
            "g_norm = tensor(0.0928, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304469585418701\n",
            "g_norm = tensor(0.0853, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.469482421875\n",
            "||∇_X meta|| = 0.0017386764520779252\n",
            "ΔX norm: 1.738674473017454e-05\n",
            "Stage 8/10:  55%|███████████████▉             | 165/300 [06:25<05:25,  2.41s/it]T Loss=2.304032802581787\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042445182800293\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043200969696045\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029167652130127\n",
            "g_norm = tensor(0.0846, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043792247772217\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.86276245117188\n",
            "||∇_X meta|| = 0.0015517879510298371\n",
            "ΔX norm: 1.5517884094151668e-05\n",
            "Stage 8/10:  55%|████████████████             | 166/300 [06:27<05:18,  2.38s/it]T Loss=2.3046908378601074\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305255651473999\n",
            "g_norm = tensor(0.1413, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303992509841919\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038840293884277\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304548740386963\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.20396423339844\n",
            "||∇_X meta|| = 0.0017431656597182155\n",
            "ΔX norm: 1.7431675587431528e-05\n",
            "Stage 8/10:  56%|████████████████▏            | 167/300 [06:29<05:13,  2.36s/it]T Loss=2.303748846054077\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304213047027588\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023924827575684\n",
            "g_norm = tensor(0.1221, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018271923065186\n",
            "g_norm = tensor(0.1235, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034090995788574\n",
            "g_norm = tensor(0.1153, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.69775390625\n",
            "||∇_X meta|| = 0.0013542991364374757\n",
            "ΔX norm: 1.3543010027206037e-05\n",
            "Stage 8/10:  56%|████████████████▏            | 168/300 [06:32<05:15,  2.39s/it]T Loss=2.3041939735412598\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304126739501953\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304131269454956\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035781383514404\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043017387390137\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4012451171875\n",
            "||∇_X meta|| = 0.0016387695213779807\n",
            "ΔX norm: 1.6387702999054454e-05\n",
            "Stage 8/10:  56%|████████████████▎            | 169/300 [06:34<05:24,  2.47s/it]T Loss=2.303536891937256\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034145832061768\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304004430770874\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038382530212402\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033223152160645\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2001495361328\n",
            "||∇_X meta|| = 0.0015987084480002522\n",
            "ΔX norm: 1.5987068763934076e-05\n",
            "Stage 8/10:  57%|████████████████▍            | 170/300 [06:37<05:25,  2.50s/it]T Loss=2.3040077686309814\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305610179901123\n",
            "g_norm = tensor(0.1583, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304893970489502\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301771640777588\n",
            "g_norm = tensor(0.1547, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303358554840088\n",
            "g_norm = tensor(0.1285, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.59457397460938\n",
            "||∇_X meta|| = 0.0015439307317137718\n",
            "ΔX norm: 1.5439298294950277e-05\n",
            "Stage 8/10:  57%|████████████████▌            | 171/300 [06:39<05:20,  2.48s/it]T Loss=2.3043384552001953\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304076671600342\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040871620178223\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304269313812256\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041672706604004\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.90447998046875\n",
            "||∇_X meta|| = 0.0015320496167987585\n",
            "ΔX norm: 1.532050737296231e-05\n",
            "Stage 8/10:  57%|████████████████▋            | 172/300 [06:42<05:28,  2.56s/it]T Loss=2.305711030960083\n",
            "g_norm = tensor(0.1291, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044655323028564\n",
            "g_norm = tensor(0.1897, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051533699035645\n",
            "g_norm = tensor(0.1911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045401573181152\n",
            "g_norm = tensor(0.1775, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303666591644287\n",
            "g_norm = tensor(0.1870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.34703063964844\n",
            "||∇_X meta|| = 0.0017271462129428983\n",
            "ΔX norm: 1.72714553627884e-05\n",
            "Stage 8/10:  58%|████████████████▋            | 173/300 [06:45<05:19,  2.51s/it]T Loss=2.3037431240081787\n",
            "g_norm = tensor(0.1352, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037009239196777\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303562641143799\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039071559906006\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032894134521484\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6754150390625\n",
            "||∇_X meta|| = 0.0016949179116636515\n",
            "ΔX norm: 1.6949190467130393e-05\n",
            "Stage 8/10:  58%|████████████████▊            | 174/300 [06:47<05:25,  2.58s/it]T Loss=2.304342746734619\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303457736968994\n",
            "g_norm = tensor(0.0902, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304506540298462\n",
            "g_norm = tensor(0.0876, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039238452911377\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303947687149048\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.29824829101562\n",
            "||∇_X meta|| = 0.0016585877165198326\n",
            "ΔX norm: 1.658586370467674e-05\n",
            "Stage 8/10:  58%|████████████████▉            | 175/300 [06:50<05:28,  2.63s/it]T Loss=2.304271697998047\n",
            "g_norm = tensor(0.1488, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30379581451416\n",
            "g_norm = tensor(0.1319, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038694858551025\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304419994354248\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040528297424316\n",
            "g_norm = tensor(0.1331, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4230194091797\n",
            "||∇_X meta|| = 0.001442521926946938\n",
            "ΔX norm: 1.4425248082261533e-05\n",
            "Stage 8/10:  59%|█████████████████            | 176/300 [06:52<05:17,  2.56s/it]T Loss=2.3040168285369873\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029863834381104\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303823471069336\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303739309310913\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021936416625977\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.62998962402344\n",
            "||∇_X meta|| = 0.0015271208249032497\n",
            "ΔX norm: 1.5271214579115622e-05\n",
            "Stage 8/10:  59%|█████████████████            | 177/300 [06:55<04:55,  2.40s/it]T Loss=2.3031516075134277\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035919666290283\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035664558410645\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027729988098145\n",
            "g_norm = tensor(0.0855, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042471408843994\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.30142211914062\n",
            "||∇_X meta|| = 0.0017362519865855575\n",
            "ΔX norm: 1.736251579131931e-05\n",
            "Stage 8/10:  59%|█████████████████▏           | 178/300 [06:56<04:35,  2.26s/it]T Loss=2.3043103218078613\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301758050918579\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302680730819702\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039255142211914\n",
            "g_norm = tensor(0.1473, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040032386779785\n",
            "g_norm = tensor(0.1454, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.320556640625\n",
            "||∇_X meta|| = 0.00152269855607301\n",
            "ΔX norm: 1.5226994946715422e-05\n",
            "Stage 8/10:  60%|█████████████████▎           | 179/300 [06:58<04:19,  2.14s/it]T Loss=2.3033974170684814\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033642768859863\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034636974334717\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031561374664307\n",
            "g_norm = tensor(0.1118, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303740978240967\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.75778198242188\n",
            "||∇_X meta|| = 0.0015073079848662019\n",
            "ΔX norm: 1.5073079339344986e-05\n",
            "Stage 8/10:  60%|█████████████████▍           | 180/300 [07:00<04:08,  2.07s/it]T Loss=2.303882122039795\n",
            "g_norm = tensor(0.0733, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304049015045166\n",
            "g_norm = tensor(0.0707, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303898334503174\n",
            "g_norm = tensor(0.0751, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303830862045288\n",
            "g_norm = tensor(0.0754, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044066429138184\n",
            "g_norm = tensor(0.0740, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.55812072753906\n",
            "||∇_X meta|| = 0.0014893676852807403\n",
            "ΔX norm: 1.4893675142957363e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 8/10:  60%|█████████████████▍           | 181/300 [07:02<04:01,  2.03s/it]T Loss=2.303807020187378\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304185390472412\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304525136947632\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043971061706543\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304513931274414\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3259735107422\n",
            "||∇_X meta|| = 0.0015975148417055607\n",
            "ΔX norm: 1.5975145288393833e-05\n",
            "Stage 8/10:  61%|█████████████████▌           | 182/300 [07:05<04:12,  2.14s/it]T Loss=2.3036651611328125\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049404621124268\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056793212890625\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304720401763916\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050382137298584\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.187744140625\n",
            "||∇_X meta|| = 0.0018257794436067343\n",
            "ΔX norm: 1.8257809642818756e-05\n",
            "Stage 8/10:  61%|█████████████████▋           | 183/300 [07:07<04:11,  2.15s/it]T Loss=2.3033618927001953\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303595781326294\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038265705108643\n",
            "g_norm = tensor(0.1022, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304004430770874\n",
            "g_norm = tensor(0.0902, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303302764892578\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8286895751953\n",
            "||∇_X meta|| = 0.0016182421240955591\n",
            "ΔX norm: 1.6182419130927883e-05\n",
            "Stage 8/10:  61%|█████████████████▊           | 184/300 [07:09<04:08,  2.14s/it]T Loss=2.304537296295166\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054757118225098\n",
            "g_norm = tensor(0.1462, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041179180145264\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039352893829346\n",
            "g_norm = tensor(0.1253, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056576251983643\n",
            "g_norm = tensor(0.1556, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.7762451171875\n",
            "||∇_X meta|| = 0.0017763531068339944\n",
            "ΔX norm: 1.7763528376235627e-05\n",
            "Stage 8/10:  62%|█████████████████▉           | 185/300 [07:11<04:00,  2.09s/it]T Loss=2.302980422973633\n",
            "g_norm = tensor(0.1386, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048932552337646\n",
            "g_norm = tensor(0.1493, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302968740463257\n",
            "g_norm = tensor(0.1403, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035190105438232\n",
            "g_norm = tensor(0.1692, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029396533966064\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.29733276367188\n",
            "||∇_X meta|| = 0.0015363978454843163\n",
            "ΔX norm: 1.5364001228590496e-05\n",
            "Stage 8/10:  62%|█████████████████▉           | 186/300 [07:13<03:53,  2.05s/it]T Loss=2.303440570831299\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030247688293457\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303398609161377\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045578002929688\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30332350730896\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.76431274414062\n",
            "||∇_X meta|| = 0.0016309202183037996\n",
            "ΔX norm: 1.630918268347159e-05\n",
            "Stage 8/10:  62%|██████████████████           | 187/300 [07:15<04:08,  2.20s/it]T Loss=2.302711009979248\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042514324188232\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30509614944458\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052659034729004\n",
            "g_norm = tensor(0.1348, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031165599823\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0458526611328\n",
            "||∇_X meta|| = 0.0014755952870473266\n",
            "ΔX norm: 1.4755953998246696e-05\n",
            "Stage 8/10:  63%|██████████████████▏          | 188/300 [07:17<04:02,  2.16s/it]T Loss=2.303828477859497\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038253784179688\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048501014709473\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303696632385254\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040969371795654\n",
            "g_norm = tensor(0.1278, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.50831604003906\n",
            "||∇_X meta|| = 0.001560838776640594\n",
            "ΔX norm: 1.5608369722031057e-05\n",
            "Stage 8/10:  63%|██████████████████▎          | 189/300 [07:19<03:54,  2.11s/it]T Loss=2.304692506790161\n",
            "g_norm = tensor(0.1465, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050150871276855\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037149906158447\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038277626037598\n",
            "g_norm = tensor(0.1320, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303159713745117\n",
            "g_norm = tensor(0.1328, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7777557373047\n",
            "||∇_X meta|| = 0.0017204111209139228\n",
            "ΔX norm: 1.7204138202941976e-05\n",
            "Stage 8/10:  63%|██████████████████▎          | 190/300 [07:21<03:48,  2.07s/it]T Loss=2.301450252532959\n",
            "g_norm = tensor(0.1344, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303126811981201\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301246404647827\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042938709259033\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301238536834717\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.87208557128906\n",
            "||∇_X meta|| = 0.0015425694873556495\n",
            "ΔX norm: 1.542571044410579e-05\n",
            "Stage 8/10:  64%|██████████████████▍          | 191/300 [07:23<03:42,  2.04s/it]T Loss=2.304619312286377\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303576707839966\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303574562072754\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046231269836426\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030407428741455\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.44105529785156\n",
            "||∇_X meta|| = 0.0015536242863163352\n",
            "ΔX norm: 1.5536221326328814e-05\n",
            "Stage 8/10:  64%|██████████████████▌          | 192/300 [07:25<03:39,  2.03s/it]T Loss=2.304088830947876\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037447929382324\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303701400756836\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040530681610107\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30374813079834\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.59669494628906\n",
            "||∇_X meta|| = 0.001506084925495088\n",
            "ΔX norm: 1.506085664004786e-05\n",
            "Stage 8/10:  64%|██████████████████▋          | 193/300 [07:27<03:38,  2.04s/it]T Loss=2.3040056228637695\n",
            "g_norm = tensor(0.0855, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303337812423706\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036949634552\n",
            "g_norm = tensor(0.0799, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30377197265625\n",
            "g_norm = tensor(0.0765, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037819862365723\n",
            "g_norm = tensor(0.0790, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3158416748047\n",
            "||∇_X meta|| = 0.0014959389809519053\n",
            "ΔX norm: 1.4959405234549195e-05\n",
            "Stage 8/10:  65%|██████████████████▊          | 194/300 [07:29<03:31,  2.00s/it]T Loss=2.3040599822998047\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044681549072266\n",
            "g_norm = tensor(0.0771, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035671710968018\n",
            "g_norm = tensor(0.0821, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304070234298706\n",
            "g_norm = tensor(0.0846, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303607225418091\n",
            "g_norm = tensor(0.0775, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.3954315185547\n",
            "||∇_X meta|| = 0.001799458870664239\n",
            "ΔX norm: 1.799461097107269e-05\n",
            "Stage 8/10:  65%|██████████████████▊          | 195/300 [07:31<03:26,  1.97s/it]T Loss=2.303734302520752\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303467273712158\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30412220954895\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303473949432373\n",
            "g_norm = tensor(0.0871, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039660453796387\n",
            "g_norm = tensor(0.0928, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6665802001953\n",
            "||∇_X meta|| = 0.0016074974555522203\n",
            "ΔX norm: 1.607497688382864e-05\n",
            "Stage 8/10:  65%|██████████████████▉          | 196/300 [07:33<03:24,  1.96s/it]T Loss=2.3053882122039795\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042819499969482\n",
            "g_norm = tensor(0.0816, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050026893615723\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037495613098145\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303954839706421\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.70867919921875\n",
            "||∇_X meta|| = 0.0015402529388666153\n",
            "ΔX norm: 1.5402520148199983e-05\n",
            "Stage 8/10:  66%|███████████████████          | 197/300 [07:35<03:27,  2.02s/it]T Loss=2.304539203643799\n",
            "g_norm = tensor(0.1406, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044896125793457\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303907632827759\n",
            "g_norm = tensor(0.1388, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050544261932373\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304361343383789\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.48861694335938\n",
            "||∇_X meta|| = 0.0014953588834032416\n",
            "ΔX norm: 1.4953596291888971e-05\n",
            "Stage 8/10:  66%|███████████████████▏         | 198/300 [07:37<03:23,  1.99s/it]T Loss=2.3036835193634033\n",
            "g_norm = tensor(0.1637, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305445909500122\n",
            "g_norm = tensor(0.1532, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305488348007202\n",
            "g_norm = tensor(0.1515, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3060953617095947\n",
            "g_norm = tensor(0.1992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045191764831543\n",
            "g_norm = tensor(0.1598, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4679718017578\n",
            "||∇_X meta|| = 0.0014624895993620157\n",
            "ΔX norm: 1.462491309212055e-05\n",
            "Stage 8/10:  66%|███████████████████▏         | 199/300 [07:39<03:19,  1.97s/it]T Loss=2.3039162158966064\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043086528778076\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041493892669678\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045151233673096\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304318428039551\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.03411865234375\n",
            "||∇_X meta|| = 0.0015840304549783468\n",
            "ΔX norm: 1.5840307241887785e-05\n",
            "Stage 8/10:  67%|███████████████████▎         | 200/300 [07:41<03:17,  1.97s/it]T Loss=2.303522825241089\n",
            "g_norm = tensor(0.0917, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304591417312622\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303682327270508\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035943508148193\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303788661956787\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.53704833984375\n",
            "||∇_X meta|| = 0.0016260006232187152\n",
            "ΔX norm: 1.6260019037872553e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 8/10:  67%|███████████████████▍         | 201/300 [07:43<03:17,  2.00s/it]T Loss=2.3038010597229004\n",
            "g_norm = tensor(0.1345, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044352531433105\n",
            "g_norm = tensor(0.1349, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033363819122314\n",
            "g_norm = tensor(0.1326, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302854061126709\n",
            "g_norm = tensor(0.1481, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303321361541748\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.6861114501953\n",
            "||∇_X meta|| = 0.001548592932522297\n",
            "ΔX norm: 1.548592626932077e-05\n",
            "Stage 8/10:  67%|███████████████████▌         | 202/300 [07:46<03:38,  2.23s/it]T Loss=2.303826332092285\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303886890411377\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039562702178955\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034515380859375\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304597854614258\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.41001892089844\n",
            "||∇_X meta|| = 0.0014661340974271297\n",
            "ΔX norm: 1.466135563532589e-05\n",
            "Stage 8/10:  68%|███████████████████▌         | 203/300 [07:48<03:35,  2.23s/it]T Loss=2.3037986755371094\n",
            "g_norm = tensor(0.0768, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304069995880127\n",
            "g_norm = tensor(0.0683, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043603897094727\n",
            "g_norm = tensor(0.0752, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304157257080078\n",
            "g_norm = tensor(0.0737, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043582439422607\n",
            "g_norm = tensor(0.0814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.16177368164062\n",
            "||∇_X meta|| = 0.0015303436666727066\n",
            "ΔX norm: 1.5303443433367647e-05\n",
            "Stage 8/10:  68%|███████████████████▋         | 204/300 [07:50<03:25,  2.14s/it]T Loss=2.3022749423980713\n",
            "g_norm = tensor(0.1317, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303941249847412\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303912878036499\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303361415863037\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039307594299316\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.58885192871094\n",
            "||∇_X meta|| = 0.0016705711605027318\n",
            "ΔX norm: 1.6705696907592937e-05\n",
            "Stage 8/10:  68%|███████████████████▊         | 205/300 [07:52<03:15,  2.06s/it]T Loss=2.30391526222229\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041558265686035\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040268421173096\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304488182067871\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303823471069336\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.90252685546875\n",
            "||∇_X meta|| = 0.0015363112324848771\n",
            "ΔX norm: 1.5363111742772162e-05\n",
            "Stage 8/10:  69%|███████████████████▉         | 206/300 [07:54<03:07,  2.00s/it]T Loss=2.3034255504608154\n",
            "g_norm = tensor(0.0797, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303208827972412\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031561374664307\n",
            "g_norm = tensor(0.0817, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303748846054077\n",
            "g_norm = tensor(0.0793, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303043842315674\n",
            "g_norm = tensor(0.0787, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7664794921875\n",
            "||∇_X meta|| = 0.0013857223093509674\n",
            "ΔX norm: 1.3857216799806338e-05\n",
            "Stage 8/10:  69%|████████████████████         | 207/300 [07:56<03:04,  1.99s/it]T Loss=2.3035531044006348\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044915199279785\n",
            "g_norm = tensor(0.1392, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036975860595703\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042922019958496\n",
            "g_norm = tensor(0.1323, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031201362609863\n",
            "g_norm = tensor(0.1473, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.44561767578125\n",
            "||∇_X meta|| = 0.001446892274543643\n",
            "ΔX norm: 1.4468906556430738e-05\n",
            "Stage 8/10:  69%|████████████████████         | 208/300 [07:58<03:01,  1.97s/it]T Loss=2.3028347492218018\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301259756088257\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303962230682373\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040452003479004\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041160106658936\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9683380126953\n",
            "||∇_X meta|| = 0.0016112980665639043\n",
            "ΔX norm: 1.6113008314277977e-05\n",
            "Stage 8/10:  70%|████████████████████▏        | 209/300 [08:00<03:19,  2.19s/it]T Loss=2.3032054901123047\n",
            "g_norm = tensor(0.0805, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042197227478027\n",
            "g_norm = tensor(0.0868, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044307231903076\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039278984069824\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037426471710205\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.52777099609375\n",
            "||∇_X meta|| = 0.0015460641589015722\n",
            "ΔX norm: 1.54606514115585e-05\n",
            "Stage 8/10:  70%|████████████████████▎        | 210/300 [08:03<03:25,  2.28s/it]T Loss=2.3040008544921875\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046622276306152\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026413917541504\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035950660705566\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030483722686768\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.69537353515625\n",
            "||∇_X meta|| = 0.0015126377111300826\n",
            "ΔX norm: 1.5126366633921862e-05\n",
            "Stage 8/10:  70%|████████████████████▍        | 211/300 [08:05<03:24,  2.30s/it]T Loss=2.304090976715088\n",
            "g_norm = tensor(0.1363, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046631813049316\n",
            "g_norm = tensor(0.1490, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303925037384033\n",
            "g_norm = tensor(0.1316, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050262928009033\n",
            "g_norm = tensor(0.1520, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302886962890625\n",
            "g_norm = tensor(0.1368, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3616943359375\n",
            "||∇_X meta|| = 0.001608744147233665\n",
            "ΔX norm: 1.608745333214756e-05\n",
            "Stage 8/10:  71%|████████████████████▍        | 212/300 [08:08<03:23,  2.32s/it]T Loss=2.3038504123687744\n",
            "g_norm = tensor(0.0757, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043246269226074\n",
            "g_norm = tensor(0.0871, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039088249206543\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039040565490723\n",
            "g_norm = tensor(0.0931, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040921688079834\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.05479431152344\n",
            "||∇_X meta|| = 0.0014872411265969276\n",
            "ΔX norm: 1.4872426618239842e-05\n",
            "Stage 8/10:  71%|████████████████████▌        | 213/300 [08:10<03:19,  2.29s/it]T Loss=2.304701566696167\n",
            "g_norm = tensor(0.0835, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304025173187256\n",
            "g_norm = tensor(0.0741, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304936170578003\n",
            "g_norm = tensor(0.0785, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045825958251953\n",
            "g_norm = tensor(0.0816, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303469181060791\n",
            "g_norm = tensor(0.0707, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.25564575195312\n",
            "||∇_X meta|| = 0.0015524595510214567\n",
            "ΔX norm: 1.5524617992923595e-05\n",
            "Stage 8/10:  71%|████████████████████▋        | 214/300 [08:12<03:17,  2.29s/it]T Loss=2.303142547607422\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303478717803955\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302788257598877\n",
            "g_norm = tensor(0.1296, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033576011657715\n",
            "g_norm = tensor(0.1307, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026232719421387\n",
            "g_norm = tensor(0.1434, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.76629638671875\n",
            "||∇_X meta|| = 0.001675596460700035\n",
            "ΔX norm: 1.675597195571754e-05\n",
            "Stage 8/10:  72%|████████████████████▊        | 215/300 [08:15<03:35,  2.54s/it]T Loss=2.304666042327881\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304716110229492\n",
            "g_norm = tensor(0.1320, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058061599731445\n",
            "g_norm = tensor(0.1324, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304330348968506\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050284385681152\n",
            "g_norm = tensor(0.1376, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.84713745117188\n",
            "||∇_X meta|| = 0.0014840540243312716\n",
            "ΔX norm: 1.4840521544101648e-05\n",
            "Stage 8/10:  72%|████████████████████▉        | 216/300 [08:18<03:33,  2.55s/it]T Loss=2.3038487434387207\n",
            "g_norm = tensor(0.1525, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039777278900146\n",
            "g_norm = tensor(0.1460, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302819013595581\n",
            "g_norm = tensor(0.1353, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039729595184326\n",
            "g_norm = tensor(0.1556, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048088550567627\n",
            "g_norm = tensor(0.1437, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9790496826172\n",
            "||∇_X meta|| = 0.0015586151275783777\n",
            "ΔX norm: 1.558614894747734e-05\n",
            "Stage 8/10:  72%|████████████████████▉        | 217/300 [08:20<03:23,  2.45s/it]T Loss=2.303867816925049\n",
            "g_norm = tensor(0.1271, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027806282043457\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028299808502197\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034329414367676\n",
            "g_norm = tensor(0.1219, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041977882385254\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.40870666503906\n",
            "||∇_X meta|| = 0.001588668441399932\n",
            "ΔX norm: 1.588669874763582e-05\n",
            "Stage 8/10:  73%|█████████████████████        | 218/300 [08:22<03:20,  2.44s/it]T Loss=2.3029513359069824\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036866188049316\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035969734191895\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034555912017822\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304003953933716\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.02194213867188\n",
            "||∇_X meta|| = 0.001480670878663659\n",
            "ΔX norm: 1.4806693798163906e-05\n",
            "Stage 8/10:  73%|█████████████████████▏       | 219/300 [08:25<03:26,  2.55s/it]T Loss=2.3044490814208984\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048510551452637\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042101860046387\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042092323303223\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047726154327393\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.87680053710938\n",
            "||∇_X meta|| = 0.0016416074940934777\n",
            "ΔX norm: 1.6416066500823945e-05\n",
            "Stage 8/10:  73%|█████████████████████▎       | 220/300 [08:28<03:16,  2.46s/it]T Loss=2.302894115447998\n",
            "g_norm = tensor(0.0831, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042707443237305\n",
            "g_norm = tensor(0.0837, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030171394348145\n",
            "g_norm = tensor(0.0736, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035731315612793\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033652305603027\n",
            "g_norm = tensor(0.0860, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.06463623046875\n",
            "||∇_X meta|| = 0.0014886020217090845\n",
            "ΔX norm: 1.4886006283632014e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 8/10:  74%|█████████████████████▎       | 221/300 [08:30<03:08,  2.39s/it]T Loss=2.3025119304656982\n",
            "g_norm = tensor(0.1312, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018550872802734\n",
            "g_norm = tensor(0.1275, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303257465362549\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031468391418457\n",
            "g_norm = tensor(0.1444, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303353786468506\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.95924377441406\n",
            "||∇_X meta|| = 0.001480465056374669\n",
            "ΔX norm: 1.4804632883169688e-05\n",
            "Stage 8/10:  74%|█████████████████████▍       | 222/300 [08:32<03:08,  2.42s/it]T Loss=2.3031868934631348\n",
            "g_norm = tensor(0.1257, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027496337890625\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036439418792725\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044538497924805\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302927255630493\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5270233154297\n",
            "||∇_X meta|| = 0.0014903596602380276\n",
            "ΔX norm: 1.4903591363690794e-05\n",
            "Stage 8/10:  74%|█████████████████████▌       | 223/300 [08:35<03:06,  2.42s/it]T Loss=2.303887128829956\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303460121154785\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303654193878174\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036885261535645\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039631843566895\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.28024291992188\n",
            "||∇_X meta|| = 0.0015441443538293242\n",
            "ΔX norm: 1.5441457435372286e-05\n",
            "Stage 8/10:  75%|█████████████████████▋       | 224/300 [08:37<03:01,  2.39s/it]T Loss=2.305070400238037\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304661273956299\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303875207901001\n",
            "g_norm = tensor(0.0878, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043503761291504\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041017055511475\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =233.34768676757812\n",
            "||∇_X meta|| = 0.0015136516885831952\n",
            "ΔX norm: 1.5136539332161192e-05\n",
            "Stage 8/10:  75%|█████████████████████▊       | 225/300 [08:40<03:10,  2.55s/it]T Loss=2.3029110431671143\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303157329559326\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041393756866455\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039753437042236\n",
            "g_norm = tensor(0.0947, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031764030456543\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.6271209716797\n",
            "||∇_X meta|| = 0.0014679437736049294\n",
            "ΔX norm: 1.4679451851407066e-05\n",
            "Stage 8/10:  75%|█████████████████████▊       | 226/300 [08:42<03:04,  2.50s/it]T Loss=2.303107738494873\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036935329437256\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036952018737793\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303173303604126\n",
            "g_norm = tensor(0.1258, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028883934020996\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.640869140625\n",
            "||∇_X meta|| = 0.0014526202576234937\n",
            "ΔX norm: 1.4526195627695415e-05\n",
            "Stage 8/10:  76%|█████████████████████▉       | 227/300 [08:45<03:01,  2.49s/it]T Loss=2.304490327835083\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036980628967285\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305305242538452\n",
            "g_norm = tensor(0.0960, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034658432006836\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305241107940674\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.79974365234375\n",
            "||∇_X meta|| = 0.001606116071343422\n",
            "ΔX norm: 1.606114165042527e-05\n",
            "Stage 8/10:  76%|██████████████████████       | 228/300 [08:47<02:56,  2.45s/it]T Loss=2.303581714630127\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304129123687744\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302929401397705\n",
            "g_norm = tensor(0.1384, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037161827087402\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044934272766113\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2237548828125\n",
            "||∇_X meta|| = 0.001497219200246036\n",
            "ΔX norm: 1.4972208191466052e-05\n",
            "Stage 8/10:  76%|██████████████████████▏      | 229/300 [08:49<02:51,  2.41s/it]T Loss=2.303628444671631\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052868843078613\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033337593078613\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303319215774536\n",
            "g_norm = tensor(0.1153, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304169178009033\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.87435913085938\n",
            "||∇_X meta|| = 0.0016417508013546467\n",
            "ΔX norm: 1.6417503502452746e-05\n",
            "Stage 8/10:  77%|██████████████████████▏      | 230/300 [08:52<02:46,  2.38s/it]T Loss=2.305084466934204\n",
            "g_norm = tensor(0.2337, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038721084594727\n",
            "g_norm = tensor(0.2224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049464225769043\n",
            "g_norm = tensor(0.1773, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041911125183105\n",
            "g_norm = tensor(0.1661, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302186965942383\n",
            "g_norm = tensor(0.2054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.83734130859375\n",
            "||∇_X meta|| = 0.0018867297330871224\n",
            "ΔX norm: 1.8867292965296656e-05\n",
            "Stage 8/10:  77%|██████████████████████▎      | 231/300 [08:54<02:42,  2.36s/it]T Loss=2.304507255554199\n",
            "g_norm = tensor(0.1493, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304090976715088\n",
            "g_norm = tensor(0.1325, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044981956481934\n",
            "g_norm = tensor(0.1423, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302443265914917\n",
            "g_norm = tensor(0.1443, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302884340286255\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.25640869140625\n",
            "||∇_X meta|| = 0.0017215375555679202\n",
            "ΔX norm: 1.7215370462508872e-05\n",
            "Stage 8/10:  77%|██████████████████████▍      | 232/300 [08:56<02:38,  2.33s/it]T Loss=2.303636074066162\n",
            "g_norm = tensor(0.0727, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303889036178589\n",
            "g_norm = tensor(0.0700, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304811477661133\n",
            "g_norm = tensor(0.0633, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304267644882202\n",
            "g_norm = tensor(0.0759, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037796020507812\n",
            "g_norm = tensor(0.0696, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.931640625\n",
            "||∇_X meta|| = 0.001555741997435689\n",
            "ΔX norm: 1.555743619974237e-05\n",
            "Stage 8/10:  78%|██████████████████████▌      | 233/300 [08:59<02:34,  2.30s/it]T Loss=2.302915096282959\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018341064453125\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042752742767334\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024773597717285\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30336856842041\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.20709228515625\n",
            "||∇_X meta|| = 0.0015901814913377166\n",
            "ΔX norm: 1.5901809092611074e-05\n",
            "Stage 8/10:  78%|██████████████████████▌      | 234/300 [09:01<02:31,  2.30s/it]T Loss=2.304548501968384\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304063081741333\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303506374359131\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038768768310547\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305067300796509\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.50547790527344\n",
            "||∇_X meta|| = 0.001641024718992412\n",
            "ΔX norm: 1.6410260286647826e-05\n",
            "Stage 8/10:  78%|██████████████████████▋      | 235/300 [09:03<02:27,  2.27s/it]T Loss=2.304978370666504\n",
            "g_norm = tensor(0.1403, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042948246002197\n",
            "g_norm = tensor(0.1609, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049590587615967\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044145107269287\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037829399108887\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.6347198486328\n",
            "||∇_X meta|| = 0.0015369676984846592\n",
            "ΔX norm: 1.5369680113508366e-05\n",
            "Stage 8/10:  79%|██████████████████████▊      | 236/300 [09:06<02:30,  2.34s/it]T Loss=2.303497552871704\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050448894500732\n",
            "g_norm = tensor(0.1257, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038549423217773\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304924488067627\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043770790100098\n",
            "g_norm = tensor(0.0868, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.05014038085938\n",
            "||∇_X meta|| = 0.0016950115095824003\n",
            "ΔX norm: 1.6950136341620237e-05\n",
            "Stage 8/10:  79%|██████████████████████▉      | 237/300 [09:08<02:29,  2.37s/it]T Loss=2.3037567138671875\n",
            "g_norm = tensor(0.0848, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303654909133911\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039774894714355\n",
            "g_norm = tensor(0.0760, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303781032562256\n",
            "g_norm = tensor(0.0683, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036563396453857\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.75567626953125\n",
            "||∇_X meta|| = 0.0015327363507822156\n",
            "ΔX norm: 1.53273758769501e-05\n",
            "Stage 8/10:  79%|███████████████████████      | 238/300 [09:11<02:37,  2.54s/it]T Loss=2.3029537200927734\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032889366149902\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304091453552246\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303389310836792\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033227920532227\n",
            "g_norm = tensor(0.0947, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5830078125\n",
            "||∇_X meta|| = 0.0017274394631385803\n",
            "ΔX norm: 1.7274382116738707e-05\n",
            "Stage 8/10:  80%|███████████████████████      | 239/300 [09:13<02:35,  2.56s/it]T Loss=2.30515718460083\n",
            "g_norm = tensor(0.1396, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041837215423584\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039944171905518\n",
            "g_norm = tensor(0.1331, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038458824157715\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030781745910645\n",
            "g_norm = tensor(0.1338, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.95249938964844\n",
            "||∇_X meta|| = 0.0015764712588861585\n",
            "ΔX norm: 1.5764693671371788e-05\n",
            "Stage 8/10:  80%|███████████████████████▏     | 240/300 [09:16<02:37,  2.62s/it]T Loss=2.306133270263672\n",
            "g_norm = tensor(0.1417, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032994270324707\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305910348892212\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044605255126953\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053135871887207\n",
            "g_norm = tensor(0.1391, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.91029357910156\n",
            "||∇_X meta|| = 0.0015665730461478233\n",
            "ΔX norm: 1.566574974276591e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 8/10:  80%|███████████████████████▎     | 241/300 [09:19<02:31,  2.56s/it]T Loss=2.303241729736328\n",
            "g_norm = tensor(0.1304, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037400245666504\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040459156036377\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032822608947754\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034615516662598\n",
            "g_norm = tensor(0.1312, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.3567352294922\n",
            "||∇_X meta|| = 0.0016958840424194932\n",
            "ΔX norm: 1.695882747299038e-05\n",
            "Stage 8/10:  81%|███████████████████████▍     | 242/300 [09:21<02:29,  2.57s/it]T Loss=2.3035900592803955\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043224811553955\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305842638015747\n",
            "g_norm = tensor(0.1295, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303586959838867\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305062770843506\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.26614379882812\n",
            "||∇_X meta|| = 0.001637944020330906\n",
            "ΔX norm: 1.637941022636369e-05\n",
            "Stage 8/10:  81%|███████████████████████▍     | 243/300 [09:24<02:26,  2.57s/it]T Loss=2.304182767868042\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045597076416016\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30364990234375\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045036792755127\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045732975006104\n",
            "g_norm = tensor(0.0790, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9112091064453\n",
            "||∇_X meta|| = 0.001650979625992477\n",
            "ΔX norm: 1.6509780834894627e-05\n",
            "Stage 8/10:  81%|███████████████████████▌     | 244/300 [09:26<02:19,  2.49s/it]T Loss=2.3050856590270996\n",
            "g_norm = tensor(0.1699, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306685447692871\n",
            "g_norm = tensor(0.1884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304506540298462\n",
            "g_norm = tensor(0.1514, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055758476257324\n",
            "g_norm = tensor(0.1724, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049685955047607\n",
            "g_norm = tensor(0.1631, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.52862548828125\n",
            "||∇_X meta|| = 0.00147242599632591\n",
            "ΔX norm: 1.47242535604164e-05\n",
            "Stage 8/10:  82%|███████████████████████▋     | 245/300 [09:28<02:13,  2.44s/it]T Loss=2.3025074005126953\n",
            "g_norm = tensor(0.1221, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026137351989746\n",
            "g_norm = tensor(0.1433, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302974224090576\n",
            "g_norm = tensor(0.1426, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302546501159668\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029704093933105\n",
            "g_norm = tensor(0.1470, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6793975830078\n",
            "||∇_X meta|| = 0.0014422958483919501\n",
            "ΔX norm: 1.4422946151171345e-05\n",
            "Stage 8/10:  82%|███████████████████████▊     | 246/300 [09:31<02:09,  2.39s/it]T Loss=2.3044068813323975\n",
            "g_norm = tensor(0.0884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051140308380127\n",
            "g_norm = tensor(0.1163, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304542064666748\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305189371109009\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044583797454834\n",
            "g_norm = tensor(0.1183, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.87606811523438\n",
            "||∇_X meta|| = 0.0015493846731260419\n",
            "ΔX norm: 1.549385160615202e-05\n",
            "Stage 8/10:  82%|███████████████████████▉     | 247/300 [09:33<02:05,  2.36s/it]T Loss=2.3031086921691895\n",
            "g_norm = tensor(0.0801, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037781715393066\n",
            "g_norm = tensor(0.0760, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041481971740723\n",
            "g_norm = tensor(0.0787, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036675453186035\n",
            "g_norm = tensor(0.0787, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037350177764893\n",
            "g_norm = tensor(0.0761, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.09327697753906\n",
            "||∇_X meta|| = 0.0016090297140181065\n",
            "ΔX norm: 1.609032005944755e-05\n",
            "Stage 8/10:  83%|███████████████████████▉     | 248/300 [09:35<02:03,  2.37s/it]T Loss=2.3043763637542725\n",
            "g_norm = tensor(0.0778, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055427074432373\n",
            "g_norm = tensor(0.0832, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303767442703247\n",
            "g_norm = tensor(0.0728, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304121255874634\n",
            "g_norm = tensor(0.0800, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032336235046387\n",
            "g_norm = tensor(0.0827, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.18759155273438\n",
            "||∇_X meta|| = 0.0015052913222461939\n",
            "ΔX norm: 1.5052907656354364e-05\n",
            "Stage 8/10:  83%|████████████████████████     | 249/300 [09:38<01:59,  2.35s/it]T Loss=2.3045296669006348\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037874698638916\n",
            "g_norm = tensor(0.0919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303391218185425\n",
            "g_norm = tensor(0.0933, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033335208892822\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031859397888184\n",
            "g_norm = tensor(0.0847, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5751953125\n",
            "||∇_X meta|| = 0.0017008582362905145\n",
            "ΔX norm: 1.7008600480039604e-05\n",
            "Stage 8/10:  83%|████████████████████████▏    | 250/300 [09:41<02:06,  2.52s/it]T Loss=2.3033106327056885\n",
            "g_norm = tensor(0.0766, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043949604034424\n",
            "g_norm = tensor(0.0923, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304236888885498\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035168647766113\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30450701713562\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.93878173828125\n",
            "||∇_X meta|| = 0.0015546507202088833\n",
            "ΔX norm: 1.5546491340501234e-05\n",
            "Stage 8/10:  84%|████████████████████████▎    | 251/300 [09:43<02:06,  2.58s/it]T Loss=2.30419921875\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025002479553223\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024184703826904\n",
            "g_norm = tensor(0.1537, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304325580596924\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032166957855225\n",
            "g_norm = tensor(0.1350, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.47891235351562\n",
            "||∇_X meta|| = 0.0014869414735585451\n",
            "ΔX norm: 1.4869408005324658e-05\n",
            "Stage 8/10:  84%|████████████████████████▎    | 252/300 [09:46<02:02,  2.55s/it]T Loss=2.3040554523468018\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052120208740234\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303706645965576\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043532371520996\n",
            "g_norm = tensor(0.1303, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046908378601074\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.160400390625\n",
            "||∇_X meta|| = 0.0015425338642671704\n",
            "ΔX norm: 1.542533573228866e-05\n",
            "Stage 8/10:  84%|████████████████████████▍    | 253/300 [09:48<01:56,  2.48s/it]T Loss=2.3034980297088623\n",
            "g_norm = tensor(0.0759, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303269863128662\n",
            "g_norm = tensor(0.0814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303595781326294\n",
            "g_norm = tensor(0.0684, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303605556488037\n",
            "g_norm = tensor(0.0783, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303886890411377\n",
            "g_norm = tensor(0.0792, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.54150390625\n",
            "||∇_X meta|| = 0.0015565232606604695\n",
            "ΔX norm: 1.5565237845294178e-05\n",
            "Stage 8/10:  85%|████████████████████████▌    | 254/300 [09:51<01:54,  2.49s/it]T Loss=2.3050222396850586\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30322527885437\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30332612991333\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020732402801514\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034141063690186\n",
            "g_norm = tensor(0.1213, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.83274841308594\n",
            "||∇_X meta|| = 0.0016044577350839972\n",
            "ΔX norm: 1.6044552467064932e-05\n",
            "Stage 8/10:  85%|████████████████████████▋    | 255/300 [09:53<01:48,  2.41s/it]T Loss=2.3026113510131836\n",
            "g_norm = tensor(0.1259, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044373989105225\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050742149353027\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057703971862793\n",
            "g_norm = tensor(0.1219, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050413131713867\n",
            "g_norm = tensor(0.1407, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0604248046875\n",
            "||∇_X meta|| = 0.0015193655854091048\n",
            "ΔX norm: 1.5193673789326567e-05\n",
            "Stage 8/10:  85%|████████████████████████▋    | 256/300 [09:55<01:42,  2.33s/it]T Loss=2.302760362625122\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031423091888428\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041326999664307\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030667304992676\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040995597839355\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8009490966797\n",
            "||∇_X meta|| = 0.0016771114896982908\n",
            "ΔX norm: 1.6771116861491464e-05\n",
            "Stage 8/10:  86%|████████████████████████▊    | 257/300 [09:57<01:39,  2.31s/it]T Loss=2.3042924404144287\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032190799713135\n",
            "g_norm = tensor(0.1481, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30403208732605\n",
            "g_norm = tensor(0.1333, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035998344421387\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304556369781494\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.89292907714844\n",
            "||∇_X meta|| = 0.0014136753743514419\n",
            "ΔX norm: 1.4136750905890949e-05\n",
            "Stage 8/10:  86%|████████████████████████▉    | 258/300 [10:00<01:35,  2.28s/it]T Loss=2.3036112785339355\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045239448547363\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301976442337036\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037946224212646\n",
            "g_norm = tensor(0.1154, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038532733917236\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5059356689453\n",
            "||∇_X meta|| = 0.0016316736582666636\n",
            "ΔX norm: 1.6316736946464516e-05\n",
            "Stage 8/10:  86%|█████████████████████████    | 259/300 [10:02<01:32,  2.25s/it]T Loss=2.3033576011657715\n",
            "g_norm = tensor(0.0704, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025708198547363\n",
            "g_norm = tensor(0.0727, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031411170959473\n",
            "g_norm = tensor(0.0785, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036015033721924\n",
            "g_norm = tensor(0.0730, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302698850631714\n",
            "g_norm = tensor(0.0665, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.25482177734375\n",
            "||∇_X meta|| = 0.0017072561895474792\n",
            "ΔX norm: 1.707255796645768e-05\n",
            "Stage 8/10:  87%|█████████████████████████▏   | 260/300 [10:04<01:31,  2.29s/it]T Loss=2.304802417755127\n",
            "g_norm = tensor(0.1431, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041200637817383\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044049739837646\n",
            "g_norm = tensor(0.1444, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052735328674316\n",
            "g_norm = tensor(0.1425, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047196865081787\n",
            "g_norm = tensor(0.1492, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.36331176757812\n",
            "||∇_X meta|| = 0.0016161202220246196\n",
            "ΔX norm: 1.6161196981556714e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 8/10:  87%|█████████████████████████▏   | 261/300 [10:07<01:31,  2.36s/it]T Loss=2.303252935409546\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041083812713623\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040881156921387\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304267406463623\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305088758468628\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.87472534179688\n",
            "||∇_X meta|| = 0.0015171902487054467\n",
            "ΔX norm: 1.5171907762123737e-05\n",
            "Stage 8/10:  87%|█████████████████████████▎   | 262/300 [10:09<01:30,  2.37s/it]T Loss=2.303083896636963\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047518730163574\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044466972351074\n",
            "g_norm = tensor(0.1099, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304173231124878\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050646781921387\n",
            "g_norm = tensor(0.0845, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.04249572753906\n",
            "||∇_X meta|| = 0.0014844571705907583\n",
            "ΔX norm: 1.4844581528450362e-05\n",
            "Stage 8/10:  88%|█████████████████████████▍   | 263/300 [10:11<01:27,  2.37s/it]T Loss=2.30281400680542\n",
            "g_norm = tensor(0.1438, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028292655944824\n",
            "g_norm = tensor(0.1375, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303347110748291\n",
            "g_norm = tensor(0.1396, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302475690841675\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031630516052246\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4996337890625\n",
            "||∇_X meta|| = 0.0016294218366965652\n",
            "ΔX norm: 1.6294225133606233e-05\n",
            "Stage 8/10:  88%|█████████████████████████▌   | 264/300 [10:14<01:23,  2.32s/it]T Loss=2.3030309677124023\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30407977104187\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041882514953613\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037421703338623\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043465614318848\n",
            "g_norm = tensor(0.0934, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.87538146972656\n",
            "||∇_X meta|| = 0.001546481391415\n",
            "ΔX norm: 1.5464818716282025e-05\n",
            "Stage 8/10:  88%|█████████████████████████▌   | 265/300 [10:16<01:25,  2.43s/it]T Loss=2.3031811714172363\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303619146347046\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039498329162598\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035728931427\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039817810058594\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.03085327148438\n",
            "||∇_X meta|| = 0.0015797035302966833\n",
            "ΔX norm: 1.5797037121956237e-05\n",
            "Stage 8/10:  89%|█████████████████████████▋   | 266/300 [10:19<01:23,  2.47s/it]T Loss=2.304426908493042\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050360679626465\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30474853515625\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049464225769043\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048155307769775\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.63656616210938\n",
            "||∇_X meta|| = 0.0014842854579910636\n",
            "ΔX norm: 1.484284621255938e-05\n",
            "Stage 8/10:  89%|█████████████████████████▊   | 267/300 [10:22<01:28,  2.69s/it]T Loss=2.303492546081543\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304535388946533\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025381565093994\n",
            "g_norm = tensor(0.1383, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034896850585938\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302900791168213\n",
            "g_norm = tensor(0.1243, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.13385009765625\n",
            "||∇_X meta|| = 0.0015258750645443797\n",
            "ΔX norm: 1.5258735402312595e-05\n",
            "Stage 8/10:  89%|█████████████████████████▉   | 268/300 [10:25<01:27,  2.75s/it]T Loss=2.301725149154663\n",
            "g_norm = tensor(0.1373, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302023410797119\n",
            "g_norm = tensor(0.1322, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303131103515625\n",
            "g_norm = tensor(0.1321, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032431602478027\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303277015686035\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.47731018066406\n",
            "||∇_X meta|| = 0.0015509389340877533\n",
            "ΔX norm: 1.550937486172188e-05\n",
            "Stage 8/10:  90%|██████████████████████████   | 269/300 [10:27<01:22,  2.65s/it]T Loss=2.3026986122131348\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302651882171631\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035435676574707\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027472496032715\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304696559906006\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7464141845703\n",
            "||∇_X meta|| = 0.0015741311945021152\n",
            "ΔX norm: 1.5741330571472645e-05\n",
            "Stage 8/10:  90%|██████████████████████████   | 270/300 [10:30<01:19,  2.66s/it]T Loss=2.3048911094665527\n",
            "g_norm = tensor(0.0866, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303971767425537\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040144443511963\n",
            "g_norm = tensor(0.0820, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047027587890625\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304550886154175\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.70248413085938\n",
            "||∇_X meta|| = 0.0017606692854315042\n",
            "ΔX norm: 1.760667328198906e-05\n",
            "Stage 8/10:  90%|██████████████████████████▏  | 271/300 [10:32<01:14,  2.56s/it]T Loss=2.302997589111328\n",
            "g_norm = tensor(0.1395, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053205013275146\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050811290740967\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055460453033447\n",
            "g_norm = tensor(0.1375, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036868572235107\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0351104736328\n",
            "||∇_X meta|| = 0.0015585182700306177\n",
            "ΔX norm: 1.558519397804048e-05\n",
            "Stage 8/10:  91%|██████████████████████████▎  | 272/300 [10:35<01:08,  2.45s/it]T Loss=2.304661273956299\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047242164611816\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044545650482178\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043246269226074\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034791946411133\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.04080200195312\n",
            "||∇_X meta|| = 0.0015903640305623412\n",
            "ΔX norm: 1.5903666280792095e-05\n",
            "Stage 8/10:  91%|██████████████████████████▍  | 273/300 [10:37<01:03,  2.37s/it]T Loss=2.3041796684265137\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029987812042236\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044629096984863\n",
            "g_norm = tensor(0.0879, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035285472869873\n",
            "g_norm = tensor(0.0747, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303562641143799\n",
            "g_norm = tensor(0.0803, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.65142822265625\n",
            "||∇_X meta|| = 0.0015901648439466953\n",
            "ΔX norm: 1.5901649021543562e-05\n",
            "Stage 8/10:  91%|██████████████████████████▍  | 274/300 [10:39<01:00,  2.34s/it]T Loss=2.304270029067993\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040685653686523\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302866220474243\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028533458709717\n",
            "g_norm = tensor(0.1213, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303440570831299\n",
            "g_norm = tensor(0.1344, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5528106689453\n",
            "||∇_X meta|| = 0.0015476889675483108\n",
            "ΔX norm: 1.5476904081879184e-05\n",
            "Stage 8/10:  92%|██████████████████████████▌  | 275/300 [10:41<00:57,  2.28s/it]T Loss=2.303654193878174\n",
            "g_norm = tensor(0.0873, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021857738494873\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029770851135254\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026695251464844\n",
            "g_norm = tensor(0.0941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029885292053223\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.63787841796875\n",
            "||∇_X meta|| = 0.001414672122336924\n",
            "ΔX norm: 1.4146708963380661e-05\n",
            "Stage 8/10:  92%|██████████████████████████▋  | 276/300 [10:43<00:53,  2.25s/it]T Loss=2.303514003753662\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039984703063965\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036696910858154\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303248167037964\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037476539611816\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8502197265625\n",
            "||∇_X meta|| = 0.0013726099859923124\n",
            "ΔX norm: 1.3726110410061665e-05\n",
            "Stage 8/10:  92%|██████████████████████████▊  | 277/300 [10:46<00:51,  2.24s/it]T Loss=2.303605794906616\n",
            "g_norm = tensor(0.1222, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303438186645508\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050949573516846\n",
            "g_norm = tensor(0.1328, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304445266723633\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027045726776123\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5815887451172\n",
            "||∇_X meta|| = 0.0016181098762899637\n",
            "ΔX norm: 1.6181100363610312e-05\n",
            "Stage 8/10:  93%|██████████████████████████▊  | 278/300 [10:48<00:50,  2.30s/it]T Loss=2.3025455474853516\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301980495452881\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036534786224365\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033366203308105\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025705814361572\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.42637634277344\n",
            "||∇_X meta|| = 0.0015515524428337812\n",
            "ΔX norm: 1.5515528502874076e-05\n",
            "Stage 8/10:  93%|██████████████████████████▉  | 279/300 [10:50<00:48,  2.29s/it]T Loss=2.304569959640503\n",
            "g_norm = tensor(0.1450, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303835391998291\n",
            "g_norm = tensor(0.1441, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044209480285645\n",
            "g_norm = tensor(0.1426, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302628517150879\n",
            "g_norm = tensor(0.1570, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049349784851074\n",
            "g_norm = tensor(0.1550, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.87103271484375\n",
            "||∇_X meta|| = 0.0014726989902555943\n",
            "ΔX norm: 1.4726990229974035e-05\n",
            "Stage 8/10:  93%|███████████████████████████  | 280/300 [10:53<00:45,  2.28s/it]T Loss=2.3046517372131348\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042266368865967\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039774894714355\n",
            "g_norm = tensor(0.0726, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039779663085938\n",
            "g_norm = tensor(0.0716, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303770065307617\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.42864990234375\n",
            "||∇_X meta|| = 0.0013522729277610779\n",
            "ΔX norm: 1.352271738142008e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 8/10:  94%|███████████████████████████▏ | 281/300 [10:55<00:45,  2.41s/it]T Loss=2.304079532623291\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303462266921997\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049449920654297\n",
            "g_norm = tensor(0.1275, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303279161453247\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050246238708496\n",
            "g_norm = tensor(0.1301, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.97496032714844\n",
            "||∇_X meta|| = 0.001599110895767808\n",
            "ΔX norm: 1.599112874828279e-05\n",
            "Stage 8/10:  94%|███████████████████████████▎ | 282/300 [10:58<00:43,  2.42s/it]T Loss=2.3038415908813477\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302868366241455\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303647041320801\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303795576095581\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303473472595215\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.27777099609375\n",
            "||∇_X meta|| = 0.0015558793675154448\n",
            "ΔX norm: 1.5558814993710257e-05\n",
            "Stage 8/10:  94%|███████████████████████████▎ | 283/300 [11:00<00:40,  2.39s/it]T Loss=2.3031973838806152\n",
            "g_norm = tensor(0.1403, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029046058654785\n",
            "g_norm = tensor(0.1530, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303039312362671\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029823303222656\n",
            "g_norm = tensor(0.1367, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303673267364502\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5111846923828\n",
            "||∇_X meta|| = 0.0014700029278174043\n",
            "ΔX norm: 1.4700031897518784e-05\n",
            "Stage 8/10:  95%|███████████████████████████▍ | 284/300 [11:02<00:37,  2.33s/it]T Loss=2.305586099624634\n",
            "g_norm = tensor(0.1345, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056302070617676\n",
            "g_norm = tensor(0.1334, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044986724853516\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304107904434204\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043384552001953\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.32298278808594\n",
            "||∇_X meta|| = 0.0015144043136388063\n",
            "ΔX norm: 1.514404357294552e-05\n",
            "Stage 8/10:  95%|███████████████████████████▌ | 285/300 [11:04<00:34,  2.28s/it]T Loss=2.3032948970794678\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303906202316284\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028531074523926\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302464485168457\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030850887298584\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.45648193359375\n",
            "||∇_X meta|| = 0.0015978023875504732\n",
            "ΔX norm: 1.5978033843566664e-05\n",
            "Stage 8/10:  95%|███████████████████████████▋ | 286/300 [11:07<00:31,  2.24s/it]T Loss=2.303032398223877\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302187204360962\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028361797332764\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3003196716308594\n",
            "g_norm = tensor(0.1407, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017406463623047\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8061065673828\n",
            "||∇_X meta|| = 0.0016238723183050752\n",
            "ΔX norm: 1.623871321498882e-05\n",
            "Stage 8/10:  96%|███████████████████████████▋ | 287/300 [11:09<00:29,  2.27s/it]T Loss=2.3048300743103027\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043951988220215\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304474353790283\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041908740997314\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304898262023926\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.01124572753906\n",
            "||∇_X meta|| = 0.001497854944318533\n",
            "ΔX norm: 1.4978541003074497e-05\n",
            "Stage 8/10:  96%|███████████████████████████▊ | 288/300 [11:11<00:27,  2.26s/it]T Loss=2.3042891025543213\n",
            "g_norm = tensor(0.1503, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303811550140381\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028299808502197\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037972450256348\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302065849304199\n",
            "g_norm = tensor(0.1278, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.6758270263672\n",
            "||∇_X meta|| = 0.0015943108592182398\n",
            "ΔX norm: 1.5943120160955004e-05\n",
            "Stage 8/10:  96%|███████████████████████████▉ | 289/300 [11:13<00:24,  2.25s/it]T Loss=2.3045475482940674\n",
            "g_norm = tensor(0.1607, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302711009979248\n",
            "g_norm = tensor(0.1572, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052401542663574\n",
            "g_norm = tensor(0.1720, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033018112182617\n",
            "g_norm = tensor(0.1641, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030612468719482\n",
            "g_norm = tensor(0.1654, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.11082458496094\n",
            "||∇_X meta|| = 0.0015588188543915749\n",
            "ΔX norm: 1.5588191672577523e-05\n",
            "Stage 8/10:  97%|████████████████████████████ | 290/300 [11:16<00:23,  2.34s/it]T Loss=2.3045010566711426\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049302101135254\n",
            "g_norm = tensor(0.0736, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304065704345703\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303870439529419\n",
            "g_norm = tensor(0.0684, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040714263916016\n",
            "g_norm = tensor(0.0861, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.21063232421875\n",
            "||∇_X meta|| = 0.0015596348093822598\n",
            "ΔX norm: 1.5596344383084215e-05\n",
            "Stage 8/10:  97%|████████████████████████████▏| 291/300 [11:18<00:21,  2.39s/it]T Loss=2.302455425262451\n",
            "g_norm = tensor(0.1295, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303797960281372\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302769422531128\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035900592803955\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304680585861206\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.55332946777344\n",
            "||∇_X meta|| = 0.0014974654186517\n",
            "ΔX norm: 1.4974665646150243e-05\n",
            "Stage 8/10:  97%|████████████████████████████▏| 292/300 [11:21<00:19,  2.45s/it]T Loss=2.3035330772399902\n",
            "g_norm = tensor(0.0705, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303755760192871\n",
            "g_norm = tensor(0.0685, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040738105773926\n",
            "g_norm = tensor(0.0739, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303455114364624\n",
            "g_norm = tensor(0.0664, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034021854400635\n",
            "g_norm = tensor(0.0723, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.45919799804688\n",
            "||∇_X meta|| = 0.0015463453019037843\n",
            "ΔX norm: 1.5463443560292944e-05\n",
            "Stage 8/10:  98%|████████████████████████████▎| 293/300 [11:23<00:16,  2.39s/it]T Loss=2.303901195526123\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040945529937744\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033854961395264\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304926633834839\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054537773132324\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.80259704589844\n",
            "||∇_X meta|| = 0.001538116135634482\n",
            "ΔX norm: 1.5381156117655337e-05\n",
            "Stage 8/10:  98%|████████████████████████████▍| 294/300 [11:26<00:14,  2.37s/it]T Loss=2.3043084144592285\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035454750061035\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038172721862793\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034827709198\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043625354766846\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.10098266601562\n",
            "||∇_X meta|| = 0.001560274395160377\n",
            "ΔX norm: 1.5602765415678732e-05\n",
            "Stage 8/10:  98%|████████████████████████████▌| 295/300 [11:28<00:11,  2.37s/it]T Loss=2.3027760982513428\n",
            "g_norm = tensor(0.1576, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303201675415039\n",
            "g_norm = tensor(0.1479, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036346435546875\n",
            "g_norm = tensor(0.1819, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039259910583496\n",
            "g_norm = tensor(0.1807, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304523229598999\n",
            "g_norm = tensor(0.1386, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.62313842773438\n",
            "||∇_X meta|| = 0.0015554087003692985\n",
            "ΔX norm: 1.5554080164292827e-05\n",
            "Stage 8/10:  99%|████████████████████████████▌| 296/300 [11:30<00:09,  2.37s/it]T Loss=2.3034844398498535\n",
            "g_norm = tensor(0.0744, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303213596343994\n",
            "g_norm = tensor(0.0741, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028109073638916\n",
            "g_norm = tensor(0.0798, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034491539001465\n",
            "g_norm = tensor(0.0682, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028297424316406\n",
            "g_norm = tensor(0.0776, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7087860107422\n",
            "||∇_X meta|| = 0.0014530750922858715\n",
            "ΔX norm: 1.4530747648677789e-05\n",
            "Stage 8/10:  99%|████████████████████████████▋| 297/300 [11:33<00:07,  2.37s/it]T Loss=2.304508686065674\n",
            "g_norm = tensor(0.1465, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303865909576416\n",
            "g_norm = tensor(0.1484, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302656650543213\n",
            "g_norm = tensor(0.1378, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303952693939209\n",
            "g_norm = tensor(0.1355, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021793365478516\n",
            "g_norm = tensor(0.1549, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.67474365234375\n",
            "||∇_X meta|| = 0.0015611969865858555\n",
            "ΔX norm: 1.5611984053975902e-05\n",
            "Stage 8/10:  99%|████████████████████████████▊| 298/300 [11:35<00:04,  2.40s/it]T Loss=2.305170774459839\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054022789001465\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304483652114868\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304413318634033\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043768405914307\n",
            "g_norm = tensor(0.1219, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0197296142578\n",
            "||∇_X meta|| = 0.001541724894195795\n",
            "ΔX norm: 1.5417239410453476e-05\n",
            "Stage 8/10: 100%|████████████████████████████▉| 299/300 [11:38<00:02,  2.43s/it]T Loss=2.3046553134918213\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039932250976562\n",
            "g_norm = tensor(0.1099, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037571907043457\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035149574279785\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040318489074707\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9581298828125\n",
            "||∇_X meta|| = 0.0015204669907689095\n",
            "ΔX norm: 1.5204679584712721e-05\n",
            "Stage 7, class 0, loss 2.208                                                    \n",
            "Stage 7, class 1, loss 2.269\n",
            "Stage 7, class 2, loss 2.339\n",
            "Stage 7, class 3, loss 2.358\n",
            "Stage 7, class 4, loss 2.306\n",
            "Stage 7, class 5, loss 2.328\n",
            "Stage 7, class 6, loss 2.384\n",
            "Stage 7, class 7, loss 2.228\n",
            "Stage 7, class 8, loss 2.367\n",
            "Stage 7, class 9, loss 2.255\n",
            "Stage 9/10:   0%|                                       | 0/300 [00:00<?, ?it/s]T Loss=2.304569721221924\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049402236938477\n",
            "g_norm = tensor(0.0627, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043346405029297\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305114269256592\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305128574371338\n",
            "g_norm = tensor(0.0804, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.44410705566406\n",
            "||∇_X meta|| = 0.004021651577204466\n",
            "ΔX norm: 4.021651693619788e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 9/10:   0%|                               | 1/300 [00:02<11:37,  2.33s/it]T Loss=2.3055765628814697\n",
            "g_norm = tensor(0.1316, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057639598846436\n",
            "g_norm = tensor(0.1470, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305020570755005\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3065025806427\n",
            "g_norm = tensor(0.1808, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033690452575684\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.08106994628906\n",
            "||∇_X meta|| = 0.0035833334550261497\n",
            "ΔX norm: 3.5833323636325076e-05\n",
            "Stage 9/10:   1%|▏                              | 2/300 [00:04<11:59,  2.42s/it]T Loss=2.303457736968994\n",
            "g_norm = tensor(0.1558, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039848804473877\n",
            "g_norm = tensor(0.2127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037750720977783\n",
            "g_norm = tensor(0.2040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301785469055176\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303022861480713\n",
            "g_norm = tensor(0.1460, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.08531188964844\n",
            "||∇_X meta|| = 0.003480195766314864\n",
            "ΔX norm: 3.480185478110798e-05\n",
            "Stage 9/10:   1%|▎                              | 3/300 [00:07<12:04,  2.44s/it]T Loss=2.3033502101898193\n",
            "g_norm = tensor(0.0785, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033664226531982\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303903341293335\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041789531707764\n",
            "g_norm = tensor(0.0746, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032054901123047\n",
            "g_norm = tensor(0.0945, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.00901794433594\n",
            "||∇_X meta|| = 0.003696811618283391\n",
            "ΔX norm: 3.69681220036e-05\n",
            "Stage 9/10:   1%|▍                              | 4/300 [00:09<11:13,  2.27s/it]T Loss=2.3038241863250732\n",
            "g_norm = tensor(0.0758, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032805919647217\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30363392829895\n",
            "g_norm = tensor(0.0803, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303389310836792\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304204225540161\n",
            "g_norm = tensor(0.0746, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2447967529297\n",
            "||∇_X meta|| = 0.0035877234768122435\n",
            "ΔX norm: 3.5877219488611445e-05\n",
            "Stage 9/10:   2%|▌                              | 5/300 [00:11<11:00,  2.24s/it]T Loss=2.3054440021514893\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304229736328125\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039650917053223\n",
            "g_norm = tensor(0.1219, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304582118988037\n",
            "g_norm = tensor(0.1234, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040263652801514\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.73895263671875\n",
            "||∇_X meta|| = 0.0035475636832416058\n",
            "ΔX norm: 3.547563392203301e-05\n",
            "Stage 9/10:   2%|▌                              | 6/300 [00:13<11:08,  2.27s/it]T Loss=2.303861141204834\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036599159240723\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037660121917725\n",
            "g_norm = tensor(0.0795, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043313026428223\n",
            "g_norm = tensor(0.1317, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039119243621826\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.57275390625\n",
            "||∇_X meta|| = 0.003542795777320862\n",
            "ΔX norm: 3.54279727616813e-05\n",
            "Stage 9/10:   2%|▋                              | 7/300 [00:16<11:38,  2.38s/it]T Loss=2.3033053874969482\n",
            "g_norm = tensor(0.1457, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303560972213745\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038370609283447\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301994800567627\n",
            "g_norm = tensor(0.1419, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028831481933594\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.99893188476562\n",
            "||∇_X meta|| = 0.0038362410850822926\n",
            "ΔX norm: 3.8362421037163585e-05\n",
            "Stage 9/10:   3%|▊                              | 8/300 [00:19<11:59,  2.46s/it]T Loss=2.3045570850372314\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041372299194336\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303683280944824\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043313026428223\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304922103881836\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.51113891601562\n",
            "||∇_X meta|| = 0.003508456517010927\n",
            "ΔX norm: 3.508454028633423e-05\n",
            "Stage 9/10:   3%|▉                              | 9/300 [00:21<12:32,  2.59s/it]T Loss=2.303468704223633\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3015122413635254\n",
            "g_norm = tensor(0.1708, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303708553314209\n",
            "g_norm = tensor(0.1278, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303554058074951\n",
            "g_norm = tensor(0.1234, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045544624328613\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4469757080078\n",
            "||∇_X meta|| = 0.003873103531077504\n",
            "ΔX norm: 3.873099558404647e-05\n",
            "Stage 9/10:   3%|█                             | 10/300 [00:24<12:20,  2.55s/it]T Loss=2.3030591011047363\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30305814743042\n",
            "g_norm = tensor(0.0931, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031537532806396\n",
            "g_norm = tensor(0.0860, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032283782958984\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304813861846924\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.20306396484375\n",
            "||∇_X meta|| = 0.003770423587411642\n",
            "ΔX norm: 3.7704223359469324e-05\n",
            "Stage 9/10:   4%|█                             | 11/300 [00:27<12:35,  2.61s/it]T Loss=2.302663803100586\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302438735961914\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302603244781494\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027873039245605\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035409450531006\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.30783081054688\n",
            "||∇_X meta|| = 0.0035145620349794626\n",
            "ΔX norm: 3.514561103656888e-05\n",
            "Stage 9/10:   4%|█▏                            | 12/300 [00:29<12:37,  2.63s/it]T Loss=2.3034276962280273\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034825325012207\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303659439086914\n",
            "g_norm = tensor(0.0764, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303147077560425\n",
            "g_norm = tensor(0.0840, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027498722076416\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.98899841308594\n",
            "||∇_X meta|| = 0.0036157036665827036\n",
            "ΔX norm: 3.615701280068606e-05\n",
            "Stage 9/10:   4%|█▎                            | 13/300 [00:32<12:21,  2.58s/it]T Loss=2.302946090698242\n",
            "g_norm = tensor(0.1299, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30264949798584\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303617477416992\n",
            "g_norm = tensor(0.1488, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021116256713867\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304192066192627\n",
            "g_norm = tensor(0.1490, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.07696533203125\n",
            "||∇_X meta|| = 0.003465190064162016\n",
            "ΔX norm: 3.465187182882801e-05\n",
            "Stage 9/10:   5%|█▍                            | 14/300 [00:35<13:35,  2.85s/it]T Loss=2.3029701709747314\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302295684814453\n",
            "g_norm = tensor(0.1510, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032472133636475\n",
            "g_norm = tensor(0.1250, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033480644226074\n",
            "g_norm = tensor(0.1425, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303156852722168\n",
            "g_norm = tensor(0.1349, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0767364501953\n",
            "||∇_X meta|| = 0.0033843370620161295\n",
            "ΔX norm: 3.3843331038951874e-05\n",
            "Stage 9/10:   5%|█▌                            | 15/300 [00:38<13:10,  2.77s/it]T Loss=2.303396224975586\n",
            "g_norm = tensor(0.0890, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303720474243164\n",
            "g_norm = tensor(0.0831, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302814245223999\n",
            "g_norm = tensor(0.0871, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304128408432007\n",
            "g_norm = tensor(0.0846, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303464889526367\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.50714111328125\n",
            "||∇_X meta|| = 0.0032961454708129168\n",
            "ΔX norm: 3.296147770015523e-05\n",
            "Stage 9/10:   5%|█▌                            | 16/300 [00:41<13:06,  2.77s/it]T Loss=2.3065590858459473\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305751323699951\n",
            "g_norm = tensor(0.1466, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305997848510742\n",
            "g_norm = tensor(0.1306, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050506114959717\n",
            "g_norm = tensor(0.1404, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305703639984131\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2707061767578\n",
            "||∇_X meta|| = 0.003552637994289398\n",
            "ΔX norm: 3.55263618985191e-05\n",
            "Stage 9/10:   6%|█▋                            | 17/300 [00:43<12:33,  2.66s/it]T Loss=2.304640293121338\n",
            "g_norm = tensor(0.1118, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306225538253784\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304053783416748\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026227951049805\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304482936859131\n",
            "g_norm = tensor(0.1288, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.46104431152344\n",
            "||∇_X meta|| = 0.00340553792193532\n",
            "ΔX norm: 3.405538518563844e-05\n",
            "Stage 9/10:   6%|█▊                            | 18/300 [00:46<12:17,  2.62s/it]T Loss=2.3053650856018066\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303734302520752\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302701473236084\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304518222808838\n",
            "g_norm = tensor(0.1355, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304882526397705\n",
            "g_norm = tensor(0.1235, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.83395385742188\n",
            "||∇_X meta|| = 0.00361679308116436\n",
            "ΔX norm: 3.616793765104376e-05\n",
            "Stage 9/10:   6%|█▉                            | 19/300 [00:48<11:52,  2.53s/it]T Loss=2.304725408554077\n",
            "g_norm = tensor(0.0793, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048737049102783\n",
            "g_norm = tensor(0.0779, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30507493019104\n",
            "g_norm = tensor(0.0696, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305543899536133\n",
            "g_norm = tensor(0.0657, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305049180984497\n",
            "g_norm = tensor(0.0618, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8849639892578\n",
            "||∇_X meta|| = 0.0031928480602800846\n",
            "ΔX norm: 3.192846997990273e-05\n",
            "Stage 9/10:   7%|██                            | 20/300 [00:51<12:00,  2.57s/it]T Loss=2.3048300743103027\n",
            "g_norm = tensor(0.0941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030295372009277\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304788589477539\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3011786937713623\n",
            "g_norm = tensor(0.1140, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027892112731934\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9358367919922\n",
            "||∇_X meta|| = 0.003152058692649007\n",
            "ΔX norm: 3.1520583434030414e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 9/10:   7%|██                            | 21/300 [00:53<11:45,  2.53s/it]T Loss=2.304704427719116\n",
            "g_norm = tensor(0.1053, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304286479949951\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041698932647705\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042240142822266\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023388385772705\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.39271545410156\n",
            "||∇_X meta|| = 0.0034333972726017237\n",
            "ΔX norm: 3.4333959774812683e-05\n",
            "Stage 9/10:   7%|██▏                           | 22/300 [00:55<11:38,  2.51s/it]T Loss=2.3037586212158203\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30228853225708\n",
            "g_norm = tensor(0.1353, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303270101547241\n",
            "g_norm = tensor(0.1338, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033082485198975\n",
            "g_norm = tensor(0.1225, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036751747131348\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.7111053466797\n",
            "||∇_X meta|| = 0.0031304694712162018\n",
            "ΔX norm: 3.130468394374475e-05\n",
            "Stage 9/10:   8%|██▎                           | 23/300 [00:58<11:55,  2.58s/it]T Loss=2.3033931255340576\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041059970855713\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303467035293579\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303978443145752\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305431842803955\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.40692138671875\n",
            "||∇_X meta|| = 0.0032181909773498774\n",
            "ΔX norm: 3.2181909773498774e-05\n",
            "Stage 9/10:   8%|██▍                           | 24/300 [01:01<12:35,  2.74s/it]T Loss=2.3044209480285645\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304474353790283\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050377368927\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303738832473755\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305196762084961\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.49220275878906\n",
            "||∇_X meta|| = 0.0036419774405658245\n",
            "ΔX norm: 3.641976945800707e-05\n",
            "Stage 9/10:   8%|██▌                           | 25/300 [01:04<12:24,  2.71s/it]T Loss=2.3038949966430664\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041739463806152\n",
            "g_norm = tensor(0.0838, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30469012260437\n",
            "g_norm = tensor(0.0862, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045825958251953\n",
            "g_norm = tensor(0.0908, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048062324523926\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3255615234375\n",
            "||∇_X meta|| = 0.003053071442991495\n",
            "ΔX norm: 3.0530733056366444e-05\n",
            "Stage 9/10:   9%|██▌                           | 26/300 [01:06<12:03,  2.64s/it]T Loss=2.302692413330078\n",
            "g_norm = tensor(0.1477, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043644428253174\n",
            "g_norm = tensor(0.1468, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037772178649902\n",
            "g_norm = tensor(0.1464, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041014671325684\n",
            "g_norm = tensor(0.1299, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30330491065979\n",
            "g_norm = tensor(0.1484, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.62936401367188\n",
            "||∇_X meta|| = 0.0028425289783626795\n",
            "ΔX norm: 2.8425312848412432e-05\n",
            "Stage 9/10:   9%|██▋                           | 27/300 [01:10<12:59,  2.86s/it]T Loss=2.303957939147949\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046422004699707\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040618896484375\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047895431518555\n",
            "g_norm = tensor(0.1143, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303924560546875\n",
            "g_norm = tensor(0.1214, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.39773559570312\n",
            "||∇_X meta|| = 0.0029231547378003597\n",
            "ΔX norm: 2.923153260780964e-05\n",
            "Stage 9/10:   9%|██▊                           | 28/300 [01:12<12:47,  2.82s/it]T Loss=2.3030993938446045\n",
            "g_norm = tensor(0.1316, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053674697875977\n",
            "g_norm = tensor(0.1401, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304776668548584\n",
            "g_norm = tensor(0.1441, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050875663757324\n",
            "g_norm = tensor(0.1243, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303800582885742\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.70693969726562\n",
            "||∇_X meta|| = 0.002760805655270815\n",
            "ΔX norm: 2.7608044547378086e-05\n",
            "Stage 9/10:  10%|██▉                           | 29/300 [01:15<12:08,  2.69s/it]T Loss=2.3032584190368652\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302993059158325\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303053379058838\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028788566589355\n",
            "g_norm = tensor(0.1143, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303009271621704\n",
            "g_norm = tensor(0.1139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6136016845703\n",
            "||∇_X meta|| = 0.003108083037659526\n",
            "ΔX norm: 3.108081000391394e-05\n",
            "Stage 9/10:  10%|███                           | 30/300 [01:17<11:50,  2.63s/it]T Loss=2.3055930137634277\n",
            "g_norm = tensor(0.1463, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306061029434204\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304971694946289\n",
            "g_norm = tensor(0.1789, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3060402870178223\n",
            "g_norm = tensor(0.1444, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054728507995605\n",
            "g_norm = tensor(0.1318, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.1432342529297\n",
            "||∇_X meta|| = 0.003000713186338544\n",
            "ΔX norm: 3.0007118766661733e-05\n",
            "Stage 9/10:  10%|███                           | 31/300 [01:20<11:27,  2.55s/it]T Loss=2.303570508956909\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035426139831543\n",
            "g_norm = tensor(0.1436, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30326771736145\n",
            "g_norm = tensor(0.1306, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033366203308105\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305159091949463\n",
            "g_norm = tensor(0.1476, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.7310791015625\n",
            "||∇_X meta|| = 0.00292084994725883\n",
            "ΔX norm: 2.9208511477918364e-05\n",
            "Stage 9/10:  11%|███▏                          | 32/300 [01:22<10:56,  2.45s/it]T Loss=2.303757667541504\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034253120422363\n",
            "g_norm = tensor(0.1340, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303194046020508\n",
            "g_norm = tensor(0.1218, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041939735412598\n",
            "g_norm = tensor(0.1469, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030169010162354\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9368438720703\n",
            "||∇_X meta|| = 0.0028808657079935074\n",
            "ΔX norm: 2.8808681236114353e-05\n",
            "Stage 9/10:  11%|███▎                          | 33/300 [01:24<10:34,  2.38s/it]T Loss=2.3040993213653564\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033413887023926\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039705753326416\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304492473602295\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042850494384766\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.39804077148438\n",
            "||∇_X meta|| = 0.002897277707234025\n",
            "ΔX norm: 2.897273407143075e-05\n",
            "Stage 9/10:  11%|███▍                          | 34/300 [01:26<10:21,  2.34s/it]T Loss=2.3037991523742676\n",
            "g_norm = tensor(0.1269, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306375026702881\n",
            "g_norm = tensor(0.1320, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30454683303833\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304022789001465\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027777671813965\n",
            "g_norm = tensor(0.1416, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.46255493164062\n",
            "||∇_X meta|| = 0.002875742269679904\n",
            "ΔX norm: 2.8757451218552887e-05\n",
            "Stage 9/10:  12%|███▌                          | 35/300 [01:29<10:13,  2.31s/it]T Loss=2.304255962371826\n",
            "g_norm = tensor(0.1556, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045413494110107\n",
            "g_norm = tensor(0.1505, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028247356414795\n",
            "g_norm = tensor(0.1482, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044838905334473\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032569885253906\n",
            "g_norm = tensor(0.1685, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.81463623046875\n",
            "||∇_X meta|| = 0.002602600958198309\n",
            "ΔX norm: 2.6025991246569902e-05\n",
            "Stage 9/10:  12%|███▌                          | 36/300 [01:31<09:57,  2.26s/it]T Loss=2.3032736778259277\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303323268890381\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302691698074341\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30363130569458\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303823232650757\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.03773498535156\n",
            "||∇_X meta|| = 0.002815850079059601\n",
            "ΔX norm: 2.81584907497745e-05\n",
            "Stage 9/10:  12%|███▋                          | 37/300 [01:33<09:44,  2.22s/it]T Loss=2.303899049758911\n",
            "g_norm = tensor(0.1655, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304504871368408\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303436756134033\n",
            "g_norm = tensor(0.1473, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305542469024658\n",
            "g_norm = tensor(0.1688, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304579257965088\n",
            "g_norm = tensor(0.1559, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0950927734375\n",
            "||∇_X meta|| = 0.002790493192151189\n",
            "ΔX norm: 2.790493454085663e-05\n",
            "Stage 9/10:  13%|███▊                          | 38/300 [01:35<09:36,  2.20s/it]T Loss=2.302424907684326\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304813861846924\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050308227539062\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026833534240723\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033816814422607\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.75936889648438\n",
            "||∇_X meta|| = 0.0030206928495317698\n",
            "ΔX norm: 3.020693111466244e-05\n",
            "Stage 9/10:  13%|███▉                          | 39/300 [01:37<09:27,  2.17s/it]T Loss=2.302736759185791\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303823947906494\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028013706207275\n",
            "g_norm = tensor(0.1330, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303999662399292\n",
            "g_norm = tensor(0.1408, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043174743652344\n",
            "g_norm = tensor(0.1828, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.73883056640625\n",
            "||∇_X meta|| = 0.002717507304623723\n",
            "ΔX norm: 2.7175066861673258e-05\n",
            "Stage 9/10:  13%|████                          | 40/300 [01:39<09:28,  2.19s/it]T Loss=2.3031563758850098\n",
            "g_norm = tensor(0.0880, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034324645996094\n",
            "g_norm = tensor(0.0716, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302905321121216\n",
            "g_norm = tensor(0.0635, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036270141601562\n",
            "g_norm = tensor(0.0635, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031630516052246\n",
            "g_norm = tensor(0.0722, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.85008239746094\n",
            "||∇_X meta|| = 0.0027744609396904707\n",
            "ΔX norm: 2.774464155663736e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 9/10:  14%|████                          | 41/300 [01:41<09:15,  2.15s/it]T Loss=2.304471731185913\n",
            "g_norm = tensor(0.1381, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042004108428955\n",
            "g_norm = tensor(0.1421, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039047718048096\n",
            "g_norm = tensor(0.1391, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025131225585938\n",
            "g_norm = tensor(0.1414, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304387331008911\n",
            "g_norm = tensor(0.1477, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.07835388183594\n",
            "||∇_X meta|| = 0.0025058959145098925\n",
            "ΔX norm: 2.505895827198401e-05\n",
            "Stage 9/10:  14%|████▏                         | 42/300 [01:44<10:14,  2.38s/it]T Loss=2.3030190467834473\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034443855285645\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305208921432495\n",
            "g_norm = tensor(0.1390, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036141395568848\n",
            "g_norm = tensor(0.1566, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302534580230713\n",
            "g_norm = tensor(0.1557, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.15611267089844\n",
            "||∇_X meta|| = 0.002761233365163207\n",
            "ΔX norm: 2.7612326448434032e-05\n",
            "Stage 9/10:  14%|████▎                         | 43/300 [01:47<10:32,  2.46s/it]T Loss=2.302786111831665\n",
            "g_norm = tensor(0.1378, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032872676849365\n",
            "g_norm = tensor(0.1323, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30418062210083\n",
            "g_norm = tensor(0.1262, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30374813079834\n",
            "g_norm = tensor(0.1330, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30291748046875\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0088348388672\n",
            "||∇_X meta|| = 0.0028002499602735043\n",
            "ΔX norm: 2.8002512408420444e-05\n",
            "Stage 9/10:  15%|████▍                         | 44/300 [01:50<10:33,  2.47s/it]T Loss=2.304103374481201\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303701877593994\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033576011657715\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045504093170166\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035950660705566\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.29486083984375\n",
            "||∇_X meta|| = 0.002475145971402526\n",
            "ΔX norm: 2.4751498131081462e-05\n",
            "Stage 9/10:  15%|████▌                         | 45/300 [01:52<10:17,  2.42s/it]T Loss=2.303974151611328\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30460524559021\n",
            "g_norm = tensor(0.0815, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048558235168457\n",
            "g_norm = tensor(0.0866, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032238483428955\n",
            "g_norm = tensor(0.0851, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040387630462646\n",
            "g_norm = tensor(0.0805, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.51760864257812\n",
            "||∇_X meta|| = 0.0027153408154845238\n",
            "ΔX norm: 2.7153451810590923e-05\n",
            "Stage 9/10:  15%|████▌                         | 46/300 [01:54<10:28,  2.48s/it]T Loss=2.304701089859009\n",
            "g_norm = tensor(0.1464, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037257194519043\n",
            "g_norm = tensor(0.1312, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305123805999756\n",
            "g_norm = tensor(0.1213, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032851219177246\n",
            "g_norm = tensor(0.1075, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039705753326416\n",
            "g_norm = tensor(0.1266, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.32835388183594\n",
            "||∇_X meta|| = 0.0030247068498283625\n",
            "ΔX norm: 3.024705256393645e-05\n",
            "Stage 9/10:  16%|████▋                         | 47/300 [01:57<10:15,  2.43s/it]T Loss=2.305494546890259\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301788330078125\n",
            "g_norm = tensor(0.1375, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032314777374268\n",
            "g_norm = tensor(0.1266, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043289184570312\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302896022796631\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4394073486328\n",
            "||∇_X meta|| = 0.002556624822318554\n",
            "ΔX norm: 2.5566230760887265e-05\n",
            "Stage 9/10:  16%|████▊                         | 48/300 [01:59<10:08,  2.41s/it]T Loss=2.3024325370788574\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037796020507812\n",
            "g_norm = tensor(0.0828, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032989501953125\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034496307373047\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035027980804443\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.6905975341797\n",
            "||∇_X meta|| = 0.002543906681239605\n",
            "ΔX norm: 2.5439048840780742e-05\n",
            "Stage 9/10:  16%|████▉                         | 49/300 [02:02<10:06,  2.41s/it]T Loss=2.3033385276794434\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043265342712402\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028788566589355\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302497386932373\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023483753204346\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5747833251953\n",
            "||∇_X meta|| = 0.003004837315529585\n",
            "ΔX norm: 3.0048367989365943e-05\n",
            "Stage 9/10:  17%|█████                         | 50/300 [02:04<09:42,  2.33s/it]T Loss=2.3031692504882812\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039798736572266\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303712844848633\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040285110473633\n",
            "g_norm = tensor(0.0792, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302643299102783\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2806854248047\n",
            "||∇_X meta|| = 0.002856664825230837\n",
            "ΔX norm: 2.8566682885866612e-05\n",
            "Stage 9/10:  17%|█████                         | 51/300 [02:06<09:30,  2.29s/it]T Loss=2.303858518600464\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031721115112305\n",
            "g_norm = tensor(0.1235, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302893877029419\n",
            "g_norm = tensor(0.1099, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303267002105713\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304574728012085\n",
            "g_norm = tensor(0.1053, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.88992309570312\n",
            "||∇_X meta|| = 0.0024454460944980383\n",
            "ΔX norm: 2.445448626531288e-05\n",
            "Stage 9/10:  17%|█████▏                        | 52/300 [02:08<09:23,  2.27s/it]T Loss=2.3037638664245605\n",
            "g_norm = tensor(0.1110, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302833080291748\n",
            "g_norm = tensor(0.1273, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303647518157959\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045859336853027\n",
            "g_norm = tensor(0.1250, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303950786590576\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.81936645507812\n",
            "||∇_X meta|| = 0.002532081911340356\n",
            "ΔX norm: 2.5320836357423104e-05\n",
            "Stage 9/10:  18%|█████▎                        | 53/300 [02:10<09:13,  2.24s/it]T Loss=2.3036322593688965\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037941455841064\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303628444671631\n",
            "g_norm = tensor(0.1305, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044891357421875\n",
            "g_norm = tensor(0.1514, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304018974304199\n",
            "g_norm = tensor(0.1255, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.98422241210938\n",
            "||∇_X meta|| = 0.0025834660045802593\n",
            "ΔX norm: 2.5834653570200317e-05\n",
            "Stage 9/10:  18%|█████▍                        | 54/300 [02:12<09:01,  2.20s/it]T Loss=2.304516315460205\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043408393859863\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051204681396484\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304574489593506\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303713083267212\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.0035400390625\n",
            "||∇_X meta|| = 0.0026434478349983692\n",
            "ΔX norm: 2.6434512619744055e-05\n",
            "Stage 9/10:  18%|█████▌                        | 55/300 [02:14<08:51,  2.17s/it]T Loss=2.3031585216522217\n",
            "g_norm = tensor(0.1395, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302875518798828\n",
            "g_norm = tensor(0.1355, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304339647293091\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024449348449707\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303513765335083\n",
            "g_norm = tensor(0.1365, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.75027465820312\n",
            "||∇_X meta|| = 0.002537750406190753\n",
            "ΔX norm: 2.537745240260847e-05\n",
            "Stage 9/10:  19%|█████▌                        | 56/300 [02:17<08:46,  2.16s/it]T Loss=2.3024497032165527\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028223514556885\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038551807403564\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024933338165283\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027729988098145\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.220947265625\n",
            "||∇_X meta|| = 0.0025070698466151953\n",
            "ΔX norm: 2.50706998485839e-05\n",
            "Stage 9/10:  19%|█████▋                        | 57/300 [02:19<09:06,  2.25s/it]T Loss=2.3035569190979004\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303151845932007\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305105447769165\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304758071899414\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038251399993896\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5948028564453\n",
            "||∇_X meta|| = 0.0023746276274323463\n",
            "ΔX norm: 2.374627729295753e-05\n",
            "Stage 9/10:  19%|█████▊                        | 58/300 [02:21<08:59,  2.23s/it]T Loss=2.303021192550659\n",
            "g_norm = tensor(0.1519, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304084539413452\n",
            "g_norm = tensor(0.1269, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052780628204346\n",
            "g_norm = tensor(0.1754, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303691864013672\n",
            "g_norm = tensor(0.1697, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028359413146973\n",
            "g_norm = tensor(0.1427, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.27053833007812\n",
            "||∇_X meta|| = 0.0025868138764053583\n",
            "ΔX norm: 2.586810296634212e-05\n",
            "Stage 9/10:  20%|█████▉                        | 59/300 [02:23<08:49,  2.20s/it]T Loss=2.305413246154785\n",
            "g_norm = tensor(0.1452, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304450511932373\n",
            "g_norm = tensor(0.1216, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056044578552246\n",
            "g_norm = tensor(0.1581, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304899215698242\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037657737731934\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.96102905273438\n",
            "||∇_X meta|| = 0.00214090826921165\n",
            "ΔX norm: 2.1409077817224897e-05\n",
            "Stage 9/10:  20%|██████                        | 60/300 [02:25<08:38,  2.16s/it]T Loss=2.3040897846221924\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30479097366333\n",
            "g_norm = tensor(0.1187, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036563396453857\n",
            "g_norm = tensor(0.1154, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303539752960205\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3059003353118896\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5305633544922\n",
            "||∇_X meta|| = 0.002513083629310131\n",
            "ΔX norm: 2.513082836230751e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 9/10:  20%|██████                        | 61/300 [02:28<09:08,  2.30s/it]T Loss=2.304523229598999\n",
            "g_norm = tensor(0.1467, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30432391166687\n",
            "g_norm = tensor(0.1433, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047664165496826\n",
            "g_norm = tensor(0.1519, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306046962738037\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304041862487793\n",
            "g_norm = tensor(0.1338, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.47372436523438\n",
            "||∇_X meta|| = 0.0027119459118694067\n",
            "ΔX norm: 2.7119453079649247e-05\n",
            "Stage 9/10:  21%|██████▏                       | 62/300 [02:31<09:24,  2.37s/it]T Loss=2.3040480613708496\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303734302520752\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020083904266357\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040263652801514\n",
            "g_norm = tensor(0.0902, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303008556365967\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.78018188476562\n",
            "||∇_X meta|| = 0.0025659098755568266\n",
            "ΔX norm: 2.5659106540842913e-05\n",
            "Stage 9/10:  21%|██████▎                       | 63/300 [02:33<09:12,  2.33s/it]T Loss=2.3029258251190186\n",
            "g_norm = tensor(0.0947, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303032159805298\n",
            "g_norm = tensor(0.0834, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032286167144775\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033559322357178\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023903369903564\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.48907470703125\n",
            "||∇_X meta|| = 0.0023501869291067123\n",
            "ΔX norm: 2.350188879063353e-05\n",
            "Stage 9/10:  21%|██████▍                       | 64/300 [02:35<08:51,  2.25s/it]T Loss=2.3054146766662598\n",
            "g_norm = tensor(0.1263, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305356502532959\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055076599121094\n",
            "g_norm = tensor(0.1275, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058831691741943\n",
            "g_norm = tensor(0.1612, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304654121398926\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5979461669922\n",
            "||∇_X meta|| = 0.002708292566239834\n",
            "ΔX norm: 2.7082911401521415e-05\n",
            "Stage 9/10:  22%|██████▌                       | 65/300 [02:37<08:34,  2.19s/it]T Loss=2.3042778968811035\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304603338241577\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044915199279785\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040759563446045\n",
            "g_norm = tensor(0.0888, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037021160125732\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.26170349121094\n",
            "||∇_X meta|| = 0.002337528858333826\n",
            "ΔX norm: 2.337530349905137e-05\n",
            "Stage 9/10:  22%|██████▌                       | 66/300 [02:39<08:50,  2.27s/it]T Loss=2.3024754524230957\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034420013427734\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302161931991577\n",
            "g_norm = tensor(0.0815, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302993059158325\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031928539276123\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9271240234375\n",
            "||∇_X meta|| = 0.0020519918762147427\n",
            "ΔX norm: 2.0519915779004805e-05\n",
            "Stage 9/10:  22%|██████▋                       | 67/300 [02:42<08:36,  2.22s/it]T Loss=2.3038973808288574\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044705390930176\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041372299194336\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023812770843506\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029627799987793\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.02932739257812\n",
            "||∇_X meta|| = 0.0020571842323988676\n",
            "ΔX norm: 2.0571835193550214e-05\n",
            "Stage 9/10:  23%|██████▊                       | 68/300 [02:44<08:26,  2.18s/it]T Loss=2.3042728900909424\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305154800415039\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304691791534424\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304108142852783\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042800426483154\n",
            "g_norm = tensor(0.1075, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.7803497314453\n",
            "||∇_X meta|| = 0.002284377347677946\n",
            "ΔX norm: 2.284377478645183e-05\n",
            "Stage 9/10:  23%|██████▉                       | 69/300 [02:46<08:39,  2.25s/it]T Loss=2.304527759552002\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302753210067749\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032336235046387\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033509254455566\n",
            "g_norm = tensor(0.0867, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304064989089966\n",
            "g_norm = tensor(0.0890, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9838409423828\n",
            "||∇_X meta|| = 0.002200739225372672\n",
            "ΔX norm: 2.2007390725775622e-05\n",
            "Stage 9/10:  23%|███████                       | 70/300 [02:48<08:22,  2.18s/it]T Loss=2.3026251792907715\n",
            "g_norm = tensor(0.0836, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303570032119751\n",
            "g_norm = tensor(0.0919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033246994018555\n",
            "g_norm = tensor(0.0764, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304507255554199\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303530693054199\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.92190551757812\n",
            "||∇_X meta|| = 0.0021317501086741686\n",
            "ΔX norm: 2.131748988176696e-05\n",
            "Stage 9/10:  24%|███████                       | 71/300 [02:51<08:39,  2.27s/it]T Loss=2.3044791221618652\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303804636001587\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30407452583313\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303636074066162\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040003776550293\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.61856079101562\n",
            "||∇_X meta|| = 0.002019717125222087\n",
            "ΔX norm: 2.0197152480250224e-05\n",
            "Stage 9/10:  24%|███████▏                      | 72/300 [02:53<08:42,  2.29s/it]T Loss=2.3021862506866455\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303112506866455\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040060997009277\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033502101898193\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304018497467041\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.65921020507812\n",
            "||∇_X meta|| = 0.002482395153492689\n",
            "ΔX norm: 2.4823981220833957e-05\n",
            "Stage 9/10:  24%|███████▎                      | 73/300 [02:55<08:50,  2.34s/it]T Loss=2.3045260906219482\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051795959472656\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303504467010498\n",
            "g_norm = tensor(0.0983, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305168867111206\n",
            "g_norm = tensor(0.1349, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044981956481934\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.74693298339844\n",
            "||∇_X meta|| = 0.0022861636243760586\n",
            "ΔX norm: 2.286160088260658e-05\n",
            "Stage 9/10:  25%|███████▍                      | 74/300 [02:57<08:35,  2.28s/it]T Loss=2.303713083267212\n",
            "g_norm = tensor(0.1736, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303617238998413\n",
            "g_norm = tensor(0.1532, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022289276123047\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302610158920288\n",
            "g_norm = tensor(0.1312, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303663969039917\n",
            "g_norm = tensor(0.1386, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.119873046875\n",
            "||∇_X meta|| = 0.00215453514829278\n",
            "ΔX norm: 2.154535468434915e-05\n",
            "Stage 9/10:  25%|███████▌                      | 75/300 [03:00<08:33,  2.28s/it]T Loss=2.3044583797454834\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304781675338745\n",
            "g_norm = tensor(0.1080, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041622638702393\n",
            "g_norm = tensor(0.0872, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038477897644043\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040995597839355\n",
            "g_norm = tensor(0.0828, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.44326782226562\n",
            "||∇_X meta|| = 0.0021968160290271044\n",
            "ΔX norm: 2.196816603827756e-05\n",
            "Stage 9/10:  25%|███████▌                      | 76/300 [03:02<08:26,  2.26s/it]T Loss=2.303637981414795\n",
            "g_norm = tensor(0.0755, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303919792175293\n",
            "g_norm = tensor(0.0705, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303633451461792\n",
            "g_norm = tensor(0.0739, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303732395172119\n",
            "g_norm = tensor(0.0672, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033928871154785\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.77784729003906\n",
            "||∇_X meta|| = 0.002206493867561221\n",
            "ΔX norm: 2.2064970835344866e-05\n",
            "Stage 9/10:  26%|███████▋                      | 77/300 [03:04<08:12,  2.21s/it]T Loss=2.3038554191589355\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303361654281616\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305015802383423\n",
            "g_norm = tensor(0.1338, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304821014404297\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034005165100098\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.15191650390625\n",
            "||∇_X meta|| = 0.0019457676680758595\n",
            "ΔX norm: 1.9457665985100903e-05\n",
            "Stage 9/10:  26%|███████▊                      | 78/300 [03:06<08:05,  2.18s/it]T Loss=2.3034284114837646\n",
            "g_norm = tensor(0.0873, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302906036376953\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023746013641357\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033699989318848\n",
            "g_norm = tensor(0.0877, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028619289398193\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =227.72372436523438\n",
            "||∇_X meta|| = 0.0020422975067049265\n",
            "ΔX norm: 2.042296910076402e-05\n",
            "Stage 9/10:  26%|███████▉                      | 79/300 [03:08<07:57,  2.16s/it]T Loss=2.303074598312378\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038218021392822\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302753210067749\n",
            "g_norm = tensor(0.0814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039729595184326\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303907871246338\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4110870361328\n",
            "||∇_X meta|| = 0.002199519658461213\n",
            "ΔX norm: 2.1995212591718882e-05\n",
            "Stage 9/10:  27%|████████                      | 80/300 [03:10<07:45,  2.12s/it]T Loss=2.304887294769287\n",
            "g_norm = tensor(0.0941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040237426757812\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051464557647705\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039021492004395\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050878047943115\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.26576232910156\n",
            "||∇_X meta|| = 0.0021597014274448156\n",
            "ΔX norm: 2.1597012164420448e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 9/10:  27%|████████                      | 81/300 [03:12<07:48,  2.14s/it]T Loss=2.303284168243408\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034071922302246\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304321765899658\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037431240081787\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303561210632324\n",
            "g_norm = tensor(0.0827, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.39564514160156\n",
            "||∇_X meta|| = 0.0018468634225428104\n",
            "ΔX norm: 1.8468626876710914e-05\n",
            "Stage 9/10:  27%|████████▏                     | 82/300 [03:15<07:45,  2.13s/it]T Loss=2.305145740509033\n",
            "g_norm = tensor(0.1511, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046278953552246\n",
            "g_norm = tensor(0.1558, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304011821746826\n",
            "g_norm = tensor(0.1376, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304041862487793\n",
            "g_norm = tensor(0.1566, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303560256958008\n",
            "g_norm = tensor(0.1486, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.6115264892578\n",
            "||∇_X meta|| = 0.001851815264672041\n",
            "ΔX norm: 1.851816887210589e-05\n",
            "Stage 9/10:  28%|████████▎                     | 83/300 [03:17<07:34,  2.09s/it]T Loss=2.3027026653289795\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304002523422241\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035571575164795\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303842306137085\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027968406677246\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9822235107422\n",
            "||∇_X meta|| = 0.0022144147660583258\n",
            "ΔX norm: 2.2144140530144796e-05\n",
            "Stage 9/10:  28%|████████▍                     | 84/300 [03:19<07:25,  2.06s/it]T Loss=2.305723190307617\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3062543869018555\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052151203155518\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041396141052246\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053488731384277\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.69900512695312\n",
            "||∇_X meta|| = 0.002435235073789954\n",
            "ΔX norm: 2.435236456221901e-05\n",
            "Stage 9/10:  28%|████████▌                     | 85/300 [03:21<07:14,  2.02s/it]T Loss=2.3034703731536865\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304962635040283\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30485200881958\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305540084838867\n",
            "g_norm = tensor(0.1140, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033647537231445\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.13365173339844\n",
            "||∇_X meta|| = 0.0019454665016382933\n",
            "ΔX norm: 1.9454644643701613e-05\n",
            "Stage 9/10:  29%|████████▌                     | 86/300 [03:23<07:13,  2.02s/it]T Loss=2.3050873279571533\n",
            "g_norm = tensor(0.1932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032093048095703\n",
            "g_norm = tensor(0.1473, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302821159362793\n",
            "g_norm = tensor(0.1542, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3007869720458984\n",
            "g_norm = tensor(0.1396, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054628372192383\n",
            "g_norm = tensor(0.1458, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.042236328125\n",
            "||∇_X meta|| = 0.001844818121753633\n",
            "ΔX norm: 1.844818143581506e-05\n",
            "Stage 9/10:  29%|████████▋                     | 87/300 [03:25<07:26,  2.10s/it]T Loss=2.304069995880127\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30548095703125\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038320541381836\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304279327392578\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039023876190186\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.84117126464844\n",
            "||∇_X meta|| = 0.0018372252816334367\n",
            "ΔX norm: 1.8372240447206423e-05\n",
            "Stage 9/10:  29%|████████▊                     | 88/300 [03:27<07:30,  2.13s/it]T Loss=2.3030378818511963\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017425537109375\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048043251037598\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044536113739014\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303812026977539\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.50228881835938\n",
            "||∇_X meta|| = 0.0020777310710400343\n",
            "ΔX norm: 2.0777310055564158e-05\n",
            "Stage 9/10:  30%|████████▉                     | 89/300 [03:29<07:29,  2.13s/it]T Loss=2.3038175106048584\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050341606140137\n",
            "g_norm = tensor(0.1340, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036859035491943\n",
            "g_norm = tensor(0.1368, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305332899093628\n",
            "g_norm = tensor(0.1321, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033814430236816\n",
            "g_norm = tensor(0.1270, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3346710205078\n",
            "||∇_X meta|| = 0.0019194637425243855\n",
            "ΔX norm: 1.919462920341175e-05\n",
            "Stage 9/10:  30%|█████████                     | 90/300 [03:31<07:24,  2.12s/it]T Loss=2.303295612335205\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030054569244385\n",
            "g_norm = tensor(0.1234, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030409812927246\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030991554260254\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018863201141357\n",
            "g_norm = tensor(0.1379, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.05816650390625\n",
            "||∇_X meta|| = 0.0020733510609716177\n",
            "ΔX norm: 2.0733497876790352e-05\n",
            "Stage 9/10:  30%|█████████                     | 91/300 [03:33<07:14,  2.08s/it]T Loss=2.303771495819092\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304152011871338\n",
            "g_norm = tensor(0.1323, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30460786819458\n",
            "g_norm = tensor(0.1320, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304309129714966\n",
            "g_norm = tensor(0.1328, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3063137531280518\n",
            "g_norm = tensor(0.1374, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.89892578125\n",
            "||∇_X meta|| = 0.0019007519586011767\n",
            "ΔX norm: 1.900752067740541e-05\n",
            "Stage 9/10:  31%|█████████▏                    | 92/300 [03:35<07:01,  2.03s/it]T Loss=2.3028616905212402\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302405834197998\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034141063690186\n",
            "g_norm = tensor(0.1333, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030123710632324\n",
            "g_norm = tensor(0.1377, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043532371520996\n",
            "g_norm = tensor(0.1362, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.039306640625\n",
            "||∇_X meta|| = 0.0019174515036866069\n",
            "ΔX norm: 1.9174522094544955e-05\n",
            "Stage 9/10:  31%|█████████▎                    | 93/300 [03:37<06:54,  2.00s/it]T Loss=2.3047142028808594\n",
            "g_norm = tensor(0.1269, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041558265686035\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041019439697266\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028550148010254\n",
            "g_norm = tensor(0.1351, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052022457122803\n",
            "g_norm = tensor(0.1309, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.61517333984375\n",
            "||∇_X meta|| = 0.0019885916262865067\n",
            "ΔX norm: 1.988591975532472e-05\n",
            "Stage 9/10:  31%|█████████▍                    | 94/300 [03:39<06:48,  1.98s/it]T Loss=2.3037452697753906\n",
            "g_norm = tensor(0.1382, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038570880889893\n",
            "g_norm = tensor(0.1582, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028202056884766\n",
            "g_norm = tensor(0.1427, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028485774993896\n",
            "g_norm = tensor(0.1644, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304084539413452\n",
            "g_norm = tensor(0.1548, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.41119384765625\n",
            "||∇_X meta|| = 0.0018203933723270893\n",
            "ΔX norm: 1.8203909348812886e-05\n",
            "Stage 9/10:  32%|█████████▌                    | 95/300 [03:41<06:43,  1.97s/it]T Loss=2.304344892501831\n",
            "g_norm = tensor(0.1442, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031387329101562\n",
            "g_norm = tensor(0.1474, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304853916168213\n",
            "g_norm = tensor(0.1416, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304919719696045\n",
            "g_norm = tensor(0.1360, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018691539764404\n",
            "g_norm = tensor(0.1410, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.55816650390625\n",
            "||∇_X meta|| = 0.0018494336400181055\n",
            "ΔX norm: 1.849431100708898e-05\n",
            "Stage 9/10:  32%|█████████▌                    | 96/300 [03:43<06:42,  1.97s/it]T Loss=2.3030409812927246\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302478790283203\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029797077178955\n",
            "g_norm = tensor(0.1639, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302414655685425\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304180145263672\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.49542236328125\n",
            "||∇_X meta|| = 0.0017691623652353883\n",
            "ΔX norm: 1.769162918208167e-05\n",
            "Stage 9/10:  32%|█████████▋                    | 97/300 [03:45<06:41,  1.98s/it]T Loss=2.302877426147461\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032901287078857\n",
            "g_norm = tensor(0.1653, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041958808898926\n",
            "g_norm = tensor(0.1393, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303656816482544\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048813343048096\n",
            "g_norm = tensor(0.1369, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.74098205566406\n",
            "||∇_X meta|| = 0.0020633158273994923\n",
            "ΔX norm: 2.063317151623778e-05\n",
            "Stage 9/10:  33%|█████████▊                    | 98/300 [03:47<06:56,  2.06s/it]T Loss=2.3040847778320312\n",
            "g_norm = tensor(0.0770, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039848804473877\n",
            "g_norm = tensor(0.0862, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303997039794922\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304436445236206\n",
            "g_norm = tensor(0.0829, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034751415252686\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7471160888672\n",
            "||∇_X meta|| = 0.0021186107769608498\n",
            "ΔX norm: 2.1186129743000492e-05\n",
            "Stage 9/10:  33%|█████████▉                    | 99/300 [03:49<06:55,  2.07s/it]T Loss=2.3048946857452393\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039631843566895\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304164409637451\n",
            "g_norm = tensor(0.1099, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304070472717285\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034493923187256\n",
            "g_norm = tensor(0.1282, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.93394470214844\n",
            "||∇_X meta|| = 0.001994986552745104\n",
            "ΔX norm: 1.994988451770041e-05\n",
            "Stage 9/10:  33%|█████████▋                   | 100/300 [03:51<06:49,  2.05s/it]T Loss=2.3042893409729004\n",
            "g_norm = tensor(0.1572, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304142475128174\n",
            "g_norm = tensor(0.1746, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304973602294922\n",
            "g_norm = tensor(0.1477, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047378063201904\n",
            "g_norm = tensor(0.1577, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303654193878174\n",
            "g_norm = tensor(0.1714, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.69834899902344\n",
            "||∇_X meta|| = 0.0016029143007472157\n",
            "ΔX norm: 1.6029149264795706e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 9/10:  34%|█████████▊                   | 101/300 [03:53<06:45,  2.04s/it]T Loss=2.3039965629577637\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031764030456543\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30371356010437\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035411834716797\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035426139831543\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.73678588867188\n",
            "||∇_X meta|| = 0.0018578823655843735\n",
            "ΔX norm: 1.8578844901639968e-05\n",
            "Stage 9/10:  34%|█████████▊                   | 102/300 [03:55<06:50,  2.07s/it]T Loss=2.3058931827545166\n",
            "g_norm = tensor(0.1325, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046534061431885\n",
            "g_norm = tensor(0.1356, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042986392974854\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040120601654053\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049705028533936\n",
            "g_norm = tensor(0.1335, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2197265625\n",
            "||∇_X meta|| = 0.0019073180155828595\n",
            "ΔX norm: 1.9073182556894608e-05\n",
            "Stage 9/10:  34%|█████████▉                   | 103/300 [03:57<06:43,  2.05s/it]T Loss=2.3052070140838623\n",
            "g_norm = tensor(0.1479, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3061745166778564\n",
            "g_norm = tensor(0.1464, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305295467376709\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304286479949951\n",
            "g_norm = tensor(0.1377, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041622638702393\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.87844848632812\n",
            "||∇_X meta|| = 0.001947734854184091\n",
            "ΔX norm: 1.947734381246846e-05\n",
            "Stage 9/10:  35%|██████████                   | 104/300 [04:00<06:49,  2.09s/it]T Loss=2.305246353149414\n",
            "g_norm = tensor(0.1356, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305417537689209\n",
            "g_norm = tensor(0.1322, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304647445678711\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305046319961548\n",
            "g_norm = tensor(0.1359, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053178787231445\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.611083984375\n",
            "||∇_X meta|| = 0.0017067881999537349\n",
            "ΔX norm: 1.706788498267997e-05\n",
            "Stage 9/10:  35%|██████████▏                  | 105/300 [04:02<06:52,  2.12s/it]T Loss=2.3061881065368652\n",
            "g_norm = tensor(0.1382, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044629096984863\n",
            "g_norm = tensor(0.1421, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036580085754395\n",
            "g_norm = tensor(0.1468, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305548906326294\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038110733032227\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.04017639160156\n",
            "||∇_X meta|| = 0.0018371905898675323\n",
            "ΔX norm: 1.8371893020230345e-05\n",
            "Stage 9/10:  35%|██████████▏                  | 106/300 [04:04<06:46,  2.09s/it]T Loss=2.3032286167144775\n",
            "g_norm = tensor(0.0846, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036203384399414\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302842855453491\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044357299804688\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037092685699463\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.36993408203125\n",
            "||∇_X meta|| = 0.001756454585120082\n",
            "ΔX norm: 1.7564549125381745e-05\n",
            "Stage 9/10:  36%|██████████▎                  | 107/300 [04:06<06:35,  2.05s/it]T Loss=2.3038747310638428\n",
            "g_norm = tensor(0.0740, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034896850585938\n",
            "g_norm = tensor(0.0749, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303384304046631\n",
            "g_norm = tensor(0.0812, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038573265075684\n",
            "g_norm = tensor(0.0644, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304020881652832\n",
            "g_norm = tensor(0.0768, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.60740661621094\n",
            "||∇_X meta|| = 0.0016747983172535896\n",
            "ΔX norm: 1.674798841122538e-05\n",
            "Stage 9/10:  36%|██████████▍                  | 108/300 [04:08<06:28,  2.02s/it]T Loss=2.303630828857422\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304002285003662\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040788173675537\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040807247161865\n",
            "g_norm = tensor(0.1259, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042664527893066\n",
            "g_norm = tensor(0.1218, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6724090576172\n",
            "||∇_X meta|| = 0.0017982996068894863\n",
            "ΔX norm: 1.798298217181582e-05\n",
            "Stage 9/10:  36%|██████████▌                  | 109/300 [04:10<06:22,  2.00s/it]T Loss=2.303994655609131\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034353256225586\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030123710632324\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303349733352661\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303191900253296\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0094451904297\n",
            "||∇_X meta|| = 0.0017652410315349698\n",
            "ΔX norm: 1.7652409951551817e-05\n",
            "Stage 9/10:  37%|██████████▋                  | 110/300 [04:12<06:56,  2.19s/it]T Loss=2.304173231124878\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304112195968628\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043253421783447\n",
            "g_norm = tensor(0.0993, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304213047027588\n",
            "g_norm = tensor(0.0983, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30487060546875\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.04562377929688\n",
            "||∇_X meta|| = 0.0021399944089353085\n",
            "ΔX norm: 2.1399933757493272e-05\n",
            "Stage 9/10:  37%|██████████▋                  | 111/300 [04:15<06:55,  2.20s/it]T Loss=2.3045437335968018\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304006814956665\n",
            "g_norm = tensor(0.0883, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045802116394043\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304290294647217\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037707805633545\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.8420867919922\n",
            "||∇_X meta|| = 0.0019863357301801443\n",
            "ΔX norm: 1.986334791581612e-05\n",
            "Stage 9/10:  37%|██████████▊                  | 112/300 [04:17<06:42,  2.14s/it]T Loss=2.3047802448272705\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304568290710449\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304142475128174\n",
            "g_norm = tensor(0.0784, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050661087036133\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042871952056885\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.98545837402344\n",
            "||∇_X meta|| = 0.0018478279234841466\n",
            "ΔX norm: 1.8478272977517918e-05\n",
            "Stage 9/10:  38%|██████████▉                  | 113/300 [04:19<06:35,  2.11s/it]T Loss=2.3027617931365967\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031280040740967\n",
            "g_norm = tensor(0.1390, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301140546798706\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040688037872314\n",
            "g_norm = tensor(0.1504, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031837940216064\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.85240173339844\n",
            "||∇_X meta|| = 0.0018742693355306983\n",
            "ΔX norm: 1.8742677639238536e-05\n",
            "Stage 9/10:  38%|███████████                  | 114/300 [04:21<06:33,  2.12s/it]T Loss=2.304685592651367\n",
            "g_norm = tensor(0.1664, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046913146972656\n",
            "g_norm = tensor(0.2169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054840564727783\n",
            "g_norm = tensor(0.1694, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026633262634277\n",
            "g_norm = tensor(0.1603, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.307814836502075\n",
            "g_norm = tensor(0.1937, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.31906127929688\n",
            "||∇_X meta|| = 0.001608616323210299\n",
            "ΔX norm: 1.6086163668660447e-05\n",
            "Stage 9/10:  38%|███████████                  | 115/300 [04:23<06:39,  2.16s/it]T Loss=2.302086353302002\n",
            "g_norm = tensor(0.1210, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303091526031494\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3016273975372314\n",
            "g_norm = tensor(0.1255, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036460876464844\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3002820014953613\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.24290466308594\n",
            "||∇_X meta|| = 0.001799144665710628\n",
            "ΔX norm: 1.79914368345635e-05\n",
            "Stage 9/10:  39%|███████████▏                 | 116/300 [04:25<06:33,  2.14s/it]T Loss=2.303107976913452\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028512001037598\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303666591644287\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030362129211426\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034579753875732\n",
            "g_norm = tensor(0.0947, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.49244689941406\n",
            "||∇_X meta|| = 0.0017166779143735766\n",
            "ΔX norm: 1.7166803445434198e-05\n",
            "Stage 9/10:  39%|███████████▎                 | 117/300 [04:27<06:23,  2.09s/it]T Loss=2.303170919418335\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304328441619873\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303611993789673\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023314476013184\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026931285858154\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.84133911132812\n",
            "||∇_X meta|| = 0.0017753472784534097\n",
            "ΔX norm: 1.7753463907865807e-05\n",
            "Stage 9/10:  39%|███████████▍                 | 118/300 [04:29<06:18,  2.08s/it]T Loss=2.3041913509368896\n",
            "g_norm = tensor(0.0865, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041818141937256\n",
            "g_norm = tensor(0.0861, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036725521087646\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039650917053223\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303473711013794\n",
            "g_norm = tensor(0.0747, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7900390625\n",
            "||∇_X meta|| = 0.0017360839992761612\n",
            "ΔX norm: 1.7360856872983277e-05\n",
            "Stage 9/10:  40%|███████████▌                 | 119/300 [04:31<06:13,  2.07s/it]T Loss=2.3030383586883545\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037936687469482\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026771545410156\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30485200881958\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032398223876953\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.32440185546875\n",
            "||∇_X meta|| = 0.0019812299869954586\n",
            "ΔX norm: 1.98122943402268e-05\n",
            "Stage 9/10:  40%|███████████▌                 | 120/300 [04:33<06:16,  2.09s/it]T Loss=2.3040060997009277\n",
            "g_norm = tensor(0.0799, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048694133758545\n",
            "g_norm = tensor(0.0843, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037333488464355\n",
            "g_norm = tensor(0.0730, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303117275238037\n",
            "g_norm = tensor(0.0830, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304753065109253\n",
            "g_norm = tensor(0.0740, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.41448974609375\n",
            "||∇_X meta|| = 0.0017025464912876487\n",
            "ΔX norm: 1.7025469787768088e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 9/10:  40%|███████████▋                 | 121/300 [04:35<06:15,  2.10s/it]T Loss=2.303684711456299\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304283618927002\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303347110748291\n",
            "g_norm = tensor(0.0923, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033642768859863\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30281400680542\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.25924682617188\n",
            "||∇_X meta|| = 0.0017010195879265666\n",
            "ΔX norm: 1.7010192095767707e-05\n",
            "Stage 9/10:  41%|███████████▊                 | 122/300 [04:38<06:27,  2.18s/it]T Loss=2.3026580810546875\n",
            "g_norm = tensor(0.0812, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037667274475098\n",
            "g_norm = tensor(0.0856, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028171062469482\n",
            "g_norm = tensor(0.0795, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302715539932251\n",
            "g_norm = tensor(0.0766, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304713726043701\n",
            "g_norm = tensor(0.1022, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.84136962890625\n",
            "||∇_X meta|| = 0.0019051306881010532\n",
            "ΔX norm: 1.9051312847295776e-05\n",
            "Stage 9/10:  41%|███████████▉                 | 123/300 [04:40<06:27,  2.19s/it]T Loss=2.3047096729278564\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303877830505371\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305483341217041\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304708957672119\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038060665130615\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.08628845214844\n",
            "||∇_X meta|| = 0.001707058516331017\n",
            "ΔX norm: 1.7070591638912447e-05\n",
            "Stage 9/10:  41%|███████████▉                 | 124/300 [04:42<06:20,  2.16s/it]T Loss=2.3036904335021973\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048484325408936\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041796684265137\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304900646209717\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304619312286377\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.52455139160156\n",
            "||∇_X meta|| = 0.0016500179190188646\n",
            "ΔX norm: 1.6500191122759134e-05\n",
            "Stage 9/10:  42%|████████████                 | 125/300 [04:44<06:27,  2.22s/it]T Loss=2.3032805919647217\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304809331893921\n",
            "g_norm = tensor(0.1389, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033366203308105\n",
            "g_norm = tensor(0.1361, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045129776000977\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053150177001953\n",
            "g_norm = tensor(0.1268, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.46437072753906\n",
            "||∇_X meta|| = 0.0018854206427931786\n",
            "ΔX norm: 1.885420351754874e-05\n",
            "Stage 9/10:  42%|████████████▏                | 126/300 [04:46<06:17,  2.17s/it]T Loss=2.304321050643921\n",
            "g_norm = tensor(0.1352, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033552169799805\n",
            "g_norm = tensor(0.1213, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302889585494995\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026254177093506\n",
            "g_norm = tensor(0.1282, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3014626502990723\n",
            "g_norm = tensor(0.1362, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5518035888672\n",
            "||∇_X meta|| = 0.0017054688651114702\n",
            "ΔX norm: 1.705469549051486e-05\n",
            "Stage 9/10:  42%|████████████▎                | 127/300 [04:48<06:06,  2.12s/it]T Loss=2.304424524307251\n",
            "g_norm = tensor(0.0686, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305105209350586\n",
            "g_norm = tensor(0.0813, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048787117004395\n",
            "g_norm = tensor(0.0858, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054962158203125\n",
            "g_norm = tensor(0.0878, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306317090988159\n",
            "g_norm = tensor(0.0830, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.76234436035156\n",
            "||∇_X meta|| = 0.0017188434721902013\n",
            "ΔX norm: 1.7188418496516533e-05\n",
            "Stage 9/10:  43%|████████████▎                | 128/300 [04:50<05:58,  2.08s/it]T Loss=2.3044466972351074\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043947219848633\n",
            "g_norm = tensor(0.1399, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042092323303223\n",
            "g_norm = tensor(0.1402, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037943840026855\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304786205291748\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2975616455078\n",
            "||∇_X meta|| = 0.001745301648043096\n",
            "ΔX norm: 1.7452988686272874e-05\n",
            "Stage 9/10:  43%|████████████▍                | 129/300 [04:53<06:04,  2.13s/it]T Loss=2.3054213523864746\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304253339767456\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042824268341064\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302549123764038\n",
            "g_norm = tensor(0.1100, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304089069366455\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1041717529297\n",
            "||∇_X meta|| = 0.0014938870444893837\n",
            "ΔX norm: 1.4938875210646074e-05\n",
            "Stage 9/10:  43%|████████████▌                | 130/300 [04:55<06:11,  2.19s/it]T Loss=2.3028573989868164\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028671741485596\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303499698638916\n",
            "g_norm = tensor(0.1157, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032803535461426\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034636974334717\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.48680114746094\n",
            "||∇_X meta|| = 0.001619261340238154\n",
            "ΔX norm: 1.619260001461953e-05\n",
            "Stage 9/10:  44%|████████████▋                | 131/300 [04:57<06:11,  2.20s/it]T Loss=2.3039252758026123\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303323745727539\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305148124694824\n",
            "g_norm = tensor(0.0960, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040547370910645\n",
            "g_norm = tensor(0.0836, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303515911102295\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.82066345214844\n",
            "||∇_X meta|| = 0.0016906355740502477\n",
            "ΔX norm: 1.6906335076782852e-05\n",
            "Stage 9/10:  44%|████████████▊                | 132/300 [05:00<06:25,  2.29s/it]T Loss=2.3024842739105225\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303574323654175\n",
            "g_norm = tensor(0.1314, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024911880493164\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030543327331543\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037450313568115\n",
            "g_norm = tensor(0.1406, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.66107177734375\n",
            "||∇_X meta|| = 0.0018639406189322472\n",
            "ΔX norm: 1.863939905888401e-05\n",
            "Stage 9/10:  44%|████████████▊                | 133/300 [05:02<06:25,  2.31s/it]T Loss=2.3037078380584717\n",
            "g_norm = tensor(0.0827, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303201675415039\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036608695983887\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304117202758789\n",
            "g_norm = tensor(0.0945, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30410099029541\n",
            "g_norm = tensor(0.0833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.9724578857422\n",
            "||∇_X meta|| = 0.0017524168360978365\n",
            "ΔX norm: 1.752416937961243e-05\n",
            "Stage 9/10:  45%|████████████▉                | 134/300 [05:05<06:31,  2.36s/it]T Loss=2.303377866744995\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303654432296753\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030505180358887\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038697242736816\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031816482543945\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.65086364746094\n",
            "||∇_X meta|| = 0.001614773995243013\n",
            "ΔX norm: 1.614773464098107e-05\n",
            "Stage 9/10:  45%|█████████████                | 135/300 [05:07<06:29,  2.36s/it]T Loss=2.305985450744629\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302766799926758\n",
            "g_norm = tensor(0.1292, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304133892059326\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303422689437866\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302823066711426\n",
            "g_norm = tensor(0.1340, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.75173950195312\n",
            "||∇_X meta|| = 0.0014927589800208807\n",
            "ΔX norm: 1.4927588381397072e-05\n",
            "Stage 9/10:  45%|█████████████▏               | 136/300 [05:09<06:17,  2.30s/it]T Loss=2.3040719032287598\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037219047546387\n",
            "g_norm = tensor(0.1117, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040108680725098\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305144786834717\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043951988220215\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.26846313476562\n",
            "||∇_X meta|| = 0.0016148483846336603\n",
            "ΔX norm: 1.6148489521583542e-05\n",
            "Stage 9/10:  46%|█████████████▏               | 137/300 [05:11<06:12,  2.29s/it]T Loss=2.3034586906433105\n",
            "g_norm = tensor(0.1295, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047709465026855\n",
            "g_norm = tensor(0.1308, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043885231018066\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303182601928711\n",
            "g_norm = tensor(0.1561, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302729845046997\n",
            "g_norm = tensor(0.1491, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4595184326172\n",
            "||∇_X meta|| = 0.0016287080943584442\n",
            "ΔX norm: 1.6287114704027772e-05\n",
            "Stage 9/10:  46%|█████████████▎               | 138/300 [05:13<05:57,  2.21s/it]T Loss=2.303402900695801\n",
            "g_norm = tensor(0.1282, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303205966949463\n",
            "g_norm = tensor(0.1235, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045105934143066\n",
            "g_norm = tensor(0.1565, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304386615753174\n",
            "g_norm = tensor(0.1531, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028950691223145\n",
            "g_norm = tensor(0.1257, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.72415161132812\n",
            "||∇_X meta|| = 0.0017406849656254053\n",
            "ΔX norm: 1.7406857296009548e-05\n",
            "Stage 9/10:  46%|█████████████▍               | 139/300 [05:16<06:04,  2.26s/it]T Loss=2.304561138153076\n",
            "g_norm = tensor(0.1099, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023781776428223\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046963214874268\n",
            "g_norm = tensor(0.1107, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306175708770752\n",
            "g_norm = tensor(0.1521, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049230575561523\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.08926391601562\n",
            "||∇_X meta|| = 0.0015363377751782537\n",
            "ΔX norm: 1.5363360944320448e-05\n",
            "Stage 9/10:  47%|█████████████▌               | 140/300 [05:18<05:51,  2.20s/it]T Loss=2.3031704425811768\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029062747955322\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022844791412354\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302429437637329\n",
            "g_norm = tensor(0.1346, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024308681488037\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4158935546875\n",
            "||∇_X meta|| = 0.0015570285031571984\n",
            "ΔX norm: 1.5570311006740667e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 9/10:  47%|█████████████▋               | 141/300 [05:20<06:02,  2.28s/it]T Loss=2.3029580116271973\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303281784057617\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304025173187256\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029074668884277\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037350177764893\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8610382080078\n",
            "||∇_X meta|| = 0.0016555084148421884\n",
            "ΔX norm: 1.655507912801113e-05\n",
            "Stage 9/10:  47%|█████████████▋               | 142/300 [05:23<06:11,  2.35s/it]T Loss=2.3031063079833984\n",
            "g_norm = tensor(0.0941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303053140640259\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033738136291504\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303952217102051\n",
            "g_norm = tensor(0.0917, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039002418518066\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.00860595703125\n",
            "||∇_X meta|| = 0.0017524188151583076\n",
            "ΔX norm: 1.752416937961243e-05\n",
            "Stage 9/10:  48%|█████████████▊               | 143/300 [05:25<06:12,  2.37s/it]T Loss=2.304840564727783\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041162490844727\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304142475128174\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304220676422119\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035054206848145\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5895538330078\n",
            "||∇_X meta|| = 0.0016744302120059729\n",
            "ΔX norm: 1.6744312233640812e-05\n",
            "Stage 9/10:  48%|█████████████▉               | 144/300 [05:28<06:09,  2.37s/it]T Loss=2.303480863571167\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303961753845215\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035271167755127\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303738832473755\n",
            "g_norm = tensor(0.0825, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304279327392578\n",
            "g_norm = tensor(0.0818, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.728759765625\n",
            "||∇_X meta|| = 0.001685830415226519\n",
            "ΔX norm: 1.6858315575518645e-05\n",
            "Stage 9/10:  48%|██████████████               | 145/300 [05:30<06:05,  2.36s/it]T Loss=2.303370952606201\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033816814422607\n",
            "g_norm = tensor(0.0707, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030812740325928\n",
            "g_norm = tensor(0.0863, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034451007843018\n",
            "g_norm = tensor(0.0766, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303323745727539\n",
            "g_norm = tensor(0.0727, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.48480224609375\n",
            "||∇_X meta|| = 0.0014573903754353523\n",
            "ΔX norm: 1.457389043935109e-05\n",
            "Stage 9/10:  49%|██████████████               | 146/300 [05:32<06:04,  2.37s/it]T Loss=2.3023324012756348\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301816463470459\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027071952819824\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027069568634033\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020834922790527\n",
            "g_norm = tensor(0.0803, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.99786376953125\n",
            "||∇_X meta|| = 0.0018758522346615791\n",
            "ΔX norm: 1.8758539226837456e-05\n",
            "Stage 9/10:  49%|██████████████▏              | 147/300 [05:35<05:58,  2.34s/it]T Loss=2.303557872772217\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036727905273438\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305004358291626\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304121255874634\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050553798675537\n",
            "g_norm = tensor(0.0922, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.09190368652344\n",
            "||∇_X meta|| = 0.0016632596962153912\n",
            "ΔX norm: 1.6632595361443236e-05\n",
            "Stage 9/10:  49%|██████████████▎              | 148/300 [05:37<05:55,  2.34s/it]T Loss=2.3042151927948\n",
            "g_norm = tensor(0.1647, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304469585418701\n",
            "g_norm = tensor(0.1556, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302577495574951\n",
            "g_norm = tensor(0.1761, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302222728729248\n",
            "g_norm = tensor(0.2007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304513454437256\n",
            "g_norm = tensor(0.1727, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.619873046875\n",
            "||∇_X meta|| = 0.0014771049609407783\n",
            "ΔX norm: 1.4771042515349109e-05\n",
            "Stage 9/10:  50%|██████████████▍              | 149/300 [05:39<05:44,  2.28s/it]T Loss=2.3008220195770264\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304351806640625\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301891565322876\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051092624664307\n",
            "g_norm = tensor(0.1496, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304419994354248\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.64060974121094\n",
            "||∇_X meta|| = 0.0016801102319732308\n",
            "ΔX norm: 1.6801122910692357e-05\n",
            "Stage 9/10:  50%|██████████████▌              | 150/300 [05:41<05:39,  2.27s/it]T Loss=2.3034253120422363\n",
            "g_norm = tensor(0.1257, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304328203201294\n",
            "g_norm = tensor(0.1340, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043413162231445\n",
            "g_norm = tensor(0.1472, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303650140762329\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024890422821045\n",
            "g_norm = tensor(0.1639, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.11782836914062\n",
            "||∇_X meta|| = 0.0015787594020366669\n",
            "ΔX norm: 1.5787612937856466e-05\n",
            "Stage 9/10:  50%|██████████████▌              | 151/300 [05:43<05:31,  2.23s/it]T Loss=2.302206039428711\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303661584854126\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040904998779297\n",
            "g_norm = tensor(0.1289, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303361654281616\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303830623626709\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.70260620117188\n",
            "||∇_X meta|| = 0.0016224859282374382\n",
            "ΔX norm: 1.6224881619564258e-05\n",
            "Stage 9/10:  51%|██████████████▋              | 152/300 [05:46<05:37,  2.28s/it]T Loss=2.3027756214141846\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039135932922363\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303741455078125\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039183616638184\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037726879119873\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3580780029297\n",
            "||∇_X meta|| = 0.0017091885674744844\n",
            "ΔX norm: 1.7091895642806776e-05\n",
            "Stage 9/10:  51%|██████████████▊              | 153/300 [05:48<05:46,  2.35s/it]T Loss=2.3050477504730225\n",
            "g_norm = tensor(0.1393, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304075002670288\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306324005126953\n",
            "g_norm = tensor(0.1324, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305677890777588\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306057929992676\n",
            "g_norm = tensor(0.1495, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.1661376953125\n",
            "||∇_X meta|| = 0.0016308254562318325\n",
            "ΔX norm: 1.6308231352013536e-05\n",
            "Stage 9/10:  51%|██████████████▉              | 154/300 [05:50<05:29,  2.26s/it]T Loss=2.303471803665161\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036859035491943\n",
            "g_norm = tensor(0.1218, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043668270111084\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037922382354736\n",
            "g_norm = tensor(0.1390, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303199291229248\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.70265197753906\n",
            "||∇_X meta|| = 0.0017113466747105122\n",
            "ΔX norm: 1.711344339128118e-05\n",
            "Stage 9/10:  52%|██████████████▉              | 155/300 [05:53<05:23,  2.23s/it]T Loss=2.302619457244873\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303354501724243\n",
            "g_norm = tensor(0.0822, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030436038970947\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032639026641846\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303846597671509\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.53077697753906\n",
            "||∇_X meta|| = 0.0014154533855617046\n",
            "ΔX norm: 1.4154513337416574e-05\n",
            "Stage 9/10:  52%|███████████████              | 156/300 [05:55<05:29,  2.29s/it]T Loss=2.30279803276062\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043696880340576\n",
            "g_norm = tensor(0.0743, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303485870361328\n",
            "g_norm = tensor(0.0787, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042259216308594\n",
            "g_norm = tensor(0.0856, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035764694213867\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0432586669922\n",
            "||∇_X meta|| = 0.0016574097098782659\n",
            "ΔX norm: 1.657410575717222e-05\n",
            "Stage 9/10:  52%|███████████████▏             | 157/300 [05:57<05:28,  2.30s/it]T Loss=2.3024230003356934\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027596473693848\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3016178607940674\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302642345428467\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034136295318604\n",
            "g_norm = tensor(0.0839, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.46263122558594\n",
            "||∇_X meta|| = 0.0015693474560976028\n",
            "ΔX norm: 1.5693478417233564e-05\n",
            "Stage 9/10:  53%|███████████████▎             | 158/300 [06:00<05:57,  2.52s/it]T Loss=2.304166793823242\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057830333709717\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304621934890747\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304356098175049\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052029609680176\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.98760986328125\n",
            "||∇_X meta|| = 0.00159125414211303\n",
            "ΔX norm: 1.591255386301782e-05\n",
            "Stage 9/10:  53%|███████████████▎             | 159/300 [06:03<05:56,  2.53s/it]T Loss=2.304654598236084\n",
            "g_norm = tensor(0.0816, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30379056930542\n",
            "g_norm = tensor(0.0731, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303061008453369\n",
            "g_norm = tensor(0.0917, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043267726898193\n",
            "g_norm = tensor(0.0873, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040308952331543\n",
            "g_norm = tensor(0.0768, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8532257080078\n",
            "||∇_X meta|| = 0.0017550245393067598\n",
            "ΔX norm: 1.755025004968047e-05\n",
            "Stage 9/10:  53%|███████████████▍             | 160/300 [06:05<05:38,  2.42s/it]T Loss=2.303823947906494\n",
            "g_norm = tensor(0.1210, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028006553649902\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029754161834717\n",
            "g_norm = tensor(0.1326, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301229476928711\n",
            "g_norm = tensor(0.1524, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047075271606445\n",
            "g_norm = tensor(0.1387, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.038818359375\n",
            "||∇_X meta|| = 0.0017895958153530955\n",
            "ΔX norm: 1.7895934433909133e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 9/10:  54%|███████████████▌             | 161/300 [06:07<05:26,  2.35s/it]T Loss=2.304112672805786\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039298057556152\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056273460388184\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051350116729736\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047986030578613\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.43264770507812\n",
            "||∇_X meta|| = 0.0014453596668317914\n",
            "ΔX norm: 1.4453600670094602e-05\n",
            "Stage 9/10:  54%|███████████████▋             | 162/300 [06:10<05:29,  2.39s/it]T Loss=2.302687644958496\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035740852355957\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303873300552368\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025999069213867\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025786876678467\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.23219299316406\n",
            "||∇_X meta|| = 0.0016363636823371053\n",
            "ΔX norm: 1.636362139834091e-05\n",
            "Stage 9/10:  54%|███████████████▊             | 163/300 [06:12<05:22,  2.35s/it]T Loss=2.3045246601104736\n",
            "g_norm = tensor(0.1838, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303729295730591\n",
            "g_norm = tensor(0.2215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044896125793457\n",
            "g_norm = tensor(0.1774, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024301528930664\n",
            "g_norm = tensor(0.1543, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303145170211792\n",
            "g_norm = tensor(0.1500, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.86778259277344\n",
            "||∇_X meta|| = 0.001557055744342506\n",
            "ΔX norm: 1.5570567484246567e-05\n",
            "Stage 9/10:  55%|███████████████▊             | 164/300 [06:14<05:07,  2.26s/it]T Loss=2.3044612407684326\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027939796447754\n",
            "g_norm = tensor(0.1386, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303846836090088\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303671360015869\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051133155822754\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2437744140625\n",
            "||∇_X meta|| = 0.0017114448128268123\n",
            "ΔX norm: 1.7114447473431937e-05\n",
            "Stage 9/10:  55%|███████████████▉             | 165/300 [06:16<04:59,  2.22s/it]T Loss=2.3038382530212402\n",
            "g_norm = tensor(0.1450, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031117916107178\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303877592086792\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304128408432007\n",
            "g_norm = tensor(0.1275, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302880048751831\n",
            "g_norm = tensor(0.1432, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.4570770263672\n",
            "||∇_X meta|| = 0.0015911898808553815\n",
            "ΔX norm: 1.591190266481135e-05\n",
            "Stage 9/10:  55%|████████████████             | 166/300 [06:18<04:55,  2.20s/it]T Loss=2.30389666557312\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029887676239014\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033294677734375\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304438352584839\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035569190979004\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.28529357910156\n",
            "||∇_X meta|| = 0.001633268315345049\n",
            "ΔX norm: 1.6332674931618385e-05\n",
            "Stage 9/10:  56%|████████████████▏            | 167/300 [06:21<04:55,  2.22s/it]T Loss=2.302340269088745\n",
            "g_norm = tensor(0.1552, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301638603210449\n",
            "g_norm = tensor(0.1279, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301926612854004\n",
            "g_norm = tensor(0.1496, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302853584289551\n",
            "g_norm = tensor(0.1531, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302564859390259\n",
            "g_norm = tensor(0.1417, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.380126953125\n",
            "||∇_X meta|| = 0.0016438029706478119\n",
            "ΔX norm: 1.6438052625744604e-05\n",
            "Stage 9/10:  56%|████████████████▏            | 168/300 [06:23<04:46,  2.17s/it]T Loss=2.3027305603027344\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303619623184204\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302847385406494\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302635908126831\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038628101348877\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.766357421875\n",
            "||∇_X meta|| = 0.001619737595319748\n",
            "ΔX norm: 1.619737668079324e-05\n",
            "Stage 9/10:  56%|████████████████▎            | 169/300 [06:25<04:48,  2.20s/it]T Loss=2.304267168045044\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045222759246826\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303797960281372\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037362098693848\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042099475860596\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8001708984375\n",
            "||∇_X meta|| = 0.0015584672801196575\n",
            "ΔX norm: 1.5584684661007486e-05\n",
            "Stage 9/10:  57%|████████████████▍            | 170/300 [06:27<04:44,  2.19s/it]T Loss=2.3049142360687256\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052470684051514\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045644760131836\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048317432403564\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304931163787842\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.10438537597656\n",
            "||∇_X meta|| = 0.001480830367654562\n",
            "ΔX norm: 1.4808325431658886e-05\n",
            "Stage 9/10:  57%|████████████████▌            | 171/300 [06:30<05:06,  2.38s/it]T Loss=2.302485704421997\n",
            "g_norm = tensor(0.0831, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020310401916504\n",
            "g_norm = tensor(0.0693, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029282093048096\n",
            "g_norm = tensor(0.0758, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021488189697266\n",
            "g_norm = tensor(0.0801, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302652597427368\n",
            "g_norm = tensor(0.0850, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.27516174316406\n",
            "||∇_X meta|| = 0.0016500349156558514\n",
            "ΔX norm: 1.6500349374837242e-05\n",
            "Stage 9/10:  57%|████████████████▋            | 172/300 [06:32<04:58,  2.33s/it]T Loss=2.303591251373291\n",
            "g_norm = tensor(0.0841, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035736083984375\n",
            "g_norm = tensor(0.1011, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037378787994385\n",
            "g_norm = tensor(0.0798, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303943634033203\n",
            "g_norm = tensor(0.0883, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047709465026855\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.45645141601562\n",
            "||∇_X meta|| = 0.0016670789336785674\n",
            "ΔX norm: 1.6670803233864717e-05\n",
            "Stage 9/10:  58%|████████████████▋            | 173/300 [06:34<04:50,  2.29s/it]T Loss=2.306015968322754\n",
            "g_norm = tensor(0.1363, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303593158721924\n",
            "g_norm = tensor(0.1393, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033697605133057\n",
            "g_norm = tensor(0.1286, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303954839706421\n",
            "g_norm = tensor(0.1322, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031997680664062\n",
            "g_norm = tensor(0.1354, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.13169860839844\n",
            "||∇_X meta|| = 0.001554623362608254\n",
            "ΔX norm: 1.5546242138952948e-05\n",
            "Stage 9/10:  58%|████████████████▊            | 174/300 [06:36<04:41,  2.24s/it]T Loss=2.303748369216919\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303307294845581\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303093194961548\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035366535186768\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302696704864502\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.98167419433594\n",
            "||∇_X meta|| = 0.0014712425181642175\n",
            "ΔX norm: 1.471242376283044e-05\n",
            "Stage 9/10:  58%|████████████████▉            | 175/300 [06:39<04:53,  2.35s/it]T Loss=2.3049654960632324\n",
            "g_norm = tensor(0.0960, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043529987335205\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045153617858887\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304661989212036\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039700984954834\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.45831298828125\n",
            "||∇_X meta|| = 0.0014636563137173653\n",
            "ΔX norm: 1.4636539162893314e-05\n",
            "Stage 9/10:  59%|█████████████████            | 176/300 [06:41<04:49,  2.34s/it]T Loss=2.3043713569641113\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303373098373413\n",
            "g_norm = tensor(0.1314, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304224729537964\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055002689361572\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047375679016113\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.83724975585938\n",
            "||∇_X meta|| = 0.0015628961846232414\n",
            "ΔX norm: 1.562894249218516e-05\n",
            "Stage 9/10:  59%|█████████████████            | 177/300 [06:44<04:41,  2.29s/it]T Loss=2.303762912750244\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037972450256348\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034605979919434\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029403686523438\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033969402313232\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.98684692382812\n",
            "||∇_X meta|| = 0.0015127485385164618\n",
            "ΔX norm: 1.5127479855436832e-05\n",
            "Stage 9/10:  59%|█████████████████▏           | 178/300 [06:46<04:37,  2.28s/it]T Loss=2.3058950901031494\n",
            "g_norm = tensor(0.1372, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054800033569336\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044371604919434\n",
            "g_norm = tensor(0.1312, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3064045906066895\n",
            "g_norm = tensor(0.1467, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306076765060425\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0622100830078\n",
            "||∇_X meta|| = 0.0016067454125732183\n",
            "ΔX norm: 1.606745172466617e-05\n",
            "Stage 9/10:  60%|█████████████████▎           | 179/300 [06:48<04:28,  2.22s/it]T Loss=2.303591251373291\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038411140441895\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034889698028564\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039145469665527\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303004026412964\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2399444580078\n",
            "||∇_X meta|| = 0.0015236684121191502\n",
            "ΔX norm: 1.5236701074172743e-05\n",
            "Stage 9/10:  60%|█████████████████▍           | 180/300 [06:50<04:24,  2.20s/it]T Loss=2.303489923477173\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028483390808105\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303642988204956\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031301498413086\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031487464904785\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.08193969726562\n",
            "||∇_X meta|| = 0.001536626718007028\n",
            "ΔX norm: 1.536627132736612e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 9/10:  60%|█████████████████▍           | 181/300 [06:52<04:23,  2.21s/it]T Loss=2.304257869720459\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304471969604492\n",
            "g_norm = tensor(0.1183, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305485486984253\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037378787994385\n",
            "g_norm = tensor(0.1184, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054444789886475\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.69715881347656\n",
            "||∇_X meta|| = 0.0017032811883836985\n",
            "ΔX norm: 1.7032818504958414e-05\n",
            "Stage 9/10:  61%|█████████████████▌           | 182/300 [06:55<04:48,  2.44s/it]T Loss=2.303593158721924\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029227256774902\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028790950775146\n",
            "g_norm = tensor(0.1286, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025505542755127\n",
            "g_norm = tensor(0.1292, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302379846572876\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8663787841797\n",
            "||∇_X meta|| = 0.0015547730727121234\n",
            "ΔX norm: 1.5547737348242663e-05\n",
            "Stage 9/10:  61%|█████████████████▋           | 183/300 [06:57<04:33,  2.34s/it]T Loss=2.3033013343811035\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035595417022705\n",
            "g_norm = tensor(0.0790, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302851915359497\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034348487854004\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038763999938965\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.59669494628906\n",
            "||∇_X meta|| = 0.0017263656482100487\n",
            "ΔX norm: 1.7263653717236593e-05\n",
            "Stage 9/10:  61%|█████████████████▊           | 184/300 [07:00<04:32,  2.35s/it]T Loss=2.3032736778259277\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024916648864746\n",
            "g_norm = tensor(0.1230, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017115592956543\n",
            "g_norm = tensor(0.1340, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018739223480225\n",
            "g_norm = tensor(0.1249, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022661209106445\n",
            "g_norm = tensor(0.1425, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3821563720703\n",
            "||∇_X meta|| = 0.0017623456660658121\n",
            "ΔX norm: 1.7623451640247367e-05\n",
            "Stage 9/10:  62%|█████████████████▉           | 185/300 [07:02<04:27,  2.33s/it]T Loss=2.3037712574005127\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024282455444336\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303504228591919\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044073581695557\n",
            "g_norm = tensor(0.1210, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041586875915527\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.66636657714844\n",
            "||∇_X meta|| = 0.0016689812764525414\n",
            "ΔX norm: 1.668981531111058e-05\n",
            "Stage 9/10:  62%|█████████████████▉           | 186/300 [07:05<04:36,  2.43s/it]T Loss=2.304865598678589\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053767681121826\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044025897979736\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30437970161438\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304018259048462\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5199737548828\n",
            "||∇_X meta|| = 0.0018258003983646631\n",
            "ΔX norm: 1.8258007912663743e-05\n",
            "Stage 9/10:  62%|██████████████████           | 187/300 [07:07<04:22,  2.32s/it]T Loss=2.304184675216675\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044586181640625\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304189443588257\n",
            "g_norm = tensor(0.0864, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047537803649902\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041491508483887\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.47268676757812\n",
            "||∇_X meta|| = 0.001649920828640461\n",
            "ΔX norm: 1.6499217963428237e-05\n",
            "Stage 9/10:  63%|██████████████████▏          | 188/300 [07:09<04:16,  2.29s/it]T Loss=2.3018336296081543\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302187442779541\n",
            "g_norm = tensor(0.1257, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304556131362915\n",
            "g_norm = tensor(0.1741, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032450675964355\n",
            "g_norm = tensor(0.1424, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049206733703613\n",
            "g_norm = tensor(0.1283, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.25723266601562\n",
            "||∇_X meta|| = 0.0014917475637048483\n",
            "ΔX norm: 1.4917473890818655e-05\n",
            "Stage 9/10:  63%|██████████████████▎          | 189/300 [07:11<04:15,  2.30s/it]T Loss=2.3046274185180664\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046772480010986\n",
            "g_norm = tensor(0.1448, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303797721862793\n",
            "g_norm = tensor(0.1457, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047640323638916\n",
            "g_norm = tensor(0.1503, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304396867752075\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.80035400390625\n",
            "||∇_X meta|| = 0.0016412284458056092\n",
            "ΔX norm: 1.6412292097811587e-05\n",
            "Stage 9/10:  63%|██████████████████▎          | 190/300 [07:13<04:08,  2.26s/it]T Loss=2.301412343978882\n",
            "g_norm = tensor(0.1508, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035573959350586\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019750118255615\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021483421325684\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029026985168457\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.54710388183594\n",
            "||∇_X meta|| = 0.0015249474672600627\n",
            "ΔX norm: 1.5249462194333319e-05\n",
            "Stage 9/10:  64%|██████████████████▍          | 191/300 [07:16<04:03,  2.24s/it]T Loss=2.304196834564209\n",
            "g_norm = tensor(0.0885, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305363416671753\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305222272872925\n",
            "g_norm = tensor(0.0857, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049509525299072\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047702312469482\n",
            "g_norm = tensor(0.0750, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =233.44924926757812\n",
            "||∇_X meta|| = 0.0016165568958967924\n",
            "ΔX norm: 1.6165577108040452e-05\n",
            "Stage 9/10:  64%|██████████████████▌          | 192/300 [07:18<03:57,  2.20s/it]T Loss=2.304799795150757\n",
            "g_norm = tensor(0.0854, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036866188049316\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304304838180542\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303744077682495\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036372661590576\n",
            "g_norm = tensor(0.0862, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.03594970703125\n",
            "||∇_X meta|| = 0.0014637812273576856\n",
            "ΔX norm: 1.4637805179518182e-05\n",
            "Stage 9/10:  64%|██████████████████▋          | 193/300 [07:20<03:59,  2.23s/it]T Loss=2.3064446449279785\n",
            "g_norm = tensor(0.1309, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305372953414917\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305814504623413\n",
            "g_norm = tensor(0.1400, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044745922088623\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045811653137207\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.68336486816406\n",
            "||∇_X meta|| = 0.001784473774023354\n",
            "ΔX norm: 1.7844728063209914e-05\n",
            "Stage 9/10:  65%|██████████████████▊          | 194/300 [07:23<04:07,  2.33s/it]T Loss=2.3037047386169434\n",
            "g_norm = tensor(0.1406, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044495582580566\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033623695373535\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30411958694458\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30364727973938\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0234832763672\n",
            "||∇_X meta|| = 0.0012941390741616488\n",
            "ΔX norm: 1.2941393833898474e-05\n",
            "Stage 9/10:  65%|██████████████████▊          | 195/300 [07:25<03:59,  2.28s/it]T Loss=2.3039135932922363\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047218322753906\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040692806243896\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045735359191895\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303781509399414\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.12770080566406\n",
            "||∇_X meta|| = 0.0015563822817057371\n",
            "ΔX norm: 1.5563817214570008e-05\n",
            "Stage 9/10:  65%|██████████████████▉          | 196/300 [07:27<03:57,  2.28s/it]T Loss=2.3023324012756348\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027548789978027\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026082515716553\n",
            "g_norm = tensor(0.0919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302551507949829\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021204471588135\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8857421875\n",
            "||∇_X meta|| = 0.0015297586796805263\n",
            "ΔX norm: 1.5297564459615387e-05\n",
            "Stage 9/10:  66%|███████████████████          | 197/300 [07:29<03:50,  2.24s/it]T Loss=2.3048524856567383\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305363416671753\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3063302040100098\n",
            "g_norm = tensor(0.1362, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303978443145752\n",
            "g_norm = tensor(0.1362, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036763668060303\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3502960205078\n",
            "||∇_X meta|| = 0.0015924826730042696\n",
            "ΔX norm: 1.592482476553414e-05\n",
            "Stage 9/10:  66%|███████████████████▏         | 198/300 [07:31<03:47,  2.23s/it]T Loss=2.3030083179473877\n",
            "g_norm = tensor(0.1372, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025641441345215\n",
            "g_norm = tensor(0.1402, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304940700531006\n",
            "g_norm = tensor(0.1433, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304741621017456\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304137706756592\n",
            "g_norm = tensor(0.1438, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.27513122558594\n",
            "||∇_X meta|| = 0.0015434421366080642\n",
            "ΔX norm: 1.5434417946380563e-05\n",
            "Stage 9/10:  66%|███████████████████▏         | 199/300 [07:34<03:42,  2.20s/it]T Loss=2.302802562713623\n",
            "g_norm = tensor(0.1353, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037924766540527\n",
            "g_norm = tensor(0.1724, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302459239959717\n",
            "g_norm = tensor(0.1545, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303926944732666\n",
            "g_norm = tensor(0.1885, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032619953155518\n",
            "g_norm = tensor(0.1504, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.49147033691406\n",
            "||∇_X meta|| = 0.001491608563810587\n",
            "ΔX norm: 1.4916065993020311e-05\n",
            "Stage 9/10:  67%|███████████████████▎         | 200/300 [07:36<03:40,  2.20s/it]T Loss=2.3040237426757812\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034558296203613\n",
            "g_norm = tensor(0.0709, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031554222106934\n",
            "g_norm = tensor(0.0937, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032114505767822\n",
            "g_norm = tensor(0.0784, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303508758544922\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.07681274414062\n",
            "||∇_X meta|| = 0.0015696812188252807\n",
            "ΔX norm: 1.5696819900767878e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 9/10:  67%|███████████████████▍         | 201/300 [07:38<03:36,  2.18s/it]T Loss=2.3025574684143066\n",
            "g_norm = tensor(0.0815, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303920269012451\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035755157470703\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303417921066284\n",
            "g_norm = tensor(0.0800, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047537803649902\n",
            "g_norm = tensor(0.0845, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.6415557861328\n",
            "||∇_X meta|| = 0.0015202545328065753\n",
            "ΔX norm: 1.5202551367110573e-05\n",
            "Stage 9/10:  67%|███████████████████▌         | 202/300 [07:41<03:46,  2.31s/it]T Loss=2.303067445755005\n",
            "g_norm = tensor(0.0833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30251145362854\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027865886688232\n",
            "g_norm = tensor(0.0858, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302410840988159\n",
            "g_norm = tensor(0.0756, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303793430328369\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.55335998535156\n",
            "||∇_X meta|| = 0.0013718195259571075\n",
            "ΔX norm: 1.371818234474631e-05\n",
            "Stage 9/10:  68%|███████████████████▌         | 203/300 [07:43<03:37,  2.24s/it]T Loss=2.3060052394866943\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304741382598877\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025553226470947\n",
            "g_norm = tensor(0.1611, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304154872894287\n",
            "g_norm = tensor(0.1424, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304417133331299\n",
            "g_norm = tensor(0.1353, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.44973754882812\n",
            "||∇_X meta|| = 0.0015844922745600343\n",
            "ΔX norm: 1.584488563821651e-05\n",
            "Stage 9/10:  68%|███████████████████▋         | 204/300 [07:45<03:29,  2.18s/it]T Loss=2.3033766746520996\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044307231903076\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040099143981934\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034262657165527\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304086446762085\n",
            "g_norm = tensor(0.1214, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.97647094726562\n",
            "||∇_X meta|| = 0.0014421655796468258\n",
            "ΔX norm: 1.442167103959946e-05\n",
            "Stage 9/10:  68%|███████████████████▊         | 205/300 [07:47<03:22,  2.13s/it]T Loss=2.302687644958496\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303590774536133\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303272247314453\n",
            "g_norm = tensor(0.1379, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303624391555786\n",
            "g_norm = tensor(0.1553, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029894828796387\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9643096923828\n",
            "||∇_X meta|| = 0.0015094703994691372\n",
            "ΔX norm: 1.5094712580321357e-05\n",
            "Stage 9/10:  69%|███████████████████▉         | 206/300 [07:49<03:20,  2.13s/it]T Loss=2.303191661834717\n",
            "g_norm = tensor(0.1301, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026232719421387\n",
            "g_norm = tensor(0.1215, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040289878845215\n",
            "g_norm = tensor(0.1178, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025662899017334\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303051233291626\n",
            "g_norm = tensor(0.1282, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.85560607910156\n",
            "||∇_X meta|| = 0.0014887003926560283\n",
            "ΔX norm: 1.4887002180330455e-05\n",
            "Stage 9/10:  69%|████████████████████         | 207/300 [07:51<03:18,  2.13s/it]T Loss=2.3050193786621094\n",
            "g_norm = tensor(0.1080, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303475856781006\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037304878234863\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302971363067627\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047683238983154\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.6029510498047\n",
            "||∇_X meta|| = 0.0014742916682735085\n",
            "ΔX norm: 1.4742912753717974e-05\n",
            "Stage 9/10:  69%|████████████████████         | 208/300 [07:53<03:18,  2.16s/it]T Loss=2.302389621734619\n",
            "g_norm = tensor(0.1250, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037352561950684\n",
            "g_norm = tensor(0.1262, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035948276519775\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034143447875977\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302908182144165\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.58848571777344\n",
            "||∇_X meta|| = 0.0015054760733619332\n",
            "ΔX norm: 1.5054763935040683e-05\n",
            "Stage 9/10:  70%|████████████████████▏        | 209/300 [07:55<03:17,  2.17s/it]T Loss=2.3032171726226807\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030028343200684\n",
            "g_norm = tensor(0.1411, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303478956222534\n",
            "g_norm = tensor(0.1219, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304121255874634\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302919864654541\n",
            "g_norm = tensor(0.1378, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.10833740234375\n",
            "||∇_X meta|| = 0.0014651129022240639\n",
            "ΔX norm: 1.4651131095888559e-05\n",
            "Stage 9/10:  70%|████████████████████▎        | 210/300 [07:58<03:21,  2.24s/it]T Loss=2.3027663230895996\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303363561630249\n",
            "g_norm = tensor(0.0828, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046939373016357\n",
            "g_norm = tensor(0.0811, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037185668945312\n",
            "g_norm = tensor(0.0833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303649425506592\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.1211395263672\n",
            "||∇_X meta|| = 0.0015583531931042671\n",
            "ΔX norm: 1.5583524145768024e-05\n",
            "Stage 9/10:  70%|████████████████████▍        | 211/300 [08:00<03:27,  2.34s/it]T Loss=2.3035571575164795\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034214973449707\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304713487625122\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30377459526062\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036067485809326\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.5150909423828\n",
            "||∇_X meta|| = 0.0015547691145911813\n",
            "ΔX norm: 1.5547675502602942e-05\n",
            "Stage 9/10:  71%|████████████████████▍        | 212/300 [08:02<03:20,  2.28s/it]T Loss=2.304879665374756\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035054206848145\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037362098693848\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303966999053955\n",
            "g_norm = tensor(0.1320, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038058280944824\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.00962829589844\n",
            "||∇_X meta|| = 0.0017132690409198403\n",
            "ΔX norm: 1.7132661014329642e-05\n",
            "Stage 9/10:  71%|████████████████████▌        | 213/300 [08:05<03:16,  2.26s/it]T Loss=2.303762912750244\n",
            "g_norm = tensor(0.1249, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055577278137207\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041694164276123\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028347492218018\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044333457946777\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.86654663085938\n",
            "||∇_X meta|| = 0.0016586248530074954\n",
            "ΔX norm: 1.658624387346208e-05\n",
            "Stage 9/10:  71%|████████████████████▋        | 214/300 [08:07<03:11,  2.22s/it]T Loss=2.3039212226867676\n",
            "g_norm = tensor(0.1376, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039848804473877\n",
            "g_norm = tensor(0.1369, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050100803375244\n",
            "g_norm = tensor(0.1808, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303859233856201\n",
            "g_norm = tensor(0.1631, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302732229232788\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.07949829101562\n",
            "||∇_X meta|| = 0.0016314152162522078\n",
            "ΔX norm: 1.631414306757506e-05\n",
            "Stage 9/10:  72%|████████████████████▊        | 215/300 [08:09<03:08,  2.22s/it]T Loss=2.304830551147461\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040413856506348\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029236793518066\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303953170776367\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039309978485107\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.35809326171875\n",
            "||∇_X meta|| = 0.0015383363934233785\n",
            "ΔX norm: 1.5383371646748856e-05\n",
            "Stage 9/10:  72%|████████████████████▉        | 216/300 [08:11<03:11,  2.28s/it]T Loss=2.305466890335083\n",
            "g_norm = tensor(0.1711, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042092323303223\n",
            "g_norm = tensor(0.1531, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051161766052246\n",
            "g_norm = tensor(0.1479, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034164905548096\n",
            "g_norm = tensor(0.1418, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303798198699951\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1361541748047\n",
            "||∇_X meta|| = 0.001615834655240178\n",
            "ΔX norm: 1.6158352082129568e-05\n",
            "Stage 9/10:  72%|████████████████████▉        | 217/300 [08:14<03:07,  2.26s/it]T Loss=2.3030617237091064\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034491539001465\n",
            "g_norm = tensor(0.0759, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021061420440674\n",
            "g_norm = tensor(0.0888, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033664226531982\n",
            "g_norm = tensor(0.0880, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037588596343994\n",
            "g_norm = tensor(0.0823, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6819610595703\n",
            "||∇_X meta|| = 0.0014550256310030818\n",
            "ΔX norm: 1.455026722396724e-05\n",
            "Stage 9/10:  73%|█████████████████████        | 218/300 [08:16<03:01,  2.21s/it]T Loss=2.304858684539795\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042373657226562\n",
            "g_norm = tensor(0.1268, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045313358306885\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303234100341797\n",
            "g_norm = tensor(0.1349, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305370807647705\n",
            "g_norm = tensor(0.1560, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.45095825195312\n",
            "||∇_X meta|| = 0.0017106273444369435\n",
            "ΔX norm: 1.7106260202126577e-05\n",
            "Stage 9/10:  73%|█████████████████████▏       | 219/300 [08:18<02:56,  2.18s/it]T Loss=2.303227424621582\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303712844848633\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302741527557373\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046512603759766\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046631813049316\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1643829345703\n",
            "||∇_X meta|| = 0.0015511647798120975\n",
            "ΔX norm: 1.5511644960497506e-05\n",
            "Stage 9/10:  73%|█████████████████████▎       | 220/300 [08:20<03:00,  2.26s/it]T Loss=2.30438232421875\n",
            "g_norm = tensor(0.0871, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304039239883423\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304633617401123\n",
            "g_norm = tensor(0.1432, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042590618133545\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045742511749268\n",
            "g_norm = tensor(0.1468, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.52005004882812\n",
            "||∇_X meta|| = 0.0016036367742344737\n",
            "ΔX norm: 1.60363797476748e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 9/10:  74%|█████████████████████▎       | 221/300 [08:22<02:55,  2.22s/it]T Loss=2.3034656047821045\n",
            "g_norm = tensor(0.1428, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304703712463379\n",
            "g_norm = tensor(0.1515, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301928758621216\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304673671722412\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304351806640625\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.55081176757812\n",
            "||∇_X meta|| = 0.0015063281171023846\n",
            "ΔX norm: 1.5063305909279734e-05\n",
            "Stage 9/10:  74%|█████████████████████▍       | 222/300 [08:25<02:56,  2.26s/it]T Loss=2.303896427154541\n",
            "g_norm = tensor(0.0841, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302330732345581\n",
            "g_norm = tensor(0.0869, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038148880004883\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029065132141113\n",
            "g_norm = tensor(0.0933, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303765058517456\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.82763671875\n",
            "||∇_X meta|| = 0.0016280869022011757\n",
            "ΔX norm: 1.628086101845838e-05\n",
            "Stage 9/10:  74%|█████████████████████▌       | 223/300 [08:27<02:52,  2.24s/it]T Loss=2.3049848079681396\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045496940612793\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303610324859619\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037943840026855\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303345203399658\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.45213317871094\n",
            "||∇_X meta|| = 0.0016025339718908072\n",
            "ΔX norm: 1.6025347576942295e-05\n",
            "Stage 9/10:  75%|█████████████████████▋       | 224/300 [08:29<02:46,  2.19s/it]T Loss=2.3028221130371094\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024792671203613\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302608013153076\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036255836486816\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302398681640625\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.11648559570312\n",
            "||∇_X meta|| = 0.0015118320006877184\n",
            "ΔX norm: 1.5118321243789978e-05\n",
            "Stage 9/10:  75%|█████████████████████▊       | 225/300 [08:31<02:45,  2.21s/it]T Loss=2.304011821746826\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038697242736816\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040690422058105\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30500864982605\n",
            "g_norm = tensor(0.1251, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304344654083252\n",
            "g_norm = tensor(0.1258, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.09864807128906\n",
            "||∇_X meta|| = 0.0016088879201561213\n",
            "ΔX norm: 1.608887941983994e-05\n",
            "Stage 9/10:  75%|█████████████████████▊       | 226/300 [08:33<02:42,  2.20s/it]T Loss=2.305025339126587\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052685260772705\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052735328674316\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055803775787354\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052101135253906\n",
            "g_norm = tensor(0.1444, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.640380859375\n",
            "||∇_X meta|| = 0.0016260773409157991\n",
            "ΔX norm: 1.6260790289379656e-05\n",
            "Stage 9/10:  76%|█████████████████████▉       | 227/300 [08:36<02:39,  2.18s/it]T Loss=2.304548501968384\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305001974105835\n",
            "g_norm = tensor(0.1297, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037667274475098\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303729772567749\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303971529006958\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.90342712402344\n",
            "||∇_X meta|| = 0.0014832058222964406\n",
            "ΔX norm: 1.4832064152869862e-05\n",
            "Stage 9/10:  76%|██████████████████████       | 228/300 [08:38<02:34,  2.15s/it]T Loss=2.3037848472595215\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303393840789795\n",
            "g_norm = tensor(0.1353, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302039623260498\n",
            "g_norm = tensor(0.1554, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046908378601074\n",
            "g_norm = tensor(0.1456, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030927181243896\n",
            "g_norm = tensor(0.1271, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7384033203125\n",
            "||∇_X meta|| = 0.0014674455160275102\n",
            "ΔX norm: 1.4674445083073806e-05\n",
            "Stage 9/10:  76%|██████████████████████▏      | 229/300 [08:40<02:33,  2.17s/it]T Loss=2.3039803504943848\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034963607788086\n",
            "g_norm = tensor(0.0885, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024487495422363\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034729957580566\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045287132263184\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7711639404297\n",
            "||∇_X meta|| = 0.0016944007948040962\n",
            "ΔX norm: 1.694402817520313e-05\n",
            "Stage 9/10:  77%|██████████████████████▏      | 230/300 [08:42<02:30,  2.15s/it]T Loss=2.3031134605407715\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038833141326904\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051137924194336\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050179481506348\n",
            "g_norm = tensor(0.1446, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303572416305542\n",
            "g_norm = tensor(0.1464, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.09481811523438\n",
            "||∇_X meta|| = 0.0015371079789474607\n",
            "ΔX norm: 1.5371066183433868e-05\n",
            "Stage 9/10:  77%|██████████████████████▎      | 231/300 [08:44<02:32,  2.22s/it]T Loss=2.3038687705993652\n",
            "g_norm = tensor(0.0800, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303462028503418\n",
            "g_norm = tensor(0.0855, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037853240966797\n",
            "g_norm = tensor(0.0811, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304166316986084\n",
            "g_norm = tensor(0.0790, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30379056930542\n",
            "g_norm = tensor(0.0637, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5103759765625\n",
            "||∇_X meta|| = 0.0015198893379420042\n",
            "ΔX norm: 1.519889246992534e-05\n",
            "Stage 9/10:  77%|██████████████████████▍      | 232/300 [08:47<02:31,  2.24s/it]T Loss=2.3038601875305176\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041365146636963\n",
            "g_norm = tensor(0.1266, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303821563720703\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044018745422363\n",
            "g_norm = tensor(0.1272, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303518056869507\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.88031005859375\n",
            "||∇_X meta|| = 0.0015937587013468146\n",
            "ΔX norm: 1.5937563148327172e-05\n",
            "Stage 9/10:  78%|██████████████████████▌      | 233/300 [08:49<02:25,  2.17s/it]T Loss=2.303328514099121\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302494764328003\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030295372009277\n",
            "g_norm = tensor(0.0882, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031234741210938\n",
            "g_norm = tensor(0.1099, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303264617919922\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4337921142578\n",
            "||∇_X meta|| = 0.0015524300979450345\n",
            "ΔX norm: 1.5524283298873343e-05\n",
            "Stage 9/10:  78%|██████████████████████▌      | 234/300 [08:51<02:21,  2.14s/it]T Loss=2.303027391433716\n",
            "g_norm = tensor(0.0828, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046977519989014\n",
            "g_norm = tensor(0.0831, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042213916778564\n",
            "g_norm = tensor(0.0847, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303966522216797\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304813861846924\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.123291015625\n",
            "||∇_X meta|| = 0.0015156642766669393\n",
            "ΔX norm: 1.5156641893554479e-05\n",
            "Stage 9/10:  78%|██████████████████████▋      | 235/300 [08:53<02:21,  2.18s/it]T Loss=2.3031868934631348\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036446571350098\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304093837738037\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302732229232788\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049302101135254\n",
            "g_norm = tensor(0.1080, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1439666748047\n",
            "||∇_X meta|| = 0.0013622189871966839\n",
            "ΔX norm: 1.3622185178974178e-05\n",
            "Stage 9/10:  79%|██████████████████████▊      | 236/300 [08:55<02:18,  2.17s/it]T Loss=2.303421974182129\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042795658111572\n",
            "g_norm = tensor(0.1283, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039815425872803\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043534755706787\n",
            "g_norm = tensor(0.1289, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303576707839966\n",
            "g_norm = tensor(0.1277, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.42086791992188\n",
            "||∇_X meta|| = 0.0015870569040998816\n",
            "ΔX norm: 1.5870558854658157e-05\n",
            "Stage 9/10:  79%|██████████████████████▉      | 237/300 [08:57<02:17,  2.18s/it]T Loss=2.3043177127838135\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303344249725342\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045458793640137\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035736083984375\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035011291503906\n",
            "g_norm = tensor(0.1316, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9580535888672\n",
            "||∇_X meta|| = 0.001516384887509048\n",
            "ΔX norm: 1.5163854186539538e-05\n",
            "Stage 9/10:  79%|███████████████████████      | 238/300 [09:00<02:21,  2.29s/it]T Loss=2.3044486045837402\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3060061931610107\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057711124420166\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058719635009766\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305554151535034\n",
            "g_norm = tensor(0.0937, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.43746948242188\n",
            "||∇_X meta|| = 0.0015348801389336586\n",
            "ΔX norm: 1.534880902909208e-05\n",
            "Stage 9/10:  80%|███████████████████████      | 239/300 [09:02<02:17,  2.26s/it]T Loss=2.304203510284424\n",
            "g_norm = tensor(0.1015, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30450701713562\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304389238357544\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044581413269043\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033287525177\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.6820526123047\n",
            "||∇_X meta|| = 0.0015180135378614068\n",
            "ΔX norm: 1.5180140508164186e-05\n",
            "Stage 9/10:  80%|███████████████████████▏     | 240/300 [09:04<02:16,  2.28s/it]T Loss=2.3042404651641846\n",
            "g_norm = tensor(0.0852, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304500102996826\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304676055908203\n",
            "g_norm = tensor(0.0776, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047032356262207\n",
            "g_norm = tensor(0.0920, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046696186065674\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.6790313720703\n",
            "||∇_X meta|| = 0.0015987148508429527\n",
            "ΔX norm: 1.5987141523510218e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 9/10:  80%|███████████████████████▎     | 241/300 [09:07<02:13,  2.26s/it]T Loss=2.302943706512451\n",
            "g_norm = tensor(0.0771, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039517402648926\n",
            "g_norm = tensor(0.0768, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303337574005127\n",
            "g_norm = tensor(0.0777, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028926849365234\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303006410598755\n",
            "g_norm = tensor(0.0848, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.05389404296875\n",
            "||∇_X meta|| = 0.0017183751333504915\n",
            "ΔX norm: 1.7183750969707035e-05\n",
            "Stage 9/10:  81%|███████████████████████▍     | 242/300 [09:09<02:18,  2.39s/it]T Loss=2.3019351959228516\n",
            "g_norm = tensor(0.0806, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039402961730957\n",
            "g_norm = tensor(0.0775, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303002119064331\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037705421447754\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039357662200928\n",
            "g_norm = tensor(0.0845, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.51754760742188\n",
            "||∇_X meta|| = 0.0015351773472502828\n",
            "ΔX norm: 1.535178307676688e-05\n",
            "Stage 9/10:  81%|███████████████████████▍     | 243/300 [09:12<02:15,  2.38s/it]T Loss=2.3046345710754395\n",
            "g_norm = tensor(0.1381, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303767681121826\n",
            "g_norm = tensor(0.1178, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303028106689453\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302820920944214\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043973445892334\n",
            "g_norm = tensor(0.1544, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.4659423828125\n",
            "||∇_X meta|| = 0.0016293823719024658\n",
            "ΔX norm: 1.6293801309075207e-05\n",
            "Stage 9/10:  81%|███████████████████████▌     | 244/300 [09:14<02:08,  2.30s/it]T Loss=2.303692579269409\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033337593078613\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30350923538208\n",
            "g_norm = tensor(0.1342, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028342723846436\n",
            "g_norm = tensor(0.1163, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303813934326172\n",
            "g_norm = tensor(0.1337, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.893798828125\n",
            "||∇_X meta|| = 0.00151498441118747\n",
            "ΔX norm: 1.5149862520047463e-05\n",
            "Stage 9/10:  82%|███████████████████████▋     | 245/300 [09:16<02:04,  2.26s/it]T Loss=2.3027231693267822\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038251399993896\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303048610687256\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027894496917725\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304337978363037\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.03268432617188\n",
            "||∇_X meta|| = 0.001443573390133679\n",
            "ΔX norm: 1.4435733646678273e-05\n",
            "Stage 9/10:  82%|███████████████████████▊     | 246/300 [09:18<02:02,  2.27s/it]T Loss=2.3023524284362793\n",
            "g_norm = tensor(0.1700, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026251792907715\n",
            "g_norm = tensor(0.1302, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054189682006836\n",
            "g_norm = tensor(0.1348, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304462194442749\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305168628692627\n",
            "g_norm = tensor(0.1627, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.8723602294922\n",
            "||∇_X meta|| = 0.001595412497408688\n",
            "ΔX norm: 1.5954105037963018e-05\n",
            "Stage 9/10:  82%|███████████████████████▉     | 247/300 [09:21<02:00,  2.27s/it]T Loss=2.3033461570739746\n",
            "g_norm = tensor(0.0652, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033270835876465\n",
            "g_norm = tensor(0.0694, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030474185943604\n",
            "g_norm = tensor(0.0678, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303675413131714\n",
            "g_norm = tensor(0.0813, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303562641143799\n",
            "g_norm = tensor(0.0657, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.53321838378906\n",
            "||∇_X meta|| = 0.0015781060792505741\n",
            "ΔX norm: 1.578107003297191e-05\n",
            "Stage 9/10:  83%|███████████████████████▉     | 248/300 [09:24<02:14,  2.59s/it]T Loss=2.303194999694824\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303398609161377\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035833835601807\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039045333862305\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303077459335327\n",
            "g_norm = tensor(0.0855, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.84652709960938\n",
            "||∇_X meta|| = 0.0014302597846835852\n",
            "ΔX norm: 1.4302594536275137e-05\n",
            "Stage 9/10:  83%|████████████████████████     | 249/300 [09:27<02:14,  2.64s/it]T Loss=2.304513692855835\n",
            "g_norm = tensor(0.0755, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038394451141357\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047657012939453\n",
            "g_norm = tensor(0.0871, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048360347747803\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043675422668457\n",
            "g_norm = tensor(0.0807, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.59681701660156\n",
            "||∇_X meta|| = 0.0015765501884743571\n",
            "ΔX norm: 1.5765492207719944e-05\n",
            "Stage 9/10:  83%|████████████████████████▏    | 250/300 [09:29<02:04,  2.50s/it]T Loss=2.304666042327881\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045918941497803\n",
            "g_norm = tensor(0.1110, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057265281677246\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048195838928223\n",
            "g_norm = tensor(0.1271, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036348819732666\n",
            "g_norm = tensor(0.1283, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.9669952392578\n",
            "||∇_X meta|| = 0.0016002992633730173\n",
            "ΔX norm: 1.6003008568077348e-05\n",
            "Stage 9/10:  84%|████████████████████████▎    | 251/300 [09:31<01:55,  2.35s/it]T Loss=2.3033907413482666\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037047386169434\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037211894989014\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032498359680176\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040342330932617\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.61924743652344\n",
            "||∇_X meta|| = 0.0015678568743169308\n",
            "ΔX norm: 1.5678595445933752e-05\n",
            "Stage 9/10:  84%|████████████████████████▎    | 252/300 [09:33<01:45,  2.20s/it]T Loss=2.3034989833831787\n",
            "g_norm = tensor(0.1235, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303602695465088\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035850524902344\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039307594299316\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037209510803223\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.27084350585938\n",
            "||∇_X meta|| = 0.0015446959296241403\n",
            "ΔX norm: 1.544696351629682e-05\n",
            "Stage 9/10:  84%|████████████████████████▍    | 253/300 [09:34<01:36,  2.06s/it]T Loss=2.3038315773010254\n",
            "g_norm = tensor(0.0843, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039743900299072\n",
            "g_norm = tensor(0.0779, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035178184509277\n",
            "g_norm = tensor(0.0691, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046298027038574\n",
            "g_norm = tensor(0.0857, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303497076034546\n",
            "g_norm = tensor(0.0828, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.84169006347656\n",
            "||∇_X meta|| = 0.0015743032563477755\n",
            "ΔX norm: 1.5743049516458996e-05\n",
            "Stage 9/10:  85%|████████████████████████▌    | 254/300 [09:36<01:30,  1.97s/it]T Loss=2.3036532402038574\n",
            "g_norm = tensor(0.1476, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303454637527466\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041932582855225\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304340362548828\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304060459136963\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.56834411621094\n",
            "||∇_X meta|| = 0.0016199599485844374\n",
            "ΔX norm: 1.6199624951696023e-05\n",
            "Stage 9/10:  85%|████████████████████████▋    | 255/300 [09:38<01:26,  1.92s/it]T Loss=2.3046844005584717\n",
            "g_norm = tensor(0.1374, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304938316345215\n",
            "g_norm = tensor(0.1531, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305791139602661\n",
            "g_norm = tensor(0.1412, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3059139251708984\n",
            "g_norm = tensor(0.1680, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053860664367676\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5695037841797\n",
            "||∇_X meta|| = 0.001579742762260139\n",
            "ΔX norm: 1.5797386367921717e-05\n",
            "Stage 9/10:  85%|████████████████████████▋    | 256/300 [09:40<01:25,  1.93s/it]T Loss=2.3034536838531494\n",
            "g_norm = tensor(0.0963, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031344413757324\n",
            "g_norm = tensor(0.0989, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302812099456787\n",
            "g_norm = tensor(0.0852, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029818534851074\n",
            "g_norm = tensor(0.0796, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303483486175537\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8980712890625\n",
            "||∇_X meta|| = 0.0016317322151735425\n",
            "ΔX norm: 1.6317304471158423e-05\n",
            "Stage 9/10:  86%|████████████████████████▊    | 257/300 [09:42<01:22,  1.92s/it]T Loss=2.3037166595458984\n",
            "g_norm = tensor(0.0740, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304511308670044\n",
            "g_norm = tensor(0.0733, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303947925567627\n",
            "g_norm = tensor(0.0761, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304471254348755\n",
            "g_norm = tensor(0.0717, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044180870056152\n",
            "g_norm = tensor(0.0758, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.9537353515625\n",
            "||∇_X meta|| = 0.0016520791687071323\n",
            "ΔX norm: 1.6520814824616536e-05\n",
            "Stage 9/10:  86%|████████████████████████▉    | 258/300 [09:44<01:18,  1.88s/it]T Loss=2.3035995960235596\n",
            "g_norm = tensor(0.1539, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030922412872314\n",
            "g_norm = tensor(0.1560, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30397367477417\n",
            "g_norm = tensor(0.1347, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302750825881958\n",
            "g_norm = tensor(0.1645, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30397367477417\n",
            "g_norm = tensor(0.1515, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1094512939453\n",
            "||∇_X meta|| = 0.0015291138552129269\n",
            "ΔX norm: 1.5291136151063256e-05\n",
            "Stage 9/10:  86%|█████████████████████████    | 259/300 [09:45<01:16,  1.87s/it]T Loss=2.3039939403533936\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033831119537354\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303496837615967\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028852939605713\n",
            "g_norm = tensor(0.1214, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30181622505188\n",
            "g_norm = tensor(0.1187, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.16055297851562\n",
            "||∇_X meta|| = 0.0014857574133202434\n",
            "ΔX norm: 1.4857581845717505e-05\n",
            "Stage 9/10:  87%|█████████████████████████▏   | 260/300 [09:47<01:13,  1.84s/it]T Loss=2.303715229034424\n",
            "g_norm = tensor(0.0774, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303359270095825\n",
            "g_norm = tensor(0.0888, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303823471069336\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032493591308594\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027491569519043\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.04376220703125\n",
            "||∇_X meta|| = 0.001499767997302115\n",
            "ΔX norm: 1.4997689504525624e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 9/10:  87%|█████████████████████████▏   | 261/300 [09:49<01:10,  1.82s/it]T Loss=2.302926540374756\n",
            "g_norm = tensor(0.1107, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034615516662598\n",
            "g_norm = tensor(0.1247, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027396202087402\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303147315979004\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303910732269287\n",
            "g_norm = tensor(0.1323, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.24481201171875\n",
            "||∇_X meta|| = 0.001568601350300014\n",
            "ΔX norm: 1.568600237078499e-05\n",
            "Stage 9/10:  87%|█████████████████████████▎   | 262/300 [09:51<01:13,  1.94s/it]T Loss=2.303989887237549\n",
            "g_norm = tensor(0.1371, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033251762390137\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041505813598633\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304853916168213\n",
            "g_norm = tensor(0.1584, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033993244171143\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.84031677246094\n",
            "||∇_X meta|| = 0.0015461521688848734\n",
            "ΔX norm: 1.5461504517588764e-05\n",
            "Stage 9/10:  88%|█████████████████████████▍   | 263/300 [09:53<01:12,  1.96s/it]T Loss=2.3059535026550293\n",
            "g_norm = tensor(0.1405, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041164875030518\n",
            "g_norm = tensor(0.1548, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043274879455566\n",
            "g_norm = tensor(0.1545, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305222511291504\n",
            "g_norm = tensor(0.1722, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049354553222656\n",
            "g_norm = tensor(0.1695, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.48089599609375\n",
            "||∇_X meta|| = 0.0016092995647341013\n",
            "ΔX norm: 1.6092999430838972e-05\n",
            "Stage 9/10:  88%|█████████████████████████▌   | 264/300 [09:55<01:12,  2.02s/it]T Loss=2.304201602935791\n",
            "g_norm = tensor(0.1377, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048484325408936\n",
            "g_norm = tensor(0.1406, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305781602859497\n",
            "g_norm = tensor(0.1497, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051466941833496\n",
            "g_norm = tensor(0.1356, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305718183517456\n",
            "g_norm = tensor(0.1534, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1676788330078\n",
            "||∇_X meta|| = 0.001583919278346002\n",
            "ΔX norm: 1.5839208572288044e-05\n",
            "Stage 9/10:  88%|█████████████████████████▌   | 265/300 [09:57<01:08,  1.96s/it]T Loss=2.303159236907959\n",
            "g_norm = tensor(0.1263, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303457736968994\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303814172744751\n",
            "g_norm = tensor(0.1320, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028035163879395\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036091327667236\n",
            "g_norm = tensor(0.1292, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.86422729492188\n",
            "||∇_X meta|| = 0.001525700674392283\n",
            "ΔX norm: 1.5256982806022279e-05\n",
            "Stage 9/10:  89%|█████████████████████████▋   | 266/300 [09:59<01:06,  1.96s/it]T Loss=2.304051637649536\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304006814956665\n",
            "g_norm = tensor(0.0752, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304407835006714\n",
            "g_norm = tensor(0.0884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035449981689453\n",
            "g_norm = tensor(0.0879, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304680109024048\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.57765197753906\n",
            "||∇_X meta|| = 0.0016257761744782329\n",
            "ΔX norm: 1.6257736206171103e-05\n",
            "Stage 9/10:  89%|█████████████████████████▊   | 267/300 [10:01<01:03,  1.94s/it]T Loss=2.3027937412261963\n",
            "g_norm = tensor(0.1582, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305934190750122\n",
            "g_norm = tensor(0.1773, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304272174835205\n",
            "g_norm = tensor(0.1376, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028337955474854\n",
            "g_norm = tensor(0.1711, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304584503173828\n",
            "g_norm = tensor(0.1461, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7969970703125\n",
            "||∇_X meta|| = 0.0014959200052544475\n",
            "ΔX norm: 1.4959210602683015e-05\n",
            "Stage 9/10:  89%|█████████████████████████▉   | 268/300 [10:03<01:00,  1.88s/it]T Loss=2.303701877593994\n",
            "g_norm = tensor(0.1351, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045384883880615\n",
            "g_norm = tensor(0.1222, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027894496917725\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302748918533325\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303750991821289\n",
            "g_norm = tensor(0.1306, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.59336853027344\n",
            "||∇_X meta|| = 0.0015422694850713015\n",
            "ΔX norm: 1.542268000775948e-05\n",
            "Stage 9/10:  90%|██████████████████████████   | 269/300 [10:05<00:59,  1.92s/it]T Loss=2.3037986755371094\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026866912841797\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039867877960205\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033814430236816\n",
            "g_norm = tensor(0.1225, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038508892059326\n",
            "g_norm = tensor(0.1308, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5542449951172\n",
            "||∇_X meta|| = 0.0015249940333887935\n",
            "ΔX norm: 1.5249930584104732e-05\n",
            "Stage 9/10:  90%|██████████████████████████   | 270/300 [10:07<00:58,  1.95s/it]T Loss=2.302227020263672\n",
            "g_norm = tensor(0.1342, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305238962173462\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304961681365967\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026766777038574\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045475482940674\n",
            "g_norm = tensor(0.1337, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.684814453125\n",
            "||∇_X meta|| = 0.001448977505788207\n",
            "ΔX norm: 1.4489783097815234e-05\n",
            "Stage 9/10:  90%|██████████████████████████▏  | 271/300 [10:09<00:55,  1.92s/it]T Loss=2.3036465644836426\n",
            "g_norm = tensor(0.1271, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028478622436523\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304255485534668\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047752380371094\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029398918151855\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.15966796875\n",
            "||∇_X meta|| = 0.0017974849324673414\n",
            "ΔX norm: 1.7974838556256145e-05\n",
            "Stage 9/10:  91%|██████████████████████████▎  | 272/300 [10:10<00:53,  1.90s/it]T Loss=2.303879976272583\n",
            "g_norm = tensor(0.1632, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302985429763794\n",
            "g_norm = tensor(0.1597, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039472103118896\n",
            "g_norm = tensor(0.1428, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302628993988037\n",
            "g_norm = tensor(0.1755, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027169704437256\n",
            "g_norm = tensor(0.1575, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.27980041503906\n",
            "||∇_X meta|| = 0.0015607961686328053\n",
            "ΔX norm: 1.560795499244705e-05\n",
            "Stage 9/10:  91%|██████████████████████████▍  | 273/300 [10:12<00:50,  1.86s/it]T Loss=2.302281379699707\n",
            "g_norm = tensor(0.1466, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303906202316284\n",
            "g_norm = tensor(0.1611, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302236557006836\n",
            "g_norm = tensor(0.1556, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027639389038086\n",
            "g_norm = tensor(0.1565, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019957542419434\n",
            "g_norm = tensor(0.1707, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3163299560547\n",
            "||∇_X meta|| = 0.0016128398710861802\n",
            "ΔX norm: 1.6128400602610782e-05\n",
            "Stage 9/10:  91%|██████████████████████████▍  | 274/300 [10:14<00:49,  1.91s/it]T Loss=2.302640914916992\n",
            "g_norm = tensor(0.0743, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303238868713379\n",
            "g_norm = tensor(0.0733, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303574800491333\n",
            "g_norm = tensor(0.0728, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302809476852417\n",
            "g_norm = tensor(0.0812, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303178310394287\n",
            "g_norm = tensor(0.0767, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.68313598632812\n",
            "||∇_X meta|| = 0.0013964077224954963\n",
            "ΔX norm: 1.3964087884232868e-05\n",
            "Stage 9/10:  92%|██████████████████████████▌  | 275/300 [10:16<00:47,  1.88s/it]T Loss=2.3038480281829834\n",
            "g_norm = tensor(0.1597, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042259216308594\n",
            "g_norm = tensor(0.1637, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039164543151855\n",
            "g_norm = tensor(0.1478, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302931070327759\n",
            "g_norm = tensor(0.1707, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029751777648926\n",
            "g_norm = tensor(0.1600, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.20782470703125\n",
            "||∇_X meta|| = 0.0015230245189741254\n",
            "ΔX norm: 1.5230245480779558e-05\n",
            "Stage 9/10:  92%|██████████████████████████▋  | 276/300 [10:18<00:44,  1.84s/it]T Loss=2.3032352924346924\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031439781188965\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302825450897217\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303560495376587\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303043842315674\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.28053283691406\n",
            "||∇_X meta|| = 0.001575210364535451\n",
            "ΔX norm: 1.5752091712784022e-05\n",
            "Stage 9/10:  92%|██████████████████████████▊  | 277/300 [10:20<00:42,  1.86s/it]T Loss=2.303804874420166\n",
            "g_norm = tensor(0.0885, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304445266723633\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042197227478027\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026676177978516\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303870677947998\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.58026123046875\n",
            "||∇_X meta|| = 0.0015386113664135337\n",
            "ΔX norm: 1.5386089216917753e-05\n",
            "Stage 9/10:  93%|██████████████████████████▊  | 278/300 [10:22<00:40,  1.85s/it]T Loss=2.3039238452911377\n",
            "g_norm = tensor(0.0902, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037779331207275\n",
            "g_norm = tensor(0.0883, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302896738052368\n",
            "g_norm = tensor(0.0945, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303300380706787\n",
            "g_norm = tensor(0.0784, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030593395233154\n",
            "g_norm = tensor(0.0797, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0330352783203\n",
            "||∇_X meta|| = 0.0015226262621581554\n",
            "ΔX norm: 1.5226269169943407e-05\n",
            "Stage 9/10:  93%|██████████████████████████▉  | 279/300 [10:23<00:38,  1.82s/it]T Loss=2.3030853271484375\n",
            "g_norm = tensor(0.1359, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303340196609497\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30372953414917\n",
            "g_norm = tensor(0.1617, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304182767868042\n",
            "g_norm = tensor(0.1363, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304353713989258\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.348388671875\n",
            "||∇_X meta|| = 0.0015137838199734688\n",
            "ΔX norm: 1.513787174189929e-05\n",
            "Stage 9/10:  93%|███████████████████████████  | 280/300 [10:25<00:36,  1.81s/it]T Loss=2.302316904067993\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031277656555176\n",
            "g_norm = tensor(0.1218, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026278018951416\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030974864959717\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030152320861816\n",
            "g_norm = tensor(0.0898, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.7864532470703\n",
            "||∇_X meta|| = 0.0015086954226717353\n",
            "ΔX norm: 1.5086949133547023e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 9/10:  94%|███████████████████████████▏ | 281/300 [10:27<00:34,  1.82s/it]T Loss=2.304725170135498\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30326771736145\n",
            "g_norm = tensor(0.1172, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303612470626831\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303257942199707\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029589653015137\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.98382568359375\n",
            "||∇_X meta|| = 0.001553863170556724\n",
            "ΔX norm: 1.5538627849309705e-05\n",
            "Stage 9/10:  94%|███████████████████████████▎ | 282/300 [10:29<00:34,  1.91s/it]T Loss=2.3032569885253906\n",
            "g_norm = tensor(0.1017, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303992509841919\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043770790100098\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043928146362305\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304102659225464\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9981231689453\n",
            "||∇_X meta|| = 0.0014859235379844904\n",
            "ΔX norm: 1.4859234397590626e-05\n",
            "Stage 9/10:  94%|███████████████████████████▎ | 283/300 [10:31<00:32,  1.92s/it]T Loss=2.3036043643951416\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037219047546387\n",
            "g_norm = tensor(0.1195, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024754524230957\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029074668884277\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048348426818848\n",
            "g_norm = tensor(0.1547, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1970672607422\n",
            "||∇_X meta|| = 0.0017101746052503586\n",
            "ΔX norm: 1.7101709090638906e-05\n",
            "Stage 9/10:  95%|███████████████████████████▍ | 284/300 [10:33<00:31,  1.97s/it]T Loss=2.3041341304779053\n",
            "g_norm = tensor(0.1486, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30549693107605\n",
            "g_norm = tensor(0.1401, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305243968963623\n",
            "g_norm = tensor(0.1488, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304443359375\n",
            "g_norm = tensor(0.1642, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044557571411133\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.43382263183594\n",
            "||∇_X meta|| = 0.001577623188495636\n",
            "ΔX norm: 1.5776209693285637e-05\n",
            "Stage 9/10:  95%|███████████████████████████▌ | 285/300 [10:35<00:30,  2.01s/it]T Loss=2.3040099143981934\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045058250427246\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30301833152771\n",
            "g_norm = tensor(0.1251, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303238868713379\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303771495819092\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.02304077148438\n",
            "||∇_X meta|| = 0.0015101599274203181\n",
            "ΔX norm: 1.5101635653991252e-05\n",
            "Stage 9/10:  95%|███████████████████████████▋ | 286/300 [10:37<00:27,  1.98s/it]T Loss=2.3039281368255615\n",
            "g_norm = tensor(0.1399, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303773880004883\n",
            "g_norm = tensor(0.1357, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303229570388794\n",
            "g_norm = tensor(0.1378, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033175468444824\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304478883743286\n",
            "g_norm = tensor(0.1312, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.05535888671875\n",
            "||∇_X meta|| = 0.0014730511466041207\n",
            "ΔX norm: 1.4730510883964598e-05\n",
            "Stage 9/10:  96%|███████████████████████████▋ | 287/300 [10:39<00:25,  1.95s/it]T Loss=2.3032336235046387\n",
            "g_norm = tensor(0.1275, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304016590118408\n",
            "g_norm = tensor(0.1023, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030195236206055\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040518760681152\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302647113800049\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.3865203857422\n",
            "||∇_X meta|| = 0.0015495329862460494\n",
            "ΔX norm: 1.5495341358473524e-05\n",
            "Stage 9/10:  96%|███████████████████████████▊ | 288/300 [10:41<00:24,  2.01s/it]T Loss=2.3046481609344482\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043832778930664\n",
            "g_norm = tensor(0.1078, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040828704833984\n",
            "g_norm = tensor(0.0917, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040714263916016\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039112091064453\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6190185546875\n",
            "||∇_X meta|| = 0.001562297809869051\n",
            "ΔX norm: 1.5622972568962723e-05\n",
            "Stage 9/10:  96%|███████████████████████████▉ | 289/300 [10:43<00:21,  1.94s/it]T Loss=2.3045454025268555\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304588794708252\n",
            "g_norm = tensor(0.1103, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038837909698486\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053412437438965\n",
            "g_norm = tensor(0.1341, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035714626312256\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.97528076171875\n",
            "||∇_X meta|| = 0.0015368432505056262\n",
            "ΔX norm: 1.536843046778813e-05\n",
            "Stage 9/10:  97%|████████████████████████████ | 290/300 [10:45<00:18,  1.88s/it]T Loss=2.3030357360839844\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045456409454346\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303074359893799\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036444187164307\n",
            "g_norm = tensor(0.1183, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304903030395508\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.35455322265625\n",
            "||∇_X meta|| = 0.001421067281626165\n",
            "ΔX norm: 1.421068373019807e-05\n",
            "Stage 9/10:  97%|████████████████████████████▏| 291/300 [10:46<00:16,  1.86s/it]T Loss=2.303558349609375\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042922019958496\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304034471511841\n",
            "g_norm = tensor(0.1225, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045601844787598\n",
            "g_norm = tensor(0.1214, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303138256072998\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.35231018066406\n",
            "||∇_X meta|| = 0.0016037138411775231\n",
            "ΔX norm: 1.6037150999181904e-05\n",
            "Stage 9/10:  97%|████████████████████████████▏| 292/300 [10:48<00:14,  1.82s/it]T Loss=2.303495407104492\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036179542541504\n",
            "g_norm = tensor(0.0991, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303373336791992\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033447265625\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040902614593506\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.19227600097656\n",
            "||∇_X meta|| = 0.0016484856605529785\n",
            "ΔX norm: 1.6484849766129628e-05\n",
            "Stage 9/10:  98%|████████████████████████████▎| 293/300 [10:50<00:12,  1.80s/it]T Loss=2.3056156635284424\n",
            "g_norm = tensor(0.1577, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045451641082764\n",
            "g_norm = tensor(0.1744, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305330276489258\n",
            "g_norm = tensor(0.1664, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054590225219727\n",
            "g_norm = tensor(0.1324, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029074668884277\n",
            "g_norm = tensor(0.1313, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5382843017578\n",
            "||∇_X meta|| = 0.0015932274982333183\n",
            "ΔX norm: 1.59322935360251e-05\n",
            "Stage 9/10:  98%|████████████████████████████▍| 294/300 [10:52<00:10,  1.78s/it]T Loss=2.303459405899048\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035879135131836\n",
            "g_norm = tensor(0.0854, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044590950012207\n",
            "g_norm = tensor(0.0821, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303619861602783\n",
            "g_norm = tensor(0.0850, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303605556488037\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.74586486816406\n",
            "||∇_X meta|| = 0.0014431981835514307\n",
            "ΔX norm: 1.4431986528506968e-05\n",
            "Stage 9/10:  98%|████████████████████████████▌| 295/300 [10:53<00:08,  1.79s/it]T Loss=2.3036446571350098\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30389142036438\n",
            "g_norm = tensor(0.0798, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030037879943848\n",
            "g_norm = tensor(0.0782, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033833503723145\n",
            "g_norm = tensor(0.0879, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036301136016846\n",
            "g_norm = tensor(0.0702, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.78627014160156\n",
            "||∇_X meta|| = 0.0014936634106561542\n",
            "ΔX norm: 1.4936625120753888e-05\n",
            "Stage 9/10:  99%|████████████████████████████▌| 296/300 [10:55<00:07,  1.78s/it]T Loss=2.303837299346924\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305079221725464\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036460876464844\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041582107543945\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046534061431885\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.7831268310547\n",
            "||∇_X meta|| = 0.0015470982762053609\n",
            "ΔX norm: 1.547098690934945e-05\n",
            "Stage 9/10:  99%|████████████████████████████▋| 297/300 [10:57<00:05,  1.80s/it]T Loss=2.3016891479492188\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022494316101074\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030941486358643\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3016505241394043\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021531105041504\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.90914916992188\n",
            "||∇_X meta|| = 0.0014967222232371569\n",
            "ΔX norm: 1.496721051807981e-05\n",
            "Stage 9/10:  99%|████████████████████████████▊| 298/300 [11:00<00:04,  2.04s/it]T Loss=2.303584575653076\n",
            "g_norm = tensor(0.1096, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303565740585327\n",
            "g_norm = tensor(0.1082, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303861141204834\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304239273071289\n",
            "g_norm = tensor(0.1139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038570880889893\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.38856506347656\n",
            "||∇_X meta|| = 0.0016771028749644756\n",
            "ΔX norm: 1.6771025912021287e-05\n",
            "Stage 9/10: 100%|████████████████████████████▉| 299/300 [11:02<00:02,  2.03s/it]T Loss=2.3043715953826904\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042047023773193\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035590648651123\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043224811553955\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302882194519043\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1153564453125\n",
            "||∇_X meta|| = 0.001548039959743619\n",
            "ΔX norm: 1.548037471366115e-05\n",
            "Stage 8, class 0, loss 2.207                                                    \n",
            "Stage 8, class 1, loss 2.269\n",
            "Stage 8, class 2, loss 2.339\n",
            "Stage 8, class 3, loss 2.357\n",
            "Stage 8, class 4, loss 2.307\n",
            "Stage 8, class 5, loss 2.326\n",
            "Stage 8, class 6, loss 2.383\n",
            "Stage 8, class 7, loss 2.229\n",
            "Stage 8, class 8, loss 2.363\n",
            "Stage 8, class 9, loss 2.254\n",
            "Stage 10/10:   0%|                                      | 0/300 [00:00<?, ?it/s]T Loss=2.3032798767089844\n",
            "g_norm = tensor(0.0867, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034868240356445\n",
            "g_norm = tensor(0.0818, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032143115997314\n",
            "g_norm = tensor(0.0753, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030521869659424\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033359050750732\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.73793029785156\n",
            "||∇_X meta|| = 0.00389080960303545\n",
            "ΔX norm: 3.8908077840460464e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 10/10:   0%|                              | 1/300 [00:02<11:58,  2.40s/it]T Loss=2.3040292263031006\n",
            "g_norm = tensor(0.0718, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042893409729004\n",
            "g_norm = tensor(0.0724, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045601844787598\n",
            "g_norm = tensor(0.0718, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304553985595703\n",
            "g_norm = tensor(0.0651, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040239810943604\n",
            "g_norm = tensor(0.0722, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.8372802734375\n",
            "||∇_X meta|| = 0.0035593125503510237\n",
            "ΔX norm: 3.5593078791862354e-05\n",
            "Stage 10/10:   1%|▏                             | 2/300 [00:04<11:34,  2.33s/it]T Loss=2.304290294647217\n",
            "g_norm = tensor(0.1018, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024303913116455\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304513931274414\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036048412323\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027241230010986\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.98611450195312\n",
            "||∇_X meta|| = 0.0038769191596657038\n",
            "ΔX norm: 3.876916889566928e-05\n",
            "Stage 10/10:   1%|▎                             | 3/300 [00:06<10:50,  2.19s/it]T Loss=2.3043599128723145\n",
            "g_norm = tensor(0.1266, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035151958465576\n",
            "g_norm = tensor(0.1118, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304440975189209\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037805557250977\n",
            "g_norm = tensor(0.1401, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034613132476807\n",
            "g_norm = tensor(0.1377, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8056182861328\n",
            "||∇_X meta|| = 0.0035012445878237486\n",
            "ΔX norm: 3.501253013382666e-05\n",
            "Stage 10/10:   1%|▍                             | 4/300 [00:08<10:18,  2.09s/it]T Loss=2.3030786514282227\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033809661865234\n",
            "g_norm = tensor(0.1485, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303363084793091\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022656440734863\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049652576446533\n",
            "g_norm = tensor(0.1387, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.0554656982422\n",
            "||∇_X meta|| = 0.0035307209473103285\n",
            "ΔX norm: 3.530717731337063e-05\n",
            "Stage 10/10:   2%|▌                             | 5/300 [00:10<09:57,  2.03s/it]T Loss=2.3035831451416016\n",
            "g_norm = tensor(0.1221, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303494930267334\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042616844177246\n",
            "g_norm = tensor(0.0980, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018555641174316\n",
            "g_norm = tensor(0.1226, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303410768508911\n",
            "g_norm = tensor(0.1318, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1534423828125\n",
            "||∇_X meta|| = 0.003486749017611146\n",
            "ΔX norm: 3.486748391878791e-05\n",
            "Stage 10/10:   2%|▌                             | 6/300 [00:12<09:35,  1.96s/it]T Loss=2.302898645401001\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041157722473145\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032898902893066\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302363395690918\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303337574005127\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7826385498047\n",
            "||∇_X meta|| = 0.0037767000030726194\n",
            "ΔX norm: 3.7767043977510184e-05\n",
            "Stage 10/10:   2%|▋                             | 7/300 [00:14<09:24,  1.93s/it]T Loss=2.305237293243408\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054428100585938\n",
            "g_norm = tensor(0.1262, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045401573181152\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057565689086914\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047566413879395\n",
            "g_norm = tensor(0.1694, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.92950439453125\n",
            "||∇_X meta|| = 0.003805474378168583\n",
            "ΔX norm: 3.805472806561738e-05\n",
            "Stage 10/10:   3%|▊                             | 8/300 [00:16<09:52,  2.03s/it]T Loss=2.3042550086975098\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304527997970581\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304009199142456\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3061118125915527\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303772449493408\n",
            "g_norm = tensor(0.0823, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.27818298339844\n",
            "||∇_X meta|| = 0.0038223937153816223\n",
            "ΔX norm: 3.8223908632062376e-05\n",
            "Stage 10/10:   3%|▉                             | 9/300 [00:18<09:29,  1.96s/it]T Loss=2.3030331134796143\n",
            "g_norm = tensor(0.1278, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305209159851074\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055977821350098\n",
            "g_norm = tensor(0.1558, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039140701293945\n",
            "g_norm = tensor(0.1283, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303635835647583\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6537628173828\n",
            "||∇_X meta|| = 0.00336053385399282\n",
            "ΔX norm: 3.3605283533688635e-05\n",
            "Stage 10/10:   3%|▉                            | 10/300 [00:20<09:43,  2.01s/it]T Loss=2.3039050102233887\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039660453796387\n",
            "g_norm = tensor(0.1178, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3013596534729004\n",
            "g_norm = tensor(0.1295, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302738666534424\n",
            "g_norm = tensor(0.1354, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303687334060669\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.45443725585938\n",
            "||∇_X meta|| = 0.003611023770645261\n",
            "ΔX norm: 3.6110210203332826e-05\n",
            "Stage 10/10:   4%|█                            | 11/300 [00:22<10:00,  2.08s/it]T Loss=2.303405523300171\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303205966949463\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029816150665283\n",
            "g_norm = tensor(0.0928, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037915229797363\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023486137390137\n",
            "g_norm = tensor(0.0839, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.6705322265625\n",
            "||∇_X meta|| = 0.003954802639782429\n",
            "ΔX norm: 3.954803105443716e-05\n",
            "Stage 10/10:   4%|█▏                           | 12/300 [00:24<09:42,  2.02s/it]T Loss=2.304098606109619\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304292917251587\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041908740997314\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034822940826416\n",
            "g_norm = tensor(0.0934, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303520917892456\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =233.1011962890625\n",
            "||∇_X meta|| = 0.0036621359176933765\n",
            "ΔX norm: 3.662132439785637e-05\n",
            "Stage 10/10:   4%|█▎                           | 13/300 [00:26<09:26,  1.97s/it]T Loss=2.30249285697937\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042454719543457\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301884651184082\n",
            "g_norm = tensor(0.1308, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045027256011963\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046653270721436\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.53843688964844\n",
            "||∇_X meta|| = 0.003475525416433811\n",
            "ΔX norm: 3.475524499663152e-05\n",
            "Stage 10/10:   5%|█▎                           | 14/300 [00:28<09:03,  1.90s/it]T Loss=2.3035480976104736\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042051792144775\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037617206573486\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303636312484741\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305171012878418\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.17564392089844\n",
            "||∇_X meta|| = 0.00336802052333951\n",
            "ΔX norm: 3.368020770722069e-05\n",
            "Stage 10/10:   5%|█▍                           | 15/300 [00:30<09:20,  1.97s/it]T Loss=2.3032095432281494\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303586006164551\n",
            "g_norm = tensor(0.1295, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045506477355957\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304715156555176\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046135902404785\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.81454467773438\n",
            "||∇_X meta|| = 0.0034826563205569983\n",
            "ΔX norm: 3.48265421052929e-05\n",
            "Stage 10/10:   5%|█▌                           | 16/300 [00:32<09:11,  1.94s/it]T Loss=2.3045871257781982\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030648231506348\n",
            "g_norm = tensor(0.0951, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304839611053467\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3062751293182373\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306381940841675\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7587890625\n",
            "||∇_X meta|| = 0.004074618220329285\n",
            "ΔX norm: 4.07461411668919e-05\n",
            "Stage 10/10:   6%|█▋                           | 17/300 [00:33<08:55,  1.89s/it]T Loss=2.302955150604248\n",
            "g_norm = tensor(0.1022, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050496578216553\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303194761276245\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035166263580322\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30295991897583\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.21652221679688\n",
            "||∇_X meta|| = 0.003558048512786627\n",
            "ΔX norm: 3.558045136742294e-05\n",
            "Stage 10/10:   6%|█▋                           | 18/300 [00:35<08:45,  1.86s/it]T Loss=2.30377197265625\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035030364990234\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043179512023926\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047268390655518\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053641319274902\n",
            "g_norm = tensor(0.1377, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5159454345703\n",
            "||∇_X meta|| = 0.0035064062103629112\n",
            "ΔX norm: 3.506406210362911e-05\n",
            "Stage 10/10:   6%|█▊                           | 19/300 [00:37<08:40,  1.85s/it]T Loss=2.3045098781585693\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304898977279663\n",
            "g_norm = tensor(0.1332, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302854299545288\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047592639923096\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036346435546875\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.08578491210938\n",
            "||∇_X meta|| = 0.0031888855155557394\n",
            "ΔX norm: 3.1888896046439186e-05\n",
            "Stage 10/10:   7%|█▉                           | 20/300 [00:39<08:32,  1.83s/it]T Loss=2.3033204078674316\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304532527923584\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304194450378418\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303853988647461\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040623664855957\n",
            "g_norm = tensor(0.1010, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.49061584472656\n",
            "||∇_X meta|| = 0.00352774141356349\n",
            "ΔX norm: 3.5277411370771006e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 10/10:   7%|██                           | 21/300 [00:41<08:39,  1.86s/it]T Loss=2.3040060997009277\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302882194519043\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302751302719116\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026247024536133\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025424480438232\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.98782348632812\n",
            "||∇_X meta|| = 0.0032938134390860796\n",
            "ΔX norm: 3.293813279015012e-05\n",
            "Stage 10/10:   7%|██▏                          | 22/300 [00:43<09:12,  1.99s/it]T Loss=2.304304361343384\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050804138183594\n",
            "g_norm = tensor(0.0937, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304269552230835\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033480644226074\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303950548171997\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.7986297607422\n",
            "||∇_X meta|| = 0.003000739263370633\n",
            "ΔX norm: 3.000744618475437e-05\n",
            "Stage 10/10:   8%|██▏                          | 23/300 [00:46<10:30,  2.28s/it]T Loss=2.3036646842956543\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302745819091797\n",
            "g_norm = tensor(0.1163, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029139041900635\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037960529327393\n",
            "g_norm = tensor(0.1268, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026528358459473\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.11447143554688\n",
            "||∇_X meta|| = 0.0031308953184634447\n",
            "ΔX norm: 3.1308929465012625e-05\n",
            "Stage 10/10:   8%|██▎                          | 24/300 [00:49<11:18,  2.46s/it]T Loss=2.3036937713623047\n",
            "g_norm = tensor(0.2150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046488761901855\n",
            "g_norm = tensor(0.1391, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039238452911377\n",
            "g_norm = tensor(0.2020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053739070892334\n",
            "g_norm = tensor(0.1741, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040125370025635\n",
            "g_norm = tensor(0.1728, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.02325439453125\n",
            "||∇_X meta|| = 0.0029401190113276243\n",
            "ΔX norm: 2.940119884442538e-05\n",
            "Stage 10/10:   8%|██▍                          | 25/300 [00:52<11:55,  2.60s/it]T Loss=2.3023672103881836\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034844398498535\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032093048095703\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027255535125732\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303150177001953\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3745880126953\n",
            "||∇_X meta|| = 0.003436629893258214\n",
            "ΔX norm: 3.4366294130450115e-05\n",
            "Stage 10/10:   9%|██▌                          | 26/300 [00:55<12:02,  2.64s/it]T Loss=2.3042120933532715\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036670684814453\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304610252380371\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036582469940186\n",
            "g_norm = tensor(0.0934, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303873062133789\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.6156005859375\n",
            "||∇_X meta|| = 0.003227620618417859\n",
            "ΔX norm: 3.2276213460136205e-05\n",
            "Stage 10/10:   9%|██▌                          | 27/300 [00:57<12:02,  2.65s/it]T Loss=2.3059499263763428\n",
            "g_norm = tensor(0.1273, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306694507598877\n",
            "g_norm = tensor(0.1316, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306896924972534\n",
            "g_norm = tensor(0.1507, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304703950881958\n",
            "g_norm = tensor(0.1059, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3060593605041504\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.03919982910156\n",
            "||∇_X meta|| = 0.0032205875031650066\n",
            "ΔX norm: 3.2205851312028244e-05\n",
            "Stage 10/10:   9%|██▋                          | 28/300 [01:00<12:18,  2.72s/it]T Loss=2.306040048599243\n",
            "g_norm = tensor(0.1567, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30580735206604\n",
            "g_norm = tensor(0.1394, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305225372314453\n",
            "g_norm = tensor(0.1500, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047707080841064\n",
            "g_norm = tensor(0.1335, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301405429840088\n",
            "g_norm = tensor(0.1724, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.42129516601562\n",
            "||∇_X meta|| = 0.002953775692731142\n",
            "ΔX norm: 2.9537764930864796e-05\n",
            "Stage 10/10:  10%|██▊                          | 29/300 [01:04<13:35,  3.01s/it]T Loss=2.3039119243621826\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303234100341797\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054580688476562\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304216146469116\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037071228027344\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3249969482422\n",
            "||∇_X meta|| = 0.0030675441958010197\n",
            "ΔX norm: 3.067546276724897e-05\n",
            "Stage 10/10:  10%|██▉                          | 30/300 [01:08<14:39,  3.26s/it]T Loss=2.3036794662475586\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302280902862549\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026628494262695\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028244972229004\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033251762390137\n",
            "g_norm = tensor(0.0821, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7637176513672\n",
            "||∇_X meta|| = 0.003051656996831298\n",
            "ΔX norm: 3.051657222385984e-05\n",
            "Stage 10/10:  10%|██▉                          | 31/300 [01:10<14:02,  3.13s/it]T Loss=2.304007053375244\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036913871765137\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045132160186768\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048627376556396\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304253578186035\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.6231231689453\n",
            "||∇_X meta|| = 0.0031015239655971527\n",
            "ΔX norm: 3.101523907389492e-05\n",
            "Stage 10/10:  11%|███                          | 32/300 [01:13<13:53,  3.11s/it]T Loss=2.30458402633667\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046987056732178\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304810047149658\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038735389709473\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304825782775879\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.15541076660156\n",
            "||∇_X meta|| = 0.0028797578997910023\n",
            "ΔX norm: 2.8797596314689144e-05\n",
            "Stage 10/10:  11%|███▏                         | 33/300 [01:16<12:59,  2.92s/it]T Loss=2.302312135696411\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032066822052\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032398223876953\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038151264190674\n",
            "g_norm = tensor(0.1022, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038647174835205\n",
            "g_norm = tensor(0.1026, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.00621032714844\n",
            "||∇_X meta|| = 0.0029148252215236425\n",
            "ΔX norm: 2.9148266548872925e-05\n",
            "Stage 10/10:  11%|███▎                         | 34/300 [01:18<12:17,  2.77s/it]T Loss=2.3032801151275635\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303415060043335\n",
            "g_norm = tensor(0.0921, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039817810058594\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303448438644409\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038270473480225\n",
            "g_norm = tensor(0.1011, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.67803955078125\n",
            "||∇_X meta|| = 0.0030349798034876585\n",
            "ΔX norm: 3.034982546523679e-05\n",
            "Stage 10/10:  12%|███▍                         | 35/300 [01:21<11:56,  2.70s/it]T Loss=2.3039944171905518\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305436611175537\n",
            "g_norm = tensor(0.0917, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040659427642822\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302926540374756\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043839931488037\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.15133666992188\n",
            "||∇_X meta|| = 0.0027042480651289225\n",
            "ΔX norm: 2.7042453439207748e-05\n",
            "Stage 10/10:  12%|███▍                         | 36/300 [01:25<13:06,  2.98s/it]T Loss=2.304435968399048\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033199310302734\n",
            "g_norm = tensor(0.1221, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032126426696777\n",
            "g_norm = tensor(0.1187, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304187297821045\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305238962173462\n",
            "g_norm = tensor(0.1409, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5039520263672\n",
            "||∇_X meta|| = 0.0026876372285187244\n",
            "ΔX norm: 2.6876397896558046e-05\n",
            "Stage 10/10:  12%|███▌                         | 37/300 [01:28<13:02,  2.98s/it]T Loss=2.3031928539276123\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303126811981201\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036389350891113\n",
            "g_norm = tensor(0.1085, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303046941757202\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038620948791504\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.42970275878906\n",
            "||∇_X meta|| = 0.0026329830288887024\n",
            "ΔX norm: 2.632981340866536e-05\n",
            "Stage 10/10:  13%|███▋                         | 38/300 [01:30<12:14,  2.80s/it]T Loss=2.3045294284820557\n",
            "g_norm = tensor(0.1426, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050267696380615\n",
            "g_norm = tensor(0.1443, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3064188957214355\n",
            "g_norm = tensor(0.1383, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304821729660034\n",
            "g_norm = tensor(0.1596, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052027225494385\n",
            "g_norm = tensor(0.1308, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.18824768066406\n",
            "||∇_X meta|| = 0.002743142656981945\n",
            "ΔX norm: 2.743142431427259e-05\n",
            "Stage 10/10:  13%|███▊                         | 39/300 [01:32<11:31,  2.65s/it]T Loss=2.3028948307037354\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049514293670654\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044793605804443\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304953098297119\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304788827896118\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6132049560547\n",
            "||∇_X meta|| = 0.002972286194562912\n",
            "ΔX norm: 2.972287438751664e-05\n",
            "Stage 10/10:  13%|███▊                         | 40/300 [01:35<11:18,  2.61s/it]T Loss=2.303941249847412\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048627376556396\n",
            "g_norm = tensor(0.1326, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304192304611206\n",
            "g_norm = tensor(0.1412, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305101156234741\n",
            "g_norm = tensor(0.0960, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056769371032715\n",
            "g_norm = tensor(0.1354, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9697265625\n",
            "||∇_X meta|| = 0.0024829269386827946\n",
            "ΔX norm: 2.482926720404066e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 10/10:  14%|███▉                         | 41/300 [01:37<11:24,  2.64s/it]T Loss=2.304023504257202\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305016279220581\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304593086242676\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041651248931885\n",
            "g_norm = tensor(0.1154, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304675340652466\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2230987548828\n",
            "||∇_X meta|| = 0.002833280013874173\n",
            "ΔX norm: 2.8332806323305704e-05\n",
            "Stage 10/10:  14%|████                         | 42/300 [01:40<11:38,  2.71s/it]T Loss=2.3034911155700684\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301558494567871\n",
            "g_norm = tensor(0.1153, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30283784866333\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022618293762207\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303837299346924\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5789794921875\n",
            "||∇_X meta|| = 0.002880953950807452\n",
            "ΔX norm: 2.8809576178900898e-05\n",
            "Stage 10/10:  14%|████▏                        | 43/300 [01:44<12:47,  2.99s/it]T Loss=2.304142475128174\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304332971572876\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304708957672119\n",
            "g_norm = tensor(0.1035, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049232959747314\n",
            "g_norm = tensor(0.1034, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046388626098633\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6993408203125\n",
            "||∇_X meta|| = 0.0028295640368014574\n",
            "ΔX norm: 2.8295626179897226e-05\n",
            "Stage 10/10:  15%|████▎                        | 44/300 [01:46<11:57,  2.80s/it]T Loss=2.302804946899414\n",
            "g_norm = tensor(0.0752, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035690784454346\n",
            "g_norm = tensor(0.0885, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031439781188965\n",
            "g_norm = tensor(0.0849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041396141052246\n",
            "g_norm = tensor(0.0956, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027396202087402\n",
            "g_norm = tensor(0.0794, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.16720581054688\n",
            "||∇_X meta|| = 0.002679936122149229\n",
            "ΔX norm: 2.679936369531788e-05\n",
            "Stage 10/10:  15%|████▎                        | 45/300 [01:49<11:25,  2.69s/it]T Loss=2.3042478561401367\n",
            "g_norm = tensor(0.1016, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303375244140625\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037095069885254\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302544593811035\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304208755493164\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.9832305908203\n",
            "||∇_X meta|| = 0.0025945473462343216\n",
            "ΔX norm: 2.594546640466433e-05\n",
            "Stage 10/10:  15%|████▍                        | 46/300 [01:51<11:12,  2.65s/it]T Loss=2.302401542663574\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304457426071167\n",
            "g_norm = tensor(0.1225, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302507162094116\n",
            "g_norm = tensor(0.1299, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039731979370117\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303229570388794\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.388671875\n",
            "||∇_X meta|| = 0.002645099302753806\n",
            "ΔX norm: 2.6450985387782566e-05\n",
            "Stage 10/10:  16%|████▌                        | 47/300 [01:54<10:47,  2.56s/it]T Loss=2.3015551567077637\n",
            "g_norm = tensor(0.2314, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30360746383667\n",
            "g_norm = tensor(0.1468, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040096759796143\n",
            "g_norm = tensor(0.2145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303809404373169\n",
            "g_norm = tensor(0.1941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302396297454834\n",
            "g_norm = tensor(0.1543, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.52294921875\n",
            "||∇_X meta|| = 0.0024298338685184717\n",
            "ΔX norm: 2.4298358766827732e-05\n",
            "Stage 10/10:  16%|████▋                        | 48/300 [01:56<10:47,  2.57s/it]T Loss=2.305220127105713\n",
            "g_norm = tensor(0.1434, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038389682769775\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025128841400146\n",
            "g_norm = tensor(0.1521, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303494691848755\n",
            "g_norm = tensor(0.1214, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037078380584717\n",
            "g_norm = tensor(0.1433, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.62681579589844\n",
            "||∇_X meta|| = 0.0025818475987762213\n",
            "ΔX norm: 2.581849184934981e-05\n",
            "Stage 10/10:  16%|████▋                        | 49/300 [01:58<10:11,  2.44s/it]T Loss=2.3042428493499756\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037636280059814\n",
            "g_norm = tensor(0.0875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053457736968994\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304133415222168\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305070400238037\n",
            "g_norm = tensor(0.0941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.07179260253906\n",
            "||∇_X meta|| = 0.0027139317244291306\n",
            "ΔX norm: 2.7139278245158494e-05\n",
            "Stage 10/10:  17%|████▊                        | 50/300 [02:01<10:01,  2.41s/it]T Loss=2.3037877082824707\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043551445007324\n",
            "g_norm = tensor(0.1183, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304082155227661\n",
            "g_norm = tensor(0.1232, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031933307647705\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303394079208374\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.14430236816406\n",
            "||∇_X meta|| = 0.0025910905096679926\n",
            "ΔX norm: 2.5910898330039345e-05\n",
            "Stage 10/10:  17%|████▉                        | 51/300 [02:03<09:57,  2.40s/it]T Loss=2.3046822547912598\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049159049987793\n",
            "g_norm = tensor(0.1225, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042778968811035\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304961681365967\n",
            "g_norm = tensor(0.0934, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30531644821167\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.43833923339844\n",
            "||∇_X meta|| = 0.00261700339615345\n",
            "ΔX norm: 2.6170055207330734e-05\n",
            "Stage 10/10:  17%|█████                        | 52/300 [02:05<09:46,  2.37s/it]T Loss=2.304133415222168\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302689552307129\n",
            "g_norm = tensor(0.1069, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036258220672607\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040897846221924\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30344820022583\n",
            "g_norm = tensor(0.0965, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.11329650878906\n",
            "||∇_X meta|| = 0.0024362271651625633\n",
            "ΔX norm: 2.4362258045584895e-05\n",
            "Stage 10/10:  18%|█████                        | 53/300 [02:08<09:39,  2.35s/it]T Loss=2.302335262298584\n",
            "g_norm = tensor(0.1124, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304499387741089\n",
            "g_norm = tensor(0.1330, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302706480026245\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019723892211914\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303680896759033\n",
            "g_norm = tensor(0.1312, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.31582641601562\n",
            "||∇_X meta|| = 0.00241187890060246\n",
            "ΔX norm: 2.4118771762005053e-05\n",
            "Stage 10/10:  18%|█████▏                       | 54/300 [02:11<10:56,  2.67s/it]T Loss=2.303764820098877\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040192127227783\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304595708847046\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033573627471924\n",
            "g_norm = tensor(0.1214, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303469181060791\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3217315673828\n",
            "||∇_X meta|| = 0.0024581821635365486\n",
            "ΔX norm: 2.4581811885582283e-05\n",
            "Stage 10/10:  18%|█████▎                       | 55/300 [02:13<10:32,  2.58s/it]T Loss=2.3035964965820312\n",
            "g_norm = tensor(0.0821, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303269386291504\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035953044891357\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032798767089844\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032519817352295\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.67257690429688\n",
            "||∇_X meta|| = 0.0024484465830028057\n",
            "ΔX norm: 2.4484454115736298e-05\n",
            "Stage 10/10:  19%|█████▍                       | 56/300 [02:16<10:03,  2.47s/it]T Loss=2.30277681350708\n",
            "g_norm = tensor(0.1199, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029067516326904\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039181232452393\n",
            "g_norm = tensor(0.1173, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030638694763184\n",
            "g_norm = tensor(0.1141, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302173137664795\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2434844970703\n",
            "||∇_X meta|| = 0.0023256251588463783\n",
            "ΔX norm: 2.3256263375515118e-05\n",
            "Stage 10/10:  19%|█████▌                       | 57/300 [02:18<09:46,  2.41s/it]T Loss=2.304659366607666\n",
            "g_norm = tensor(0.0973, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305424928665161\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049588203430176\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304624557495117\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30439829826355\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.3975372314453\n",
            "||∇_X meta|| = 0.0022190005984157324\n",
            "ΔX norm: 2.2190006347955205e-05\n",
            "Stage 10/10:  19%|█████▌                       | 58/300 [02:20<09:42,  2.41s/it]T Loss=2.3039209842681885\n",
            "g_norm = tensor(0.1228, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034422397613525\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301814556121826\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031320571899414\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303192138671875\n",
            "g_norm = tensor(0.1491, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.31442260742188\n",
            "||∇_X meta|| = 0.0026687460485845804\n",
            "ΔX norm: 2.6687474019126967e-05\n",
            "Stage 10/10:  20%|█████▋                       | 59/300 [02:23<09:34,  2.38s/it]T Loss=2.3042380809783936\n",
            "g_norm = tensor(0.1955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034167289733887\n",
            "g_norm = tensor(0.1595, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036394119262695\n",
            "g_norm = tensor(0.1875, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306328535079956\n",
            "g_norm = tensor(0.1694, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055434226989746\n",
            "g_norm = tensor(0.1860, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.78213500976562\n",
            "||∇_X meta|| = 0.0027810893952846527\n",
            "ΔX norm: 2.7810901883640327e-05\n",
            "Stage 10/10:  20%|█████▊                       | 60/300 [02:25<09:35,  2.40s/it]T Loss=2.3042964935302734\n",
            "g_norm = tensor(0.1224, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041491508483887\n",
            "g_norm = tensor(0.1340, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303713321685791\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30482816696167\n",
            "g_norm = tensor(0.1075, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304253578186035\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.36770629882812\n",
            "||∇_X meta|| = 0.0025895405560731888\n",
            "ΔX norm: 2.589540417829994e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 10/10:  20%|█████▉                       | 61/300 [02:27<09:16,  2.33s/it]T Loss=2.302602767944336\n",
            "g_norm = tensor(0.1431, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028950691223145\n",
            "g_norm = tensor(0.1219, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032193183898926\n",
            "g_norm = tensor(0.1331, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302924633026123\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024027347564697\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1154022216797\n",
            "||∇_X meta|| = 0.0023482483811676502\n",
            "ΔX norm: 2.3482460164814256e-05\n",
            "Stage 10/10:  21%|█████▉                       | 62/300 [02:30<09:50,  2.48s/it]T Loss=2.3046457767486572\n",
            "g_norm = tensor(0.1333, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303762197494507\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304141044616699\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303880453109741\n",
            "g_norm = tensor(0.1425, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032829761505127\n",
            "g_norm = tensor(0.1115, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.20420837402344\n",
            "||∇_X meta|| = 0.002416852628812194\n",
            "ΔX norm: 2.416852476017084e-05\n",
            "Stage 10/10:  21%|██████                       | 63/300 [02:33<09:48,  2.48s/it]T Loss=2.3040053844451904\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044261932373047\n",
            "g_norm = tensor(0.1022, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041629791259766\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044745922088623\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040785789489746\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6251678466797\n",
            "||∇_X meta|| = 0.002501145238056779\n",
            "ΔX norm: 2.5011484467540868e-05\n",
            "Stage 10/10:  21%|██████▏                      | 64/300 [02:35<09:42,  2.47s/it]T Loss=2.3048548698425293\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028783798217773\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037710189819336\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048532009124756\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042006492614746\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.51998901367188\n",
            "||∇_X meta|| = 0.002374761737883091\n",
            "ΔX norm: 2.374757059442345e-05\n",
            "Stage 10/10:  22%|██████▎                      | 65/300 [02:38<09:48,  2.50s/it]T Loss=2.3050296306610107\n",
            "g_norm = tensor(0.0978, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055615425109863\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049204349517822\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051328659057617\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305341958999634\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =234.0565643310547\n",
            "||∇_X meta|| = 0.0020430658478289843\n",
            "ΔX norm: 2.043064705503639e-05\n",
            "Stage 10/10:  22%|██████▍                      | 66/300 [02:40<09:41,  2.49s/it]T Loss=2.3040168285369873\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035831451416016\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033323287963867\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046417236328125\n",
            "g_norm = tensor(0.1305, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303912401199341\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7527618408203\n",
            "||∇_X meta|| = 0.0021022155415266752\n",
            "ΔX norm: 2.1022149667260237e-05\n",
            "Stage 10/10:  22%|██████▍                      | 67/300 [02:42<09:26,  2.43s/it]T Loss=2.3010754585266113\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039467334747314\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302854061126709\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303323268890381\n",
            "g_norm = tensor(0.1303, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017497062683105\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.72203063964844\n",
            "||∇_X meta|| = 0.002300543710589409\n",
            "ΔX norm: 2.3005461116554216e-05\n",
            "Stage 10/10:  23%|██████▌                      | 68/300 [02:45<09:09,  2.37s/it]T Loss=2.303300380706787\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018364906311035\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028769493103027\n",
            "g_norm = tensor(0.1420, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026599884033203\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037378787994385\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.42298889160156\n",
            "||∇_X meta|| = 0.0021968900691717863\n",
            "ΔX norm: 2.1968917280901223e-05\n",
            "Stage 10/10:  23%|██████▋                      | 69/300 [02:47<08:56,  2.32s/it]T Loss=2.304978847503662\n",
            "g_norm = tensor(0.0941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050384521484375\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055760860443115\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040366172790527\n",
            "g_norm = tensor(0.0969, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044378757476807\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.77745056152344\n",
            "||∇_X meta|| = 0.0020602697040885687\n",
            "ΔX norm: 2.0602692529791966e-05\n",
            "Stage 10/10:  23%|██████▊                      | 70/300 [02:49<09:04,  2.37s/it]T Loss=2.3035335540771484\n",
            "g_norm = tensor(0.1235, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304962635040283\n",
            "g_norm = tensor(0.1249, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053653240203857\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037776947021484\n",
            "g_norm = tensor(0.1217, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304889440536499\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9706268310547\n",
            "||∇_X meta|| = 0.0023387896362692118\n",
            "ΔX norm: 2.338791273359675e-05\n",
            "Stage 10/10:  24%|██████▊                      | 71/300 [02:52<09:14,  2.42s/it]T Loss=2.3046557903289795\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053066730499268\n",
            "g_norm = tensor(0.1329, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044276237487793\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048958778381348\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047497272491455\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.36004638671875\n",
            "||∇_X meta|| = 0.002082438673824072\n",
            "ΔX norm: 2.0824390958296135e-05\n",
            "Stage 10/10:  24%|██████▉                      | 72/300 [02:54<09:13,  2.43s/it]T Loss=2.303955078125\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304779291152954\n",
            "g_norm = tensor(0.1021, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037946224212646\n",
            "g_norm = tensor(0.0849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042595386505127\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048553466796875\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.1759033203125\n",
            "||∇_X meta|| = 0.002528754761442542\n",
            "ΔX norm: 2.5287528842454776e-05\n",
            "Stage 10/10:  24%|███████                      | 73/300 [02:57<09:06,  2.41s/it]T Loss=2.3028881549835205\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303755283355713\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040530681610107\n",
            "g_norm = tensor(0.1149, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029284477233887\n",
            "g_norm = tensor(0.1371, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038830757141113\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.81787109375\n",
            "||∇_X meta|| = 0.002079162048175931\n",
            "ΔX norm: 2.0791621864191256e-05\n",
            "Stage 10/10:  25%|███████▏                     | 74/300 [02:59<08:53,  2.36s/it]T Loss=2.3018100261688232\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302687406539917\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302739381790161\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301887273788452\n",
            "g_norm = tensor(0.1080, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302428960800171\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.75848388671875\n",
            "||∇_X meta|| = 0.0020512468181550503\n",
            "ΔX norm: 2.0512452465482056e-05\n",
            "Stage 10/10:  25%|███████▎                     | 75/300 [03:01<08:41,  2.32s/it]T Loss=2.304562568664551\n",
            "g_norm = tensor(0.1068, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3060975074768066\n",
            "g_norm = tensor(0.1255, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046751022338867\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053200244903564\n",
            "g_norm = tensor(0.1288, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049252033233643\n",
            "g_norm = tensor(0.1447, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.1461944580078\n",
            "||∇_X meta|| = 0.0023054168559610844\n",
            "ΔX norm: 2.3054159100865945e-05\n",
            "Stage 10/10:  25%|███████▎                     | 76/300 [03:04<08:52,  2.38s/it]T Loss=2.3029747009277344\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039467334747314\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30403470993042\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034744262695312\n",
            "g_norm = tensor(0.1000, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303349018096924\n",
            "g_norm = tensor(0.0819, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.77589416503906\n",
            "||∇_X meta|| = 0.002078055404126644\n",
            "ΔX norm: 2.0780571503564715e-05\n",
            "Stage 10/10:  26%|███████▍                     | 77/300 [03:06<08:38,  2.32s/it]T Loss=2.3033268451690674\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30462908744812\n",
            "g_norm = tensor(0.0827, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303895950317383\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303971290588379\n",
            "g_norm = tensor(0.0902, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302319049835205\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.88919067382812\n",
            "||∇_X meta|| = 0.002056938363239169\n",
            "ΔX norm: 2.0569425032590516e-05\n",
            "Stage 10/10:  26%|███████▌                     | 78/300 [03:08<08:31,  2.31s/it]T Loss=2.302105188369751\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032584190368652\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021798133850098\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303539991378784\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304419755935669\n",
            "g_norm = tensor(0.0903, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.67445373535156\n",
            "||∇_X meta|| = 0.002309134928509593\n",
            "ΔX norm: 2.3091381081030704e-05\n",
            "Stage 10/10:  26%|███████▋                     | 79/300 [03:10<08:28,  2.30s/it]T Loss=2.3021435737609863\n",
            "g_norm = tensor(0.1597, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302900791168213\n",
            "g_norm = tensor(0.1480, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3012096881866455\n",
            "g_norm = tensor(0.1435, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042984008789062\n",
            "g_norm = tensor(0.1516, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.300830364227295\n",
            "g_norm = tensor(0.1784, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.763916015625\n",
            "||∇_X meta|| = 0.002138109877705574\n",
            "ΔX norm: 2.1381107217166573e-05\n",
            "Stage 10/10:  27%|███████▋                     | 80/300 [03:14<09:54,  2.70s/it]T Loss=2.3042969703674316\n",
            "g_norm = tensor(0.1378, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301985502243042\n",
            "g_norm = tensor(0.1171, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026721477508545\n",
            "g_norm = tensor(0.1561, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303117275238037\n",
            "g_norm = tensor(0.1504, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303220510482788\n",
            "g_norm = tensor(0.1487, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.82257080078125\n",
            "||∇_X meta|| = 0.002097475342452526\n",
            "ΔX norm: 2.0974759536329657e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 10/10:  27%|███████▊                     | 81/300 [03:17<09:57,  2.73s/it]T Loss=2.3027701377868652\n",
            "g_norm = tensor(0.1155, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036017417907715\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303715467453003\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037607669830322\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024888038635254\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.57594299316406\n",
            "||∇_X meta|| = 0.001974207116290927\n",
            "ΔX norm: 1.9742074073292315e-05\n",
            "Stage 10/10:  27%|███████▉                     | 82/300 [03:20<10:23,  2.86s/it]T Loss=2.3055641651153564\n",
            "g_norm = tensor(0.1546, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032467365264893\n",
            "g_norm = tensor(0.1488, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025496006011963\n",
            "g_norm = tensor(0.1366, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018791675567627\n",
            "g_norm = tensor(0.1291, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303581476211548\n",
            "g_norm = tensor(0.1332, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.60316467285156\n",
            "||∇_X meta|| = 0.0023495457135140896\n",
            "ΔX norm: 2.349545684410259e-05\n",
            "Stage 10/10:  28%|████████                     | 83/300 [03:22<09:55,  2.74s/it]T Loss=2.3050918579101562\n",
            "g_norm = tensor(0.1192, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303858995437622\n",
            "g_norm = tensor(0.1404, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037025928497314\n",
            "g_norm = tensor(0.1268, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036551475524902\n",
            "g_norm = tensor(0.1363, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305042028427124\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.278564453125\n",
            "||∇_X meta|| = 0.001858766539953649\n",
            "ΔX norm: 1.8587665181257762e-05\n",
            "Stage 10/10:  28%|████████                     | 84/300 [03:25<09:44,  2.71s/it]T Loss=2.3036489486694336\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028056621551514\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036022186279297\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304503917694092\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303284168243408\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.48240661621094\n",
            "||∇_X meta|| = 0.0020218631252646446\n",
            "ΔX norm: 2.0218622012180276e-05\n",
            "Stage 10/10:  28%|████████▏                    | 85/300 [03:27<09:09,  2.56s/it]T Loss=2.303565502166748\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304257869720459\n",
            "g_norm = tensor(0.0861, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023791313171387\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303605794906616\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303853988647461\n",
            "g_norm = tensor(0.0795, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.38931274414062\n",
            "||∇_X meta|| = 0.002033377531915903\n",
            "ΔX norm: 2.033378041232936e-05\n",
            "Stage 10/10:  29%|████████▎                    | 86/300 [03:29<08:42,  2.44s/it]T Loss=2.303684711456299\n",
            "g_norm = tensor(0.0835, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040521144866943\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042759895324707\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039627075195312\n",
            "g_norm = tensor(0.0947, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032219409942627\n",
            "g_norm = tensor(0.1080, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.36154174804688\n",
            "||∇_X meta|| = 0.002009948715567589\n",
            "ΔX norm: 2.009950731007848e-05\n",
            "Stage 10/10:  29%|████████▍                    | 87/300 [03:32<08:51,  2.50s/it]T Loss=2.302445650100708\n",
            "g_norm = tensor(0.1340, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302849292755127\n",
            "g_norm = tensor(0.1703, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017969131469727\n",
            "g_norm = tensor(0.1497, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049964904785156\n",
            "g_norm = tensor(0.1316, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018569946289062\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.15267944335938\n",
            "||∇_X meta|| = 0.001974948216229677\n",
            "ΔX norm: 1.9749491912079975e-05\n",
            "Stage 10/10:  29%|████████▌                    | 88/300 [03:34<08:34,  2.42s/it]T Loss=2.303703784942627\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303342819213867\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30332612991333\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304267644882202\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302985429763794\n",
            "g_norm = tensor(0.1262, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.34170532226562\n",
            "||∇_X meta|| = 0.0020041002426296473\n",
            "ΔX norm: 2.004100679187104e-05\n",
            "Stage 10/10:  30%|████████▌                    | 89/300 [03:37<08:17,  2.36s/it]T Loss=2.3029284477233887\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035941123962402\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302407741546631\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043053150177\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023521900177\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.85107421875\n",
            "||∇_X meta|| = 0.00202953745611012\n",
            "ΔX norm: 2.0295376089052297e-05\n",
            "Stage 10/10:  30%|████████▋                    | 90/300 [03:39<07:58,  2.28s/it]T Loss=2.3048088550567627\n",
            "g_norm = tensor(0.1426, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037893772125244\n",
            "g_norm = tensor(0.1264, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034653663635254\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036303520202637\n",
            "g_norm = tensor(0.0994, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030271530151367\n",
            "g_norm = tensor(0.1262, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.66607666015625\n",
            "||∇_X meta|| = 0.0019880919717252254\n",
            "ΔX norm: 1.9880944819306023e-05\n",
            "Stage 10/10:  30%|████████▊                    | 91/300 [03:41<07:54,  2.27s/it]T Loss=2.306143283843994\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305026054382324\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048253059387207\n",
            "g_norm = tensor(0.1246, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024470806121826\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304912805557251\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.11134338378906\n",
            "||∇_X meta|| = 0.0021243307273834944\n",
            "ΔX norm: 2.1243313312879764e-05\n",
            "Stage 10/10:  31%|████████▉                    | 92/300 [03:43<07:47,  2.25s/it]T Loss=2.304994583129883\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303966522216797\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304307460784912\n",
            "g_norm = tensor(0.0904, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036863803863525\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303074359893799\n",
            "g_norm = tensor(0.0805, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.58018493652344\n",
            "||∇_X meta|| = 0.0018538185395300388\n",
            "ΔX norm: 1.853817047958728e-05\n",
            "Stage 10/10:  31%|████████▉                    | 93/300 [03:45<07:35,  2.20s/it]T Loss=2.304497241973877\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304816722869873\n",
            "g_norm = tensor(0.1347, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303504467010498\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039441108703613\n",
            "g_norm = tensor(0.1274, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040690422058105\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.29092407226562\n",
            "||∇_X meta|| = 0.0019483097130432725\n",
            "ΔX norm: 1.9483080905047245e-05\n",
            "Stage 10/10:  31%|█████████                    | 94/300 [03:48<07:44,  2.26s/it]T Loss=2.3030521869659424\n",
            "g_norm = tensor(0.1408, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303496837615967\n",
            "g_norm = tensor(0.1485, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038363456726074\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302375316619873\n",
            "g_norm = tensor(0.1371, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305083751678467\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.55630493164062\n",
            "||∇_X meta|| = 0.0020904771517962217\n",
            "ΔX norm: 2.0904761186102405e-05\n",
            "Stage 10/10:  32%|█████████▏                   | 95/300 [03:50<07:44,  2.27s/it]T Loss=2.305168867111206\n",
            "g_norm = tensor(0.1577, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040008544921875\n",
            "g_norm = tensor(0.1566, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306029796600342\n",
            "g_norm = tensor(0.1517, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040881156921387\n",
            "g_norm = tensor(0.1485, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303546905517578\n",
            "g_norm = tensor(0.1416, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.438720703125\n",
            "||∇_X meta|| = 0.002164148725569248\n",
            "ΔX norm: 2.1641495550284162e-05\n",
            "Stage 10/10:  32%|█████████▎                   | 96/300 [03:52<07:54,  2.32s/it]T Loss=2.304361343383789\n",
            "g_norm = tensor(0.1003, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305007219314575\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029239177703857\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026692867279053\n",
            "g_norm = tensor(0.0995, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031044006347656\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.0049285888672\n",
            "||∇_X meta|| = 0.0018728345166891813\n",
            "ΔX norm: 1.8728318536886945e-05\n",
            "Stage 10/10:  32%|█████████▍                   | 97/300 [03:54<07:43,  2.28s/it]T Loss=2.3056421279907227\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044211864471436\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302708148956299\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302847385406494\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030402660369873\n",
            "g_norm = tensor(0.1584, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.38011169433594\n",
            "||∇_X meta|| = 0.0018971951212733984\n",
            "ΔX norm: 1.897195579658728e-05\n",
            "Stage 10/10:  33%|█████████▍                   | 98/300 [03:57<07:28,  2.22s/it]T Loss=2.303474187850952\n",
            "g_norm = tensor(0.1342, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027279376983643\n",
            "g_norm = tensor(0.1263, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045220375061035\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025975227355957\n",
            "g_norm = tensor(0.1344, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036725521087646\n",
            "g_norm = tensor(0.1187, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.4093780517578\n",
            "||∇_X meta|| = 0.0017559588886797428\n",
            "ΔX norm: 1.755958146532066e-05\n",
            "Stage 10/10:  33%|█████████▌                   | 99/300 [03:59<07:41,  2.30s/it]T Loss=2.303804636001587\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030436038970947\n",
            "g_norm = tensor(0.0964, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304044008255005\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038153648376465\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035495281219482\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.23849487304688\n",
            "||∇_X meta|| = 0.001726685673929751\n",
            "ΔX norm: 1.7266862414544448e-05\n",
            "Stage 10/10:  33%|█████████▎                  | 100/300 [04:01<07:42,  2.31s/it]T Loss=2.3047256469726562\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047022819519043\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046302795410156\n",
            "g_norm = tensor(0.0844, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046910762786865\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046162128448486\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8252716064453\n",
            "||∇_X meta|| = 0.0019856158178299665\n",
            "ΔX norm: 1.985614471777808e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 10/10:  34%|█████████▍                  | 101/300 [04:04<07:32,  2.27s/it]T Loss=2.3036515712738037\n",
            "g_norm = tensor(0.0864, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031601905822754\n",
            "g_norm = tensor(0.0811, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029558658599854\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303115129470825\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029186725616455\n",
            "g_norm = tensor(0.0839, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.41525268554688\n",
            "||∇_X meta|| = 0.0018216217868030071\n",
            "ΔX norm: 1.8216231183032505e-05\n",
            "Stage 10/10:  34%|█████████▌                  | 102/300 [04:06<07:54,  2.40s/it]T Loss=2.3034465312957764\n",
            "g_norm = tensor(0.1245, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031632900238037\n",
            "g_norm = tensor(0.1482, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040554523468018\n",
            "g_norm = tensor(0.1067, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044357299804688\n",
            "g_norm = tensor(0.1434, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029327392578125\n",
            "g_norm = tensor(0.1292, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.41297912597656\n",
            "||∇_X meta|| = 0.001688060350716114\n",
            "ΔX norm: 1.6880594557733275e-05\n",
            "Stage 10/10:  34%|█████████▌                  | 103/300 [04:09<07:47,  2.37s/it]T Loss=2.3034074306488037\n",
            "g_norm = tensor(0.0996, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040201663970947\n",
            "g_norm = tensor(0.1397, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049798011779785\n",
            "g_norm = tensor(0.1353, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039214611053467\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30366849899292\n",
            "g_norm = tensor(0.1391, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7526397705078\n",
            "||∇_X meta|| = 0.00173298513982445\n",
            "ΔX norm: 1.7329846741631627e-05\n",
            "Stage 10/10:  35%|█████████▋                  | 104/300 [04:11<07:39,  2.35s/it]T Loss=2.305398941040039\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033926486968994\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037657737731934\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305290699005127\n",
            "g_norm = tensor(0.1301, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049476146698\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.74078369140625\n",
            "||∇_X meta|| = 0.0017421749653294683\n",
            "ΔX norm: 1.7421749362256378e-05\n",
            "Stage 10/10:  35%|█████████▊                  | 105/300 [04:13<07:25,  2.29s/it]T Loss=2.305420398712158\n",
            "g_norm = tensor(0.1223, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035736083984375\n",
            "g_norm = tensor(0.1143, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052408695220947\n",
            "g_norm = tensor(0.1114, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041775226593018\n",
            "g_norm = tensor(0.1163, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303823232650757\n",
            "g_norm = tensor(0.1120, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.2061767578125\n",
            "||∇_X meta|| = 0.0018979031592607498\n",
            "ΔX norm: 1.897901893244125e-05\n",
            "Stage 10/10:  35%|█████████▉                  | 106/300 [04:15<07:32,  2.33s/it]T Loss=2.3052978515625\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304555892944336\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304647922515869\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304513454437256\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036227226257324\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.68565368652344\n",
            "||∇_X meta|| = 0.001745288260281086\n",
            "ΔX norm: 1.745289409882389e-05\n",
            "Stage 10/10:  36%|█████████▉                  | 107/300 [04:18<07:30,  2.33s/it]T Loss=2.303452968597412\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047242164611816\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302993059158325\n",
            "g_norm = tensor(0.1021, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303600788116455\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028647899627686\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.330078125\n",
            "||∇_X meta|| = 0.0016531498404219747\n",
            "ΔX norm: 1.6531488654436544e-05\n",
            "Stage 10/10:  36%|██████████                  | 108/300 [04:21<07:55,  2.48s/it]T Loss=2.3027076721191406\n",
            "g_norm = tensor(0.1582, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034913539886475\n",
            "g_norm = tensor(0.2248, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040740489959717\n",
            "g_norm = tensor(0.1802, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034231662750244\n",
            "g_norm = tensor(0.1386, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032941818237305\n",
            "g_norm = tensor(0.1741, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.21969604492188\n",
            "||∇_X meta|| = 0.0017655519768595695\n",
            "ΔX norm: 1.765550950949546e-05\n",
            "Stage 10/10:  36%|██████████▏                 | 109/300 [04:23<08:00,  2.52s/it]T Loss=2.303367853164673\n",
            "g_norm = tensor(0.1566, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041703701019287\n",
            "g_norm = tensor(0.1236, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303802490234375\n",
            "g_norm = tensor(0.1371, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043367862701416\n",
            "g_norm = tensor(0.1405, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304189682006836\n",
            "g_norm = tensor(0.1334, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.10116577148438\n",
            "||∇_X meta|| = 0.001879302435554564\n",
            "ΔX norm: 1.8793036360875703e-05\n",
            "Stage 10/10:  37%|██████████▎                 | 110/300 [04:25<07:43,  2.44s/it]T Loss=2.304090976715088\n",
            "g_norm = tensor(0.0926, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045401573181152\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304899215698242\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055412769317627\n",
            "g_norm = tensor(0.1103, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303800106048584\n",
            "g_norm = tensor(0.0864, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.91957092285156\n",
            "||∇_X meta|| = 0.001740379724651575\n",
            "ΔX norm: 1.7403788660885766e-05\n",
            "Stage 10/10:  37%|██████████▎                 | 111/300 [04:28<07:45,  2.46s/it]T Loss=2.302096128463745\n",
            "g_norm = tensor(0.1276, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030285835266113\n",
            "g_norm = tensor(0.1599, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30391263961792\n",
            "g_norm = tensor(0.1385, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024768829345703\n",
            "g_norm = tensor(0.1602, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034768104553223\n",
            "g_norm = tensor(0.1369, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.64541625976562\n",
            "||∇_X meta|| = 0.001700390363112092\n",
            "ΔX norm: 1.7003891116473824e-05\n",
            "Stage 10/10:  37%|██████████▍                 | 112/300 [04:30<07:29,  2.39s/it]T Loss=2.3032400608062744\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049514293670654\n",
            "g_norm = tensor(0.1108, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031578063964844\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303884744644165\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055262565612793\n",
            "g_norm = tensor(0.1257, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.96824645996094\n",
            "||∇_X meta|| = 0.0019335709512233734\n",
            "ΔX norm: 1.9335702745593153e-05\n",
            "Stage 10/10:  38%|██████████▌                 | 113/300 [04:32<07:17,  2.34s/it]T Loss=2.304595947265625\n",
            "g_norm = tensor(0.0757, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041939735412598\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041021823883057\n",
            "g_norm = tensor(0.0763, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052611351013184\n",
            "g_norm = tensor(0.0908, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046960830688477\n",
            "g_norm = tensor(0.0814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2910919189453\n",
            "||∇_X meta|| = 0.0017831888981163502\n",
            "ΔX norm: 1.7831909644883126e-05\n",
            "Stage 10/10:  38%|██████████▋                 | 114/300 [04:35<07:13,  2.33s/it]T Loss=2.3045248985290527\n",
            "g_norm = tensor(0.1320, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043813705444336\n",
            "g_norm = tensor(0.1240, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304486036300659\n",
            "g_norm = tensor(0.1419, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035385608673096\n",
            "g_norm = tensor(0.1429, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303678035736084\n",
            "g_norm = tensor(0.1225, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.80116271972656\n",
            "||∇_X meta|| = 0.0015869280323386192\n",
            "ΔX norm: 1.5869291019043885e-05\n",
            "Stage 10/10:  38%|██████████▋                 | 115/300 [04:38<07:57,  2.58s/it]T Loss=2.303635835647583\n",
            "g_norm = tensor(0.0914, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026986122131348\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303179979324341\n",
            "g_norm = tensor(0.0733, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021183013916016\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301708459854126\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.34344482421875\n",
            "||∇_X meta|| = 0.001865218160673976\n",
            "ΔX norm: 1.8652179278433323e-05\n",
            "Stage 10/10:  39%|██████████▊                 | 116/300 [04:41<07:56,  2.59s/it]T Loss=2.303305149078369\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303490161895752\n",
            "g_norm = tensor(0.1020, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030800819396973\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302722692489624\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302851915359497\n",
            "g_norm = tensor(0.1097, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.11428833007812\n",
            "||∇_X meta|| = 0.0018739089136943221\n",
            "ΔX norm: 1.873909423011355e-05\n",
            "Stage 10/10:  39%|██████████▉                 | 117/300 [04:43<07:49,  2.57s/it]T Loss=2.304044008255005\n",
            "g_norm = tensor(0.0871, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036673069000244\n",
            "g_norm = tensor(0.0811, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304271936416626\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304084300994873\n",
            "g_norm = tensor(0.0907, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045973777770996\n",
            "g_norm = tensor(0.0796, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.62550354003906\n",
            "||∇_X meta|| = 0.002007901668548584\n",
            "ΔX norm: 2.007897819567006e-05\n",
            "Stage 10/10:  39%|███████████                 | 118/300 [04:46<07:43,  2.55s/it]T Loss=2.3031044006347656\n",
            "g_norm = tensor(0.0868, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303988218307495\n",
            "g_norm = tensor(0.0692, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035738468170166\n",
            "g_norm = tensor(0.0741, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303866147994995\n",
            "g_norm = tensor(0.0714, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028929233551025\n",
            "g_norm = tensor(0.0796, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.48779296875\n",
            "||∇_X meta|| = 0.0016921772621572018\n",
            "ΔX norm: 1.692178557277657e-05\n",
            "Stage 10/10:  40%|███████████                 | 119/300 [04:48<07:30,  2.49s/it]T Loss=2.3040003776550293\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303558588027954\n",
            "g_norm = tensor(0.0897, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304314136505127\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034112453460693\n",
            "g_norm = tensor(0.0883, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034138679504395\n",
            "g_norm = tensor(0.1071, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.61866760253906\n",
            "||∇_X meta|| = 0.0016484683146700263\n",
            "ΔX norm: 1.6484687876072712e-05\n",
            "Stage 10/10:  40%|███████████▏                | 120/300 [04:50<07:10,  2.39s/it]T Loss=2.3040988445281982\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029096126556396\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040413856506348\n",
            "g_norm = tensor(0.1188, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034698963165283\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304198980331421\n",
            "g_norm = tensor(0.1263, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.38812255859375\n",
            "||∇_X meta|| = 0.001905865385197103\n",
            "ΔX norm: 1.9058648831560276e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 10/10:  40%|███████████▎                | 121/300 [04:52<07:08,  2.39s/it]T Loss=2.304943323135376\n",
            "g_norm = tensor(0.1836, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035197257995605\n",
            "g_norm = tensor(0.1533, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303530216217041\n",
            "g_norm = tensor(0.1644, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302046060562134\n",
            "g_norm = tensor(0.1743, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301316738128662\n",
            "g_norm = tensor(0.1573, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.63970947265625\n",
            "||∇_X meta|| = 0.001737854559905827\n",
            "ΔX norm: 1.7378522898070514e-05\n",
            "Stage 10/10:  41%|███████████▍                | 122/300 [04:55<07:10,  2.42s/it]T Loss=2.3042337894439697\n",
            "g_norm = tensor(0.0977, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303607225418091\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304706335067749\n",
            "g_norm = tensor(0.1305, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035383224487305\n",
            "g_norm = tensor(0.1196, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303485870361328\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.3971710205078\n",
            "||∇_X meta|| = 0.0017293001292273402\n",
            "ΔX norm: 1.7293001292273402e-05\n",
            "Stage 10/10:  41%|███████████▍                | 123/300 [04:57<07:13,  2.45s/it]T Loss=2.302834987640381\n",
            "g_norm = tensor(0.1410, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051209449768066\n",
            "g_norm = tensor(0.1534, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045549392700195\n",
            "g_norm = tensor(0.1499, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305318593978882\n",
            "g_norm = tensor(0.1584, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304258346557617\n",
            "g_norm = tensor(0.1497, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.89462280273438\n",
            "||∇_X meta|| = 0.001628197031095624\n",
            "ΔX norm: 1.6281956050079316e-05\n",
            "Stage 10/10:  41%|███████████▌                | 124/300 [05:00<07:03,  2.41s/it]T Loss=2.302051544189453\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044650554656982\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303253412246704\n",
            "g_norm = tensor(0.1300, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053152561187744\n",
            "g_norm = tensor(0.1282, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304609537124634\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.59542846679688\n",
            "||∇_X meta|| = 0.0016458927420899272\n",
            "ΔX norm: 1.6458921891171485e-05\n",
            "Stage 10/10:  42%|███████████▋                | 125/300 [05:02<06:55,  2.38s/it]T Loss=2.304720163345337\n",
            "g_norm = tensor(0.0759, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032801151275635\n",
            "g_norm = tensor(0.0831, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303804874420166\n",
            "g_norm = tensor(0.0867, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027780055999756\n",
            "g_norm = tensor(0.0834, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304588556289673\n",
            "g_norm = tensor(0.0784, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.26324462890625\n",
            "||∇_X meta|| = 0.0018203363288193941\n",
            "ΔX norm: 1.8203354557044804e-05\n",
            "Stage 10/10:  42%|███████████▊                | 126/300 [05:04<06:44,  2.32s/it]T Loss=2.3047330379486084\n",
            "g_norm = tensor(0.1276, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036997318267822\n",
            "g_norm = tensor(0.1187, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054251670837402\n",
            "g_norm = tensor(0.1197, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30304217338562\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025474548339844\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.87303161621094\n",
            "||∇_X meta|| = 0.0020147827453911304\n",
            "ΔX norm: 2.0147803297732025e-05\n",
            "Stage 10/10:  42%|███████████▊                | 127/300 [05:06<06:38,  2.30s/it]T Loss=2.303645610809326\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038368225097656\n",
            "g_norm = tensor(0.1434, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303947925567627\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045766353607178\n",
            "g_norm = tensor(0.1461, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303637742996216\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.93814086914062\n",
            "||∇_X meta|| = 0.0017016093479469419\n",
            "ΔX norm: 1.7016089259414002e-05\n",
            "Stage 10/10:  43%|███████████▉                | 128/300 [05:09<06:32,  2.28s/it]T Loss=2.3045654296875\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044915199279785\n",
            "g_norm = tensor(0.1207, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041749000549316\n",
            "g_norm = tensor(0.1307, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034722805023193\n",
            "g_norm = tensor(0.1194, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033740520477295\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0281219482422\n",
            "||∇_X meta|| = 0.0015256511978805065\n",
            "ΔX norm: 1.5256522601703182e-05\n",
            "Stage 10/10:  43%|████████████                | 129/300 [05:11<06:34,  2.31s/it]T Loss=2.303982734680176\n",
            "g_norm = tensor(0.1312, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304291009902954\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042092323303223\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304736852645874\n",
            "g_norm = tensor(0.1296, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305144786834717\n",
            "g_norm = tensor(0.1286, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1413116455078\n",
            "||∇_X meta|| = 0.0016153504839166999\n",
            "ΔX norm: 1.6153493561432697e-05\n",
            "Stage 10/10:  43%|████████████▏               | 130/300 [05:13<06:26,  2.28s/it]T Loss=2.304058313369751\n",
            "g_norm = tensor(0.1381, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056528568267822\n",
            "g_norm = tensor(0.1326, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022353649139404\n",
            "g_norm = tensor(0.1347, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045010566711426\n",
            "g_norm = tensor(0.1268, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30305814743042\n",
            "g_norm = tensor(0.1367, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6609344482422\n",
            "||∇_X meta|| = 0.001712546800263226\n",
            "ΔX norm: 1.7125466911238618e-05\n",
            "Stage 10/10:  44%|████████████▏               | 131/300 [05:15<06:21,  2.26s/it]T Loss=2.303861618041992\n",
            "g_norm = tensor(0.0803, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305722236633301\n",
            "g_norm = tensor(0.0880, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304518938064575\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306273937225342\n",
            "g_norm = tensor(0.0806, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052661418914795\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2579803466797\n",
            "||∇_X meta|| = 0.0019015520811080933\n",
            "ΔX norm: 1.901553332572803e-05\n",
            "Stage 10/10:  44%|████████████▎               | 132/300 [05:18<06:20,  2.27s/it]T Loss=2.3046627044677734\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056628704071045\n",
            "g_norm = tensor(0.1351, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050904273986816\n",
            "g_norm = tensor(0.1163, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057093620300293\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049044609069824\n",
            "g_norm = tensor(0.1381, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.23899841308594\n",
            "||∇_X meta|| = 0.0017057321965694427\n",
            "ΔX norm: 1.705732756818179e-05\n",
            "Stage 10/10:  44%|████████████▍               | 133/300 [05:20<06:25,  2.31s/it]T Loss=2.303415060043335\n",
            "g_norm = tensor(0.0833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302828073501587\n",
            "g_norm = tensor(0.0934, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302992343902588\n",
            "g_norm = tensor(0.0754, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035502433776855\n",
            "g_norm = tensor(0.0761, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031675815582275\n",
            "g_norm = tensor(0.0826, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.21377563476562\n",
            "||∇_X meta|| = 0.0018618142930790782\n",
            "ΔX norm: 1.8618107787915505e-05\n",
            "Stage 10/10:  45%|████████████▌               | 134/300 [05:23<06:24,  2.32s/it]T Loss=2.3024837970733643\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302626371383667\n",
            "g_norm = tensor(0.0829, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304274320602417\n",
            "g_norm = tensor(0.0755, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036367893218994\n",
            "g_norm = tensor(0.0911, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304184675216675\n",
            "g_norm = tensor(0.0794, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.69833374023438\n",
            "||∇_X meta|| = 0.0015837084501981735\n",
            "ΔX norm: 1.5837096725590527e-05\n",
            "Stage 10/10:  45%|████████████▌               | 135/300 [05:25<06:41,  2.43s/it]T Loss=2.304502010345459\n",
            "g_norm = tensor(0.1166, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30397629737854\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033595085144043\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039042949676514\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036420345306396\n",
            "g_norm = tensor(0.1446, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.61085510253906\n",
            "||∇_X meta|| = 0.0015477038687095046\n",
            "ΔX norm: 1.5477027773158625e-05\n",
            "Stage 10/10:  45%|████████████▋               | 136/300 [05:27<06:29,  2.37s/it]T Loss=2.304297924041748\n",
            "g_norm = tensor(0.1268, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031973838806152\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044159412384033\n",
            "g_norm = tensor(0.0958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304112195968628\n",
            "g_norm = tensor(0.1451, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030717372894287\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.61590576171875\n",
            "||∇_X meta|| = 0.001760912942700088\n",
            "ΔX norm: 1.7609121641726233e-05\n",
            "Stage 10/10:  46%|████████████▊               | 137/300 [05:30<06:27,  2.38s/it]T Loss=2.302762508392334\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037147521972656\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031067848205566\n",
            "g_norm = tensor(0.0844, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035175800323486\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027071952819824\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.01950073242188\n",
            "||∇_X meta|| = 0.0016821929020807147\n",
            "ΔX norm: 1.6821930330479518e-05\n",
            "Stage 10/10:  46%|████████████▉               | 138/300 [05:32<06:37,  2.46s/it]T Loss=2.3026602268218994\n",
            "g_norm = tensor(0.1089, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302572250366211\n",
            "g_norm = tensor(0.1081, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032736778259277\n",
            "g_norm = tensor(0.1051, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028359413146973\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030362129211426\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.06353759765625\n",
            "||∇_X meta|| = 0.001602279837243259\n",
            "ΔX norm: 1.6022793715819716e-05\n",
            "Stage 10/10:  46%|████████████▉               | 139/300 [05:35<06:33,  2.44s/it]T Loss=2.3025472164154053\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039512634277344\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303165912628174\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302675485610962\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045296669006348\n",
            "g_norm = tensor(0.1139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.28262329101562\n",
            "||∇_X meta|| = 0.0015911824302747846\n",
            "ΔX norm: 1.591182081028819e-05\n",
            "Stage 10/10:  47%|█████████████               | 140/300 [05:37<06:15,  2.35s/it]T Loss=2.303997039794922\n",
            "g_norm = tensor(0.0997, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025691509246826\n",
            "g_norm = tensor(0.1102, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031249046325684\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039042949676514\n",
            "g_norm = tensor(0.0936, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303086757659912\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5034637451172\n",
            "||∇_X meta|| = 0.0016750079812482\n",
            "ΔX norm: 1.6750085706007667e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 10/10:  47%|█████████████▏              | 141/300 [05:40<06:32,  2.47s/it]T Loss=2.305037260055542\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306375026702881\n",
            "g_norm = tensor(0.1376, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051209449768066\n",
            "g_norm = tensor(0.1418, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305326223373413\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.308178663253784\n",
            "g_norm = tensor(0.1432, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.38665771484375\n",
            "||∇_X meta|| = 0.0016884548822417855\n",
            "ΔX norm: 1.6884514479897916e-05\n",
            "Stage 10/10:  47%|█████████████▎              | 142/300 [05:42<06:26,  2.45s/it]T Loss=2.3026626110076904\n",
            "g_norm = tensor(0.0800, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037006855010986\n",
            "g_norm = tensor(0.0771, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038928508758545\n",
            "g_norm = tensor(0.0827, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304462432861328\n",
            "g_norm = tensor(0.1032, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041112422943115\n",
            "g_norm = tensor(0.0771, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.77053833007812\n",
            "||∇_X meta|| = 0.001733846147544682\n",
            "ΔX norm: 1.7338477846351452e-05\n",
            "Stage 10/10:  48%|█████████████▎              | 143/300 [05:44<06:15,  2.39s/it]T Loss=2.3022077083587646\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042759895324707\n",
            "g_norm = tensor(0.1050, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304487943649292\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302396535873413\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032357692718506\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.36622619628906\n",
            "||∇_X meta|| = 0.0016001809854060411\n",
            "ΔX norm: 1.6001831681933254e-05\n",
            "Stage 10/10:  48%|█████████████▍              | 144/300 [05:47<06:05,  2.34s/it]T Loss=2.305154323577881\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30513072013855\n",
            "g_norm = tensor(0.1147, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045268058776855\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036675453186035\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30612850189209\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.83590698242188\n",
            "||∇_X meta|| = 0.0016666952287778258\n",
            "ΔX norm: 1.6666954252286814e-05\n",
            "Stage 10/10:  48%|█████████████▌              | 145/300 [05:49<05:57,  2.31s/it]T Loss=2.3038229942321777\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303534984588623\n",
            "g_norm = tensor(0.1052, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028829097747803\n",
            "g_norm = tensor(0.1150, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032474517822266\n",
            "g_norm = tensor(0.1169, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027451038360596\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.0387725830078\n",
            "||∇_X meta|| = 0.0016706620808690786\n",
            "ΔX norm: 1.670663186814636e-05\n",
            "Stage 10/10:  49%|█████████████▋              | 146/300 [05:51<06:01,  2.35s/it]T Loss=2.304466962814331\n",
            "g_norm = tensor(0.1025, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038954734802246\n",
            "g_norm = tensor(0.0873, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303865671157837\n",
            "g_norm = tensor(0.1011, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039629459381104\n",
            "g_norm = tensor(0.1225, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303114414215088\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.17237854003906\n",
            "||∇_X meta|| = 0.0016526873223483562\n",
            "ΔX norm: 1.6526892068213783e-05\n",
            "Stage 10/10:  49%|█████████████▋              | 147/300 [05:54<05:57,  2.33s/it]T Loss=2.303572177886963\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303555965423584\n",
            "g_norm = tensor(0.1251, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30293607711792\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038413524627686\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038601875305176\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.77816772460938\n",
            "||∇_X meta|| = 0.0017684269696474075\n",
            "ΔX norm: 1.7684264093986712e-05\n",
            "Stage 10/10:  49%|█████████████▊              | 148/300 [05:56<05:47,  2.28s/it]T Loss=2.3037896156311035\n",
            "g_norm = tensor(0.1263, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032023906707764\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042426109313965\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301988363265991\n",
            "g_norm = tensor(0.1409, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031697273254395\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.95960998535156\n",
            "||∇_X meta|| = 0.00174372096080333\n",
            "ΔX norm: 1.743719622027129e-05\n",
            "Stage 10/10:  50%|█████████████▉              | 149/300 [05:58<05:40,  2.25s/it]T Loss=2.304856538772583\n",
            "g_norm = tensor(0.1077, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304408550262451\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304140567779541\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305168628692627\n",
            "g_norm = tensor(0.1040, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042197227478027\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.79493713378906\n",
            "||∇_X meta|| = 0.0018701569642871618\n",
            "ΔX norm: 1.8701572116697207e-05\n",
            "Stage 10/10:  50%|██████████████              | 150/300 [06:00<05:30,  2.20s/it]T Loss=2.304133176803589\n",
            "g_norm = tensor(0.0983, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029818534851074\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029398918151855\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303565263748169\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304720401763916\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.10450744628906\n",
            "||∇_X meta|| = 0.0016532703302800655\n",
            "ΔX norm: 1.653270737733692e-05\n",
            "Stage 10/10:  50%|██████████████              | 151/300 [06:02<05:26,  2.19s/it]T Loss=2.3034939765930176\n",
            "g_norm = tensor(0.0960, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032121658325195\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30342173576355\n",
            "g_norm = tensor(0.1293, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042521476745605\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304152488708496\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.22645568847656\n",
            "||∇_X meta|| = 0.0015073701506480575\n",
            "ΔX norm: 1.5073715985636227e-05\n",
            "Stage 10/10:  51%|██████████████▏             | 152/300 [06:05<06:09,  2.50s/it]T Loss=2.304212808609009\n",
            "g_norm = tensor(0.1425, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034727573394775\n",
            "g_norm = tensor(0.1186, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304957866668701\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041231632232666\n",
            "g_norm = tensor(0.1092, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305053234100342\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.17819213867188\n",
            "||∇_X meta|| = 0.0017203030874952674\n",
            "ΔX norm: 1.72030213434482e-05\n",
            "Stage 10/10:  51%|██████████████▎             | 153/300 [06:08<06:04,  2.48s/it]T Loss=2.3026111125946045\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031158447265625\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039395809173584\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302704334259033\n",
            "g_norm = tensor(0.0857, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302375316619873\n",
            "g_norm = tensor(0.0794, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3632354736328\n",
            "||∇_X meta|| = 0.0015711302403360605\n",
            "ΔX norm: 1.5711320884292945e-05\n",
            "Stage 10/10:  51%|██████████████▎             | 154/300 [06:10<05:58,  2.45s/it]T Loss=2.3028597831726074\n",
            "g_norm = tensor(0.0610, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033807277679443\n",
            "g_norm = tensor(0.0754, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303335189819336\n",
            "g_norm = tensor(0.0814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030707836151123\n",
            "g_norm = tensor(0.0743, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027923107147217\n",
            "g_norm = tensor(0.0876, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.01254272460938\n",
            "||∇_X meta|| = 0.0014885168056935072\n",
            "ΔX norm: 1.488515772507526e-05\n",
            "Stage 10/10:  52%|██████████████▍             | 155/300 [06:12<05:45,  2.38s/it]T Loss=2.3028500080108643\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302520275115967\n",
            "g_norm = tensor(0.1411, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304349899291992\n",
            "g_norm = tensor(0.1349, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305030107498169\n",
            "g_norm = tensor(0.1683, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032941818237305\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.32730102539062\n",
            "||∇_X meta|| = 0.0017715963767841458\n",
            "ΔX norm: 1.7715956346364692e-05\n",
            "Stage 10/10:  52%|██████████████▌             | 156/300 [06:15<05:43,  2.39s/it]T Loss=2.304405927658081\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040239810943604\n",
            "g_norm = tensor(0.1316, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305140733718872\n",
            "g_norm = tensor(0.1514, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035664558410645\n",
            "g_norm = tensor(0.1479, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044824600219727\n",
            "g_norm = tensor(0.1359, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.06903076171875\n",
            "||∇_X meta|| = 0.0016673990758135915\n",
            "ΔX norm: 1.6673997379257344e-05\n",
            "Stage 10/10:  52%|██████████████▋             | 157/300 [06:17<05:37,  2.36s/it]T Loss=2.303781270980835\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041186332702637\n",
            "g_norm = tensor(0.1253, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304182529449463\n",
            "g_norm = tensor(0.1413, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039021492004395\n",
            "g_norm = tensor(0.1446, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043200969696045\n",
            "g_norm = tensor(0.1366, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.09326171875\n",
            "||∇_X meta|| = 0.0015756631037220359\n",
            "ΔX norm: 1.5756619177409448e-05\n",
            "Stage 10/10:  53%|██████████████▋             | 158/300 [06:20<05:49,  2.46s/it]T Loss=2.3033084869384766\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036599159240723\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041510581970215\n",
            "g_norm = tensor(0.1133, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303746223449707\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025825023651123\n",
            "g_norm = tensor(0.1183, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.81088256835938\n",
            "||∇_X meta|| = 0.0017596171237528324\n",
            "ΔX norm: 1.7596159523236565e-05\n",
            "Stage 10/10:  53%|██████████████▊             | 159/300 [06:22<05:50,  2.48s/it]T Loss=2.3022704124450684\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029539585113525\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302191734313965\n",
            "g_norm = tensor(0.1409, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041512966156006\n",
            "g_norm = tensor(0.1464, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035104274749756\n",
            "g_norm = tensor(0.1271, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.44400024414062\n",
            "||∇_X meta|| = 0.0015886010369285941\n",
            "ΔX norm: 1.5886018445598893e-05\n",
            "Stage 10/10:  53%|██████████████▉             | 160/300 [06:25<05:32,  2.37s/it]T Loss=2.30299711227417\n",
            "g_norm = tensor(0.1259, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037021160125732\n",
            "g_norm = tensor(0.1333, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3018884658813477\n",
            "g_norm = tensor(0.1352, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304474353790283\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301602840423584\n",
            "g_norm = tensor(0.1249, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.81788635253906\n",
            "||∇_X meta|| = 0.001633045612834394\n",
            "ΔX norm: 1.633046122151427e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 10/10:  54%|███████████████             | 161/300 [06:27<05:33,  2.40s/it]T Loss=2.3040616512298584\n",
            "g_norm = tensor(0.0838, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031058311462402\n",
            "g_norm = tensor(0.0783, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030073642730713\n",
            "g_norm = tensor(0.0860, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035659790039062\n",
            "g_norm = tensor(0.0836, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302445888519287\n",
            "g_norm = tensor(0.0762, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.1338348388672\n",
            "||∇_X meta|| = 0.0014528392348438501\n",
            "ΔX norm: 1.4528402971336618e-05\n",
            "Stage 10/10:  54%|███████████████             | 162/300 [06:30<05:36,  2.44s/it]T Loss=2.3048064708709717\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040947914123535\n",
            "g_norm = tensor(0.1021, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050105571746826\n",
            "g_norm = tensor(0.1144, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038229942321777\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303493022918701\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.63064575195312\n",
            "||∇_X meta|| = 0.001747764297761023\n",
            "ΔX norm: 1.7477615983807482e-05\n",
            "Stage 10/10:  54%|███████████████▏            | 163/300 [06:32<05:48,  2.54s/it]T Loss=2.304368495941162\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304086446762085\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305309534072876\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046956062316895\n",
            "g_norm = tensor(0.0750, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304957866668701\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.13914489746094\n",
            "||∇_X meta|| = 0.0017875954508781433\n",
            "ΔX norm: 1.7875934645417146e-05\n",
            "Stage 10/10:  55%|███████████████▎            | 164/300 [06:34<05:30,  2.43s/it]T Loss=2.307049512863159\n",
            "g_norm = tensor(0.1037, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044331073760986\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054146766662598\n",
            "g_norm = tensor(0.0902, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047428131103516\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304591655731201\n",
            "g_norm = tensor(0.0781, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3797149658203\n",
            "||∇_X meta|| = 0.0017700520111247897\n",
            "ΔX norm: 1.7700522221275605e-05\n",
            "Stage 10/10:  55%|███████████████▍            | 165/300 [06:37<05:18,  2.36s/it]T Loss=2.3053202629089355\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302788019180298\n",
            "g_norm = tensor(0.1291, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303097724914551\n",
            "g_norm = tensor(0.1060, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302203893661499\n",
            "g_norm = tensor(0.1209, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054938316345215\n",
            "g_norm = tensor(0.1177, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.73651123046875\n",
            "||∇_X meta|| = 0.0014951707562431693\n",
            "ΔX norm: 1.4951707271393389e-05\n",
            "Stage 10/10:  55%|███████████████▍            | 166/300 [06:39<05:06,  2.29s/it]T Loss=2.3034656047821045\n",
            "g_norm = tensor(0.0850, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032450675964355\n",
            "g_norm = tensor(0.0832, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038971424102783\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029894828796387\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028247356414795\n",
            "g_norm = tensor(0.0940, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.84988403320312\n",
            "||∇_X meta|| = 0.0017193102976307273\n",
            "ΔX norm: 1.71931205841247e-05\n",
            "Stage 10/10:  56%|███████████████▌            | 167/300 [06:41<05:05,  2.30s/it]T Loss=2.303177833557129\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037571907043457\n",
            "g_norm = tensor(0.1241, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301248073577881\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017451763153076\n",
            "g_norm = tensor(0.1119, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021445274353027\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.15673828125\n",
            "||∇_X meta|| = 0.0017283759079873562\n",
            "ΔX norm: 1.7283795386902057e-05\n",
            "Stage 10/10:  56%|███████████████▋            | 168/300 [06:43<04:56,  2.25s/it]T Loss=2.3033289909362793\n",
            "g_norm = tensor(0.0844, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303356885910034\n",
            "g_norm = tensor(0.0833, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032541275024414\n",
            "g_norm = tensor(0.0737, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303703784942627\n",
            "g_norm = tensor(0.0818, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034260272979736\n",
            "g_norm = tensor(0.0884, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.87098693847656\n",
            "||∇_X meta|| = 0.0016920113703235984\n",
            "ΔX norm: 1.6920106645557098e-05\n",
            "Stage 10/10:  56%|███████████████▊            | 169/300 [06:46<05:07,  2.35s/it]T Loss=2.303778886795044\n",
            "g_norm = tensor(0.1422, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304198980331421\n",
            "g_norm = tensor(0.1390, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304234743118286\n",
            "g_norm = tensor(0.1498, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042099475860596\n",
            "g_norm = tensor(0.1427, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304847478866577\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2574005126953\n",
            "||∇_X meta|| = 0.001585805555805564\n",
            "ΔX norm: 1.585803875059355e-05\n",
            "Stage 10/10:  57%|███████████████▊            | 170/300 [06:48<05:10,  2.39s/it]T Loss=2.3026294708251953\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302579402923584\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3020308017730713\n",
            "g_norm = tensor(0.1064, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031656742095947\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041419982910156\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.16696166992188\n",
            "||∇_X meta|| = 0.0015496574342250824\n",
            "ΔX norm: 1.5496589185204357e-05\n",
            "Stage 10/10:  57%|███████████████▉            | 171/300 [06:51<05:07,  2.39s/it]T Loss=2.304420232772827\n",
            "g_norm = tensor(0.1319, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045654296875\n",
            "g_norm = tensor(0.1275, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035991191864014\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052525520324707\n",
            "g_norm = tensor(0.1007, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304884910583496\n",
            "g_norm = tensor(0.1157, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.263916015625\n",
            "||∇_X meta|| = 0.001518868375569582\n",
            "ΔX norm: 1.5188664292509202e-05\n",
            "Stage 10/10:  57%|████████████████            | 172/300 [06:53<05:10,  2.43s/it]T Loss=2.3042685985565186\n",
            "g_norm = tensor(0.1506, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037281036376953\n",
            "g_norm = tensor(0.1341, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303439140319824\n",
            "g_norm = tensor(0.1398, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305380344390869\n",
            "g_norm = tensor(0.1341, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305412530899048\n",
            "g_norm = tensor(0.1414, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.43740844726562\n",
            "||∇_X meta|| = 0.001671198639087379\n",
            "ΔX norm: 1.6711983334971592e-05\n",
            "Stage 10/10:  58%|████████████████▏           | 173/300 [06:56<05:07,  2.42s/it]T Loss=2.3054378032684326\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046770095825195\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304678440093994\n",
            "g_norm = tensor(0.1105, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303086757659912\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055920600891113\n",
            "g_norm = tensor(0.0941, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.6697235107422\n",
            "||∇_X meta|| = 0.0016363131580874324\n",
            "ΔX norm: 1.6363146642106585e-05\n",
            "Stage 10/10:  58%|████████████████▏           | 174/300 [06:58<05:04,  2.42s/it]T Loss=2.303290843963623\n",
            "g_norm = tensor(0.0896, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303440809249878\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032267093658447\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303860902786255\n",
            "g_norm = tensor(0.0906, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303250789642334\n",
            "g_norm = tensor(0.0935, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.3786163330078\n",
            "||∇_X meta|| = 0.0014733877032995224\n",
            "ΔX norm: 1.4733869647898246e-05\n",
            "Stage 10/10:  58%|████████████████▎           | 175/300 [07:00<04:53,  2.35s/it]T Loss=2.3043646812438965\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044023513793945\n",
            "g_norm = tensor(0.0839, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036911487579346\n",
            "g_norm = tensor(0.0814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303618907928467\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303571939468384\n",
            "g_norm = tensor(0.0814, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.72567749023438\n",
            "||∇_X meta|| = 0.0014968977775424719\n",
            "ΔX norm: 1.4968977666285355e-05\n",
            "Stage 10/10:  59%|████████████████▍           | 176/300 [07:02<04:42,  2.28s/it]T Loss=2.303776979446411\n",
            "g_norm = tensor(0.0857, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048105239868164\n",
            "g_norm = tensor(0.0919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044590950012207\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303758144378662\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304532527923584\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.86630249023438\n",
            "||∇_X meta|| = 0.0016667945310473442\n",
            "ΔX norm: 1.6667940144543536e-05\n",
            "Stage 10/10:  59%|████████████████▌           | 177/300 [07:04<04:33,  2.22s/it]T Loss=2.303288221359253\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303330898284912\n",
            "g_norm = tensor(0.1198, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303882598876953\n",
            "g_norm = tensor(0.1261, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303867816925049\n",
            "g_norm = tensor(0.1121, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032290935516357\n",
            "g_norm = tensor(0.1380, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.56959533691406\n",
            "||∇_X meta|| = 0.0015702953096479177\n",
            "ΔX norm: 1.5702953533036634e-05\n",
            "Stage 10/10:  59%|████████████████▌           | 178/300 [07:06<04:25,  2.18s/it]T Loss=2.3035888671875\n",
            "g_norm = tensor(0.1080, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035483360290527\n",
            "g_norm = tensor(0.1055, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304429531097412\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044934272766113\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303901195526123\n",
            "g_norm = tensor(0.0987, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.4772491455078\n",
            "||∇_X meta|| = 0.0015206604730337858\n",
            "ΔX norm: 1.5206598618533462e-05\n",
            "Stage 10/10:  60%|████████████████▋           | 179/300 [07:09<04:25,  2.19s/it]T Loss=2.3043205738067627\n",
            "g_norm = tensor(0.0795, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034942150115967\n",
            "g_norm = tensor(0.0932, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304069995880127\n",
            "g_norm = tensor(0.0799, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043527603149414\n",
            "g_norm = tensor(0.0763, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304544448852539\n",
            "g_norm = tensor(0.0811, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.77261352539062\n",
            "||∇_X meta|| = 0.0014624577015638351\n",
            "ΔX norm: 1.462458476453321e-05\n",
            "Stage 10/10:  60%|████████████████▊           | 180/300 [07:11<04:38,  2.32s/it]T Loss=2.305020332336426\n",
            "g_norm = tensor(0.0939, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023014068603516\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046956062316895\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305311679840088\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032498359680176\n",
            "g_norm = tensor(0.0873, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.05178833007812\n",
            "||∇_X meta|| = 0.0015162660274654627\n",
            "ΔX norm: 1.5162666386459023e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 10/10:  60%|████████████████▉           | 181/300 [07:14<04:35,  2.32s/it]T Loss=2.3029768466949463\n",
            "g_norm = tensor(0.1142, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057403564453125\n",
            "g_norm = tensor(0.1213, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303750514984131\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304191827774048\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033604621887207\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.22137451171875\n",
            "||∇_X meta|| = 0.0016312255756929517\n",
            "ΔX norm: 1.63122658705106e-05\n",
            "Stage 10/10:  61%|████████████████▉           | 182/300 [07:16<04:45,  2.42s/it]T Loss=2.303241729736328\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304373025894165\n",
            "g_norm = tensor(0.1440, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302229404449463\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30426287651062\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033969402313232\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.02230834960938\n",
            "||∇_X meta|| = 0.001394548686221242\n",
            "ΔX norm: 1.3945499631518032e-05\n",
            "Stage 10/10:  61%|█████████████████           | 183/300 [07:19<04:40,  2.39s/it]T Loss=2.3042538166046143\n",
            "g_norm = tensor(0.0738, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303921699523926\n",
            "g_norm = tensor(0.0686, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039793968200684\n",
            "g_norm = tensor(0.0794, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303774356842041\n",
            "g_norm = tensor(0.0726, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036694526672363\n",
            "g_norm = tensor(0.0780, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.28921508789062\n",
            "||∇_X meta|| = 0.0015339360106736422\n",
            "ΔX norm: 1.5339363017119467e-05\n",
            "Stage 10/10:  61%|█████████████████▏          | 184/300 [07:21<04:43,  2.44s/it]T Loss=2.3031556606292725\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032820224761963\n",
            "g_norm = tensor(0.0869, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035943508148193\n",
            "g_norm = tensor(0.1013, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039729595184326\n",
            "g_norm = tensor(0.0909, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304826259613037\n",
            "g_norm = tensor(0.0876, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.1078643798828\n",
            "||∇_X meta|| = 0.0016583346296101809\n",
            "ΔX norm: 1.658335531828925e-05\n",
            "Stage 10/10:  62%|█████████████████▎          | 185/300 [07:24<04:49,  2.52s/it]T Loss=2.3042149543762207\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302016496658325\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30314040184021\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30245041847229\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031253814697266\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.10794067382812\n",
            "||∇_X meta|| = 0.0016784619074314833\n",
            "ΔX norm: 1.6784615581855178e-05\n",
            "Stage 10/10:  62%|█████████████████▎          | 186/300 [07:26<04:39,  2.45s/it]T Loss=2.3041388988494873\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042235374450684\n",
            "g_norm = tensor(0.1140, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038060665130615\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303549289703369\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039283752441406\n",
            "g_norm = tensor(0.1008, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.22312927246094\n",
            "||∇_X meta|| = 0.0015377308009192348\n",
            "ΔX norm: 1.537731077405624e-05\n",
            "Stage 10/10:  62%|█████████████████▍          | 187/300 [07:28<04:28,  2.38s/it]T Loss=2.303980827331543\n",
            "g_norm = tensor(0.1639, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30218243598938\n",
            "g_norm = tensor(0.1958, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039677143096924\n",
            "g_norm = tensor(0.1881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3056371212005615\n",
            "g_norm = tensor(0.1758, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041181564331055\n",
            "g_norm = tensor(0.1855, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.907470703125\n",
            "||∇_X meta|| = 0.0016729736234992743\n",
            "ΔX norm: 1.6729765775380656e-05\n",
            "Stage 10/10:  63%|█████████████████▌          | 188/300 [07:31<04:24,  2.36s/it]T Loss=2.3060286045074463\n",
            "g_norm = tensor(0.1468, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303175449371338\n",
            "g_norm = tensor(0.1692, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047127723693848\n",
            "g_norm = tensor(0.1613, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043394088745117\n",
            "g_norm = tensor(0.1599, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054373264312744\n",
            "g_norm = tensor(0.1459, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.13914489746094\n",
            "||∇_X meta|| = 0.0015326151624321938\n",
            "ΔX norm: 1.5326151697081514e-05\n",
            "Stage 10/10:  63%|█████████████████▋          | 189/300 [07:33<04:18,  2.33s/it]T Loss=2.30527925491333\n",
            "g_norm = tensor(0.1202, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047080039978027\n",
            "g_norm = tensor(0.1265, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037304878234863\n",
            "g_norm = tensor(0.1346, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304964542388916\n",
            "g_norm = tensor(0.1262, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3016998767852783\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.08587646484375\n",
            "||∇_X meta|| = 0.0015053009847179055\n",
            "ΔX norm: 1.5053012248245068e-05\n",
            "Stage 10/10:  63%|█████████████████▋          | 190/300 [07:35<04:11,  2.29s/it]T Loss=2.304891347885132\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038341999053955\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049979209899902\n",
            "g_norm = tensor(0.0901, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045806884765625\n",
            "g_norm = tensor(0.0942, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306065797805786\n",
            "g_norm = tensor(0.1233, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.27142333984375\n",
            "||∇_X meta|| = 0.00159327348228544\n",
            "ΔX norm: 1.5932728274492547e-05\n",
            "Stage 10/10:  64%|█████████████████▊          | 191/300 [07:38<04:18,  2.37s/it]T Loss=2.303039789199829\n",
            "g_norm = tensor(0.1045, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304002285003662\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303635597229004\n",
            "g_norm = tensor(0.0917, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040738105773926\n",
            "g_norm = tensor(0.1047, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043980598449707\n",
            "g_norm = tensor(0.1033, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.54623413085938\n",
            "||∇_X meta|| = 0.001594287808984518\n",
            "ΔX norm: 1.5942898244247772e-05\n",
            "Stage 10/10:  64%|█████████████████▉          | 192/300 [07:40<04:16,  2.37s/it]T Loss=2.303083896636963\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30354642868042\n",
            "g_norm = tensor(0.1552, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301792621612549\n",
            "g_norm = tensor(0.1258, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303908109664917\n",
            "g_norm = tensor(0.1393, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302682638168335\n",
            "g_norm = tensor(0.1367, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.13571166992188\n",
            "||∇_X meta|| = 0.0016139592044055462\n",
            "ΔX norm: 1.6139605577336624e-05\n",
            "Stage 10/10:  64%|██████████████████          | 193/300 [07:42<04:08,  2.33s/it]T Loss=2.3022618293762207\n",
            "g_norm = tensor(0.1057, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034329414367676\n",
            "g_norm = tensor(0.1311, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024001121520996\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031351566314697\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031365871429443\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.9593963623047\n",
            "||∇_X meta|| = 0.0015655154129490256\n",
            "ΔX norm: 1.5655163224437274e-05\n",
            "Stage 10/10:  65%|██████████████████          | 194/300 [07:45<04:02,  2.29s/it]T Loss=2.3041422367095947\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032288551330566\n",
            "g_norm = tensor(0.1315, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045620918273926\n",
            "g_norm = tensor(0.1271, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305546522140503\n",
            "g_norm = tensor(0.1157, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30330228805542\n",
            "g_norm = tensor(0.1255, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.93521118164062\n",
            "||∇_X meta|| = 0.0015173640567809343\n",
            "ΔX norm: 1.5173633983067703e-05\n",
            "Stage 10/10:  65%|██████████████████▏         | 195/300 [07:47<04:03,  2.32s/it]T Loss=2.30311918258667\n",
            "g_norm = tensor(0.0917, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303628444671631\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303185224533081\n",
            "g_norm = tensor(0.0984, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303053617477417\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30294132232666\n",
            "g_norm = tensor(0.0849, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.75088500976562\n",
            "||∇_X meta|| = 0.0015128848608583212\n",
            "ΔX norm: 1.512885410193121e-05\n",
            "Stage 10/10:  65%|██████████████████▎         | 196/300 [07:49<04:02,  2.33s/it]T Loss=2.303675651550293\n",
            "g_norm = tensor(0.1167, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031322956085205\n",
            "g_norm = tensor(0.1157, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045427799224854\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303403854370117\n",
            "g_norm = tensor(0.0948, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30486798286438\n",
            "g_norm = tensor(0.1095, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.43862915039062\n",
            "||∇_X meta|| = 0.0015830249758437276\n",
            "ΔX norm: 1.5830251868464984e-05\n",
            "Stage 10/10:  66%|██████████████████▍         | 197/300 [07:52<04:07,  2.41s/it]T Loss=2.304079055786133\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030080795288086\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045711517333984\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304349899291992\n",
            "g_norm = tensor(0.0860, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303476095199585\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.490966796875\n",
            "||∇_X meta|| = 0.0015559723833575845\n",
            "ΔX norm: 1.5559751773253083e-05\n",
            "Stage 10/10:  66%|██████████████████▍         | 198/300 [07:54<04:05,  2.41s/it]T Loss=2.304039478302002\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3021793365478516\n",
            "g_norm = tensor(0.1332, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303440570831299\n",
            "g_norm = tensor(0.1123, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303251266479492\n",
            "g_norm = tensor(0.1182, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023829460144043\n",
            "g_norm = tensor(0.1382, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.38507080078125\n",
            "||∇_X meta|| = 0.0014830657746642828\n",
            "ΔX norm: 1.4830667169007938e-05\n",
            "Stage 10/10:  66%|██████████████████▌         | 199/300 [07:56<03:58,  2.36s/it]T Loss=2.3040947914123535\n",
            "g_norm = tensor(0.1109, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044896125793457\n",
            "g_norm = tensor(0.0950, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304417610168457\n",
            "g_norm = tensor(0.0917, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048226833343506\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041932582855225\n",
            "g_norm = tensor(0.0999, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.69039916992188\n",
            "||∇_X meta|| = 0.0018021208234131336\n",
            "ΔX norm: 1.802120459615253e-05\n",
            "Stage 10/10:  67%|██████████████████▋         | 200/300 [07:59<04:11,  2.51s/it]T Loss=2.303443670272827\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046982288360596\n",
            "g_norm = tensor(0.1205, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30381178855896\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304246187210083\n",
            "g_norm = tensor(0.1365, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025355339050293\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.35052490234375\n",
            "||∇_X meta|| = 0.001549678621813655\n",
            "ΔX norm: 1.549678017909173e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 10/10:  67%|██████████████████▊         | 201/300 [08:02<04:04,  2.47s/it]T Loss=2.3034684658050537\n",
            "g_norm = tensor(0.1476, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305499315261841\n",
            "g_norm = tensor(0.1721, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3055260181427\n",
            "g_norm = tensor(0.1763, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304823637008667\n",
            "g_norm = tensor(0.1379, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032920360565186\n",
            "g_norm = tensor(0.1474, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.98712158203125\n",
            "||∇_X meta|| = 0.0016295475652441382\n",
            "ΔX norm: 1.6295514797093347e-05\n",
            "Stage 10/10:  67%|██████████████████▊         | 202/300 [08:04<04:02,  2.47s/it]T Loss=2.3035683631896973\n",
            "g_norm = tensor(0.0688, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304640769958496\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303666114807129\n",
            "g_norm = tensor(0.0755, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302330255508423\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034684658050537\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6005859375\n",
            "||∇_X meta|| = 0.0015795622020959854\n",
            "ΔX norm: 1.5795621948200278e-05\n",
            "Stage 10/10:  68%|██████████████████▉         | 203/300 [08:07<04:01,  2.49s/it]T Loss=2.3040289878845215\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303957462310791\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025314807891846\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033676147460938\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041844367980957\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.8450927734375\n",
            "||∇_X meta|| = 0.0015495301922783256\n",
            "ΔX norm: 1.5495315892621875e-05\n",
            "Stage 10/10:  68%|███████████████████         | 204/300 [08:09<03:55,  2.45s/it]T Loss=2.3039984703063965\n",
            "g_norm = tensor(0.1219, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303006649017334\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303199529647827\n",
            "g_norm = tensor(0.1063, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052313327789307\n",
            "g_norm = tensor(0.1294, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040337562561035\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1886444091797\n",
            "||∇_X meta|| = 0.0016917784232646227\n",
            "ΔX norm: 1.6917798348004e-05\n",
            "Stage 10/10:  68%|███████████████████▏        | 205/300 [08:11<03:47,  2.39s/it]T Loss=2.303877592086792\n",
            "g_norm = tensor(0.1332, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024439811706543\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047144412994385\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034424781799316\n",
            "g_norm = tensor(0.1397, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304104804992676\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.84970092773438\n",
            "||∇_X meta|| = 0.0014799775090068579\n",
            "ΔX norm: 1.4799757991568185e-05\n",
            "Stage 10/10:  69%|███████████████████▏        | 206/300 [08:14<03:44,  2.39s/it]T Loss=2.306281328201294\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040969371795654\n",
            "g_norm = tensor(0.0915, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304605007171631\n",
            "g_norm = tensor(0.0857, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044118881225586\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304154872894287\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.21682739257812\n",
            "||∇_X meta|| = 0.0016071023419499397\n",
            "ΔX norm: 1.6071020581875928e-05\n",
            "Stage 10/10:  69%|███████████████████▎        | 207/300 [08:16<03:50,  2.48s/it]T Loss=2.3033318519592285\n",
            "g_norm = tensor(0.0850, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029322624206543\n",
            "g_norm = tensor(0.0916, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040108680725098\n",
            "g_norm = tensor(0.0952, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303349256515503\n",
            "g_norm = tensor(0.0774, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038017749786377\n",
            "g_norm = tensor(0.0787, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.25965881347656\n",
            "||∇_X meta|| = 0.001644369913265109\n",
            "ΔX norm: 1.6443700587842613e-05\n",
            "Stage 10/10:  69%|███████████████████▍        | 208/300 [08:19<03:53,  2.54s/it]T Loss=2.3036112785339355\n",
            "g_norm = tensor(0.1426, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302987575531006\n",
            "g_norm = tensor(0.1471, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036394119262695\n",
            "g_norm = tensor(0.1469, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034021854400635\n",
            "g_norm = tensor(0.1633, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30181622505188\n",
            "g_norm = tensor(0.1738, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.10951232910156\n",
            "||∇_X meta|| = 0.0015729634324088693\n",
            "ΔX norm: 1.5729625374660827e-05\n",
            "Stage 10/10:  70%|███████████████████▌        | 209/300 [08:22<03:52,  2.55s/it]T Loss=2.303774356842041\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045129776000977\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30395245552063\n",
            "g_norm = tensor(0.0924, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024580478668213\n",
            "g_norm = tensor(0.0986, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039445877075195\n",
            "g_norm = tensor(0.1159, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.6431427001953\n",
            "||∇_X meta|| = 0.0014911723555997014\n",
            "ΔX norm: 1.4911744983692188e-05\n",
            "Stage 10/10:  70%|███████████████████▌        | 210/300 [08:24<03:42,  2.47s/it]T Loss=2.303870916366577\n",
            "g_norm = tensor(0.0802, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038036823272705\n",
            "g_norm = tensor(0.0737, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045270442962646\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30419921875\n",
            "g_norm = tensor(0.0933, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303368091583252\n",
            "g_norm = tensor(0.0913, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2288055419922\n",
            "||∇_X meta|| = 0.001656900392845273\n",
            "ΔX norm: 1.656900712987408e-05\n",
            "Stage 10/10:  70%|███████████████████▋        | 211/300 [08:26<03:35,  2.42s/it]T Loss=2.304874897003174\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303828239440918\n",
            "g_norm = tensor(0.0899, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303480625152588\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038480281829834\n",
            "g_norm = tensor(0.0970, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303701162338257\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2096710205078\n",
            "||∇_X meta|| = 0.0015370688633993268\n",
            "ΔX norm: 1.537066782475449e-05\n",
            "Stage 10/10:  71%|███████████████████▊        | 212/300 [08:29<03:35,  2.45s/it]T Loss=2.3038058280944824\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303562879562378\n",
            "g_norm = tensor(0.1043, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045334815979004\n",
            "g_norm = tensor(0.1145, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032121658325195\n",
            "g_norm = tensor(0.1094, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038713932037354\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8547821044922\n",
            "||∇_X meta|| = 0.0015729796141386032\n",
            "ΔX norm: 1.572979635966476e-05\n",
            "Stage 10/10:  71%|███████████████████▉        | 213/300 [08:31<03:28,  2.40s/it]T Loss=2.3040847778320312\n",
            "g_norm = tensor(0.1061, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304056406021118\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035731315612793\n",
            "g_norm = tensor(0.0831, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050026893615723\n",
            "g_norm = tensor(0.0992, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037354946136475\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.72190856933594\n",
            "||∇_X meta|| = 0.0017113047651946545\n",
            "ΔX norm: 1.711303229967598e-05\n",
            "Stage 10/10:  71%|███████████████████▉        | 214/300 [08:34<03:28,  2.42s/it]T Loss=2.304466962814331\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303515672683716\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033688068389893\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042562007904053\n",
            "g_norm = tensor(0.1084, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303683042526245\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.8342742919922\n",
            "||∇_X meta|| = 0.0016618921654298902\n",
            "ΔX norm: 1.661892019910738e-05\n",
            "Stage 10/10:  72%|████████████████████        | 215/300 [08:36<03:22,  2.38s/it]T Loss=2.3044867515563965\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037161827087402\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304582357406616\n",
            "g_norm = tensor(0.1282, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303316116333008\n",
            "g_norm = tensor(0.1158, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032326698303223\n",
            "g_norm = tensor(0.1146, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.7636260986328\n",
            "||∇_X meta|| = 0.001506589469499886\n",
            "ΔX norm: 1.5065877050801646e-05\n",
            "Stage 10/10:  72%|████████████████████▏       | 216/300 [08:38<03:17,  2.36s/it]T Loss=2.304555892944336\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30492901802063\n",
            "g_norm = tensor(0.1153, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304952383041382\n",
            "g_norm = tensor(0.1088, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037185668945312\n",
            "g_norm = tensor(0.0979, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049192428588867\n",
            "g_norm = tensor(0.1271, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.68601989746094\n",
            "||∇_X meta|| = 0.0014672144316136837\n",
            "ΔX norm: 1.4672147699457128e-05\n",
            "Stage 10/10:  72%|████████████████████▎       | 217/300 [08:40<03:14,  2.35s/it]T Loss=2.304736614227295\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304593563079834\n",
            "g_norm = tensor(0.0927, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044369220733643\n",
            "g_norm = tensor(0.0972, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304069757461548\n",
            "g_norm = tensor(0.0982, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050973415374756\n",
            "g_norm = tensor(0.0908, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.85525512695312\n",
            "||∇_X meta|| = 0.0016343571478500962\n",
            "ΔX norm: 1.6343597962986678e-05\n",
            "Stage 10/10:  73%|████████████████████▎       | 218/300 [08:43<03:13,  2.36s/it]T Loss=2.3030266761779785\n",
            "g_norm = tensor(0.1189, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034191131591797\n",
            "g_norm = tensor(0.1143, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027262687683105\n",
            "g_norm = tensor(0.1138, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30189847946167\n",
            "g_norm = tensor(0.1244, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303884983062744\n",
            "g_norm = tensor(0.1270, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5991668701172\n",
            "||∇_X meta|| = 0.001441551255993545\n",
            "ΔX norm: 1.4415485566132702e-05\n",
            "Stage 10/10:  73%|████████████████████▍       | 219/300 [08:45<03:08,  2.33s/it]T Loss=2.303617477416992\n",
            "g_norm = tensor(0.0698, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039541244506836\n",
            "g_norm = tensor(0.0693, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039333820343018\n",
            "g_norm = tensor(0.0705, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303549289703369\n",
            "g_norm = tensor(0.0670, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032515048980713\n",
            "g_norm = tensor(0.0752, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.1488494873047\n",
            "||∇_X meta|| = 0.0014377398183569312\n",
            "ΔX norm: 1.4377393199538346e-05\n",
            "Stage 10/10:  73%|████████████████████▌       | 220/300 [08:48<03:13,  2.42s/it]T Loss=2.304053783416748\n",
            "g_norm = tensor(0.1178, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30332612991333\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041093349456787\n",
            "g_norm = tensor(0.0934, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030805587768555\n",
            "g_norm = tensor(0.1331, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037524223327637\n",
            "g_norm = tensor(0.1208, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.28823852539062\n",
            "||∇_X meta|| = 0.0015389530453830957\n",
            "ΔX norm: 1.5389523468911648e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 10/10:  74%|████████████████████▋       | 221/300 [08:50<03:07,  2.38s/it]T Loss=2.304471492767334\n",
            "g_norm = tensor(0.1066, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039183616638184\n",
            "g_norm = tensor(0.1309, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303271770477295\n",
            "g_norm = tensor(0.1178, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303757667541504\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043527603149414\n",
            "g_norm = tensor(0.1072, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6051788330078\n",
            "||∇_X meta|| = 0.0015441338764503598\n",
            "ΔX norm: 1.544133192510344e-05\n",
            "Stage 10/10:  74%|████████████████████▋       | 222/300 [08:53<03:12,  2.47s/it]T Loss=2.3041558265686035\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052902221679688\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046672344207764\n",
            "g_norm = tensor(0.1271, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3057987689971924\n",
            "g_norm = tensor(0.1493, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053741455078125\n",
            "g_norm = tensor(0.1405, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.57505798339844\n",
            "||∇_X meta|| = 0.0016346422489732504\n",
            "ΔX norm: 1.6346411939593963e-05\n",
            "Stage 10/10:  74%|████████████████████▊       | 223/300 [08:55<03:09,  2.47s/it]T Loss=2.3040690422058105\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303393840789795\n",
            "g_norm = tensor(0.1111, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033852577209473\n",
            "g_norm = tensor(0.1229, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040924072265625\n",
            "g_norm = tensor(0.1029, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303654670715332\n",
            "g_norm = tensor(0.1093, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0379180908203\n",
            "||∇_X meta|| = 0.0016962351510301232\n",
            "ΔX norm: 1.696233266557101e-05\n",
            "Stage 10/10:  75%|████████████████████▉       | 224/300 [08:57<03:00,  2.38s/it]T Loss=2.3032288551330566\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.300952196121216\n",
            "g_norm = tensor(0.1201, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026793003082275\n",
            "g_norm = tensor(0.1011, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028273582458496\n",
            "g_norm = tensor(0.1161, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029932975769043\n",
            "g_norm = tensor(0.0943, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.39743041992188\n",
            "||∇_X meta|| = 0.0015644098166376352\n",
            "ΔX norm: 1.5644120139768347e-05\n",
            "Stage 10/10:  75%|█████████████████████       | 225/300 [09:00<02:55,  2.34s/it]T Loss=2.3034658432006836\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304307460784912\n",
            "g_norm = tensor(0.1225, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304042339324951\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304483413696289\n",
            "g_norm = tensor(0.1130, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038594722747803\n",
            "g_norm = tensor(0.1091, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.92474365234375\n",
            "||∇_X meta|| = 0.0014495004434138536\n",
            "ΔX norm: 1.4495010873361025e-05\n",
            "Stage 10/10:  75%|█████████████████████       | 226/300 [09:02<02:55,  2.37s/it]T Loss=2.303551197052002\n",
            "g_norm = tensor(0.1103, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305027723312378\n",
            "g_norm = tensor(0.1418, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043410778045654\n",
            "g_norm = tensor(0.1395, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039608001708984\n",
            "g_norm = tensor(0.1290, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3022804260253906\n",
            "g_norm = tensor(0.1419, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.18014526367188\n",
            "||∇_X meta|| = 0.0015148891834542155\n",
            "ΔX norm: 1.5148893908190075e-05\n",
            "Stage 10/10:  76%|█████████████████████▏      | 227/300 [09:05<02:56,  2.41s/it]T Loss=2.304293155670166\n",
            "g_norm = tensor(0.1301, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044981956481934\n",
            "g_norm = tensor(0.1495, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047873973846436\n",
            "g_norm = tensor(0.1328, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030619621276855\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043124675750732\n",
            "g_norm = tensor(0.1160, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2240447998047\n",
            "||∇_X meta|| = 0.0017755109583958983\n",
            "ΔX norm: 1.775508644641377e-05\n",
            "Stage 10/10:  76%|█████████████████████▎      | 228/300 [09:07<02:49,  2.36s/it]T Loss=2.303715944290161\n",
            "g_norm = tensor(0.1122, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304316997528076\n",
            "g_norm = tensor(0.0933, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032524585723877\n",
            "g_norm = tensor(0.1041, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303600788116455\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045449256896973\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.92672729492188\n",
            "||∇_X meta|| = 0.0014096060767769814\n",
            "ΔX norm: 1.4096071936364751e-05\n",
            "Stage 10/10:  76%|█████████████████████▎      | 229/300 [09:09<02:42,  2.29s/it]T Loss=2.30475115776062\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025076389312744\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304124593734741\n",
            "g_norm = tensor(0.0937, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052308559417725\n",
            "g_norm = tensor(0.1131, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044331073760986\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.88722229003906\n",
            "||∇_X meta|| = 0.001647787750698626\n",
            "ΔX norm: 1.6477875760756433e-05\n",
            "Stage 10/10:  77%|█████████████████████▍      | 230/300 [09:11<02:37,  2.25s/it]T Loss=2.303529739379883\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033196926116943\n",
            "g_norm = tensor(0.1104, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303737163543701\n",
            "g_norm = tensor(0.1151, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303176164627075\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045570850372314\n",
            "g_norm = tensor(0.0980, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.94515991210938\n",
            "||∇_X meta|| = 0.0015237332554534078\n",
            "ΔX norm: 1.5237340448948089e-05\n",
            "Stage 10/10:  77%|█████████████████████▌      | 231/300 [09:13<02:34,  2.23s/it]T Loss=2.3024353981018066\n",
            "g_norm = tensor(0.1340, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3061165809631348\n",
            "g_norm = tensor(0.1242, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304675579071045\n",
            "g_norm = tensor(0.1405, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032333850860596\n",
            "g_norm = tensor(0.1181, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304509401321411\n",
            "g_norm = tensor(0.1282, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.92190551757812\n",
            "||∇_X meta|| = 0.0015907061751931906\n",
            "ΔX norm: 1.59070550580509e-05\n",
            "Stage 10/10:  77%|█████████████████████▋      | 232/300 [09:16<02:32,  2.25s/it]T Loss=2.303143262863159\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303990125656128\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304810047149658\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037853240966797\n",
            "g_norm = tensor(0.1106, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042173385620117\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.5587158203125\n",
            "||∇_X meta|| = 0.0014705655630677938\n",
            "ΔX norm: 1.4705673493153881e-05\n",
            "Stage 10/10:  78%|█████████████████████▋      | 233/300 [09:18<02:40,  2.40s/it]T Loss=2.303234100341797\n",
            "g_norm = tensor(0.1009, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033692836761475\n",
            "g_norm = tensor(0.1134, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031108379364014\n",
            "g_norm = tensor(0.0944, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036391735076904\n",
            "g_norm = tensor(0.1191, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017807006835938\n",
            "g_norm = tensor(0.1156, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.37588500976562\n",
            "||∇_X meta|| = 0.0015635679010301828\n",
            "ΔX norm: 1.5635685485904105e-05\n",
            "Stage 10/10:  78%|█████████████████████▊      | 234/300 [09:21<02:52,  2.61s/it]T Loss=2.3042759895324707\n",
            "g_norm = tensor(0.1383, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052868843078613\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058440685272217\n",
            "g_norm = tensor(0.1512, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.306225061416626\n",
            "g_norm = tensor(0.1484, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303243398666382\n",
            "g_norm = tensor(0.1491, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.29965209960938\n",
            "||∇_X meta|| = 0.0018072355305776\n",
            "ΔX norm: 1.807234548323322e-05\n",
            "Stage 10/10:  78%|█████████████████████▉      | 235/300 [09:24<02:46,  2.57s/it]T Loss=2.3029093742370605\n",
            "g_norm = tensor(0.1488, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302048921585083\n",
            "g_norm = tensor(0.1480, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029589653015137\n",
            "g_norm = tensor(0.1533, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019137382507324\n",
            "g_norm = tensor(0.1497, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302551746368408\n",
            "g_norm = tensor(0.1726, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.30328369140625\n",
            "||∇_X meta|| = 0.0015416666865348816\n",
            "ΔX norm: 1.5416675523738377e-05\n",
            "Stage 10/10:  79%|██████████████████████      | 236/300 [09:26<02:40,  2.51s/it]T Loss=2.303313732147217\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304563283920288\n",
            "g_norm = tensor(0.0912, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302943229675293\n",
            "g_norm = tensor(0.1255, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039748668670654\n",
            "g_norm = tensor(0.1278, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037383556365967\n",
            "g_norm = tensor(0.0971, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.61636352539062\n",
            "||∇_X meta|| = 0.0015503378817811608\n",
            "ΔX norm: 1.5503381291637197e-05\n",
            "Stage 10/10:  79%|██████████████████████      | 237/300 [09:29<02:34,  2.45s/it]T Loss=2.3034467697143555\n",
            "g_norm = tensor(0.0990, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027024269104004\n",
            "g_norm = tensor(0.1048, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035428524017334\n",
            "g_norm = tensor(0.1137, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304020404815674\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303467273712158\n",
            "g_norm = tensor(0.0878, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.71511840820312\n",
            "||∇_X meta|| = 0.0017399122007191181\n",
            "ΔX norm: 1.7399108401150443e-05\n",
            "Stage 10/10:  79%|██████████████████████▏     | 238/300 [09:31<02:37,  2.53s/it]T Loss=2.305860996246338\n",
            "g_norm = tensor(0.1456, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041739463806152\n",
            "g_norm = tensor(0.1324, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304295301437378\n",
            "g_norm = tensor(0.1180, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045918941497803\n",
            "g_norm = tensor(0.1200, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039143085479736\n",
            "g_norm = tensor(0.1239, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.3925018310547\n",
            "||∇_X meta|| = 0.0016011047409847379\n",
            "ΔX norm: 1.601105395820923e-05\n",
            "Stage 10/10:  80%|██████████████████████▎     | 239/300 [09:34<02:30,  2.47s/it]T Loss=2.30485463142395\n",
            "g_norm = tensor(0.1325, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045082092285156\n",
            "g_norm = tensor(0.1042, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052921295166016\n",
            "g_norm = tensor(0.1283, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028364181518555\n",
            "g_norm = tensor(0.1289, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3049473762512207\n",
            "g_norm = tensor(0.1110, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.75502014160156\n",
            "||∇_X meta|| = 0.0015973499976098537\n",
            "ΔX norm: 1.5973510016920045e-05\n",
            "Stage 10/10:  80%|██████████████████████▍     | 240/300 [09:36<02:23,  2.40s/it]T Loss=2.303955554962158\n",
            "g_norm = tensor(0.1086, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305595874786377\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304384708404541\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304748773574829\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051390647888184\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7953338623047\n",
            "||∇_X meta|| = 0.0016372441314160824\n",
            "ΔX norm: 1.6372447134926915e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 10/10:  80%|██████████████████████▍     | 241/300 [09:38<02:19,  2.37s/it]T Loss=2.302475929260254\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033080101013184\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303748607635498\n",
            "g_norm = tensor(0.1101, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302908420562744\n",
            "g_norm = tensor(0.1152, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042001724243164\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.6454620361328\n",
            "||∇_X meta|| = 0.0015363007551059127\n",
            "ΔX norm: 1.5363011698354967e-05\n",
            "Stage 10/10:  81%|██████████████████████▌     | 242/300 [09:41<02:23,  2.47s/it]T Loss=2.303149700164795\n",
            "g_norm = tensor(0.1021, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303090810775757\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303863048553467\n",
            "g_norm = tensor(0.1004, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034915924072266\n",
            "g_norm = tensor(0.1073, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304138660430908\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =232.135009765625\n",
            "||∇_X meta|| = 0.0015726700657978654\n",
            "ΔX norm: 1.572671317262575e-05\n",
            "Stage 10/10:  81%|██████████████████████▋     | 243/300 [09:43<02:23,  2.51s/it]T Loss=2.3039345741271973\n",
            "g_norm = tensor(0.1440, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304736614227295\n",
            "g_norm = tensor(0.1584, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302090883255005\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032705783843994\n",
            "g_norm = tensor(0.1213, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3016629219055176\n",
            "g_norm = tensor(0.1179, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.70819091796875\n",
            "||∇_X meta|| = 0.0015090329106897116\n",
            "ΔX norm: 1.5090324268385302e-05\n",
            "Stage 10/10:  81%|██████████████████████▊     | 244/300 [09:46<02:16,  2.43s/it]T Loss=2.304185152053833\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046281337738037\n",
            "g_norm = tensor(0.0848, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304896354675293\n",
            "g_norm = tensor(0.0781, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044090270996094\n",
            "g_norm = tensor(0.0988, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304687261581421\n",
            "g_norm = tensor(0.0890, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.7754669189453\n",
            "||∇_X meta|| = 0.0015799538232386112\n",
            "ΔX norm: 1.579954187036492e-05\n",
            "Stage 10/10:  82%|██████████████████████▊     | 245/300 [09:48<02:10,  2.38s/it]T Loss=2.304450035095215\n",
            "g_norm = tensor(0.0910, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045380115509033\n",
            "g_norm = tensor(0.0933, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036468029022217\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304194211959839\n",
            "g_norm = tensor(0.0895, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303311824798584\n",
            "g_norm = tensor(0.1256, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.84898376464844\n",
            "||∇_X meta|| = 0.0016900193877518177\n",
            "ΔX norm: 1.6900215996429324e-05\n",
            "Stage 10/10:  82%|██████████████████████▉     | 246/300 [09:50<02:09,  2.39s/it]T Loss=2.3036458492279053\n",
            "g_norm = tensor(0.0823, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303328514099121\n",
            "g_norm = tensor(0.0870, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30322003364563\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031792640686035\n",
            "g_norm = tensor(0.1005, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036465644836426\n",
            "g_norm = tensor(0.0708, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.23052978515625\n",
            "||∇_X meta|| = 0.0013887896202504635\n",
            "ΔX norm: 1.3887906789022963e-05\n",
            "Stage 10/10:  82%|███████████████████████     | 247/300 [09:53<02:07,  2.41s/it]T Loss=2.304769992828369\n",
            "g_norm = tensor(0.1363, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050923347473145\n",
            "g_norm = tensor(0.1402, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30169939994812\n",
            "g_norm = tensor(0.1429, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304360866546631\n",
            "g_norm = tensor(0.1309, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3013930320739746\n",
            "g_norm = tensor(0.1704, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0563201904297\n",
            "||∇_X meta|| = 0.0015903357416391373\n",
            "ΔX norm: 1.5903358871582896e-05\n",
            "Stage 10/10:  83%|███████████████████████▏    | 248/300 [09:55<02:04,  2.39s/it]T Loss=2.303443431854248\n",
            "g_norm = tensor(0.0881, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303880214691162\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039462566375732\n",
            "g_norm = tensor(0.0930, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036751747131348\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038382530212402\n",
            "g_norm = tensor(0.0829, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.76405334472656\n",
            "||∇_X meta|| = 0.0016719172708690166\n",
            "ΔX norm: 1.6719186533009633e-05\n",
            "Stage 10/10:  83%|███████████████████████▏    | 249/300 [09:58<02:03,  2.42s/it]T Loss=2.3035836219787598\n",
            "g_norm = tensor(0.1254, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032360076904297\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3053781986236572\n",
            "g_norm = tensor(0.1287, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026394844055176\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304279088973999\n",
            "g_norm = tensor(0.1260, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.13070678710938\n",
            "||∇_X meta|| = 0.0016628524754196405\n",
            "ΔX norm: 1.6628511730232276e-05\n",
            "Stage 10/10:  83%|███████████████████████▎    | 250/300 [10:00<01:57,  2.34s/it]T Loss=2.303915023803711\n",
            "g_norm = tensor(0.1099, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032140731811523\n",
            "g_norm = tensor(0.0919, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040590286254883\n",
            "g_norm = tensor(0.0955, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046164512634277\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304779052734375\n",
            "g_norm = tensor(0.0793, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.17738342285156\n",
            "||∇_X meta|| = 0.0014587602345272899\n",
            "ΔX norm: 1.4587599252990913e-05\n",
            "Stage 10/10:  84%|███████████████████████▍    | 251/300 [10:02<01:52,  2.29s/it]T Loss=2.301969528198242\n",
            "g_norm = tensor(0.1556, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302687406539917\n",
            "g_norm = tensor(0.1408, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302036762237549\n",
            "g_norm = tensor(0.1686, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025734424591064\n",
            "g_norm = tensor(0.1520, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303118944168091\n",
            "g_norm = tensor(0.1350, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.17864990234375\n",
            "||∇_X meta|| = 0.00156620133202523\n",
            "ΔX norm: 1.5661991710658185e-05\n",
            "Stage 10/10:  84%|███████████████████████▌    | 252/300 [10:04<01:48,  2.26s/it]T Loss=2.3034348487854004\n",
            "g_norm = tensor(0.1498, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029630184173584\n",
            "g_norm = tensor(0.1521, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303290605545044\n",
            "g_norm = tensor(0.1440, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30295991897583\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302330493927002\n",
            "g_norm = tensor(0.1445, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.93136596679688\n",
            "||∇_X meta|| = 0.0014559298288077116\n",
            "ΔX norm: 1.4559286682924721e-05\n",
            "Stage 10/10:  84%|███████████████████████▌    | 253/300 [10:06<01:43,  2.21s/it]T Loss=2.3048081398010254\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303917407989502\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303770065307617\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304952621459961\n",
            "g_norm = tensor(0.1024, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035430908203125\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.76133728027344\n",
            "||∇_X meta|| = 0.0016568556893616915\n",
            "ΔX norm: 1.6568556020502e-05\n",
            "Stage 10/10:  85%|███████████████████████▋    | 254/300 [10:08<01:41,  2.22s/it]T Loss=2.303128719329834\n",
            "g_norm = tensor(0.0778, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029630184173584\n",
            "g_norm = tensor(0.1054, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303846836090088\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037242889404297\n",
            "g_norm = tensor(0.0925, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303776502609253\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.61712646484375\n",
            "||∇_X meta|| = 0.001515887095592916\n",
            "ΔX norm: 1.5158868336584419e-05\n",
            "Stage 10/10:  85%|███████████████████████▊    | 255/300 [10:11<01:44,  2.33s/it]T Loss=2.302733898162842\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303588390350342\n",
            "g_norm = tensor(0.1087, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303074359893799\n",
            "g_norm = tensor(0.1252, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038249015808105\n",
            "g_norm = tensor(0.1442, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029837608337402\n",
            "g_norm = tensor(0.1139, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.39874267578125\n",
            "||∇_X meta|| = 0.0016240397235378623\n",
            "ΔX norm: 1.624039032321889e-05\n",
            "Stage 10/10:  85%|███████████████████████▉    | 256/300 [10:13<01:39,  2.27s/it]T Loss=2.304500102996826\n",
            "g_norm = tensor(0.1238, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050131797790527\n",
            "g_norm = tensor(0.1234, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058040142059326\n",
            "g_norm = tensor(0.1406, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303116798400879\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043386936187744\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.5348358154297\n",
            "||∇_X meta|| = 0.001584031037054956\n",
            "ΔX norm: 1.584030906087719e-05\n",
            "Stage 10/10:  86%|███████████████████████▉    | 257/300 [10:16<01:43,  2.40s/it]T Loss=2.3032679557800293\n",
            "g_norm = tensor(0.0928, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3019700050354004\n",
            "g_norm = tensor(0.1062, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303184747695923\n",
            "g_norm = tensor(0.0894, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032634258270264\n",
            "g_norm = tensor(0.1012, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036258220672607\n",
            "g_norm = tensor(0.0898, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.26727294921875\n",
            "||∇_X meta|| = 0.0016415308928117156\n",
            "ΔX norm: 1.641532981011551e-05\n",
            "Stage 10/10:  86%|████████████████████████    | 258/300 [10:18<01:40,  2.38s/it]T Loss=2.303647994995117\n",
            "g_norm = tensor(0.1031, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3017868995666504\n",
            "g_norm = tensor(0.1193, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035054206848145\n",
            "g_norm = tensor(0.0975, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.300366163253784\n",
            "g_norm = tensor(0.1289, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.301085948944092\n",
            "g_norm = tensor(0.1190, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.09182739257812\n",
            "||∇_X meta|| = 0.0015234099701046944\n",
            "ΔX norm: 1.523410355730448e-05\n",
            "Stage 10/10:  86%|████████████████████████▏   | 259/300 [10:21<01:40,  2.46s/it]T Loss=2.30637788772583\n",
            "g_norm = tensor(0.1401, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042683601379395\n",
            "g_norm = tensor(0.1342, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305647850036621\n",
            "g_norm = tensor(0.1330, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3050804138183594\n",
            "g_norm = tensor(0.1113, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303833484649658\n",
            "g_norm = tensor(0.1370, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.71365356445312\n",
            "||∇_X meta|| = 0.0015289008151739836\n",
            "ΔX norm: 1.5289042494259775e-05\n",
            "Stage 10/10:  87%|████████████████████████▎   | 260/300 [10:23<01:39,  2.49s/it]T Loss=2.304298162460327\n",
            "g_norm = tensor(0.1249, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044686317443848\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304757595062256\n",
            "g_norm = tensor(0.1339, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304006338119507\n",
            "g_norm = tensor(0.1222, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039803504943848\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.57554626464844\n",
            "||∇_X meta|| = 0.0015506965573877096\n",
            "ΔX norm: 1.5506970157730393e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 10/10:  87%|████████████████████████▎   | 261/300 [10:26<01:34,  2.42s/it]T Loss=2.3029651641845703\n",
            "g_norm = tensor(0.1135, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304173707962036\n",
            "g_norm = tensor(0.1380, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304750919342041\n",
            "g_norm = tensor(0.1281, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304332733154297\n",
            "g_norm = tensor(0.1136, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045132160186768\n",
            "g_norm = tensor(0.1248, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5768280029297\n",
            "||∇_X meta|| = 0.0015115456189960241\n",
            "ΔX norm: 1.5115470887394622e-05\n",
            "Stage 10/10:  87%|████████████████████████▍   | 262/300 [10:28<01:35,  2.51s/it]T Loss=2.3049702644348145\n",
            "g_norm = tensor(0.1413, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038079738616943\n",
            "g_norm = tensor(0.1204, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305304527282715\n",
            "g_norm = tensor(0.1328, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303377866744995\n",
            "g_norm = tensor(0.1348, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30588436126709\n",
            "g_norm = tensor(0.1463, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =228.93141174316406\n",
            "||∇_X meta|| = 0.001555548282340169\n",
            "ΔX norm: 1.55555026140064e-05\n",
            "Stage 10/10:  88%|████████████████████████▌   | 263/300 [10:31<01:30,  2.44s/it]T Loss=2.3036625385284424\n",
            "g_norm = tensor(0.1001, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303226947784424\n",
            "g_norm = tensor(0.1436, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304527997970581\n",
            "g_norm = tensor(0.1125, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032445907592773\n",
            "g_norm = tensor(0.1540, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304379940032959\n",
            "g_norm = tensor(0.1002, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.359619140625\n",
            "||∇_X meta|| = 0.0014798945048823953\n",
            "ΔX norm: 1.4798921256442554e-05\n",
            "Stage 10/10:  88%|████████████████████████▋   | 264/300 [10:33<01:25,  2.38s/it]T Loss=2.3044660091400146\n",
            "g_norm = tensor(0.1743, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054678440093994\n",
            "g_norm = tensor(0.1580, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302183151245117\n",
            "g_norm = tensor(0.1227, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304246664047241\n",
            "g_norm = tensor(0.1454, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303858518600464\n",
            "g_norm = tensor(0.1371, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.91224670410156\n",
            "||∇_X meta|| = 0.001606660196557641\n",
            "ΔX norm: 1.6066642274381593e-05\n",
            "Stage 10/10:  88%|████████████████████████▋   | 265/300 [10:35<01:21,  2.34s/it]T Loss=2.3041603565216064\n",
            "g_norm = tensor(0.0815, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042891025543213\n",
            "g_norm = tensor(0.1038, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032116889953613\n",
            "g_norm = tensor(0.0821, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030967712402344\n",
            "g_norm = tensor(0.0823, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036255836486816\n",
            "g_norm = tensor(0.0893, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.86041259765625\n",
            "||∇_X meta|| = 0.0015246541006490588\n",
            "ΔX norm: 1.5246532711898908e-05\n",
            "Stage 10/10:  89%|████████████████████████▊   | 266/300 [10:38<01:20,  2.38s/it]T Loss=2.3035085201263428\n",
            "g_norm = tensor(0.0887, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028807640075684\n",
            "g_norm = tensor(0.0781, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303493022918701\n",
            "g_norm = tensor(0.0842, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302922248840332\n",
            "g_norm = tensor(0.0855, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030447959899902\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.62088012695312\n",
            "||∇_X meta|| = 0.0015701577067375183\n",
            "ΔX norm: 1.5701567463111132e-05\n",
            "Stage 10/10:  89%|████████████████████████▉   | 267/300 [10:40<01:17,  2.33s/it]T Loss=2.3035330772399902\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033106327056885\n",
            "g_norm = tensor(0.1070, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032584190368652\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031177520751953\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3039581775665283\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.82196044921875\n",
            "||∇_X meta|| = 0.001617533853277564\n",
            "ΔX norm: 1.6175355995073915e-05\n",
            "Stage 10/10:  89%|█████████████████████████   | 268/300 [10:42<01:14,  2.34s/it]T Loss=2.303708553314209\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043417930603027\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034117221832275\n",
            "g_norm = tensor(0.0902, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303623914718628\n",
            "g_norm = tensor(0.1014, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038182258605957\n",
            "g_norm = tensor(0.0968, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.6529083251953\n",
            "||∇_X meta|| = 0.0015735841589048505\n",
            "ΔX norm: 1.5735851775389165e-05\n",
            "Stage 10/10:  90%|█████████████████████████   | 269/300 [10:45<01:11,  2.32s/it]T Loss=2.302546739578247\n",
            "g_norm = tensor(0.1148, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30385160446167\n",
            "g_norm = tensor(0.1079, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303311586380005\n",
            "g_norm = tensor(0.1350, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033556938171387\n",
            "g_norm = tensor(0.1211, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038439750671387\n",
            "g_norm = tensor(0.1212, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.70103454589844\n",
            "||∇_X meta|| = 0.0014966264134272933\n",
            "ΔX norm: 1.4966260096116457e-05\n",
            "Stage 10/10:  90%|█████████████████████████▏  | 270/300 [10:47<01:08,  2.30s/it]T Loss=2.302661418914795\n",
            "g_norm = tensor(0.1535, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034491539001465\n",
            "g_norm = tensor(0.1432, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3024840354919434\n",
            "g_norm = tensor(0.1386, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030624389648438\n",
            "g_norm = tensor(0.1601, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3025412559509277\n",
            "g_norm = tensor(0.1341, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.0853271484375\n",
            "||∇_X meta|| = 0.0016046174569055438\n",
            "ΔX norm: 1.6046153177740052e-05\n",
            "Stage 10/10:  90%|█████████████████████████▎  | 271/300 [10:49<01:10,  2.43s/it]T Loss=2.3037197589874268\n",
            "g_norm = tensor(0.0830, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042006492614746\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3026270866394043\n",
            "g_norm = tensor(0.0967, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032889366149902\n",
            "g_norm = tensor(0.0783, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037891387939453\n",
            "g_norm = tensor(0.0891, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.5497589111328\n",
            "||∇_X meta|| = 0.0015202683862298727\n",
            "ΔX norm: 1.520269870525226e-05\n",
            "Stage 10/10:  91%|█████████████████████████▍  | 272/300 [10:52<01:08,  2.44s/it]T Loss=2.3032398223876953\n",
            "g_norm = tensor(0.1280, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303981304168701\n",
            "g_norm = tensor(0.1098, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038203716278076\n",
            "g_norm = tensor(0.1164, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3046977519989014\n",
            "g_norm = tensor(0.1175, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034775257110596\n",
            "g_norm = tensor(0.1162, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.66384887695312\n",
            "||∇_X meta|| = 0.001558165648020804\n",
            "ΔX norm: 1.5581656043650582e-05\n",
            "Stage 10/10:  91%|█████████████████████████▍  | 273/300 [10:54<01:05,  2.42s/it]T Loss=2.303253412246704\n",
            "g_norm = tensor(0.1614, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30159068107605\n",
            "g_norm = tensor(0.1496, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302168369293213\n",
            "g_norm = tensor(0.1699, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032116889953613\n",
            "g_norm = tensor(0.1600, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037073612213135\n",
            "g_norm = tensor(0.1509, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.606689453125\n",
            "||∇_X meta|| = 0.0015842100838199258\n",
            "ΔX norm: 1.5842124412301928e-05\n",
            "Stage 10/10:  91%|█████████████████████████▌  | 274/300 [10:57<01:01,  2.38s/it]T Loss=2.3034307956695557\n",
            "g_norm = tensor(0.1028, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303422689437866\n",
            "g_norm = tensor(0.1118, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030009269714355\n",
            "g_norm = tensor(0.0985, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028182983398438\n",
            "g_norm = tensor(0.1127, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303049087524414\n",
            "g_norm = tensor(0.1132, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.8165283203125\n",
            "||∇_X meta|| = 0.0014480717945843935\n",
            "ΔX norm: 1.4480724530585576e-05\n",
            "Stage 10/10:  92%|█████████████████████████▋  | 275/300 [10:59<00:58,  2.35s/it]T Loss=2.3050525188446045\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037242889404297\n",
            "g_norm = tensor(0.0892, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035502433776855\n",
            "g_norm = tensor(0.1049, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036231994628906\n",
            "g_norm = tensor(0.1185, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043768405914307\n",
            "g_norm = tensor(0.0905, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.45314025878906\n",
            "||∇_X meta|| = 0.0015591231640428305\n",
            "ΔX norm: 1.559121119498741e-05\n",
            "Stage 10/10:  92%|█████████████████████████▊  | 276/300 [11:01<00:55,  2.30s/it]T Loss=2.3047759532928467\n",
            "g_norm = tensor(0.1493, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303004026412964\n",
            "g_norm = tensor(0.1298, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305206775665283\n",
            "g_norm = tensor(0.1728, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048782348632812\n",
            "g_norm = tensor(0.1447, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30472469329834\n",
            "g_norm = tensor(0.1743, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.3068084716797\n",
            "||∇_X meta|| = 0.001655292115174234\n",
            "ΔX norm: 1.6552918168599717e-05\n",
            "Stage 10/10:  92%|█████████████████████████▊  | 277/300 [11:04<00:54,  2.37s/it]T Loss=2.303095817565918\n",
            "g_norm = tensor(0.1453, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303755044937134\n",
            "g_norm = tensor(0.1058, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3027923107147217\n",
            "g_norm = tensor(0.1275, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305527925491333\n",
            "g_norm = tensor(0.1591, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034825325012207\n",
            "g_norm = tensor(0.1220, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.21803283691406\n",
            "||∇_X meta|| = 0.0016409485833719373\n",
            "ΔX norm: 1.640948721615132e-05\n",
            "Stage 10/10:  93%|█████████████████████████▉  | 278/300 [11:06<00:51,  2.35s/it]T Loss=2.3031201362609863\n",
            "g_norm = tensor(0.0938, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029098510742188\n",
            "g_norm = tensor(0.0879, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036348819732666\n",
            "g_norm = tensor(0.0815, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030951023101807\n",
            "g_norm = tensor(0.0859, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303006649017334\n",
            "g_norm = tensor(0.0788, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.02467346191406\n",
            "||∇_X meta|| = 0.0016708829207345843\n",
            "ΔX norm: 1.6708807379473e-05\n",
            "Stage 10/10:  93%|██████████████████████████  | 279/300 [11:08<00:48,  2.32s/it]T Loss=2.3028578758239746\n",
            "g_norm = tensor(0.1706, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304098606109619\n",
            "g_norm = tensor(0.1502, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031654357910156\n",
            "g_norm = tensor(0.1343, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028459548950195\n",
            "g_norm = tensor(0.1488, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035030364990234\n",
            "g_norm = tensor(0.1486, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.764892578125\n",
            "||∇_X meta|| = 0.0015308188740164042\n",
            "ΔX norm: 1.5308176443795674e-05\n",
            "Stage 10/10:  93%|██████████████████████████▏ | 280/300 [11:10<00:45,  2.27s/it]T Loss=2.3041815757751465\n",
            "g_norm = tensor(0.1030, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037209510803223\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036041259765625\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041138648986816\n",
            "g_norm = tensor(0.0929, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040664196014404\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.78378295898438\n",
            "||∇_X meta|| = 0.001724153640680015\n",
            "ΔX norm: 1.7241554814972915e-05\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 10/10:  94%|██████████████████████████▏ | 281/300 [11:13<00:42,  2.26s/it]T Loss=2.3040852546691895\n",
            "g_norm = tensor(0.0874, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303183078765869\n",
            "g_norm = tensor(0.0867, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031485080718994\n",
            "g_norm = tensor(0.1090, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303182601928711\n",
            "g_norm = tensor(0.0974, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303424596786499\n",
            "g_norm = tensor(0.0821, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.59544372558594\n",
            "||∇_X meta|| = 0.0014247074723243713\n",
            "ΔX norm: 1.4247078070184216e-05\n",
            "Stage 10/10:  94%|██████████████████████████▎ | 282/300 [11:16<00:46,  2.58s/it]T Loss=2.3043107986450195\n",
            "g_norm = tensor(0.1527, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3048744201660156\n",
            "g_norm = tensor(0.1553, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044791221618652\n",
            "g_norm = tensor(0.1510, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052313327789307\n",
            "g_norm = tensor(0.1330, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305039882659912\n",
            "g_norm = tensor(0.1509, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.55511474609375\n",
            "||∇_X meta|| = 0.0013655837392434478\n",
            "ΔX norm: 1.3655867405759636e-05\n",
            "Stage 10/10:  94%|██████████████████████████▍ | 283/300 [11:18<00:42,  2.52s/it]T Loss=2.3043644428253174\n",
            "g_norm = tensor(0.1116, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302889347076416\n",
            "g_norm = tensor(0.1291, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304476261138916\n",
            "g_norm = tensor(0.1128, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3032708168029785\n",
            "g_norm = tensor(0.1284, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044521808624268\n",
            "g_norm = tensor(0.1076, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.22874450683594\n",
            "||∇_X meta|| = 0.0015117302536964417\n",
            "ΔX norm: 1.5117292605282273e-05\n",
            "Stage 10/10:  95%|██████████████████████████▌ | 284/300 [11:21<00:39,  2.48s/it]T Loss=2.3037421703338623\n",
            "g_norm = tensor(0.0949, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044798374176025\n",
            "g_norm = tensor(0.0900, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303725481033325\n",
            "g_norm = tensor(0.0828, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304091453552246\n",
            "g_norm = tensor(0.0981, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054275512695312\n",
            "g_norm = tensor(0.1019, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.2030792236328\n",
            "||∇_X meta|| = 0.0014571725623682141\n",
            "ΔX norm: 1.4571732208423782e-05\n",
            "Stage 10/10:  95%|██████████████████████████▌ | 285/300 [11:23<00:36,  2.45s/it]T Loss=2.30458402633667\n",
            "g_norm = tensor(0.1398, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042123317718506\n",
            "g_norm = tensor(0.1312, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3031678199768066\n",
            "g_norm = tensor(0.1469, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304973602294922\n",
            "g_norm = tensor(0.1351, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3030779361724854\n",
            "g_norm = tensor(0.1425, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.67958068847656\n",
            "||∇_X meta|| = 0.001605700934305787\n",
            "ΔX norm: 1.6056999811553396e-05\n",
            "Stage 10/10:  95%|██████████████████████████▋ | 286/300 [11:26<00:35,  2.56s/it]T Loss=2.303502321243286\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3054912090301514\n",
            "g_norm = tensor(0.1563, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3028347492218018\n",
            "g_norm = tensor(0.1693, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029513359069824\n",
            "g_norm = tensor(0.1416, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304222822189331\n",
            "g_norm = tensor(0.1103, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.60882568359375\n",
            "||∇_X meta|| = 0.0016422267071902752\n",
            "ΔX norm: 1.642228198761586e-05\n",
            "Stage 10/10:  96%|██████████████████████████▊ | 287/300 [11:29<00:34,  2.68s/it]T Loss=2.3034896850585938\n",
            "g_norm = tensor(0.0931, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041434288024902\n",
            "g_norm = tensor(0.1295, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045172691345215\n",
            "g_norm = tensor(0.1363, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304187536239624\n",
            "g_norm = tensor(0.1345, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038482666015625\n",
            "g_norm = tensor(0.1319, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.84201049804688\n",
            "||∇_X meta|| = 0.0018399672117084265\n",
            "ΔX norm: 1.8399670807411894e-05\n",
            "Stage 10/10:  96%|██████████████████████████▉ | 288/300 [11:31<00:30,  2.58s/it]T Loss=2.304729700088501\n",
            "g_norm = tensor(0.1655, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058505058288574\n",
            "g_norm = tensor(0.1230, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.305511951446533\n",
            "g_norm = tensor(0.1174, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3061110973358154\n",
            "g_norm = tensor(0.1170, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304992914199829\n",
            "g_norm = tensor(0.1336, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.9364013671875\n",
            "||∇_X meta|| = 0.0014722002670168877\n",
            "ΔX norm: 1.4722013474965934e-05\n",
            "Stage 10/10:  96%|██████████████████████████▉ | 289/300 [11:34<00:30,  2.74s/it]T Loss=2.3035449981689453\n",
            "g_norm = tensor(0.0788, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303525924682617\n",
            "g_norm = tensor(0.0871, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3041186332702637\n",
            "g_norm = tensor(0.0840, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303694248199463\n",
            "g_norm = tensor(0.0962, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035669326782227\n",
            "g_norm = tensor(0.0946, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.2397918701172\n",
            "||∇_X meta|| = 0.0017580860294401646\n",
            "ΔX norm: 1.758085454639513e-05\n",
            "Stage 10/10:  97%|███████████████████████████ | 290/300 [11:37<00:26,  2.66s/it]T Loss=2.305156707763672\n",
            "g_norm = tensor(0.1165, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3061232566833496\n",
            "g_norm = tensor(0.1103, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058252334594727\n",
            "g_norm = tensor(0.1056, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3052268028259277\n",
            "g_norm = tensor(0.1176, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30422043800354\n",
            "g_norm = tensor(0.1237, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.96371459960938\n",
            "||∇_X meta|| = 0.001754472847096622\n",
            "ΔX norm: 1.754471850290429e-05\n",
            "Stage 10/10:  97%|███████████████████████████▏| 291/300 [11:39<00:22,  2.52s/it]T Loss=2.30412220954895\n",
            "g_norm = tensor(0.1065, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304452896118164\n",
            "g_norm = tensor(0.1006, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304259777069092\n",
            "g_norm = tensor(0.0957, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303906202316284\n",
            "g_norm = tensor(0.0961, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3042664527893066\n",
            "g_norm = tensor(0.1129, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.99267578125\n",
            "||∇_X meta|| = 0.001502707600593567\n",
            "ΔX norm: 1.5027073459350504e-05\n",
            "Stage 10/10:  97%|███████████████████████████▎| 292/300 [11:41<00:19,  2.38s/it]T Loss=2.3024706840515137\n",
            "g_norm = tensor(0.1036, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302001953125\n",
            "g_norm = tensor(0.0998, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304264783859253\n",
            "g_norm = tensor(0.0865, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3033175468444824\n",
            "g_norm = tensor(0.0889, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303626775741577\n",
            "g_norm = tensor(0.0922, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.05897521972656\n",
            "||∇_X meta|| = 0.001762667903676629\n",
            "ΔX norm: 1.7626667613512836e-05\n",
            "Stage 10/10:  98%|███████████████████████████▎| 293/300 [11:43<00:16,  2.38s/it]T Loss=2.304677724838257\n",
            "g_norm = tensor(0.1778, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304692506790161\n",
            "g_norm = tensor(0.1782, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303539991378784\n",
            "g_norm = tensor(0.1448, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040614128112793\n",
            "g_norm = tensor(0.1663, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040502071380615\n",
            "g_norm = tensor(0.1680, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.27574157714844\n",
            "||∇_X meta|| = 0.0014711810508742929\n",
            "ΔX norm: 1.4711796211486217e-05\n",
            "Stage 10/10:  98%|███████████████████████████▍| 294/300 [11:46<00:14,  2.37s/it]T Loss=2.3039042949676514\n",
            "g_norm = tensor(0.0953, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3051159381866455\n",
            "g_norm = tensor(0.0954, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3036112785339355\n",
            "g_norm = tensor(0.1027, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3044626712799072\n",
            "g_norm = tensor(0.0966, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303623676300049\n",
            "g_norm = tensor(0.1112, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =231.49583435058594\n",
            "||∇_X meta|| = 0.001444692024961114\n",
            "ΔX norm: 1.4446943168877624e-05\n",
            "Stage 10/10:  98%|███████████████████████████▌| 295/300 [11:48<00:12,  2.45s/it]T Loss=2.3036272525787354\n",
            "g_norm = tensor(0.1417, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3037781715393066\n",
            "g_norm = tensor(0.1203, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303338050842285\n",
            "g_norm = tensor(0.1380, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.302522659301758\n",
            "g_norm = tensor(0.1516, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3043391704559326\n",
            "g_norm = tensor(0.1267, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.18411254882812\n",
            "||∇_X meta|| = 0.0015670278808102012\n",
            "ΔX norm: 1.567025356052909e-05\n",
            "Stage 10/10:  99%|███████████████████████████▋| 296/300 [11:51<00:09,  2.48s/it]T Loss=2.3037493228912354\n",
            "g_norm = tensor(0.0976, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3040757179260254\n",
            "g_norm = tensor(0.1143, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304222583770752\n",
            "g_norm = tensor(0.1083, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.30328106880188\n",
            "g_norm = tensor(0.1039, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3047544956207275\n",
            "g_norm = tensor(0.1044, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.3002166748047\n",
            "||∇_X meta|| = 0.001623081392608583\n",
            "ΔX norm: 1.6230804249062203e-05\n",
            "Stage 10/10:  99%|███████████████████████████▋| 297/300 [11:54<00:07,  2.58s/it]T Loss=2.3026115894317627\n",
            "g_norm = tensor(0.1126, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3034420013427734\n",
            "g_norm = tensor(0.1168, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3058981895446777\n",
            "g_norm = tensor(0.1310, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045384883880615\n",
            "g_norm = tensor(0.1074, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304788112640381\n",
            "g_norm = tensor(0.1046, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.65122985839844\n",
            "||∇_X meta|| = 0.0014952663332223892\n",
            "ΔX norm: 1.495266224083025e-05\n",
            "Stage 10/10:  99%|███████████████████████████▊| 298/300 [11:56<00:04,  2.46s/it]T Loss=2.3032963275909424\n",
            "g_norm = tensor(0.0959, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3038337230682373\n",
            "g_norm = tensor(0.0761, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3045482635498047\n",
            "g_norm = tensor(0.0886, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3035197257995605\n",
            "g_norm = tensor(0.0918, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.303109645843506\n",
            "g_norm = tensor(0.0862, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =230.92919921875\n",
            "||∇_X meta|| = 0.001527095795609057\n",
            "ΔX norm: 1.527096173958853e-05\n",
            "Stage 10/10: 100%|███████████████████████████▉| 299/300 [11:58<00:02,  2.38s/it]T Loss=2.302150249481201\n",
            "g_norm = tensor(0.1292, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3023908138275146\n",
            "g_norm = tensor(0.1257, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.3029232025146484\n",
            "g_norm = tensor(0.1231, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304788589477539\n",
            "g_norm = tensor(0.1273, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "T Loss=2.304394483566284\n",
            "g_norm = tensor(0.1340, grad_fn=<LinalgVectorNormBackward0>)\n",
            "alpha_t= 0.0010000233305618167\n",
            "K Loss      =229.44163513183594\n",
            "||∇_X meta|| = 0.0015514851547777653\n",
            "ΔX norm: 1.5514833648921922e-05\n",
            "Stage 9, class 0, loss 2.207                                                    \n",
            "Stage 9, class 1, loss 2.270\n",
            "Stage 9, class 2, loss 2.339\n",
            "Stage 9, class 3, loss 2.355\n",
            "Stage 9, class 4, loss 2.308\n",
            "Stage 9, class 5, loss 2.330\n",
            "Stage 9, class 6, loss 2.384\n",
            "Stage 9, class 7, loss 2.232\n",
            "Stage 9, class 8, loss 2.362\n",
            "Stage 9, class 9, loss 2.253\n",
            "     - Distilled time = 6457.92 seconds\n",
            "     - Saving...\n",
            "     - model saved to data/checkpoints/meta-model-matching_cifar10_convnet.pth\n",
            "     - distilled dataset & history saved to data/Distilled/meta-model-matching_cifar10_convnet.pt\n",
            "     - Plotted & saved stage 1 → assets/viz_synthetic/synthetic_stage_01.png\n",
            "     - Plotted & saved stage 2 → assets/viz_synthetic/synthetic_stage_02.png\n",
            "     - Plotted & saved stage 3 → assets/viz_synthetic/synthetic_stage_03.png\n",
            "     - Plotted & saved stage 4 → assets/viz_synthetic/synthetic_stage_04.png\n",
            "     - Plotted & saved stage 5 → assets/viz_synthetic/synthetic_stage_05.png\n",
            "     - Plotted & saved stage 6 → assets/viz_synthetic/synthetic_stage_06.png\n",
            "     - Plotted & saved stage 7 → assets/viz_synthetic/synthetic_stage_07.png\n",
            "     - Plotted & saved stage 8 → assets/viz_synthetic/synthetic_stage_08.png\n",
            "     - Plotted & saved stage 9 → assets/viz_synthetic/synthetic_stage_09.png\n",
            "     - Plotted & saved stage 10 → assets/viz_synthetic/synthetic_stage_10.png\n",
            "     - Done.\n"
          ]
        }
      ],
      "source": [
        "!python main.py meta-model-matching \\\n",
        "    --dataset cifar10 \\\n",
        "    --model convnet \\\n",
        "    --batch-size 32 \\\n",
        "    --ipc 10 \\\n",
        "    --P 10 \\\n",
        "    --K 300 \\\n",
        "    --T 5 \\\n",
        "    --lr-model 1e-3 \\\n",
        "    --lr-syn-data 1e-2 \\\n",
        "    --regularisation 1 \\\n",
        "    --syn-optimizer momentum \\\n",
        "    --inner-optimizer momentum \\\n",
        "    --debug True \\\n",
        "    --out-dir data/Distilled \\\n",
        "    --ckpt-dir data/checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Aggregation"
      ],
      "metadata": {
        "id": "QbNWrxlBvGVW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1aUIB2wUuDSK",
        "outputId": "241ae19e-091a-4947-b35b-3f1878e1c969",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Dataloader]:\n",
            "     - Loading...\n",
            "100% 9.91M/9.91M [00:01<00:00, 5.07MB/s]\n",
            "100% 28.9k/28.9k [00:00<00:00, 133kB/s]\n",
            "100% 1.65M/1.65M [00:06<00:00, 245kB/s]\n",
            "100% 4.54k/4.54k [00:00<00:00, 13.2MB/s]\n",
            "     - Done.\n",
            "[Distillator]:\n",
            "Stage 1/5:   0% 0/50 [00:00<?, ?it/s]     - Model 1: T Loss      =[tensor(2.3040, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6250, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.08606026321649551\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3040, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6250, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 506.1029357910156\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.2790, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.2778, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 14.975476264953613\n",
            "ΔX norm:       0.14975474774837494\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/5:   2% 1/50 [00:03<02:37,  3.22s/it]     - Model 1: T Loss      =[tensor(2.3045, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5561, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.08787456154823303\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3045, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5561, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 410.8484191894531\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3175, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.3682, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 9.049980163574219\n",
            "ΔX norm:       0.09049980342388153\n",
            "Stage 1/5:   4% 2/50 [00:03<01:15,  1.57s/it]     - Model 1: T Loss      =[tensor(2.3032, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3795, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.10887306928634644\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3032, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3795, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 332.0315246582031\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3031, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.5447, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 11.472094535827637\n",
            "ΔX norm:       0.11472094804048538\n",
            "Stage 1/5:   6% 3/50 [00:04<00:48,  1.03s/it]     - Model 1: T Loss      =[tensor(2.3035, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4470, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.092833511531353\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3035, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4470, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 528.004150390625\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3037, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.4329, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 9.35273265838623\n",
            "ΔX norm:       0.09352732449769974\n",
            "Stage 1/5:   8% 4/50 [00:04<00:35,  1.28it/s]     - Model 1: T Loss      =[tensor(2.3033, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.1799, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.09892912954092026\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3033, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.1799, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 276.40484619140625\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3103, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.4738, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 7.565638065338135\n",
            "ΔX norm:       0.07565637677907944\n",
            "Stage 1/5:  10% 5/50 [00:04<00:28,  1.56it/s]     - Model 1: T Loss      =[tensor(2.3035, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4162, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.09337678551673889\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3035, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4162, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 396.20953369140625\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3042, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.6127, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 15.454524040222168\n",
            "ΔX norm:       0.15454523265361786\n",
            "Stage 1/5:  12% 6/50 [00:05<00:24,  1.80it/s]     - Model 1: T Loss      =[tensor(2.3021, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3263, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.12944819033145905\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3021, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3263, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 618.509521484375\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3010, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.3973, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 18.767894744873047\n",
            "ΔX norm:       0.18767894804477692\n",
            "Stage 1/5:  14% 7/50 [00:05<00:21,  1.98it/s]     - Model 1: T Loss      =[tensor(2.3036, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.2842, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.08236686140298843\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3036, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.2842, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 476.9749755859375\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3161, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.4037, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 12.695868492126465\n",
            "ΔX norm:       0.1269586831331253\n",
            "Stage 1/5:  16% 8/50 [00:06<00:19,  2.14it/s]     - Model 1: T Loss      =[tensor(2.3022, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4670, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.08701109141111374\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3022, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4670, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 288.8099670410156\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3063, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.2977, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 7.392420768737793\n",
            "ΔX norm:       0.07392420619726181\n",
            "Stage 1/5:  18% 9/50 [00:06<00:18,  2.22it/s]     - Model 1: T Loss      =[tensor(2.3041, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3448, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.09075821191072464\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3041, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3448, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 350.1508483886719\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3046, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.5378, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 13.603321075439453\n",
            "ΔX norm:       0.13603320717811584\n",
            "Stage 1/5:  20% 10/50 [00:06<00:17,  2.30it/s]     - Model 1: T Loss      =[tensor(2.3027, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3813, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.10478617995977402\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3027, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3813, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 461.1825256347656\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3015, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.4702, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 10.176169395446777\n",
            "ΔX norm:       0.10176169872283936\n",
            "Stage 1/5:  22% 11/50 [00:07<00:16,  2.36it/s]     - Model 1: T Loss      =[tensor(2.3026, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3850, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.1170726791024208\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3026, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3850, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 410.8493347167969\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3098, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.6454, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 12.040772438049316\n",
            "ΔX norm:       0.12040772289037704\n",
            "Stage 1/5:  24% 12/50 [00:07<00:15,  2.41it/s]     - Model 1: T Loss      =[tensor(2.3038, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6107, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.08266346156597137\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3038, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6107, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 285.3957214355469\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.2791, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.3919, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 8.248629570007324\n",
            "ΔX norm:       0.08248628675937653\n",
            "Stage 1/5:  26% 13/50 [00:07<00:15,  2.45it/s]     - Model 1: T Loss      =[tensor(2.3039, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4698, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.07453550398349762\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3039, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4698, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 406.6202087402344\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3231, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.5466, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 12.534109115600586\n",
            "ΔX norm:       0.12534108757972717\n",
            "Stage 1/5:  28% 14/50 [00:08<00:14,  2.45it/s]     - Model 1: T Loss      =[tensor(2.3039, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4985, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.09931737184524536\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3039, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4985, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 340.852294921875\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.2975, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.6611, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 5.982326984405518\n",
            "ΔX norm:       0.05982327088713646\n",
            "Stage 1/5:  30% 15/50 [00:08<00:14,  2.47it/s]     - Model 1: T Loss      =[tensor(2.3037, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4727, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.10090731084346771\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3037, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4727, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 496.1640319824219\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.2929, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.4446, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 17.04738426208496\n",
            "ΔX norm:       0.1704738289117813\n",
            "Stage 1/5:  32% 16/50 [00:09<00:13,  2.49it/s]     - Model 1: T Loss      =[tensor(2.3036, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4743, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.09466418623924255\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3036, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4743, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 634.856689453125\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.2933, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.5287, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 21.938114166259766\n",
            "ΔX norm:       0.21938113868236542\n",
            "Stage 1/5:  34% 17/50 [00:09<00:13,  2.48it/s]     - Model 1: T Loss      =[tensor(2.3038, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4276, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.0924791768193245\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3038, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4276, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 393.9618835449219\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3142, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.6103, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 5.693210124969482\n",
            "ΔX norm:       0.05693209916353226\n",
            "Stage 1/5:  36% 18/50 [00:09<00:12,  2.50it/s]     - Model 1: T Loss      =[tensor(2.3035, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4298, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.0905177891254425\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3035, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4298, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 554.452880859375\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3016, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.5335, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 38.34494400024414\n",
            "ΔX norm:       0.3834494650363922\n",
            "Stage 1/5:  38% 19/50 [00:10<00:12,  2.50it/s]     - Model 1: T Loss      =[tensor(2.3032, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5799, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.11081265658140182\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3032, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5799, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 253.83139038085938\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3162, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.6462, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 29.7236270904541\n",
            "ΔX norm:       0.29723626375198364\n",
            "Stage 1/5:  40% 20/50 [00:10<00:11,  2.51it/s]     - Model 1: T Loss      =[tensor(2.3052, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4066, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.09647764265537262\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3052, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4066, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 405.3598327636719\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3101, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.6184, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 10.414953231811523\n",
            "ΔX norm:       0.10414952784776688\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/5:  42% 21/50 [00:11<00:11,  2.51it/s]     - Model 1: T Loss      =[tensor(2.3049, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5158, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.08436474949121475\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3049, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5158, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 277.4492492675781\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3154, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.6518, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 5.348691940307617\n",
            "ΔX norm:       0.05348691716790199\n",
            "Stage 1/5:  44% 22/50 [00:11<00:11,  2.50it/s]     - Model 1: T Loss      =[tensor(2.3032, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4644, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.09021788090467453\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3032, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4644, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 428.2900695800781\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3070, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.1998, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 14.095086097717285\n",
            "ΔX norm:       0.14095085859298706\n",
            "Stage 1/5:  46% 23/50 [00:11<00:10,  2.52it/s]     - Model 1: T Loss      =[tensor(2.3040, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.2995, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.10692373663187027\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3040, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.2995, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 491.2742614746094\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3183, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.4349, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 22.258798599243164\n",
            "ΔX norm:       0.22258798778057098\n",
            "Stage 1/5:  48% 24/50 [00:12<00:10,  2.52it/s]     - Model 1: T Loss      =[tensor(2.3039, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4463, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.10218385607004166\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3039, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4463, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 350.47186279296875\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.2891, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.2783, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 7.780725479125977\n",
            "ΔX norm:       0.07780724763870239\n",
            "Stage 1/5:  50% 25/50 [00:12<00:09,  2.52it/s]     - Model 1: T Loss      =[tensor(2.3033, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6056, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.07716044783592224\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3033, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.6056, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 406.07757568359375\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3120, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.6593, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 15.718429565429688\n",
            "ΔX norm:       0.15718428790569305\n",
            "Stage 1/5:  52% 26/50 [00:13<00:09,  2.54it/s]     - Model 1: T Loss      =[tensor(2.3040, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4369, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.11505228281021118\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3040, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4369, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 361.4341125488281\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3058, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.4697, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 15.506426811218262\n",
            "ΔX norm:       0.15506426990032196\n",
            "Stage 1/5:  54% 27/50 [00:13<00:09,  2.45it/s]     - Model 1: T Loss      =[tensor(2.3043, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4744, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.09638950973749161\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3043, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4744, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 442.8325500488281\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.2929, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.5722, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 16.840478897094727\n",
            "ΔX norm:       0.16840477287769318\n",
            "Stage 1/5:  56% 28/50 [00:14<00:08,  2.46it/s]     - Model 1: T Loss      =[tensor(2.3048, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4018, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.09883043169975281\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3048, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4018, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 375.88427734375\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.2931, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.4641, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 10.37015438079834\n",
            "ΔX norm:       0.10370153933763504\n",
            "Stage 1/5:  58% 29/50 [00:14<00:08,  2.47it/s]     - Model 1: T Loss      =[tensor(2.3036, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4099, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.08575188368558884\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3036, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4099, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 473.96954345703125\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.2999, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.4389, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 18.136648178100586\n",
            "ΔX norm:       0.1813664734363556\n",
            "Stage 1/5:  60% 30/50 [00:14<00:08,  2.48it/s]     - Model 1: T Loss      =[tensor(2.3034, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3336, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.0920979455113411\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3034, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3336, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 530.3421630859375\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3052, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.3397, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 13.426408767700195\n",
            "ΔX norm:       0.13426408171653748\n",
            "Stage 1/5:  62% 31/50 [00:15<00:07,  2.50it/s]     - Model 1: T Loss      =[tensor(2.3039, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5327, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.08406342566013336\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3039, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5327, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 342.0265808105469\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.2971, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.6078, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 14.969243049621582\n",
            "ΔX norm:       0.14969243109226227\n",
            "Stage 1/5:  64% 32/50 [00:15<00:07,  2.49it/s]     - Model 1: T Loss      =[tensor(2.3041, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.2721, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.08182980120182037\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3041, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.2721, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 505.816162109375\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3174, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.3756, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 11.298654556274414\n",
            "ΔX norm:       0.11298654228448868\n",
            "Stage 1/5:  66% 33/50 [00:15<00:06,  2.51it/s]     - Model 1: T Loss      =[tensor(2.3031, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3140, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.10324828326702118\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3031, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3140, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 358.2539978027344\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.2886, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.4104, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 14.84835433959961\n",
            "ΔX norm:       0.148483544588089\n",
            "Stage 1/5:  68% 34/50 [00:16<00:06,  2.51it/s]     - Model 1: T Loss      =[tensor(2.3045, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3889, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.12989318370819092\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3045, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3889, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 331.3337707519531\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3108, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.4858, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 12.601503372192383\n",
            "ΔX norm:       0.12601502239704132\n",
            "Stage 1/5:  70% 35/50 [00:16<00:05,  2.52it/s]     - Model 1: T Loss      =[tensor(2.3050, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4215, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.10486331582069397\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3050, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4215, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 455.4464416503906\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3061, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.3126, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 17.9597110748291\n",
            "ΔX norm:       0.17959710955619812\n",
            "Stage 1/5:  72% 36/50 [00:17<00:05,  2.54it/s]     - Model 1: T Loss      =[tensor(2.3041, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3586, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.06465435773134232\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3041, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3586, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 373.7146301269531\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3157, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.3780, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 12.36784553527832\n",
            "ΔX norm:       0.12367844581604004\n",
            "Stage 1/5:  74% 37/50 [00:17<00:05,  2.55it/s]     - Model 1: T Loss      =[tensor(2.3021, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4885, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.08824116736650467\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3021, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4885, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 387.4071044921875\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.2971, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.4812, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 16.45581817626953\n",
            "ΔX norm:       0.16455818712711334\n",
            "Stage 1/5:  76% 38/50 [00:17<00:04,  2.56it/s]     - Model 1: T Loss      =[tensor(2.3046, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4399, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.087369903922081\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3046, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4399, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 415.416015625\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3034, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.4779, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 14.51850700378418\n",
            "ΔX norm:       0.14518506824970245\n",
            "Stage 1/5:  78% 39/50 [00:18<00:04,  2.56it/s]     - Model 1: T Loss      =[tensor(2.3054, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3937, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.11766300350427628\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3054, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3937, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 513.1886596679688\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3164, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.3888, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 19.73485565185547\n",
            "ΔX norm:       0.19734854996204376\n",
            "Stage 1/5:  80% 40/50 [00:18<00:03,  2.50it/s]     - Model 1: T Loss      =[tensor(2.3052, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4744, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.06912852823734283\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3052, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4744, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 436.5675354003906\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3049, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.5712, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 10.681732177734375\n",
            "ΔX norm:       0.1068173199892044\n",
            "Saved synthetic image grid to assets/debug/synthetic.png\n",
            "Stage 1/5:  82% 41/50 [00:19<00:03,  2.46it/s]     - Model 1: T Loss      =[tensor(2.3037, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3902, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.08639246225357056\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3037, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3902, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 286.5592956542969\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3252, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.3486, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 14.032596588134766\n",
            "ΔX norm:       0.14032596349716187\n",
            "Stage 1/5:  84% 42/50 [00:19<00:03,  2.46it/s]     - Model 1: T Loss      =[tensor(2.3033, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4569, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.0901583805680275\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3033, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4569, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 415.833740234375\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.2959, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.3613, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 18.499195098876953\n",
            "ΔX norm:       0.1849919557571411\n",
            "Stage 1/5:  86% 43/50 [00:19<00:02,  2.49it/s]     - Model 1: T Loss      =[tensor(2.3036, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5894, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.09447535127401352\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3036, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5894, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 368.32672119140625\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.2970, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.4314, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 13.22962474822998\n",
            "ΔX norm:       0.13229624927043915\n",
            "Stage 1/5:  88% 44/50 [00:20<00:02,  2.50it/s]     - Model 1: T Loss      =[tensor(2.3037, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3735, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.09324103593826294\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3037, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3735, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 516.4248657226562\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.2962, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.3601, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 13.595695495605469\n",
            "ΔX norm:       0.13595694303512573\n",
            "Stage 1/5:  90% 45/50 [00:20<00:02,  2.45it/s]     - Model 1: T Loss      =[tensor(2.3045, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4995, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.09068526327610016\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3045, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4995, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 401.71063232421875\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.3078, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.5288, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 16.563098907470703\n",
            "ΔX norm:       0.1656309962272644\n",
            "Stage 1/5:  92% 46/50 [00:21<00:01,  2.49it/s]     - Model 1: T Loss      =[tensor(2.3031, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3599, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.11058346182107925\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3031, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.3599, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 338.0098876953125\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.2892, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.4258, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 13.23381519317627\n",
            "ΔX norm:       0.13233815133571625\n",
            "Stage 1/5:  94% 47/50 [00:21<00:01,  2.49it/s]     - Model 1: T Loss      =[tensor(2.3046, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4671, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.09247300028800964\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3046, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.4671, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 405.900634765625\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.2954, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.4778, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 13.994579315185547\n",
            "ΔX norm:       0.13994579017162323\n",
            "Stage 1/5:  96% 48/50 [00:21<00:00,  2.51it/s]     - Model 1: T Loss      =[tensor(2.3047, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5038, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.07982807606458664\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3047, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5038, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 352.5445251464844\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.2910, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.7262, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 7.2508416175842285\n",
            "ΔX norm:       0.07250840961933136\n",
            "Stage 1/5:  98% 49/50 [00:22<00:00,  2.53it/s]     - Model 1: T Loss      =[tensor(2.3029, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5067, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 1: g_norm      = 0.12580333650112152\n",
            "     - Model 1: alpha_t     = 0.0010000233305618167\n",
            "     - Model 2: T Loss      =[tensor(2.3029, device='cuda:0', grad_fn=<DivBackward0>), tensor(2.5067, device='cuda:0', grad_fn=<DivBackward0>)]\n",
            "     - Model 2: g_norm      = 492.17547607421875\n",
            "     - Model 2: alpha_t     = 0.0010000233305618167\n",
            "K Losses    =[tensor(2.2966, device='cuda:0', grad_fn=<AddBackward0>), tensor(2.4128, device='cuda:0', grad_fn=<AddBackward0>)]\n",
            "||∇_X meta|| = 16.613954544067383\n",
            "ΔX norm:       0.16613954305648804\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/main.py\", line 468, in <module>\n",
            "    main()\n",
            "  File \"/content/main.py\", line 465, in main\n",
            "    args.func(args)    \n",
            "    ^^^^^^^^^^^^^^^\n",
            "  File \"/content/main.py\", line 101, in cmd_ga\n",
            "    X_syn, Y_syn = pdd.distill()\n",
            "                   ^^^^^^^^^^^^^\n",
            "  File \"/content/Distillations/PDD_GA.py\", line 279, in distill\n",
            "    losses_c = [F.cross_entropy(net(x_r), y_r) for net in nets]\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Distillations/PDD_GA.py\", line 279, in <listcomp>\n",
            "    losses_c = [F.cross_entropy(net(x_r), y_r) for net in nets]\n",
            "                                ^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/Models/model.py\", line 39, in forward\n",
            "    x = self.features(x)\n",
            "        ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "            ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 554, in forward\n",
            "    return self._conv_forward(input, self.weight, self.bias)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\", line 549, in _conv_forward\n",
            "    return F.conv2d(\n",
            "           ^^^^^^^^^\n",
            "RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor\n"
          ]
        }
      ],
      "source": [
        "!python main.py gradient-aggregation \\\n",
        "    --dataset mnist \\\n",
        "    --model convnet resnet10\\\n",
        "    --batch-size 32 \\\n",
        "    --ipc 1 \\\n",
        "    --P 5 \\\n",
        "    --K 50 \\\n",
        "    --T 1 \\\n",
        "    --lr-model 1e-3 \\\n",
        "    --lr-syn-data 1e-2 \\\n",
        "    --syn-optimizer momentum \\\n",
        "    --inner-optimizer momentum \\\n",
        "    --debug True \\\n",
        "    --out-dir data/Distilled \\\n",
        "    --ckpt-dir data/checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py gradient-aggregation \\\n",
        "    --dataset cifar10 \\\n",
        "    --model convnet resnet10\\\n",
        "    --batch-size 32 \\\n",
        "    --ipc 10 \\\n",
        "    --P 10 \\\n",
        "    --K 300 \\\n",
        "    --T 5 \\\n",
        "    --lr-model 1e-3 \\\n",
        "    --lr-syn-data 1e-2 \\\n",
        "    --regularisation 1 \\\n",
        "    --syn-optimizer momentum \\\n",
        "    --inner-optimizer momentum \\\n",
        "    --debug True \\\n",
        "    --out-dir data/Distilled \\\n",
        "    --ckpt-dir data/checkpoints"
      ],
      "metadata": {
        "id": "75UcwHNIvS8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkLw7LYSuDSK"
      },
      "source": [
        "### Benchmarking of Distilled Dataset (dev - accuracy performance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZxCDqATuDSK",
        "outputId": "0637865e-8e05-4469-c4ce-545a13cc39e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Benchmarker]:\n",
            "     - Using device: cpu\n",
            "     - Loading distilled data from data/Distilled/meta-model-matching_cifar10_convnet.pt\n",
            "     - Total synthetic examples = 1000; real subset size = 1000\n",
            "\n",
            "     - [Syn] Stage 1/10: 100 examples\n",
            "       - Epoch 1/10 → loss 2.3099\n",
            "       - Epoch 2/10 → loss 2.3013\n",
            "       - Epoch 3/10 → loss 2.2967\n",
            "       - Epoch 4/10 → loss 2.2881\n",
            "       - Epoch 5/10 → loss 2.2760\n",
            "       - Epoch 6/10 → loss 2.2452\n",
            "       - Epoch 7/10 → loss 2.2044\n",
            "       - Epoch 8/10 → loss 2.1363\n",
            "       - Epoch 9/10 → loss 2.0434\n",
            "       - Epoch 10/10 → loss 1.9242\n",
            "\n",
            "     - [Syn] Stage 2/10: 100 examples\n",
            "       - Epoch 1/10 → loss 1.8214\n",
            "       - Epoch 2/10 → loss 1.6980\n",
            "       - Epoch 3/10 → loss 1.5841\n",
            "       - Epoch 4/10 → loss 1.4594\n",
            "       - Epoch 5/10 → loss 1.3280\n",
            "       - Epoch 6/10 → loss 1.2482\n",
            "       - Epoch 7/10 → loss 1.0842\n",
            "       - Epoch 8/10 → loss 0.9600\n",
            "       - Epoch 9/10 → loss 0.9304\n",
            "       - Epoch 10/10 → loss 0.8757\n",
            "\n",
            "     - [Syn] Stage 3/10: 100 examples\n",
            "       - Epoch 1/10 → loss 0.8667\n",
            "       - Epoch 2/10 → loss 0.8318\n",
            "       - Epoch 3/10 → loss 0.7826\n",
            "       - Epoch 4/10 → loss 0.8628\n",
            "       - Epoch 5/10 → loss 0.7182\n",
            "       - Epoch 6/10 → loss 0.6853\n",
            "       - Epoch 7/10 → loss 0.6440\n",
            "       - Epoch 8/10 → loss 0.6466\n",
            "       - Epoch 9/10 → loss 0.6027\n",
            "       - Epoch 10/10 → loss 0.6356\n",
            "\n",
            "     - [Syn] Stage 4/10: 100 examples\n",
            "       - Epoch 1/10 → loss 0.7952\n",
            "       - Epoch 2/10 → loss 0.6737\n",
            "       - Epoch 3/10 → loss 0.7174\n",
            "       - Epoch 4/10 → loss 0.6336\n",
            "       - Epoch 5/10 → loss 0.6675\n",
            "       - Epoch 6/10 → loss 0.6527\n",
            "       - Epoch 7/10 → loss 0.6118\n",
            "       - Epoch 8/10 → loss 0.5928\n",
            "       - Epoch 9/10 → loss 0.5916\n",
            "       - Epoch 10/10 → loss 0.5602\n",
            "\n",
            "     - [Syn] Stage 5/10: 100 examples\n",
            "       - Epoch 1/10 → loss 0.7429\n",
            "       - Epoch 2/10 → loss 0.7628\n",
            "       - Epoch 3/10 → loss 0.7216\n",
            "       - Epoch 4/10 → loss 0.7066\n",
            "       - Epoch 5/10 → loss 0.6774\n",
            "       - Epoch 6/10 → loss 0.6782\n",
            "       - Epoch 7/10 → loss 0.6315\n",
            "       - Epoch 8/10 → loss 0.6182\n",
            "       - Epoch 9/10 → loss 0.5878\n",
            "       - Epoch 10/10 → loss 0.5832\n",
            "\n",
            "     - [Syn] Stage 6/10: 100 examples\n",
            "       - Epoch 1/10 → loss 0.6226\n",
            "       - Epoch 2/10 → loss 0.5559\n",
            "       - Epoch 3/10 → loss 0.5999\n",
            "       - Epoch 4/10 → loss 0.5687\n",
            "       - Epoch 5/10 → loss 0.5306\n",
            "       - Epoch 6/10 → loss 0.5268\n",
            "       - Epoch 7/10 → loss 0.5040\n",
            "       - Epoch 8/10 → loss 0.4829\n",
            "       - Epoch 9/10 → loss 0.4518\n",
            "       - Epoch 10/10 → loss 0.4915\n",
            "\n",
            "     - [Syn] Stage 7/10: 100 examples\n",
            "       - Epoch 1/10 → loss 0.5292\n",
            "       - Epoch 2/10 → loss 0.4224\n",
            "       - Epoch 3/10 → loss 0.4444\n",
            "       - Epoch 4/10 → loss 0.4296\n",
            "       - Epoch 5/10 → loss 0.4109\n",
            "       - Epoch 6/10 → loss 0.3562\n",
            "       - Epoch 7/10 → loss 0.3445\n",
            "       - Epoch 8/10 → loss 0.3197\n",
            "       - Epoch 9/10 → loss 0.2953\n",
            "       - Epoch 10/10 → loss 0.2804\n",
            "\n",
            "     - [Syn] Stage 8/10: 100 examples\n",
            "       - Epoch 1/10 → loss 0.4567\n",
            "       - Epoch 2/10 → loss 0.4228\n",
            "       - Epoch 3/10 → loss 0.4286\n",
            "       - Epoch 4/10 → loss 0.4198\n",
            "       - Epoch 5/10 → loss 0.4663\n",
            "       - Epoch 6/10 → loss 0.4853\n",
            "       - Epoch 7/10 → loss 0.4582\n",
            "       - Epoch 8/10 → loss 0.3997\n",
            "       - Epoch 9/10 → loss 0.4655\n",
            "       - Epoch 10/10 → loss 0.3517\n",
            "\n",
            "     - [Syn] Stage 9/10: 100 examples\n",
            "       - Epoch 1/10 → loss 0.5184\n",
            "       - Epoch 2/10 → loss 0.6312\n",
            "       - Epoch 3/10 → loss 0.5699\n",
            "       - Epoch 4/10 → loss 0.4970\n",
            "       - Epoch 5/10 → loss 0.5260\n",
            "       - Epoch 6/10 → loss 0.4995\n",
            "       - Epoch 7/10 → loss 0.4223\n",
            "       - Epoch 8/10 → loss 0.4978\n",
            "       - Epoch 9/10 → loss 0.3824\n",
            "       - Epoch 10/10 → loss 0.3876\n",
            "\n",
            "     - [Syn] Stage 10/10: 100 examples\n",
            "       - Epoch 1/10 → loss 0.5725\n",
            "       - Epoch 2/10 → loss 0.4876\n",
            "       - Epoch 3/10 → loss 0.5327\n",
            "       - Epoch 4/10 → loss 0.4981\n",
            "       - Epoch 5/10 → loss 0.4770\n",
            "       - Epoch 6/10 → loss 0.4732\n",
            "       - Epoch 7/10 → loss 0.4562\n",
            "       - Epoch 8/10 → loss 0.4484\n",
            "       - Epoch 9/10 → loss 0.4209\n",
            "       - Epoch 10/10 → loss 0.4003\n",
            "\n",
            "     - Evaluating on real cifar10 test set…\n",
            "Final test accuracy on real cifar10: 27.85%\n"
          ]
        }
      ],
      "source": [
        "!python main.py benchmark \\\n",
        "    --distilled-path data/Distilled/meta-model-matching_cifar10_convnet.pt \\\n",
        "    --benchmark-mode synthetic \\\n",
        "    --model convnet \\\n",
        "    --syn-batch-size 64 \\\n",
        "    --test-batch-size 64 \\\n",
        "    --lr 1e-3  \\\n",
        "    --epochs-per-stage 10 \\\n",
        "    --till-stage 10 \\\n",
        "    --real-size 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7M60xcEuDSK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}