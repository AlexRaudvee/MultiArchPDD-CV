{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexRaudvee/MultiArchPDD-CV/blob/main/main_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup of environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TLPdrWx1evU",
        "outputId": "f3936cac-c245-4826-f6da-70f93c8f49eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "def mount_google_drive(mount_point: Path = Path('/content/drive')) -> Path:\n",
        "    \"\"\"Mounts Google Drive and returns the mount point.\"\"\"\n",
        "    drive.mount(str(mount_point))\n",
        "    return mount_point\n",
        "\n",
        "def extract_zip(zip_path: Path, extract_to: Path) -> None:\n",
        "    \"\"\"Extracts a zip file to the given directory.\"\"\"\n",
        "    if not zip_path.is_file():\n",
        "        raise FileNotFoundError(f\"Could not find zip file at {zip_path}\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "        z.extractall(str(extract_to))\n",
        "\n",
        "def move_contents(src_dir: Path, dst_dir: Path) -> None:\n",
        "    \"\"\"\n",
        "    Moves everything from src_dir into dst_dir.\n",
        "    Overwrites any existing files or folders of the same name.\n",
        "    Cleans up the now-empty src_dir at the end.\n",
        "    \"\"\"\n",
        "    if not src_dir.is_dir():\n",
        "        raise FileNotFoundError(f\"{src_dir} does not exist\")\n",
        "    for item in src_dir.iterdir():\n",
        "        target = dst_dir / item.name\n",
        "        if target.exists():\n",
        "            print(f\"Warning: {target} already exists, overwriting\")\n",
        "            if target.is_dir():\n",
        "                shutil.rmtree(target)\n",
        "            else:\n",
        "                target.unlink()\n",
        "        shutil.move(str(item), str(target))\n",
        "    src_dir.rmdir()\n",
        "\n",
        "def setup_directories(*dirs: Path) -> None:\n",
        "    \"\"\"Ensures that each directory in `dirs` exists.\"\"\"\n",
        "    for d in dirs:\n",
        "        d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def zip_folder(folder_path: Path, output_path: Path) -> None:\n",
        "    \"\"\"\n",
        "    Recursively zip the contents of folder_path into a .zip file at output_path.\n",
        "    \"\"\"\n",
        "    with zipfile.ZipFile(output_path, 'w', compression=zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, _, files in os.walk(folder_path):\n",
        "            for fname in files:\n",
        "                fpath = Path(root) / fname\n",
        "                arcname = fpath.relative_to(folder_path)\n",
        "                zipf.write(str(fpath), arcname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ——— Constants ———\n",
        "DRIVE_MOUNT_POINT = Path('/content/drive')\n",
        "ZIP_PATH            = DRIVE_MOUNT_POINT / 'MyDrive/.colab.zip'\n",
        "EXTRACT_TO          = Path('/content')\n",
        "SRC_DIR             = EXTRACT_TO / '.colab'\n",
        "DST_DIR             = EXTRACT_TO\n",
        "DISTILLED_DIR       = EXTRACT_TO / 'data' / 'Distilled'\n",
        "MODEL_DIR           = EXTRACT_TO / 'data' / 'checkpoints'\n",
        "ASSETS_DIR          = EXTRACT_TO / 'assets' / 'viz_synthetic'\n",
        "\n",
        "# ——— SetUp ———\n",
        "mount_google_drive(DRIVE_MOUNT_POINT)\n",
        "extract_zip(ZIP_PATH, EXTRACT_TO)\n",
        "move_contents(SRC_DIR, DST_DIR)\n",
        "setup_directories(DISTILLED_DIR)\n",
        "setup_directories(ASSETS_DIR)\n",
        "setup_directories(MODEL_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Launch of Dataset Distillation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Dataloader]:\n",
            "     - Loading...\n",
            "     - Done.\n",
            "[Distillator]:\n",
            "/usr/local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "     - Saving...                                                                \n",
            "     - models saved to ['data/checkpoints/mult-branch_mnist_convnet.pth', 'data/checkpoints/mult-branch_mnist_lenet.pth']\n",
            "     - distilled dataset & history saved to data/Distilled/mult-branch_mnist_convnet_lenet.pt\n",
            "     - Plotted & saved stage 1 → assets/viz_synthetic/synthetic_stage_01.png\n",
            "     - Done.\n"
          ]
        }
      ],
      "source": [
        "!python main.py multi-branch \\\n",
        "    --dataset mnist \\\n",
        "    --model convnet lenet \\\n",
        "    --batch-size 64 \\\n",
        "    --ipc 2 \\\n",
        "    --P 1 \\\n",
        "    --K 1 \\\n",
        "    --T 1 \\\n",
        "    --lr-model 1e-3 \\\n",
        "    --lr-syn-data 1e-2 \\\n",
        "    --syn-optimizer adam \\\n",
        "    --inner-optimizer momentum \\\n",
        "    --debug False \\\n",
        "    --out-dir data/Distilled \\\n",
        "    --ckpt-dir data/checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Dataloader]:\n",
            "     - Loading...\n",
            "     - Done.\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/workspaces/MultiArchPDD-CV/scripts/run_distill.py\", line 141, in <module>\n",
            "    main()\n",
            "  File \"/workspaces/MultiArchPDD-CV/scripts/run_distill.py\", line 112, in main\n",
            "    X_syn, Y_syn = pdd.distill()\n",
            "                   ^^^^^^^^^^^^^\n",
            "  File \"/workspaces/MultiArchPDD-CV/distillation/PDD.py\", line 101, in distill\n",
            "    syn_opt = Adam(opt_params,\n",
            "              ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/site-packages/torch/optim/adam.py\", line 100, in __init__\n",
            "    super().__init__(params, defaults)\n",
            "  File \"/usr/local/lib/python3.12/site-packages/torch/optim/optimizer.py\", line 369, in __init__\n",
            "    self.add_param_group(cast(dict, param_group))\n",
            "  File \"/usr/local/lib/python3.12/site-packages/torch/_compile.py\", line 51, in inner\n",
            "    return disable_fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py\", line 838, in _fn\n",
            "    return fn(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/site-packages/torch/optim/optimizer.py\", line 1056, in add_param_group\n",
            "    raise ValueError(\"can't optimize a non-leaf Tensor\")\n",
            "ValueError: can't optimize a non-leaf Tensor\n"
          ]
        }
      ],
      "source": [
        "!python -m scripts.run_distill \\\n",
        "  --pdd-core mm-match \\\n",
        "  --dataset cifar10 \\\n",
        "  --model convnet \\\n",
        "  --batch-size 64 \\\n",
        "  --synthetic-size 10 \\\n",
        "  --P 1 \\\n",
        "  --K 1 \\\n",
        "  --T 1 \\\n",
        "  --lr-model 1e-3 \\\n",
        "  --lr-syn-data 1e-2 \\\n",
        "  --syn-optimizer adam \\\n",
        "  --inner-optimizer momentum \\\n",
        "  --out-dir data/Distilled \\\n",
        "  --ckpt-dir data/checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Benchmarking of Distilled Dataset (dev - accuracy performance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Benchmarker]:\n",
            "     - Using device: cpu\n",
            "     - Loading distilled data from data/Distilled/cmps-loss_mnist_lenet_convnet.pt\n",
            "     - Total synthetic examples = 40; real subset size = 1000\n",
            "\n",
            "     - [Real] Sampling 1000 examples from real mnist train split\n",
            "     - [Real] Training for 5 total epochs on real data\n",
            "\n",
            "     - Epoch 1/5 → loss 2.2248\n",
            "     - Epoch 2/5 → loss 1.3308\n",
            "     - Epoch 3/5 → loss 0.6539\n",
            "     - Epoch 4/5 → loss 0.4139\n",
            "     - Epoch 5/5 → loss 0.2905\n",
            "\n",
            "     - Evaluating on real mnist test set…\n",
            "Final test accuracy on real mnist: 88.70%\n"
          ]
        }
      ],
      "source": [
        "!python main.py benchmark \\\n",
        "    --distilled-path data/Distilled/cmps-loss_mnist_lenet_convnet.pt \\\n",
        "    --benchmark-mode real \\\n",
        "    --model convnet \\\n",
        "    --syn-batch-size 64 \\\n",
        "    --test-batch-size 256 \\\n",
        "    --lr 1e-3  \\\n",
        "    --epochs-per-stage 5 \\\n",
        "    --till-stage 1 \\\n",
        "    --real-size 1000 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
