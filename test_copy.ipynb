{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Meta Loss: 2.3014073371887207, Synthetic Data Grad Norm: 0.00023451208835467696\n",
      "Epoch 0, Meta Loss: 2.3062636852264404, Synthetic Data Grad Norm: 0.00018316101341042668\n",
      "Epoch 0, Meta Loss: 2.2943055629730225, Synthetic Data Grad Norm: 0.00022500810155179352\n",
      "Epoch 0, Meta Loss: 2.338576078414917, Synthetic Data Grad Norm: 0.0002465610159561038\n",
      "Epoch 0, Meta Loss: 2.2824208736419678, Synthetic Data Grad Norm: 0.00019406000501476228\n",
      "Epoch 0, Meta Loss: 2.293628215789795, Synthetic Data Grad Norm: 0.00020671387028414756\n",
      "Epoch 0, Meta Loss: 2.325824737548828, Synthetic Data Grad Norm: 0.00021623716747853905\n",
      "Epoch 0, Meta Loss: 2.3228230476379395, Synthetic Data Grad Norm: 0.00023001639056019485\n",
      "Epoch 0, Meta Loss: 2.313199043273926, Synthetic Data Grad Norm: 0.00020561102428473532\n",
      "Epoch 0, Meta Loss: 2.3036396503448486, Synthetic Data Grad Norm: 0.00016873315325938165\n",
      "Epoch 0, Meta Loss: 2.30584454536438, Synthetic Data Grad Norm: 0.0002702000201679766\n",
      "Epoch 0, Meta Loss: 2.30875301361084, Synthetic Data Grad Norm: 0.00028489145915955305\n",
      "Epoch 0, Meta Loss: 2.2929482460021973, Synthetic Data Grad Norm: 0.00018199199985247105\n",
      "Epoch 0, Meta Loss: 2.3106961250305176, Synthetic Data Grad Norm: 0.000256323313806206\n",
      "Epoch 0, Meta Loss: 2.3136885166168213, Synthetic Data Grad Norm: 0.00021973601542413235\n",
      "Epoch 0, Meta Loss: 2.2939276695251465, Synthetic Data Grad Norm: 0.00017718711751513183\n",
      "Epoch 0, Meta Loss: 2.3143794536590576, Synthetic Data Grad Norm: 0.0001749468792695552\n",
      "Epoch 0, Meta Loss: 2.3077473640441895, Synthetic Data Grad Norm: 0.00022215630451682955\n",
      "Epoch 0, Meta Loss: 2.301379919052124, Synthetic Data Grad Norm: 0.00017735804431140423\n",
      "Epoch 0, Meta Loss: 2.3140945434570312, Synthetic Data Grad Norm: 0.00026911398163065314\n",
      "Epoch 0, Meta Loss: 2.3158488273620605, Synthetic Data Grad Norm: 0.00019237777451053262\n",
      "Epoch 0, Meta Loss: 2.3130805492401123, Synthetic Data Grad Norm: 0.00027253219741396606\n",
      "Epoch 0, Meta Loss: 2.303588390350342, Synthetic Data Grad Norm: 0.00020197713456582278\n",
      "Epoch 0, Meta Loss: 2.298980712890625, Synthetic Data Grad Norm: 0.00018540449673309922\n",
      "Epoch 0, Meta Loss: 2.3052995204925537, Synthetic Data Grad Norm: 0.0002026382862823084\n",
      "Epoch 0, Meta Loss: 2.3118557929992676, Synthetic Data Grad Norm: 0.00023982053971849382\n",
      "Epoch 0, Meta Loss: 2.3074347972869873, Synthetic Data Grad Norm: 0.00024943926837295294\n",
      "Epoch 0, Meta Loss: 2.32063364982605, Synthetic Data Grad Norm: 0.0002505290030967444\n",
      "Epoch 0, Meta Loss: 2.2883434295654297, Synthetic Data Grad Norm: 0.00027152581606060266\n",
      "Epoch 0, Meta Loss: 2.3202288150787354, Synthetic Data Grad Norm: 0.00022502362844534218\n",
      "Epoch 0, Meta Loss: 2.3079144954681396, Synthetic Data Grad Norm: 0.00019645309657789767\n",
      "Epoch 0, Meta Loss: 2.310927629470825, Synthetic Data Grad Norm: 0.0002321268111700192\n",
      "Epoch 0, Meta Loss: 2.3238391876220703, Synthetic Data Grad Norm: 0.00020352855790406466\n",
      "Epoch 0, Meta Loss: 2.288679838180542, Synthetic Data Grad Norm: 0.00019586602866183966\n",
      "Epoch 0, Meta Loss: 2.3262927532196045, Synthetic Data Grad Norm: 0.00023729696113150567\n",
      "Epoch 0, Meta Loss: 2.309166669845581, Synthetic Data Grad Norm: 0.0003166213573422283\n",
      "Epoch 0, Meta Loss: 2.312134027481079, Synthetic Data Grad Norm: 0.00016841088654473424\n",
      "Epoch 0, Meta Loss: 2.2994792461395264, Synthetic Data Grad Norm: 0.00029165748856030405\n",
      "Epoch 0, Meta Loss: 2.317981719970703, Synthetic Data Grad Norm: 0.0002095099480357021\n",
      "Epoch 0, Meta Loss: 2.313120126724243, Synthetic Data Grad Norm: 0.0002234242419945076\n",
      "Epoch 0, Meta Loss: 2.3217387199401855, Synthetic Data Grad Norm: 0.00024405853764619678\n",
      "Epoch 0, Meta Loss: 2.3016610145568848, Synthetic Data Grad Norm: 0.0002143886376870796\n",
      "Epoch 0, Meta Loss: 2.2960338592529297, Synthetic Data Grad Norm: 0.00019370894005987793\n",
      "Epoch 0, Meta Loss: 2.3341946601867676, Synthetic Data Grad Norm: 0.00023468515428248793\n",
      "Epoch 0, Meta Loss: 2.300781726837158, Synthetic Data Grad Norm: 0.000308455026242882\n",
      "Epoch 0, Meta Loss: 2.30031681060791, Synthetic Data Grad Norm: 0.0002217411674791947\n",
      "Epoch 0, Meta Loss: 2.3166463375091553, Synthetic Data Grad Norm: 0.00022025148791726679\n",
      "Epoch 0, Meta Loss: 2.308368444442749, Synthetic Data Grad Norm: 0.0001641869021113962\n",
      "Epoch 0, Meta Loss: 2.306443214416504, Synthetic Data Grad Norm: 0.0002171727392124012\n",
      "Epoch 0, Meta Loss: 2.2879414558410645, Synthetic Data Grad Norm: 0.00019847661314997822\n",
      "Epoch 0, Meta Loss: 2.310049295425415, Synthetic Data Grad Norm: 0.000243506976403296\n",
      "Epoch 0, Meta Loss: 2.3075573444366455, Synthetic Data Grad Norm: 0.00018925954645965248\n",
      "Epoch 0, Meta Loss: 2.2822909355163574, Synthetic Data Grad Norm: 0.00020430579024832696\n",
      "Epoch 0, Meta Loss: 2.3153269290924072, Synthetic Data Grad Norm: 0.00023150056949816644\n",
      "Epoch 0, Meta Loss: 2.3073744773864746, Synthetic Data Grad Norm: 0.0002969124470837414\n",
      "Epoch 0, Meta Loss: 2.295379638671875, Synthetic Data Grad Norm: 0.00015710547449998558\n",
      "Epoch 0, Meta Loss: 2.3181772232055664, Synthetic Data Grad Norm: 0.00012845911260228604\n",
      "Epoch 0, Meta Loss: 2.3018360137939453, Synthetic Data Grad Norm: 0.0002366241387790069\n",
      "Epoch 0, Meta Loss: 2.323228597640991, Synthetic Data Grad Norm: 0.00026756804436445236\n",
      "Epoch 0, Meta Loss: 2.3229334354400635, Synthetic Data Grad Norm: 0.00017279818712268025\n",
      "Epoch 0, Meta Loss: 2.2999234199523926, Synthetic Data Grad Norm: 0.00014110046322457492\n",
      "Epoch 0, Meta Loss: 2.300675630569458, Synthetic Data Grad Norm: 0.0002788646088447422\n",
      "Epoch 0, Meta Loss: 2.3084864616394043, Synthetic Data Grad Norm: 0.000244826398557052\n",
      "Epoch 0, Meta Loss: 2.316845417022705, Synthetic Data Grad Norm: 0.00025747864856384695\n",
      "Epoch 0, Meta Loss: 2.3015401363372803, Synthetic Data Grad Norm: 0.00019020959734916687\n",
      "Epoch 0, Meta Loss: 2.306946277618408, Synthetic Data Grad Norm: 0.00019552810408640653\n",
      "Epoch 0, Meta Loss: 2.3171324729919434, Synthetic Data Grad Norm: 0.00021981322788633406\n",
      "Epoch 0, Meta Loss: 2.315699338912964, Synthetic Data Grad Norm: 0.00025404684129171073\n",
      "Epoch 0, Meta Loss: 2.3357605934143066, Synthetic Data Grad Norm: 0.0002605543122626841\n",
      "Epoch 0, Meta Loss: 2.3115193843841553, Synthetic Data Grad Norm: 0.0003014039830304682\n",
      "Epoch 0, Meta Loss: 2.3265135288238525, Synthetic Data Grad Norm: 0.000248049502260983\n",
      "Epoch 0, Meta Loss: 2.309669256210327, Synthetic Data Grad Norm: 0.00023513160704169422\n",
      "Epoch 0, Meta Loss: 2.297571897506714, Synthetic Data Grad Norm: 0.00016525184037163854\n",
      "Epoch 0, Meta Loss: 2.313581705093384, Synthetic Data Grad Norm: 0.00022144395916257054\n",
      "Epoch 0, Meta Loss: 2.3057100772857666, Synthetic Data Grad Norm: 0.00015246818657033145\n",
      "Epoch 0, Meta Loss: 2.3281543254852295, Synthetic Data Grad Norm: 0.00021464606106746942\n",
      "Epoch 0, Meta Loss: 2.291717767715454, Synthetic Data Grad Norm: 0.0003067783545702696\n",
      "Epoch 0, Meta Loss: 2.2888519763946533, Synthetic Data Grad Norm: 0.00023439482902176678\n",
      "Epoch 0, Meta Loss: 2.3028154373168945, Synthetic Data Grad Norm: 0.0002383017708780244\n",
      "Epoch 0, Meta Loss: 2.2985422611236572, Synthetic Data Grad Norm: 0.0002238359593320638\n",
      "Epoch 0, Meta Loss: 2.299933433532715, Synthetic Data Grad Norm: 0.0001898203045129776\n",
      "Epoch 0, Meta Loss: 2.2935831546783447, Synthetic Data Grad Norm: 0.000217811917536892\n",
      "Epoch 0, Meta Loss: 2.30151104927063, Synthetic Data Grad Norm: 0.0002196371351601556\n",
      "Epoch 0, Meta Loss: 2.2950491905212402, Synthetic Data Grad Norm: 0.0002800044894684106\n",
      "Epoch 0, Meta Loss: 2.302621841430664, Synthetic Data Grad Norm: 0.00018939320580102503\n",
      "Epoch 0, Meta Loss: 2.293936014175415, Synthetic Data Grad Norm: 0.0002656845608726144\n",
      "Epoch 0, Meta Loss: 2.321209192276001, Synthetic Data Grad Norm: 0.0002728636609390378\n",
      "Epoch 0, Meta Loss: 2.3054213523864746, Synthetic Data Grad Norm: 0.00024882625439204276\n",
      "Epoch 0, Meta Loss: 2.2978270053863525, Synthetic Data Grad Norm: 0.00024099685833789408\n",
      "Epoch 0, Meta Loss: 2.307659387588501, Synthetic Data Grad Norm: 0.00016336327826138586\n",
      "Epoch 0, Meta Loss: 2.3188750743865967, Synthetic Data Grad Norm: 0.0002597796556074172\n",
      "Epoch 0, Meta Loss: 2.307652235031128, Synthetic Data Grad Norm: 0.0001493729796493426\n",
      "Epoch 0, Meta Loss: 2.3194689750671387, Synthetic Data Grad Norm: 0.00020083694835193455\n",
      "Epoch 0, Meta Loss: 2.3172309398651123, Synthetic Data Grad Norm: 0.00023776151647325605\n",
      "Epoch 0, Meta Loss: 2.3129639625549316, Synthetic Data Grad Norm: 0.0002435414062347263\n",
      "Epoch 0, Meta Loss: 2.318632125854492, Synthetic Data Grad Norm: 0.0002056972443824634\n",
      "Epoch 0, Meta Loss: 2.3001275062561035, Synthetic Data Grad Norm: 0.00022331818763632327\n",
      "Epoch 0, Meta Loss: 2.30633807182312, Synthetic Data Grad Norm: 0.00017823789676185697\n",
      "Epoch 0, Meta Loss: 2.320464611053467, Synthetic Data Grad Norm: 0.0003262776299379766\n",
      "Epoch 0, Meta Loss: 2.3272366523742676, Synthetic Data Grad Norm: 0.0002880085085052997\n",
      "Epoch 0, Meta Loss: 2.30649733543396, Synthetic Data Grad Norm: 0.00023966968001332134\n",
      "Epoch 0, Meta Loss: 2.294894218444824, Synthetic Data Grad Norm: 0.00017732138803694397\n",
      "Epoch 0, Meta Loss: 2.2876508235931396, Synthetic Data Grad Norm: 0.00024420631234534085\n",
      "Epoch 0, Meta Loss: 2.3006069660186768, Synthetic Data Grad Norm: 0.00020749626855831593\n",
      "Epoch 0, Meta Loss: 2.296760320663452, Synthetic Data Grad Norm: 0.00025468628155067563\n",
      "Epoch 0, Meta Loss: 2.293790102005005, Synthetic Data Grad Norm: 0.00029979762621223927\n",
      "Epoch 0, Meta Loss: 2.2979729175567627, Synthetic Data Grad Norm: 0.00020729893003590405\n",
      "Epoch 0, Meta Loss: 2.305570125579834, Synthetic Data Grad Norm: 0.00018553250993136317\n",
      "Epoch 0, Meta Loss: 2.2926034927368164, Synthetic Data Grad Norm: 0.0002009687596000731\n",
      "Epoch 0, Meta Loss: 2.3233046531677246, Synthetic Data Grad Norm: 0.0002013917692238465\n",
      "Epoch 0, Meta Loss: 2.298516273498535, Synthetic Data Grad Norm: 0.00023052013420965523\n",
      "Epoch 0, Meta Loss: 2.306753158569336, Synthetic Data Grad Norm: 0.00024734289036132395\n",
      "Epoch 0, Meta Loss: 2.312562942504883, Synthetic Data Grad Norm: 0.0002819785731844604\n",
      "Epoch 0, Meta Loss: 2.3055930137634277, Synthetic Data Grad Norm: 0.00020764236978720874\n",
      "Epoch 0, Meta Loss: 2.302583932876587, Synthetic Data Grad Norm: 0.00021645989909302443\n",
      "Epoch 0, Meta Loss: 2.3045341968536377, Synthetic Data Grad Norm: 0.00038682526792399585\n",
      "Epoch 0, Meta Loss: 2.3070871829986572, Synthetic Data Grad Norm: 0.0002336853794986382\n",
      "Epoch 0, Meta Loss: 2.3039164543151855, Synthetic Data Grad Norm: 0.00031924352515488863\n",
      "Epoch 0, Meta Loss: 2.3150546550750732, Synthetic Data Grad Norm: 0.00019270891789346933\n",
      "Epoch 0, Meta Loss: 2.300960063934326, Synthetic Data Grad Norm: 0.00021299040236044675\n",
      "Epoch 0, Meta Loss: 2.3038439750671387, Synthetic Data Grad Norm: 0.00017551964265294373\n",
      "Epoch 0, Meta Loss: 2.29614520072937, Synthetic Data Grad Norm: 0.000222565489821136\n",
      "Epoch 0, Meta Loss: 2.3026010990142822, Synthetic Data Grad Norm: 0.00019078273908235133\n",
      "Epoch 0, Meta Loss: 2.312340021133423, Synthetic Data Grad Norm: 0.00022279919357970357\n",
      "Epoch 0, Meta Loss: 2.3151681423187256, Synthetic Data Grad Norm: 0.00020591724023688585\n",
      "Epoch 0, Meta Loss: 2.29593825340271, Synthetic Data Grad Norm: 0.0002313112054252997\n",
      "Epoch 0, Meta Loss: 2.3208394050598145, Synthetic Data Grad Norm: 0.00022275855008047074\n",
      "Epoch 0, Meta Loss: 2.306823968887329, Synthetic Data Grad Norm: 0.00020263702026568353\n",
      "Epoch 0, Meta Loss: 2.2955124378204346, Synthetic Data Grad Norm: 0.00022901914780959487\n",
      "Epoch 0, Meta Loss: 2.319765329360962, Synthetic Data Grad Norm: 0.000201500064576976\n",
      "Epoch 0, Meta Loss: 2.293975353240967, Synthetic Data Grad Norm: 0.00030901835998520255\n",
      "Epoch 0, Meta Loss: 2.2922065258026123, Synthetic Data Grad Norm: 0.00017634229152463377\n",
      "Epoch 0, Meta Loss: 2.265127420425415, Synthetic Data Grad Norm: 0.00022481477935798466\n",
      "Epoch 0, Meta Loss: 2.3140969276428223, Synthetic Data Grad Norm: 0.00032947244471870363\n",
      "Epoch 0, Meta Loss: 2.3097660541534424, Synthetic Data Grad Norm: 0.0002177151181967929\n",
      "Epoch 0, Meta Loss: 2.3188562393188477, Synthetic Data Grad Norm: 0.00024561965255998075\n",
      "Epoch 0, Meta Loss: 2.3051323890686035, Synthetic Data Grad Norm: 0.0002705207443796098\n",
      "Epoch 0, Meta Loss: 2.297070264816284, Synthetic Data Grad Norm: 0.0002070288173854351\n",
      "Epoch 0, Meta Loss: 2.294271469116211, Synthetic Data Grad Norm: 0.00023463013349100947\n",
      "Epoch 0, Meta Loss: 2.300875186920166, Synthetic Data Grad Norm: 0.00022388579964172095\n",
      "Epoch 0, Meta Loss: 2.3165175914764404, Synthetic Data Grad Norm: 0.00020825196406804025\n",
      "Epoch 0, Meta Loss: 2.3032143115997314, Synthetic Data Grad Norm: 0.0002537824329920113\n",
      "Epoch 0, Meta Loss: 2.310805082321167, Synthetic Data Grad Norm: 0.00019311779760755599\n",
      "Epoch 0, Meta Loss: 2.3066132068634033, Synthetic Data Grad Norm: 0.00019345100736245513\n",
      "Epoch 0, Meta Loss: 2.3142385482788086, Synthetic Data Grad Norm: 0.00018958121654577553\n",
      "Epoch 0, Meta Loss: 2.3230557441711426, Synthetic Data Grad Norm: 0.00027840115944854915\n",
      "Epoch 0, Meta Loss: 2.3030266761779785, Synthetic Data Grad Norm: 0.00021915473917033523\n",
      "Epoch 0, Meta Loss: 2.31097674369812, Synthetic Data Grad Norm: 0.00019103477825410664\n",
      "Epoch 0, Meta Loss: 2.294018507003784, Synthetic Data Grad Norm: 0.00028056008159182966\n",
      "Epoch 0, Meta Loss: 2.2958202362060547, Synthetic Data Grad Norm: 0.0001941640512086451\n",
      "Epoch 0, Meta Loss: 2.311692237854004, Synthetic Data Grad Norm: 0.00021587889932561666\n",
      "Epoch 0, Meta Loss: 2.2986936569213867, Synthetic Data Grad Norm: 0.00018559031013865024\n",
      "Epoch 0, Meta Loss: 2.2953364849090576, Synthetic Data Grad Norm: 0.00026773189892992377\n",
      "Epoch 0, Meta Loss: 2.292363166809082, Synthetic Data Grad Norm: 0.00023321933986153454\n",
      "Epoch 0, Meta Loss: 2.298142910003662, Synthetic Data Grad Norm: 0.00018708009156398475\n",
      "Epoch 0, Meta Loss: 2.3023135662078857, Synthetic Data Grad Norm: 0.00015876159886829555\n",
      "Epoch 0, Meta Loss: 2.312807321548462, Synthetic Data Grad Norm: 0.00023376249009743333\n",
      "Epoch 0, Meta Loss: 2.288562536239624, Synthetic Data Grad Norm: 0.0002514460647944361\n",
      "Epoch 0, Meta Loss: 2.301778793334961, Synthetic Data Grad Norm: 0.00023166657774709165\n",
      "Epoch 0, Meta Loss: 2.3099074363708496, Synthetic Data Grad Norm: 0.00024279423814732581\n",
      "Epoch 0, Meta Loss: 2.3132219314575195, Synthetic Data Grad Norm: 0.00022806889319326729\n",
      "Epoch 0, Meta Loss: 2.3084511756896973, Synthetic Data Grad Norm: 0.00025834934785962105\n",
      "Epoch 0, Meta Loss: 2.3071558475494385, Synthetic Data Grad Norm: 0.00023342743224930018\n",
      "Epoch 0, Meta Loss: 2.3041672706604004, Synthetic Data Grad Norm: 0.0001484110689489171\n",
      "Epoch 0, Meta Loss: 2.3238685131073, Synthetic Data Grad Norm: 0.0002393579634372145\n",
      "Epoch 0, Meta Loss: 2.3026840686798096, Synthetic Data Grad Norm: 0.00025487111997790635\n",
      "Epoch 0, Meta Loss: 2.28999400138855, Synthetic Data Grad Norm: 0.00013150904851499945\n",
      "Epoch 0, Meta Loss: 2.301140069961548, Synthetic Data Grad Norm: 0.00022738594270776957\n",
      "Epoch 0, Meta Loss: 2.302738904953003, Synthetic Data Grad Norm: 0.00024818224483169615\n",
      "Epoch 0, Meta Loss: 2.2929623126983643, Synthetic Data Grad Norm: 0.0002854850026778877\n",
      "Epoch 0, Meta Loss: 2.3058862686157227, Synthetic Data Grad Norm: 0.0001798868615878746\n",
      "Epoch 0, Meta Loss: 2.3044848442077637, Synthetic Data Grad Norm: 0.00026965636061504483\n",
      "Epoch 0, Meta Loss: 2.2858526706695557, Synthetic Data Grad Norm: 0.00027938460698351264\n",
      "Epoch 0, Meta Loss: 2.3046581745147705, Synthetic Data Grad Norm: 0.0002061417471850291\n",
      "Epoch 0, Meta Loss: 2.29707932472229, Synthetic Data Grad Norm: 0.0002867231669370085\n",
      "Epoch 0, Meta Loss: 2.30846905708313, Synthetic Data Grad Norm: 0.00021327950526028872\n",
      "Epoch 0, Meta Loss: 2.3025577068328857, Synthetic Data Grad Norm: 0.0001854210568126291\n",
      "Epoch 0, Meta Loss: 2.296480178833008, Synthetic Data Grad Norm: 0.00018073308456223458\n",
      "Epoch 0, Meta Loss: 2.302961826324463, Synthetic Data Grad Norm: 0.00019606828573159873\n",
      "Epoch 0, Meta Loss: 2.312020778656006, Synthetic Data Grad Norm: 0.00027412775671109557\n",
      "Epoch 0, Meta Loss: 2.297267198562622, Synthetic Data Grad Norm: 0.00021663900406565517\n",
      "Epoch 0, Meta Loss: 2.290463924407959, Synthetic Data Grad Norm: 0.0002251936384709552\n",
      "Epoch 0, Meta Loss: 2.3142807483673096, Synthetic Data Grad Norm: 0.0002130985667463392\n",
      "Epoch 0, Meta Loss: 2.3033649921417236, Synthetic Data Grad Norm: 0.0001548703876323998\n",
      "Epoch 0, Meta Loss: 2.2946643829345703, Synthetic Data Grad Norm: 0.00029067302239127457\n",
      "Epoch 0, Meta Loss: 2.307281494140625, Synthetic Data Grad Norm: 0.00018748176808003336\n",
      "Epoch 0, Meta Loss: 2.308112382888794, Synthetic Data Grad Norm: 0.0003087393706664443\n",
      "Epoch 0, Meta Loss: 2.306741237640381, Synthetic Data Grad Norm: 0.00020567853061947972\n",
      "Epoch 0, Meta Loss: 2.293543815612793, Synthetic Data Grad Norm: 0.00018241432553622872\n",
      "Epoch 0, Meta Loss: 2.304300546646118, Synthetic Data Grad Norm: 0.00026064066332764924\n",
      "Epoch 0, Meta Loss: 2.301274299621582, Synthetic Data Grad Norm: 0.00018295228073839098\n",
      "Epoch 0, Meta Loss: 2.3015034198760986, Synthetic Data Grad Norm: 0.0001876873429864645\n",
      "Epoch 0, Meta Loss: 2.3147168159484863, Synthetic Data Grad Norm: 0.00019461293413769454\n",
      "Epoch 0, Meta Loss: 2.3013508319854736, Synthetic Data Grad Norm: 0.00016627674631308764\n",
      "Epoch 0, Meta Loss: 2.3114352226257324, Synthetic Data Grad Norm: 0.0002565556496847421\n",
      "Epoch 0, Meta Loss: 2.300276517868042, Synthetic Data Grad Norm: 0.00020254624541848898\n",
      "Epoch 0, Meta Loss: 2.310451030731201, Synthetic Data Grad Norm: 0.00025787638151086867\n",
      "Epoch 0, Meta Loss: 2.309438467025757, Synthetic Data Grad Norm: 0.0003477367281448096\n",
      "Epoch 0, Meta Loss: 2.303443431854248, Synthetic Data Grad Norm: 0.00029491769964806736\n",
      "Epoch 0, Meta Loss: 2.2919766902923584, Synthetic Data Grad Norm: 0.0002742907381616533\n",
      "Epoch 0, Meta Loss: 2.3130815029144287, Synthetic Data Grad Norm: 0.00021907960763201118\n",
      "Epoch 0, Meta Loss: 2.302091360092163, Synthetic Data Grad Norm: 0.00025187325081788003\n",
      "Epoch 0, Meta Loss: 2.2947936058044434, Synthetic Data Grad Norm: 0.00022975778847467154\n",
      "Epoch 0, Meta Loss: 2.3017563819885254, Synthetic Data Grad Norm: 0.00023713038535788655\n",
      "Epoch 0, Meta Loss: 2.309126853942871, Synthetic Data Grad Norm: 0.00026819066260941327\n",
      "Epoch 0, Meta Loss: 2.294706344604492, Synthetic Data Grad Norm: 0.0002065634762402624\n",
      "Epoch 0, Meta Loss: 2.3011891841888428, Synthetic Data Grad Norm: 0.0002495931403245777\n",
      "Epoch 0, Meta Loss: 2.286400318145752, Synthetic Data Grad Norm: 0.00019815433188341558\n",
      "Epoch 0, Meta Loss: 2.301968574523926, Synthetic Data Grad Norm: 0.000282335706287995\n",
      "Epoch 0, Meta Loss: 2.2955548763275146, Synthetic Data Grad Norm: 0.0002030899777309969\n",
      "Epoch 0, Meta Loss: 2.3105814456939697, Synthetic Data Grad Norm: 0.00025728382752276957\n",
      "Epoch 0, Meta Loss: 2.307555675506592, Synthetic Data Grad Norm: 0.00024866702733561397\n",
      "Epoch 0, Meta Loss: 2.2988526821136475, Synthetic Data Grad Norm: 0.00023983456776477396\n",
      "Epoch 0, Meta Loss: 2.296797752380371, Synthetic Data Grad Norm: 0.00024036338436417282\n",
      "Epoch 0, Meta Loss: 2.303252935409546, Synthetic Data Grad Norm: 0.0002127001207554713\n",
      "Epoch 0, Meta Loss: 2.311068296432495, Synthetic Data Grad Norm: 0.0002566129551269114\n",
      "Epoch 0, Meta Loss: 2.294614791870117, Synthetic Data Grad Norm: 0.0002482103300280869\n",
      "Epoch 0, Meta Loss: 2.2923502922058105, Synthetic Data Grad Norm: 0.00022328959312289953\n",
      "Epoch 0, Meta Loss: 2.2947936058044434, Synthetic Data Grad Norm: 0.00027301424415782094\n",
      "Epoch 0, Meta Loss: 2.3016252517700195, Synthetic Data Grad Norm: 0.00021400570403784513\n",
      "Epoch 0, Meta Loss: 2.3231201171875, Synthetic Data Grad Norm: 0.00028163293609395623\n",
      "Epoch 0, Meta Loss: 2.3016114234924316, Synthetic Data Grad Norm: 0.00021148299856577069\n",
      "Epoch 0, Meta Loss: 2.302677631378174, Synthetic Data Grad Norm: 0.0003114225110039115\n",
      "Epoch 0, Meta Loss: 2.3001461029052734, Synthetic Data Grad Norm: 0.00022563467791769654\n",
      "Epoch 0, Meta Loss: 2.3271167278289795, Synthetic Data Grad Norm: 0.0002714663278311491\n",
      "Epoch 0, Meta Loss: 2.316227436065674, Synthetic Data Grad Norm: 0.0003732799377758056\n",
      "Epoch 0, Meta Loss: 2.2872509956359863, Synthetic Data Grad Norm: 0.0002586813934613019\n",
      "Epoch 0, Meta Loss: 2.299328088760376, Synthetic Data Grad Norm: 0.00021482844022102654\n",
      "Epoch 0, Meta Loss: 2.313628911972046, Synthetic Data Grad Norm: 0.0002725892118178308\n",
      "Epoch 0, Meta Loss: 2.313189744949341, Synthetic Data Grad Norm: 0.00016770166985224932\n",
      "Epoch 0, Meta Loss: 2.308762788772583, Synthetic Data Grad Norm: 0.00021042089792899787\n",
      "Epoch 0, Meta Loss: 2.311124801635742, Synthetic Data Grad Norm: 0.00027824388234876096\n",
      "Epoch 0, Meta Loss: 2.327301502227783, Synthetic Data Grad Norm: 0.0002460491959936917\n",
      "Epoch 0, Meta Loss: 2.291304588317871, Synthetic Data Grad Norm: 0.00023235443222802132\n",
      "Epoch 0, Meta Loss: 2.299123764038086, Synthetic Data Grad Norm: 0.0002493735810276121\n",
      "Epoch 0, Meta Loss: 2.3078973293304443, Synthetic Data Grad Norm: 0.00019862642511725426\n",
      "Epoch 0, Meta Loss: 2.3094677925109863, Synthetic Data Grad Norm: 0.00021593680139631033\n",
      "Epoch 0, Meta Loss: 2.3008832931518555, Synthetic Data Grad Norm: 0.00029977477970533073\n",
      "Epoch 0, Meta Loss: 2.3133487701416016, Synthetic Data Grad Norm: 0.00024887037579901516\n",
      "Epoch 0, Meta Loss: 2.3084826469421387, Synthetic Data Grad Norm: 0.0002237977460026741\n",
      "Epoch 0, Meta Loss: 2.3075902462005615, Synthetic Data Grad Norm: 0.00022963120136409998\n",
      "Epoch 0, Meta Loss: 2.3000762462615967, Synthetic Data Grad Norm: 0.0003028318751603365\n",
      "Epoch 0, Meta Loss: 2.3114633560180664, Synthetic Data Grad Norm: 0.0002652919210959226\n",
      "Epoch 0, Meta Loss: 2.3049182891845703, Synthetic Data Grad Norm: 0.00023158710973802954\n",
      "Epoch 0, Meta Loss: 2.2912521362304688, Synthetic Data Grad Norm: 0.00021143388585187495\n",
      "Epoch 0, Meta Loss: 2.318220376968384, Synthetic Data Grad Norm: 0.0002501879062037915\n",
      "Epoch 0, Meta Loss: 2.2981181144714355, Synthetic Data Grad Norm: 0.00024394028878305107\n",
      "Epoch 0, Meta Loss: 2.3306996822357178, Synthetic Data Grad Norm: 0.000303810607874766\n",
      "Epoch 0, Meta Loss: 2.3159103393554688, Synthetic Data Grad Norm: 0.0002454976493027061\n",
      "Epoch 0, Meta Loss: 2.3109233379364014, Synthetic Data Grad Norm: 0.00022728113981429487\n",
      "Epoch 0, Meta Loss: 2.303506851196289, Synthetic Data Grad Norm: 0.00017445483535993844\n",
      "Epoch 0, Meta Loss: 2.2896647453308105, Synthetic Data Grad Norm: 0.00020504645362962037\n",
      "Epoch 0, Meta Loss: 2.289422035217285, Synthetic Data Grad Norm: 0.0003413347585592419\n",
      "Epoch 0, Meta Loss: 2.3043534755706787, Synthetic Data Grad Norm: 0.00021890780772082508\n",
      "Epoch 0, Meta Loss: 2.3073625564575195, Synthetic Data Grad Norm: 0.00034420311567373574\n",
      "Epoch 0, Meta Loss: 2.3097174167633057, Synthetic Data Grad Norm: 0.00020081023103557527\n",
      "Epoch 0, Meta Loss: 2.3028268814086914, Synthetic Data Grad Norm: 0.0002901507541537285\n",
      "Epoch 0, Meta Loss: 2.2911441326141357, Synthetic Data Grad Norm: 0.0001934375031851232\n",
      "Epoch 0, Meta Loss: 2.2868990898132324, Synthetic Data Grad Norm: 0.00021221495990175754\n",
      "Epoch 0, Meta Loss: 2.2884793281555176, Synthetic Data Grad Norm: 0.0002548879710957408\n",
      "Epoch 0, Meta Loss: 2.294666051864624, Synthetic Data Grad Norm: 0.00023017871717456728\n",
      "Epoch 0, Meta Loss: 2.301546335220337, Synthetic Data Grad Norm: 0.00027418864192441106\n",
      "Epoch 0, Meta Loss: 2.310248613357544, Synthetic Data Grad Norm: 0.00024331282475031912\n",
      "Epoch 0, Meta Loss: 2.3064544200897217, Synthetic Data Grad Norm: 0.0002023321867454797\n",
      "Epoch 0, Meta Loss: 2.3195183277130127, Synthetic Data Grad Norm: 0.0003389274061191827\n",
      "Epoch 0, Meta Loss: 2.3155570030212402, Synthetic Data Grad Norm: 0.00022840977180749178\n",
      "Epoch 0, Meta Loss: 2.3050458431243896, Synthetic Data Grad Norm: 0.0003187971597071737\n",
      "Epoch 0, Meta Loss: 2.2879891395568848, Synthetic Data Grad Norm: 0.00021250285499263555\n",
      "Epoch 0, Meta Loss: 2.310286521911621, Synthetic Data Grad Norm: 0.0003047142818104476\n",
      "Epoch 0, Meta Loss: 2.305797576904297, Synthetic Data Grad Norm: 0.00020489006419666111\n",
      "Epoch 0, Meta Loss: 2.2985916137695312, Synthetic Data Grad Norm: 0.0002459899988025427\n",
      "Epoch 0, Meta Loss: 2.306236743927002, Synthetic Data Grad Norm: 0.00021586372167803347\n",
      "Epoch 0, Meta Loss: 2.3046975135803223, Synthetic Data Grad Norm: 0.0002483295102138072\n",
      "Epoch 0, Meta Loss: 2.2946813106536865, Synthetic Data Grad Norm: 0.0002345707471249625\n",
      "Epoch 0, Meta Loss: 2.3145740032196045, Synthetic Data Grad Norm: 0.00020221140584908426\n",
      "Epoch 0, Meta Loss: 2.302513837814331, Synthetic Data Grad Norm: 0.00024000904522836208\n",
      "Epoch 0, Meta Loss: 2.330878973007202, Synthetic Data Grad Norm: 0.00028400219161994755\n",
      "Epoch 0, Meta Loss: 2.3078773021698, Synthetic Data Grad Norm: 0.00028806933551095426\n",
      "Epoch 0, Meta Loss: 2.301541566848755, Synthetic Data Grad Norm: 0.0002620790619403124\n",
      "Epoch 0, Meta Loss: 2.296281099319458, Synthetic Data Grad Norm: 0.0003748567251022905\n",
      "Epoch 0, Meta Loss: 2.2807865142822266, Synthetic Data Grad Norm: 0.00024221325293183327\n",
      "Epoch 0, Meta Loss: 2.302554130554199, Synthetic Data Grad Norm: 0.0002125107275787741\n",
      "Epoch 0, Meta Loss: 2.309406280517578, Synthetic Data Grad Norm: 0.00019977035117335618\n",
      "Epoch 0, Meta Loss: 2.30971360206604, Synthetic Data Grad Norm: 0.0002855617494788021\n",
      "Epoch 0, Meta Loss: 2.307175874710083, Synthetic Data Grad Norm: 0.00023526149743702263\n",
      "Epoch 0, Meta Loss: 2.2951412200927734, Synthetic Data Grad Norm: 0.00021372869377955794\n",
      "Epoch 0, Meta Loss: 2.2983956336975098, Synthetic Data Grad Norm: 0.00017272985132876784\n",
      "Epoch 0, Meta Loss: 2.2985727787017822, Synthetic Data Grad Norm: 0.0002590974618215114\n",
      "Epoch 0, Meta Loss: 2.318143606185913, Synthetic Data Grad Norm: 0.00030149187659844756\n",
      "Epoch 0, Meta Loss: 2.3007917404174805, Synthetic Data Grad Norm: 0.00026417471235617995\n",
      "Epoch 0, Meta Loss: 2.2912094593048096, Synthetic Data Grad Norm: 0.0001814435818232596\n",
      "Epoch 0, Meta Loss: 2.316488265991211, Synthetic Data Grad Norm: 0.00026583592989481986\n",
      "Epoch 0, Meta Loss: 2.3016269207000732, Synthetic Data Grad Norm: 0.00024263285740744323\n",
      "Epoch 0, Meta Loss: 2.307554006576538, Synthetic Data Grad Norm: 0.00019830145174637437\n",
      "Epoch 0, Meta Loss: 2.296220302581787, Synthetic Data Grad Norm: 0.00017751945415511727\n",
      "Epoch 0, Meta Loss: 2.2960939407348633, Synthetic Data Grad Norm: 0.0002715724695008248\n",
      "Epoch 0, Meta Loss: 2.309708595275879, Synthetic Data Grad Norm: 0.0002726189559325576\n",
      "Epoch 0, Meta Loss: 2.3004655838012695, Synthetic Data Grad Norm: 0.0002635272976476699\n",
      "Epoch 0, Meta Loss: 2.3040757179260254, Synthetic Data Grad Norm: 0.00028780868160538375\n",
      "Epoch 0, Meta Loss: 2.3220252990722656, Synthetic Data Grad Norm: 0.00025986312539316714\n",
      "Epoch 0, Meta Loss: 2.28277325630188, Synthetic Data Grad Norm: 0.00022605372942052782\n",
      "Epoch 0, Meta Loss: 2.3092286586761475, Synthetic Data Grad Norm: 0.00026084447745233774\n",
      "Epoch 0, Meta Loss: 2.3013315200805664, Synthetic Data Grad Norm: 0.00022488606919068843\n",
      "Epoch 0, Meta Loss: 2.3013198375701904, Synthetic Data Grad Norm: 0.00027662719367071986\n",
      "Epoch 0, Meta Loss: 2.2798821926116943, Synthetic Data Grad Norm: 0.0002763245429378003\n",
      "Epoch 0, Meta Loss: 2.2974109649658203, Synthetic Data Grad Norm: 0.00024318556825164706\n",
      "Epoch 0, Meta Loss: 2.311466932296753, Synthetic Data Grad Norm: 0.00034552766010165215\n",
      "Epoch 0, Meta Loss: 2.297405958175659, Synthetic Data Grad Norm: 0.00023550621699541807\n",
      "Epoch 0, Meta Loss: 2.3210396766662598, Synthetic Data Grad Norm: 0.0002043135609710589\n",
      "Epoch 0, Meta Loss: 2.2982089519500732, Synthetic Data Grad Norm: 0.00019654547213576734\n",
      "Epoch 0, Meta Loss: 2.298145294189453, Synthetic Data Grad Norm: 0.0003013625100720674\n",
      "Epoch 0, Meta Loss: 2.3101840019226074, Synthetic Data Grad Norm: 0.0002625163469929248\n",
      "Epoch 0, Meta Loss: 2.3122782707214355, Synthetic Data Grad Norm: 0.0003097487206105143\n",
      "Epoch 0, Meta Loss: 2.272118330001831, Synthetic Data Grad Norm: 0.00024150691751856357\n",
      "Epoch 0, Meta Loss: 2.329037666320801, Synthetic Data Grad Norm: 0.00028967042453587055\n",
      "Epoch 0, Meta Loss: 2.3061013221740723, Synthetic Data Grad Norm: 0.00021343061234802008\n",
      "Epoch 0, Meta Loss: 2.302988290786743, Synthetic Data Grad Norm: 0.00027689174748957157\n",
      "Epoch 0, Meta Loss: 2.292341470718384, Synthetic Data Grad Norm: 0.00020869540458079427\n",
      "Epoch 0, Meta Loss: 2.3080337047576904, Synthetic Data Grad Norm: 0.0002187080681324005\n",
      "Epoch 0, Meta Loss: 2.294586420059204, Synthetic Data Grad Norm: 0.00024096221022773534\n",
      "Epoch 0, Meta Loss: 2.2985825538635254, Synthetic Data Grad Norm: 0.00027266977122053504\n",
      "Epoch 0, Meta Loss: 2.2976582050323486, Synthetic Data Grad Norm: 0.0004758794675581157\n",
      "Epoch 0, Meta Loss: 2.3057608604431152, Synthetic Data Grad Norm: 0.0002989420900121331\n",
      "Epoch 0, Meta Loss: 2.3004612922668457, Synthetic Data Grad Norm: 0.0002243982453364879\n",
      "Epoch 0, Meta Loss: 2.3002207279205322, Synthetic Data Grad Norm: 0.00020508149464149028\n",
      "Epoch 0, Meta Loss: 2.3171355724334717, Synthetic Data Grad Norm: 0.0002465041761752218\n",
      "Epoch 0, Meta Loss: 2.2992022037506104, Synthetic Data Grad Norm: 0.0002351419097976759\n",
      "Epoch 0, Meta Loss: 2.3066084384918213, Synthetic Data Grad Norm: 0.00018350043683312833\n",
      "Epoch 0, Meta Loss: 2.3161823749542236, Synthetic Data Grad Norm: 0.0002801907539833337\n",
      "Epoch 0, Meta Loss: 2.2757208347320557, Synthetic Data Grad Norm: 0.00024600460892543197\n",
      "Epoch 0, Meta Loss: 2.2909839153289795, Synthetic Data Grad Norm: 0.00033219900797121227\n",
      "Epoch 0, Meta Loss: 2.293696641921997, Synthetic Data Grad Norm: 0.0002506554883439094\n",
      "Epoch 0, Meta Loss: 2.3002681732177734, Synthetic Data Grad Norm: 0.00021379215468186885\n",
      "Epoch 0, Meta Loss: 2.2931504249572754, Synthetic Data Grad Norm: 0.00019801549206022173\n",
      "Epoch 0, Meta Loss: 2.3040082454681396, Synthetic Data Grad Norm: 0.0002934026997536421\n",
      "Epoch 0, Meta Loss: 2.335426092147827, Synthetic Data Grad Norm: 0.00024952576495707035\n",
      "Epoch 0, Meta Loss: 2.2927112579345703, Synthetic Data Grad Norm: 0.0002485196164343506\n",
      "Epoch 0, Meta Loss: 2.3049042224884033, Synthetic Data Grad Norm: 0.00021197105525061488\n",
      "Epoch 0, Meta Loss: 2.3020663261413574, Synthetic Data Grad Norm: 0.00022296067618299276\n",
      "Epoch 0, Meta Loss: 2.320012331008911, Synthetic Data Grad Norm: 0.00026302089099772274\n",
      "Epoch 0, Meta Loss: 2.303950309753418, Synthetic Data Grad Norm: 0.0002658839803189039\n",
      "Epoch 0, Meta Loss: 2.307262420654297, Synthetic Data Grad Norm: 0.0002600778825581074\n",
      "Epoch 0, Meta Loss: 2.311002016067505, Synthetic Data Grad Norm: 0.00017734829452820122\n",
      "Epoch 0, Meta Loss: 2.304900884628296, Synthetic Data Grad Norm: 0.000247007526922971\n",
      "Epoch 0, Meta Loss: 2.309560775756836, Synthetic Data Grad Norm: 0.00024802342522889376\n",
      "Epoch 0, Meta Loss: 2.3106513023376465, Synthetic Data Grad Norm: 0.00028906288207508624\n",
      "Epoch 0, Meta Loss: 2.306083917617798, Synthetic Data Grad Norm: 0.00026492096367292106\n",
      "Epoch 0, Meta Loss: 2.3067049980163574, Synthetic Data Grad Norm: 0.00020502052211668342\n",
      "Epoch 0, Meta Loss: 2.2989466190338135, Synthetic Data Grad Norm: 0.0002509065670892596\n",
      "Epoch 0, Meta Loss: 2.3046798706054688, Synthetic Data Grad Norm: 0.00020268622029107064\n",
      "Epoch 0, Meta Loss: 2.3086094856262207, Synthetic Data Grad Norm: 0.0002522915892768651\n",
      "Epoch 0, Meta Loss: 2.2913577556610107, Synthetic Data Grad Norm: 0.0003515866701491177\n",
      "Epoch 0, Meta Loss: 2.281292200088501, Synthetic Data Grad Norm: 0.00023983031860552728\n",
      "Epoch 0, Meta Loss: 2.293822765350342, Synthetic Data Grad Norm: 0.0002595129481051117\n",
      "Epoch 0, Meta Loss: 2.289297342300415, Synthetic Data Grad Norm: 0.0002564445894677192\n",
      "Epoch 0, Meta Loss: 2.297927141189575, Synthetic Data Grad Norm: 0.0003280992095824331\n",
      "Epoch 0, Meta Loss: 2.290714740753174, Synthetic Data Grad Norm: 0.0002392296155449003\n",
      "Epoch 0, Meta Loss: 2.289569616317749, Synthetic Data Grad Norm: 0.0002100994752254337\n",
      "Epoch 0, Meta Loss: 2.2905795574188232, Synthetic Data Grad Norm: 0.00031601570663042367\n",
      "Epoch 0, Meta Loss: 2.295060634613037, Synthetic Data Grad Norm: 0.00033419649116694927\n",
      "Epoch 0, Meta Loss: 2.3049156665802, Synthetic Data Grad Norm: 0.00023454926849808544\n",
      "Epoch 0, Meta Loss: 2.2958199977874756, Synthetic Data Grad Norm: 0.0002684266946744174\n",
      "Epoch 0, Meta Loss: 2.2816901206970215, Synthetic Data Grad Norm: 0.00025482705677859485\n",
      "Epoch 0, Meta Loss: 2.299870729446411, Synthetic Data Grad Norm: 0.00031257994123734534\n",
      "Epoch 0, Meta Loss: 2.3061983585357666, Synthetic Data Grad Norm: 0.00023130644694902003\n",
      "Epoch 0, Meta Loss: 2.3032803535461426, Synthetic Data Grad Norm: 0.00023862061789259315\n",
      "Epoch 0, Meta Loss: 2.3139026165008545, Synthetic Data Grad Norm: 0.0003229632566217333\n",
      "Epoch 0, Meta Loss: 2.303752899169922, Synthetic Data Grad Norm: 0.00019338124548085034\n",
      "Epoch 0, Meta Loss: 2.2743070125579834, Synthetic Data Grad Norm: 0.0003556766314432025\n",
      "Epoch 0, Meta Loss: 2.3022780418395996, Synthetic Data Grad Norm: 0.00025715422816574574\n",
      "Epoch 0, Meta Loss: 2.299100875854492, Synthetic Data Grad Norm: 0.00031064642826095223\n",
      "Epoch 0, Meta Loss: 2.297635555267334, Synthetic Data Grad Norm: 0.0001936551561811939\n",
      "Epoch 0, Meta Loss: 2.2947041988372803, Synthetic Data Grad Norm: 0.0002123519661836326\n",
      "Epoch 0, Meta Loss: 2.308323860168457, Synthetic Data Grad Norm: 0.00019527286349330097\n",
      "Epoch 0, Meta Loss: 2.2839515209198, Synthetic Data Grad Norm: 0.00023120072728488594\n",
      "Epoch 0, Meta Loss: 2.3010215759277344, Synthetic Data Grad Norm: 0.000228907068958506\n",
      "Epoch 0, Meta Loss: 2.3070008754730225, Synthetic Data Grad Norm: 0.0002071163326036185\n",
      "Epoch 0, Meta Loss: 2.318023681640625, Synthetic Data Grad Norm: 0.0001871104905148968\n",
      "Epoch 0, Meta Loss: 2.3051578998565674, Synthetic Data Grad Norm: 0.00020072745974175632\n",
      "Epoch 0, Meta Loss: 2.3011298179626465, Synthetic Data Grad Norm: 0.00032400680356658995\n",
      "Epoch 0, Meta Loss: 2.3187506198883057, Synthetic Data Grad Norm: 0.00031063775531947613\n",
      "Epoch 0, Meta Loss: 2.309509038925171, Synthetic Data Grad Norm: 0.00029598537366837263\n",
      "Epoch 0, Meta Loss: 2.3037304878234863, Synthetic Data Grad Norm: 0.00025337451370432973\n",
      "Epoch 0, Meta Loss: 2.2944698333740234, Synthetic Data Grad Norm: 0.00025971169816330075\n",
      "Epoch 0, Meta Loss: 2.313354015350342, Synthetic Data Grad Norm: 0.0002744028752204031\n",
      "Epoch 0, Meta Loss: 2.2759265899658203, Synthetic Data Grad Norm: 0.00022132095182314515\n",
      "Epoch 0, Meta Loss: 2.2934234142303467, Synthetic Data Grad Norm: 0.0002637263387441635\n",
      "Epoch 0, Meta Loss: 2.308687925338745, Synthetic Data Grad Norm: 0.0003545793006196618\n",
      "Epoch 0, Meta Loss: 2.287287950515747, Synthetic Data Grad Norm: 0.0003349757462274283\n",
      "Epoch 0, Meta Loss: 2.318716287612915, Synthetic Data Grad Norm: 0.0003384550509508699\n",
      "Epoch 0, Meta Loss: 2.3081061840057373, Synthetic Data Grad Norm: 0.0002249506360385567\n",
      "Epoch 0, Meta Loss: 2.299281120300293, Synthetic Data Grad Norm: 0.00023438628704752773\n",
      "Epoch 0, Meta Loss: 2.3030712604522705, Synthetic Data Grad Norm: 0.0002726563543546945\n",
      "Epoch 0, Meta Loss: 2.3035316467285156, Synthetic Data Grad Norm: 0.0002846820862032473\n",
      "Epoch 0, Meta Loss: 2.2983789443969727, Synthetic Data Grad Norm: 0.000339914025971666\n",
      "Epoch 0, Meta Loss: 2.2930350303649902, Synthetic Data Grad Norm: 0.00031391691300086677\n",
      "Epoch 0, Meta Loss: 2.3107709884643555, Synthetic Data Grad Norm: 0.000254954764386639\n",
      "Epoch 0, Meta Loss: 2.278364896774292, Synthetic Data Grad Norm: 0.0002724440419115126\n",
      "Epoch 0, Meta Loss: 2.3011412620544434, Synthetic Data Grad Norm: 0.0002617602876853198\n",
      "Epoch 0, Meta Loss: 2.308358669281006, Synthetic Data Grad Norm: 0.0002541186986491084\n",
      "Epoch 0, Meta Loss: 2.3132083415985107, Synthetic Data Grad Norm: 0.0001818345335777849\n",
      "Epoch 0, Meta Loss: 2.3004403114318848, Synthetic Data Grad Norm: 0.0002531004138290882\n",
      "Epoch 0, Meta Loss: 2.315671443939209, Synthetic Data Grad Norm: 0.0002646219509188086\n",
      "Epoch 0, Meta Loss: 2.298309087753296, Synthetic Data Grad Norm: 0.0002113212103722617\n",
      "Epoch 0, Meta Loss: 2.327021837234497, Synthetic Data Grad Norm: 0.00026437119231559336\n",
      "Epoch 0, Meta Loss: 2.305300235748291, Synthetic Data Grad Norm: 0.0002159962459700182\n",
      "Epoch 0, Meta Loss: 2.3100085258483887, Synthetic Data Grad Norm: 0.00025866663781926036\n",
      "Epoch 0, Meta Loss: 2.295339584350586, Synthetic Data Grad Norm: 0.00027822295669466257\n",
      "Epoch 0, Meta Loss: 2.2977213859558105, Synthetic Data Grad Norm: 0.00026940531097352505\n",
      "Epoch 0, Meta Loss: 2.3122901916503906, Synthetic Data Grad Norm: 0.000292259210254997\n",
      "Epoch 0, Meta Loss: 2.303010940551758, Synthetic Data Grad Norm: 0.00020516762742772698\n",
      "Epoch 0, Meta Loss: 2.3099777698516846, Synthetic Data Grad Norm: 0.00028306187596172094\n",
      "Epoch 0, Meta Loss: 2.279195785522461, Synthetic Data Grad Norm: 0.00021071446826681495\n",
      "Epoch 0, Meta Loss: 2.3065102100372314, Synthetic Data Grad Norm: 0.00027406823937781155\n",
      "Epoch 0, Meta Loss: 2.3044655323028564, Synthetic Data Grad Norm: 0.0002792280865833163\n",
      "Epoch 0, Meta Loss: 2.2961556911468506, Synthetic Data Grad Norm: 0.0002339392522117123\n",
      "Epoch 0, Meta Loss: 2.2908775806427, Synthetic Data Grad Norm: 0.0002279897016705945\n",
      "Epoch 0, Meta Loss: 2.2781822681427, Synthetic Data Grad Norm: 0.00029499377706088126\n",
      "Epoch 0, Meta Loss: 2.298966884613037, Synthetic Data Grad Norm: 0.00037786646862514317\n",
      "Epoch 0, Meta Loss: 2.3022382259368896, Synthetic Data Grad Norm: 0.0002354871976422146\n",
      "Epoch 0, Meta Loss: 2.3011984825134277, Synthetic Data Grad Norm: 0.00023196708934847265\n",
      "Epoch 0, Meta Loss: 2.294236421585083, Synthetic Data Grad Norm: 0.00026946893194690347\n",
      "Epoch 0, Meta Loss: 2.2982006072998047, Synthetic Data Grad Norm: 0.0001961062225745991\n",
      "Epoch 0, Meta Loss: 2.2730185985565186, Synthetic Data Grad Norm: 0.0002445299760438502\n",
      "Epoch 0, Meta Loss: 2.30910062789917, Synthetic Data Grad Norm: 0.0003159082552883774\n",
      "Epoch 0, Meta Loss: 2.297722816467285, Synthetic Data Grad Norm: 0.0002486540761310607\n",
      "Epoch 0, Meta Loss: 2.2974395751953125, Synthetic Data Grad Norm: 0.0002768560079857707\n",
      "Epoch 0, Meta Loss: 2.2868423461914062, Synthetic Data Grad Norm: 0.00032451152219437063\n",
      "Epoch 0, Meta Loss: 2.3082053661346436, Synthetic Data Grad Norm: 0.000321666884701699\n",
      "Epoch 0, Meta Loss: 2.303715944290161, Synthetic Data Grad Norm: 0.0002348838170291856\n",
      "Epoch 0, Meta Loss: 2.3082778453826904, Synthetic Data Grad Norm: 0.0001553776819491759\n",
      "Epoch 0, Meta Loss: 2.2890515327453613, Synthetic Data Grad Norm: 0.00027348374715074897\n",
      "Epoch 0, Meta Loss: 2.297628402709961, Synthetic Data Grad Norm: 0.00021516261040233076\n",
      "Epoch 0, Meta Loss: 2.311042308807373, Synthetic Data Grad Norm: 0.00023253768449649215\n",
      "Epoch 0, Meta Loss: 2.3078136444091797, Synthetic Data Grad Norm: 0.00024922192096710205\n",
      "Epoch 0, Meta Loss: 2.303825616836548, Synthetic Data Grad Norm: 0.0002741417265497148\n",
      "Epoch 0, Meta Loss: 2.3020377159118652, Synthetic Data Grad Norm: 0.0002206631179433316\n",
      "Epoch 0, Meta Loss: 2.295954942703247, Synthetic Data Grad Norm: 0.00020766755915246904\n",
      "Epoch 0, Meta Loss: 2.294764280319214, Synthetic Data Grad Norm: 0.0002571208169683814\n",
      "Epoch 0, Meta Loss: 2.3021225929260254, Synthetic Data Grad Norm: 0.00021202412608545274\n",
      "Epoch 0, Meta Loss: 2.2943403720855713, Synthetic Data Grad Norm: 0.0003080515016335994\n",
      "Epoch 0, Meta Loss: 2.2902626991271973, Synthetic Data Grad Norm: 0.0002133277157554403\n",
      "Epoch 0, Meta Loss: 2.2938647270202637, Synthetic Data Grad Norm: 0.000263507041381672\n",
      "Epoch 0, Meta Loss: 2.3071653842926025, Synthetic Data Grad Norm: 0.00022498503676615655\n",
      "Epoch 0, Meta Loss: 2.3010756969451904, Synthetic Data Grad Norm: 0.000232492369832471\n",
      "Epoch 0, Meta Loss: 2.2902309894561768, Synthetic Data Grad Norm: 0.00019714007794391364\n",
      "Epoch 0, Meta Loss: 2.295293092727661, Synthetic Data Grad Norm: 0.0003041505115106702\n",
      "Epoch 0, Meta Loss: 2.291832447052002, Synthetic Data Grad Norm: 0.00016400606546085328\n",
      "Epoch 0, Meta Loss: 2.29555606842041, Synthetic Data Grad Norm: 0.00028089137049391866\n",
      "Epoch 0, Meta Loss: 2.2888448238372803, Synthetic Data Grad Norm: 0.0001813971612136811\n",
      "Epoch 0, Meta Loss: 2.2964093685150146, Synthetic Data Grad Norm: 0.00025967424153350294\n",
      "Epoch 0, Meta Loss: 2.3056228160858154, Synthetic Data Grad Norm: 0.00029279140289872885\n",
      "Epoch 0, Meta Loss: 2.311767816543579, Synthetic Data Grad Norm: 0.00019514409359544516\n",
      "Epoch 0, Meta Loss: 2.313244104385376, Synthetic Data Grad Norm: 0.0002386596897849813\n",
      "Epoch 0, Meta Loss: 2.3337087631225586, Synthetic Data Grad Norm: 0.0003696558123920113\n",
      "Epoch 0, Meta Loss: 2.299285411834717, Synthetic Data Grad Norm: 0.00025103919324465096\n",
      "Epoch 0, Meta Loss: 2.3063602447509766, Synthetic Data Grad Norm: 0.00028430376551114023\n",
      "Epoch 0, Meta Loss: 2.289832830429077, Synthetic Data Grad Norm: 0.00026960799004882574\n",
      "Epoch 0, Meta Loss: 2.3209056854248047, Synthetic Data Grad Norm: 0.0002611223026178777\n",
      "Epoch 0, Meta Loss: 2.29764723777771, Synthetic Data Grad Norm: 0.00020066715660504997\n",
      "Epoch 0, Meta Loss: 2.3113114833831787, Synthetic Data Grad Norm: 0.0002111685462296009\n",
      "Epoch 0, Meta Loss: 2.329996347427368, Synthetic Data Grad Norm: 0.00030262430664151907\n",
      "Epoch 0, Meta Loss: 2.3137423992156982, Synthetic Data Grad Norm: 0.00025828363141044974\n",
      "Epoch 0, Meta Loss: 2.3070335388183594, Synthetic Data Grad Norm: 0.00020590826170518994\n",
      "Epoch 0, Meta Loss: 2.272470474243164, Synthetic Data Grad Norm: 0.00023732901900075376\n",
      "Epoch 0, Meta Loss: 2.3059494495391846, Synthetic Data Grad Norm: 0.0002008118317462504\n",
      "Epoch 0, Meta Loss: 2.309446096420288, Synthetic Data Grad Norm: 0.0002509739715605974\n",
      "Epoch 0, Meta Loss: 2.2925925254821777, Synthetic Data Grad Norm: 0.0002867064904421568\n",
      "Epoch 0, Meta Loss: 2.308610677719116, Synthetic Data Grad Norm: 0.0002695753937587142\n",
      "Epoch 0, Meta Loss: 2.2965807914733887, Synthetic Data Grad Norm: 0.00021914317039772868\n",
      "Epoch 0, Meta Loss: 2.3116085529327393, Synthetic Data Grad Norm: 0.0002432023175060749\n",
      "Epoch 0, Meta Loss: 2.311241626739502, Synthetic Data Grad Norm: 0.0002747613179963082\n",
      "Epoch 0, Meta Loss: 2.305353879928589, Synthetic Data Grad Norm: 0.000170137791428715\n",
      "Epoch 0, Meta Loss: 2.3057456016540527, Synthetic Data Grad Norm: 0.00022151540906634182\n",
      "Epoch 0, Meta Loss: 2.290832281112671, Synthetic Data Grad Norm: 0.00024092041712719947\n",
      "Epoch 0, Meta Loss: 2.2955338954925537, Synthetic Data Grad Norm: 0.0003697607317008078\n",
      "Epoch 0, Meta Loss: 2.3007919788360596, Synthetic Data Grad Norm: 0.00022757519036531448\n",
      "Epoch 0, Meta Loss: 2.301342725753784, Synthetic Data Grad Norm: 0.00016350287478417158\n",
      "Epoch 0, Meta Loss: 2.3123016357421875, Synthetic Data Grad Norm: 0.00022723522852174938\n",
      "Epoch 0, Meta Loss: 2.3150675296783447, Synthetic Data Grad Norm: 0.00022707223251927644\n",
      "Epoch 0, Meta Loss: 2.296642780303955, Synthetic Data Grad Norm: 0.0002510317717678845\n",
      "Epoch 0, Meta Loss: 2.3015246391296387, Synthetic Data Grad Norm: 0.00018151408585254103\n",
      "Epoch 0, Meta Loss: 2.2982113361358643, Synthetic Data Grad Norm: 0.0003525317588355392\n",
      "Epoch 0, Meta Loss: 2.2970707416534424, Synthetic Data Grad Norm: 0.000212304454180412\n",
      "Epoch 0, Meta Loss: 2.2918753623962402, Synthetic Data Grad Norm: 0.00019170332234352827\n",
      "Epoch 0, Meta Loss: 2.3008663654327393, Synthetic Data Grad Norm: 0.00025847594952210784\n",
      "Epoch 0, Meta Loss: 2.2968199253082275, Synthetic Data Grad Norm: 0.00039309507701545954\n",
      "Epoch 0, Meta Loss: 2.2991726398468018, Synthetic Data Grad Norm: 0.00028125912649556994\n",
      "Epoch 0, Meta Loss: 2.300220489501953, Synthetic Data Grad Norm: 0.00021234822634141892\n",
      "Epoch 0, Meta Loss: 2.28560209274292, Synthetic Data Grad Norm: 0.00031120472704060376\n",
      "Epoch 0, Meta Loss: 2.2988388538360596, Synthetic Data Grad Norm: 0.0003057984577026218\n",
      "Epoch 0, Meta Loss: 2.296879529953003, Synthetic Data Grad Norm: 0.00024533309624530375\n",
      "Epoch 0, Meta Loss: 2.3009185791015625, Synthetic Data Grad Norm: 0.0003146891249343753\n",
      "Epoch 0, Meta Loss: 2.308411121368408, Synthetic Data Grad Norm: 0.0002065188018605113\n",
      "Epoch 0, Meta Loss: 2.3017163276672363, Synthetic Data Grad Norm: 0.0002530121128074825\n",
      "Epoch 0, Meta Loss: 2.307037115097046, Synthetic Data Grad Norm: 0.00029621936846524477\n",
      "Epoch 0, Meta Loss: 2.2990617752075195, Synthetic Data Grad Norm: 0.00026336530572734773\n",
      "Epoch 0, Meta Loss: 2.3069398403167725, Synthetic Data Grad Norm: 0.0002567394694779068\n",
      "Epoch 0, Meta Loss: 2.2921597957611084, Synthetic Data Grad Norm: 0.00026929855812340975\n",
      "Epoch 0, Meta Loss: 2.304975748062134, Synthetic Data Grad Norm: 0.00021371751790866256\n",
      "Epoch 0, Meta Loss: 2.300921678543091, Synthetic Data Grad Norm: 0.0003420808061491698\n",
      "Epoch 0, Meta Loss: 2.2956275939941406, Synthetic Data Grad Norm: 0.00026759362663142383\n",
      "Epoch 0, Meta Loss: 2.3068299293518066, Synthetic Data Grad Norm: 0.00023708461958449334\n",
      "Epoch 0, Meta Loss: 2.2777369022369385, Synthetic Data Grad Norm: 0.00022873921261634678\n",
      "Epoch 0, Meta Loss: 2.3097496032714844, Synthetic Data Grad Norm: 0.0002159837313229218\n",
      "Epoch 0, Meta Loss: 2.278952121734619, Synthetic Data Grad Norm: 0.000323285668855533\n",
      "Epoch 0, Meta Loss: 2.2836532592773438, Synthetic Data Grad Norm: 0.00028635055059567094\n",
      "Epoch 0, Meta Loss: 2.302325963973999, Synthetic Data Grad Norm: 0.00030389323364943266\n",
      "Epoch 0, Meta Loss: 2.295128345489502, Synthetic Data Grad Norm: 0.00023099323152564466\n",
      "Epoch 0, Meta Loss: 2.299208641052246, Synthetic Data Grad Norm: 0.00023428021813742816\n",
      "Epoch 0, Meta Loss: 2.298539400100708, Synthetic Data Grad Norm: 0.00020896954811178148\n",
      "Epoch 0, Meta Loss: 2.3227312564849854, Synthetic Data Grad Norm: 0.00024831239716149867\n",
      "Epoch 0, Meta Loss: 2.2856388092041016, Synthetic Data Grad Norm: 0.00033316659391857684\n",
      "Epoch 0, Meta Loss: 2.3001344203948975, Synthetic Data Grad Norm: 0.0002184648037655279\n",
      "Epoch 0, Meta Loss: 2.3114495277404785, Synthetic Data Grad Norm: 0.0002659312158357352\n",
      "Epoch 0, Meta Loss: 2.3071343898773193, Synthetic Data Grad Norm: 0.0003959039750043303\n",
      "Epoch 0, Meta Loss: 2.285642623901367, Synthetic Data Grad Norm: 0.00032344364444725215\n",
      "Epoch 0, Meta Loss: 2.2928037643432617, Synthetic Data Grad Norm: 0.0002732361317612231\n",
      "Epoch 0, Meta Loss: 2.306405544281006, Synthetic Data Grad Norm: 0.0003421292349230498\n",
      "Epoch 0, Meta Loss: 2.3144519329071045, Synthetic Data Grad Norm: 0.00021443217701744288\n",
      "Epoch 0, Meta Loss: 2.2963953018188477, Synthetic Data Grad Norm: 0.0002535184903535992\n",
      "Epoch 0, Meta Loss: 2.3104376792907715, Synthetic Data Grad Norm: 0.00043186263064853847\n",
      "Epoch 0, Meta Loss: 2.3024840354919434, Synthetic Data Grad Norm: 0.0004087577690370381\n",
      "Epoch 0, Meta Loss: 2.3123602867126465, Synthetic Data Grad Norm: 0.0002449048333801329\n",
      "Epoch 0, Meta Loss: 2.29398250579834, Synthetic Data Grad Norm: 0.0002546533360145986\n",
      "Epoch 0, Meta Loss: 2.292933225631714, Synthetic Data Grad Norm: 0.00032003215164877474\n",
      "Epoch 0, Meta Loss: 2.3019304275512695, Synthetic Data Grad Norm: 0.00024176172155421227\n",
      "Epoch 0, Meta Loss: 2.3007686138153076, Synthetic Data Grad Norm: 0.0002386184933129698\n",
      "Epoch 0, Meta Loss: 2.3012945652008057, Synthetic Data Grad Norm: 0.00027177928132005036\n",
      "Epoch 0, Meta Loss: 2.306877374649048, Synthetic Data Grad Norm: 0.00026845227694138885\n",
      "Epoch 0, Meta Loss: 2.2943177223205566, Synthetic Data Grad Norm: 0.00029869162244722247\n",
      "Epoch 0, Meta Loss: 2.3013229370117188, Synthetic Data Grad Norm: 0.00019632047042250633\n",
      "Epoch 0, Meta Loss: 2.3320934772491455, Synthetic Data Grad Norm: 0.0002785015676636249\n",
      "Epoch 0, Meta Loss: 2.306705951690674, Synthetic Data Grad Norm: 0.00029274378903210163\n",
      "Epoch 0, Meta Loss: 2.3081984519958496, Synthetic Data Grad Norm: 0.00023840296489652246\n",
      "Epoch 0, Meta Loss: 2.298570394515991, Synthetic Data Grad Norm: 0.000278068968327716\n",
      "Epoch 0, Meta Loss: 2.3039634227752686, Synthetic Data Grad Norm: 0.0003404415037948638\n",
      "Epoch 0, Meta Loss: 2.3078114986419678, Synthetic Data Grad Norm: 0.00026896264171227813\n",
      "Epoch 0, Meta Loss: 2.2941651344299316, Synthetic Data Grad Norm: 0.000202701790840365\n",
      "Epoch 0, Meta Loss: 2.2947280406951904, Synthetic Data Grad Norm: 0.00022453194833360612\n",
      "Epoch 0, Meta Loss: 2.316486358642578, Synthetic Data Grad Norm: 0.0003588756371755153\n",
      "Epoch 0, Meta Loss: 2.299257516860962, Synthetic Data Grad Norm: 0.0002493659558240324\n",
      "Epoch 0, Meta Loss: 2.2977957725524902, Synthetic Data Grad Norm: 0.0003098239249084145\n",
      "Epoch 0, Meta Loss: 2.30324125289917, Synthetic Data Grad Norm: 0.0001995369530050084\n",
      "Epoch 0, Meta Loss: 2.3006508350372314, Synthetic Data Grad Norm: 0.0002606337075121701\n",
      "Epoch 0, Meta Loss: 2.322894334793091, Synthetic Data Grad Norm: 0.00039448621100746095\n",
      "Epoch 0, Meta Loss: 2.3120412826538086, Synthetic Data Grad Norm: 0.00021268207638058811\n",
      "Epoch 0, Meta Loss: 2.3059542179107666, Synthetic Data Grad Norm: 0.00028116945759393275\n",
      "Epoch 0, Meta Loss: 2.2960751056671143, Synthetic Data Grad Norm: 0.00020286932704038918\n",
      "Epoch 0, Meta Loss: 2.305898427963257, Synthetic Data Grad Norm: 0.0003335729707032442\n",
      "Epoch 0, Meta Loss: 2.2934696674346924, Synthetic Data Grad Norm: 0.00046507653314620256\n",
      "Epoch 0, Meta Loss: 2.304574966430664, Synthetic Data Grad Norm: 0.00021939084399491549\n",
      "Epoch 0, Meta Loss: 2.293409824371338, Synthetic Data Grad Norm: 0.0002311251882929355\n",
      "Epoch 0, Meta Loss: 2.290259838104248, Synthetic Data Grad Norm: 0.0003598096373025328\n",
      "Epoch 0, Meta Loss: 2.3103199005126953, Synthetic Data Grad Norm: 0.00017611304065212607\n",
      "Epoch 0, Meta Loss: 2.293436050415039, Synthetic Data Grad Norm: 0.0002891629992518574\n",
      "Epoch 0, Meta Loss: 2.295682907104492, Synthetic Data Grad Norm: 0.0003451892116572708\n",
      "Epoch 0, Meta Loss: 2.288590431213379, Synthetic Data Grad Norm: 0.00017407008272130042\n",
      "Epoch 0, Meta Loss: 2.300457715988159, Synthetic Data Grad Norm: 0.0002606049529276788\n",
      "Epoch 0, Meta Loss: 2.3020246028900146, Synthetic Data Grad Norm: 0.00019350058573763818\n",
      "Epoch 0, Meta Loss: 2.3038809299468994, Synthetic Data Grad Norm: 0.00023399847850669175\n",
      "Epoch 0, Meta Loss: 2.302445411682129, Synthetic Data Grad Norm: 0.00019077684555668384\n",
      "Epoch 0, Meta Loss: 2.3172168731689453, Synthetic Data Grad Norm: 0.0002782866358757019\n",
      "Epoch 0, Meta Loss: 2.306159734725952, Synthetic Data Grad Norm: 0.00028199897496961057\n",
      "Epoch 0, Meta Loss: 2.2769792079925537, Synthetic Data Grad Norm: 0.0003843419544864446\n",
      "Epoch 0, Meta Loss: 2.305067777633667, Synthetic Data Grad Norm: 0.0002552428049966693\n",
      "Epoch 0, Meta Loss: 2.277956247329712, Synthetic Data Grad Norm: 0.00033420254476368427\n",
      "Epoch 0, Meta Loss: 2.2854321002960205, Synthetic Data Grad Norm: 0.0002056500961771235\n",
      "Epoch 0, Meta Loss: 2.3075766563415527, Synthetic Data Grad Norm: 0.00020821411453653127\n",
      "Epoch 0, Meta Loss: 2.3016719818115234, Synthetic Data Grad Norm: 0.00024767755530774593\n",
      "Epoch 0, Meta Loss: 2.310913324356079, Synthetic Data Grad Norm: 0.0002259677421534434\n",
      "Epoch 0, Meta Loss: 2.2934796810150146, Synthetic Data Grad Norm: 0.00022870002430863678\n",
      "Epoch 0, Meta Loss: 2.290010929107666, Synthetic Data Grad Norm: 0.00019333124510012567\n",
      "Epoch 0, Meta Loss: 2.313586473464966, Synthetic Data Grad Norm: 0.00022993226593825966\n",
      "Epoch 0, Meta Loss: 2.296311616897583, Synthetic Data Grad Norm: 0.0003064186021219939\n",
      "Epoch 0, Meta Loss: 2.294269561767578, Synthetic Data Grad Norm: 0.0001910174178192392\n",
      "Epoch 0, Meta Loss: 2.3296420574188232, Synthetic Data Grad Norm: 0.0003535448631737381\n",
      "Epoch 0, Meta Loss: 2.2947747707366943, Synthetic Data Grad Norm: 0.0002566504117567092\n",
      "Epoch 0, Meta Loss: 2.3147737979888916, Synthetic Data Grad Norm: 0.0002116878458764404\n",
      "Epoch 0, Meta Loss: 2.2944395542144775, Synthetic Data Grad Norm: 0.0002717874594964087\n",
      "Epoch 0, Meta Loss: 2.3025596141815186, Synthetic Data Grad Norm: 0.0003651748411357403\n",
      "Epoch 0, Meta Loss: 2.2965307235717773, Synthetic Data Grad Norm: 0.0002469650935381651\n",
      "Epoch 0, Meta Loss: 2.290919780731201, Synthetic Data Grad Norm: 0.00024501699954271317\n",
      "Epoch 0, Meta Loss: 2.2983365058898926, Synthetic Data Grad Norm: 0.0002940873964689672\n",
      "Epoch 0, Meta Loss: 2.292985200881958, Synthetic Data Grad Norm: 0.00021681428188458085\n",
      "Epoch 0, Meta Loss: 2.307793617248535, Synthetic Data Grad Norm: 0.00023923591652419418\n",
      "Epoch 0, Meta Loss: 2.288015842437744, Synthetic Data Grad Norm: 0.00022574578179046512\n",
      "Epoch 0, Meta Loss: 2.3158254623413086, Synthetic Data Grad Norm: 0.0003946746583096683\n",
      "Epoch 0, Meta Loss: 2.2922797203063965, Synthetic Data Grad Norm: 0.00026787948445416987\n",
      "Epoch 0, Meta Loss: 2.2841460704803467, Synthetic Data Grad Norm: 0.0002560750872362405\n",
      "Epoch 0, Meta Loss: 2.3097076416015625, Synthetic Data Grad Norm: 0.0003412815276533365\n",
      "Epoch 0, Meta Loss: 2.291311264038086, Synthetic Data Grad Norm: 0.0002489130129106343\n",
      "Epoch 0, Meta Loss: 2.3100461959838867, Synthetic Data Grad Norm: 0.00027117429999634624\n",
      "Epoch 0, Meta Loss: 2.283702850341797, Synthetic Data Grad Norm: 0.0002225109637947753\n",
      "Epoch 0, Meta Loss: 2.2961833477020264, Synthetic Data Grad Norm: 0.00019486549717839807\n",
      "Epoch 0, Meta Loss: 2.2894601821899414, Synthetic Data Grad Norm: 0.00018012264627031982\n",
      "Epoch 0, Meta Loss: 2.3178958892822266, Synthetic Data Grad Norm: 0.0003049079386983067\n",
      "Epoch 0, Meta Loss: 2.2862014770507812, Synthetic Data Grad Norm: 0.000304368237266317\n",
      "Epoch 0, Meta Loss: 2.299600124359131, Synthetic Data Grad Norm: 0.00037000735756009817\n",
      "Epoch 0, Meta Loss: 2.3091115951538086, Synthetic Data Grad Norm: 0.0002535250096116215\n",
      "Epoch 0, Meta Loss: 2.298642635345459, Synthetic Data Grad Norm: 0.0002316449536010623\n",
      "Epoch 0, Meta Loss: 2.3115174770355225, Synthetic Data Grad Norm: 0.00021299705258570611\n",
      "Epoch 0, Meta Loss: 2.2963521480560303, Synthetic Data Grad Norm: 0.00022583891404792666\n",
      "Epoch 0, Meta Loss: 2.3081767559051514, Synthetic Data Grad Norm: 0.00032954305061139166\n",
      "Epoch 0, Meta Loss: 2.3005177974700928, Synthetic Data Grad Norm: 0.00022026213991921395\n",
      "Epoch 0, Meta Loss: 2.293966293334961, Synthetic Data Grad Norm: 0.00023350097762886435\n",
      "Epoch 0, Meta Loss: 2.295496940612793, Synthetic Data Grad Norm: 0.0001812236150726676\n",
      "Epoch 0, Meta Loss: 2.310530185699463, Synthetic Data Grad Norm: 0.0003175830643158406\n",
      "Epoch 0, Meta Loss: 2.28641939163208, Synthetic Data Grad Norm: 0.00027073107776232064\n",
      "Epoch 0, Meta Loss: 2.3155364990234375, Synthetic Data Grad Norm: 0.00028698795358650386\n",
      "Epoch 0, Meta Loss: 2.3199737071990967, Synthetic Data Grad Norm: 0.0002763709344435483\n",
      "Epoch 0, Meta Loss: 2.3028757572174072, Synthetic Data Grad Norm: 0.00015230505960062146\n",
      "Epoch 0, Meta Loss: 2.308875560760498, Synthetic Data Grad Norm: 0.0003458434366621077\n",
      "Epoch 0, Meta Loss: 2.307434558868408, Synthetic Data Grad Norm: 0.00026040663942694664\n",
      "Epoch 0, Meta Loss: 2.303645372390747, Synthetic Data Grad Norm: 0.0002323222579434514\n",
      "Epoch 0, Meta Loss: 2.3107895851135254, Synthetic Data Grad Norm: 0.0002900804684031755\n",
      "Epoch 0, Meta Loss: 2.2790422439575195, Synthetic Data Grad Norm: 0.0002551437064539641\n",
      "Epoch 0, Meta Loss: 2.293585777282715, Synthetic Data Grad Norm: 0.0002329079870833084\n",
      "Epoch 0, Meta Loss: 2.318791389465332, Synthetic Data Grad Norm: 0.00031076266895979643\n",
      "Epoch 0, Meta Loss: 2.297954797744751, Synthetic Data Grad Norm: 0.00044645785237662494\n",
      "Epoch 0, Meta Loss: 2.301182270050049, Synthetic Data Grad Norm: 0.00022735954553354532\n",
      "Epoch 0, Meta Loss: 2.3069355487823486, Synthetic Data Grad Norm: 0.0002680891193449497\n",
      "Epoch 0, Meta Loss: 2.291043281555176, Synthetic Data Grad Norm: 0.0002782270312309265\n",
      "Epoch 0, Meta Loss: 2.298888921737671, Synthetic Data Grad Norm: 0.0002567832707427442\n",
      "Epoch 0, Meta Loss: 2.2975029945373535, Synthetic Data Grad Norm: 0.0002603927277959883\n",
      "Epoch 0, Meta Loss: 2.3019087314605713, Synthetic Data Grad Norm: 0.00020426776609383523\n",
      "Epoch 0, Meta Loss: 2.290462017059326, Synthetic Data Grad Norm: 0.00029761483892798424\n",
      "Epoch 0, Meta Loss: 2.3005778789520264, Synthetic Data Grad Norm: 0.0002588204515632242\n",
      "Epoch 0, Meta Loss: 2.3129160404205322, Synthetic Data Grad Norm: 0.00022072219871915877\n",
      "Epoch 0, Meta Loss: 2.300424814224243, Synthetic Data Grad Norm: 0.0001903875672724098\n",
      "Epoch 0, Meta Loss: 2.313702344894409, Synthetic Data Grad Norm: 0.0002557744737714529\n",
      "Epoch 0, Meta Loss: 2.29689359664917, Synthetic Data Grad Norm: 0.00023590058845002204\n",
      "Epoch 0, Meta Loss: 2.297605037689209, Synthetic Data Grad Norm: 0.0002542043512221426\n",
      "Epoch 0, Meta Loss: 2.2886924743652344, Synthetic Data Grad Norm: 0.0003358951071277261\n",
      "Epoch 0, Meta Loss: 2.288374900817871, Synthetic Data Grad Norm: 0.00018059586000163108\n",
      "Epoch 0, Meta Loss: 2.316136360168457, Synthetic Data Grad Norm: 0.00029586651362478733\n",
      "Epoch 0, Meta Loss: 2.3270344734191895, Synthetic Data Grad Norm: 0.00037811542279087007\n",
      "Epoch 0, Meta Loss: 2.2847161293029785, Synthetic Data Grad Norm: 0.00027483695885166526\n",
      "Epoch 0, Meta Loss: 2.3050801753997803, Synthetic Data Grad Norm: 0.0002183559990953654\n",
      "Epoch 0, Meta Loss: 2.3014769554138184, Synthetic Data Grad Norm: 0.00023853768652770668\n",
      "Epoch 0, Meta Loss: 2.2913107872009277, Synthetic Data Grad Norm: 0.00031492000562138855\n",
      "Epoch 0, Meta Loss: 2.2836544513702393, Synthetic Data Grad Norm: 0.00023982254788279533\n",
      "Epoch 0, Meta Loss: 2.310957908630371, Synthetic Data Grad Norm: 0.00023178521951194853\n",
      "Epoch 0, Meta Loss: 2.2948646545410156, Synthetic Data Grad Norm: 0.0003958536544814706\n",
      "Epoch 0, Meta Loss: 2.299767017364502, Synthetic Data Grad Norm: 0.0003140107146464288\n",
      "Epoch 0, Meta Loss: 2.2903006076812744, Synthetic Data Grad Norm: 0.0002615879930090159\n",
      "Epoch 0, Meta Loss: 2.2878050804138184, Synthetic Data Grad Norm: 0.00024615449365228415\n",
      "Epoch 0, Meta Loss: 2.306250810623169, Synthetic Data Grad Norm: 0.0001790208916645497\n",
      "Epoch 0, Meta Loss: 2.2822470664978027, Synthetic Data Grad Norm: 0.00030893110670149326\n",
      "Epoch 0, Meta Loss: 2.3008203506469727, Synthetic Data Grad Norm: 0.0002844009723048657\n",
      "Epoch 0, Meta Loss: 2.300706386566162, Synthetic Data Grad Norm: 0.00024024012964218855\n",
      "Epoch 0, Meta Loss: 2.3005740642547607, Synthetic Data Grad Norm: 0.0002885194553527981\n",
      "Epoch 0, Meta Loss: 2.2982735633850098, Synthetic Data Grad Norm: 0.00023552036145702004\n",
      "Epoch 0, Meta Loss: 2.29465389251709, Synthetic Data Grad Norm: 0.00020975885854568332\n",
      "Epoch 0, Meta Loss: 2.3227593898773193, Synthetic Data Grad Norm: 0.00032027572160586715\n",
      "Epoch 0, Meta Loss: 2.2917935848236084, Synthetic Data Grad Norm: 0.00023009697906672955\n",
      "Epoch 0, Meta Loss: 2.306591510772705, Synthetic Data Grad Norm: 0.0002835711638908833\n",
      "Epoch 0, Meta Loss: 2.316810369491577, Synthetic Data Grad Norm: 0.00022650374739896506\n",
      "Epoch 0, Meta Loss: 2.307722806930542, Synthetic Data Grad Norm: 0.00026561476988717914\n",
      "Epoch 0, Meta Loss: 2.284649133682251, Synthetic Data Grad Norm: 0.00030700507340952754\n",
      "Epoch 0, Meta Loss: 2.285106658935547, Synthetic Data Grad Norm: 0.0003213255840819329\n",
      "Epoch 0, Meta Loss: 2.3015224933624268, Synthetic Data Grad Norm: 0.0004820166213903576\n",
      "Epoch 0, Meta Loss: 2.3023853302001953, Synthetic Data Grad Norm: 0.00030730964499525726\n",
      "Epoch 0, Meta Loss: 2.29045033454895, Synthetic Data Grad Norm: 0.00023126151063479483\n",
      "Epoch 0, Meta Loss: 2.2888870239257812, Synthetic Data Grad Norm: 0.00024361131363548338\n",
      "Epoch 0, Meta Loss: 2.2964422702789307, Synthetic Data Grad Norm: 0.0003068063233513385\n",
      "Epoch 0, Meta Loss: 2.3124144077301025, Synthetic Data Grad Norm: 0.00031605272670276463\n",
      "Epoch 0, Meta Loss: 2.2968857288360596, Synthetic Data Grad Norm: 0.0002198120200773701\n",
      "Epoch 0, Meta Loss: 2.3077332973480225, Synthetic Data Grad Norm: 0.00019696587696671486\n",
      "Epoch 0, Meta Loss: 2.2985095977783203, Synthetic Data Grad Norm: 0.00035386186209507287\n",
      "Epoch 0, Meta Loss: 2.3154492378234863, Synthetic Data Grad Norm: 0.00030307937413454056\n",
      "Epoch 0, Meta Loss: 2.2946667671203613, Synthetic Data Grad Norm: 0.00027497531846165657\n",
      "Epoch 0, Meta Loss: 2.3074140548706055, Synthetic Data Grad Norm: 0.000246121286181733\n",
      "Epoch 0, Meta Loss: 2.299872636795044, Synthetic Data Grad Norm: 0.00023052831238601357\n",
      "Epoch 0, Meta Loss: 2.3000071048736572, Synthetic Data Grad Norm: 0.00022117668413557112\n",
      "Epoch 0, Meta Loss: 2.2932748794555664, Synthetic Data Grad Norm: 0.00023262736795004457\n",
      "Epoch 0, Meta Loss: 2.3128061294555664, Synthetic Data Grad Norm: 0.00028725736774504185\n",
      "Epoch 0, Meta Loss: 2.299891471862793, Synthetic Data Grad Norm: 0.000277918268693611\n",
      "Epoch 0, Meta Loss: 2.2789058685302734, Synthetic Data Grad Norm: 0.00024971956736408174\n",
      "Epoch 0, Meta Loss: 2.2940335273742676, Synthetic Data Grad Norm: 0.00028477172600105405\n",
      "Epoch 0, Meta Loss: 2.3047280311584473, Synthetic Data Grad Norm: 0.00022738125699106604\n",
      "Epoch 0, Meta Loss: 2.3058767318725586, Synthetic Data Grad Norm: 0.00019743334269151092\n",
      "Epoch 0, Meta Loss: 2.2776100635528564, Synthetic Data Grad Norm: 0.0002447117876727134\n",
      "Epoch 0, Meta Loss: 2.305603504180908, Synthetic Data Grad Norm: 0.00021803837444167584\n",
      "Epoch 0, Meta Loss: 2.309723138809204, Synthetic Data Grad Norm: 0.00034836484701372683\n",
      "Epoch 0, Meta Loss: 2.322443962097168, Synthetic Data Grad Norm: 0.00027167919324710965\n",
      "Epoch 0, Meta Loss: 2.2825608253479004, Synthetic Data Grad Norm: 0.0002830052108038217\n",
      "Epoch 0, Meta Loss: 2.311368465423584, Synthetic Data Grad Norm: 0.00023892663011793047\n",
      "Epoch 0, Meta Loss: 2.292304277420044, Synthetic Data Grad Norm: 0.00020170070638414472\n",
      "Epoch 0, Meta Loss: 2.301302194595337, Synthetic Data Grad Norm: 0.00025273929350078106\n",
      "Epoch 0, Meta Loss: 2.3197617530822754, Synthetic Data Grad Norm: 0.0002556219114921987\n",
      "Epoch 0, Meta Loss: 2.317812442779541, Synthetic Data Grad Norm: 0.00024769181618466973\n",
      "Epoch 0, Meta Loss: 2.3128836154937744, Synthetic Data Grad Norm: 0.0002673383860383183\n",
      "Epoch 0, Meta Loss: 2.293081045150757, Synthetic Data Grad Norm: 0.00034225868876092136\n",
      "Epoch 0, Meta Loss: 2.30743670463562, Synthetic Data Grad Norm: 0.0002758344344329089\n",
      "Epoch 0, Meta Loss: 2.3051083087921143, Synthetic Data Grad Norm: 0.0003205322427675128\n",
      "Epoch 0, Meta Loss: 2.282179117202759, Synthetic Data Grad Norm: 0.00023564614821225405\n",
      "Epoch 0, Meta Loss: 2.2962934970855713, Synthetic Data Grad Norm: 0.000261977402260527\n",
      "Epoch 0, Meta Loss: 2.3032426834106445, Synthetic Data Grad Norm: 0.00024123696493916214\n",
      "Epoch 0, Meta Loss: 2.318758964538574, Synthetic Data Grad Norm: 0.0002892209740821272\n",
      "Epoch 0, Meta Loss: 2.2922072410583496, Synthetic Data Grad Norm: 0.00022623245604336262\n",
      "Epoch 0, Meta Loss: 2.2988526821136475, Synthetic Data Grad Norm: 0.0002347679837839678\n",
      "Epoch 0, Meta Loss: 2.3138625621795654, Synthetic Data Grad Norm: 0.000311436626361683\n",
      "Epoch 0, Meta Loss: 2.3149185180664062, Synthetic Data Grad Norm: 0.0004048562259413302\n",
      "Epoch 0, Meta Loss: 2.291572332382202, Synthetic Data Grad Norm: 0.0002442353870719671\n",
      "Epoch 0, Meta Loss: 2.300767183303833, Synthetic Data Grad Norm: 0.00022474217985291034\n",
      "Epoch 0, Meta Loss: 2.3145718574523926, Synthetic Data Grad Norm: 0.00040620495565235615\n",
      "Epoch 0, Meta Loss: 2.302443504333496, Synthetic Data Grad Norm: 0.00023535301443189383\n",
      "Epoch 0, Meta Loss: 2.2902116775512695, Synthetic Data Grad Norm: 0.00031984466477297246\n",
      "Epoch 0, Meta Loss: 2.310439109802246, Synthetic Data Grad Norm: 0.0002371753507759422\n",
      "Epoch 0, Meta Loss: 2.2776479721069336, Synthetic Data Grad Norm: 0.00033555791014805436\n",
      "Epoch 0, Meta Loss: 2.287855386734009, Synthetic Data Grad Norm: 0.00023201048315968364\n",
      "Epoch 0, Meta Loss: 2.3041434288024902, Synthetic Data Grad Norm: 0.00020940563990734518\n",
      "Epoch 0, Meta Loss: 2.3219540119171143, Synthetic Data Grad Norm: 0.00032864988315850496\n",
      "Epoch 0, Meta Loss: 2.315074920654297, Synthetic Data Grad Norm: 0.00031011708779260516\n",
      "Epoch 0, Meta Loss: 2.3143413066864014, Synthetic Data Grad Norm: 0.0002204214542871341\n",
      "Epoch 0, Meta Loss: 2.3164212703704834, Synthetic Data Grad Norm: 0.0003088685334660113\n",
      "Epoch 0, Meta Loss: 2.288851737976074, Synthetic Data Grad Norm: 0.00031773970113135874\n",
      "Epoch 0, Meta Loss: 2.316079616546631, Synthetic Data Grad Norm: 0.00029132599593140185\n",
      "Epoch 0, Meta Loss: 2.3081114292144775, Synthetic Data Grad Norm: 0.00023593934020027518\n",
      "Epoch 0, Meta Loss: 2.287959337234497, Synthetic Data Grad Norm: 0.0002468315651640296\n",
      "Epoch 0, Meta Loss: 2.305565595626831, Synthetic Data Grad Norm: 0.00034240566310472786\n",
      "Epoch 0, Meta Loss: 2.292246103286743, Synthetic Data Grad Norm: 0.0002646648499649018\n",
      "Epoch 0, Meta Loss: 2.29358172416687, Synthetic Data Grad Norm: 0.00023507986043114215\n",
      "Epoch 0, Meta Loss: 2.2994391918182373, Synthetic Data Grad Norm: 0.00022231521143112332\n",
      "Epoch 0, Meta Loss: 2.2969472408294678, Synthetic Data Grad Norm: 0.00024328789731953293\n",
      "Epoch 0, Meta Loss: 2.2961997985839844, Synthetic Data Grad Norm: 0.00028702139388769865\n",
      "Epoch 0, Meta Loss: 2.288165807723999, Synthetic Data Grad Norm: 0.000319844315527007\n",
      "Epoch 0, Meta Loss: 2.288465738296509, Synthetic Data Grad Norm: 0.0003141771594528109\n",
      "Epoch 0, Meta Loss: 2.310242176055908, Synthetic Data Grad Norm: 0.0002145456528523937\n",
      "Epoch 0, Meta Loss: 2.281752586364746, Synthetic Data Grad Norm: 0.0002828471770044416\n",
      "Epoch 0, Meta Loss: 2.302520990371704, Synthetic Data Grad Norm: 0.0002526508760638535\n",
      "Epoch 0, Meta Loss: 2.2901883125305176, Synthetic Data Grad Norm: 0.0002766868274193257\n",
      "Epoch 0, Meta Loss: 2.293048143386841, Synthetic Data Grad Norm: 0.0002252949634566903\n",
      "Epoch 0, Meta Loss: 2.319993257522583, Synthetic Data Grad Norm: 0.00036781036760658026\n",
      "Epoch 0, Meta Loss: 2.3047094345092773, Synthetic Data Grad Norm: 0.0004854361177422106\n",
      "Epoch 0, Meta Loss: 2.3142356872558594, Synthetic Data Grad Norm: 0.000243297778069973\n",
      "Epoch 0, Meta Loss: 2.3036375045776367, Synthetic Data Grad Norm: 0.0001887310208985582\n",
      "Epoch 0, Meta Loss: 2.2962024211883545, Synthetic Data Grad Norm: 0.00029578039539046586\n",
      "Epoch 0, Meta Loss: 2.294424533843994, Synthetic Data Grad Norm: 0.00024890960776247084\n",
      "Epoch 0, Meta Loss: 2.3129453659057617, Synthetic Data Grad Norm: 0.000276979902992025\n",
      "Epoch 0, Meta Loss: 2.296283006668091, Synthetic Data Grad Norm: 0.00038126250728964806\n",
      "Epoch 0, Meta Loss: 2.30112886428833, Synthetic Data Grad Norm: 0.0002129451313521713\n",
      "Epoch 0, Meta Loss: 2.285212755203247, Synthetic Data Grad Norm: 0.00034525824594311416\n",
      "Epoch 0, Meta Loss: 2.289477825164795, Synthetic Data Grad Norm: 0.0002547416661400348\n",
      "Epoch 0, Meta Loss: 2.2989394664764404, Synthetic Data Grad Norm: 0.000274249556241557\n",
      "Epoch 0, Meta Loss: 2.319788932800293, Synthetic Data Grad Norm: 0.0003338457609061152\n",
      "Epoch 0, Meta Loss: 2.3126323223114014, Synthetic Data Grad Norm: 0.00024437066167593\n",
      "Epoch 0, Meta Loss: 2.2975881099700928, Synthetic Data Grad Norm: 0.00031483478960581124\n",
      "Epoch 0, Meta Loss: 2.2903361320495605, Synthetic Data Grad Norm: 0.0004318458086345345\n",
      "Epoch 0, Meta Loss: 2.3111257553100586, Synthetic Data Grad Norm: 0.00027396497898735106\n",
      "Epoch 0, Meta Loss: 2.299006700515747, Synthetic Data Grad Norm: 0.00030626828083768487\n",
      "Epoch 0, Meta Loss: 2.297299861907959, Synthetic Data Grad Norm: 0.00019684841390699148\n",
      "Epoch 0, Meta Loss: 2.3017239570617676, Synthetic Data Grad Norm: 0.00033698970219120383\n",
      "Epoch 0, Meta Loss: 2.3089005947113037, Synthetic Data Grad Norm: 0.000170828279806301\n",
      "Epoch 0, Meta Loss: 2.3041269779205322, Synthetic Data Grad Norm: 0.00026512256590649486\n",
      "Epoch 0, Meta Loss: 2.300849676132202, Synthetic Data Grad Norm: 0.00020694077829830348\n",
      "Epoch 0, Meta Loss: 2.298255205154419, Synthetic Data Grad Norm: 0.00025658815866336226\n",
      "Epoch 0, Meta Loss: 2.299034833908081, Synthetic Data Grad Norm: 0.00036023370921611786\n",
      "Epoch 0, Meta Loss: 2.3063549995422363, Synthetic Data Grad Norm: 0.00039011225453577936\n",
      "Epoch 0, Meta Loss: 2.30814266204834, Synthetic Data Grad Norm: 0.0002500391856301576\n",
      "Epoch 0, Meta Loss: 2.3036274909973145, Synthetic Data Grad Norm: 0.00024007444153539836\n",
      "Epoch 0, Meta Loss: 2.3024556636810303, Synthetic Data Grad Norm: 0.00028826171183027327\n",
      "Epoch 0, Meta Loss: 2.291404962539673, Synthetic Data Grad Norm: 0.00024761041277088225\n",
      "Epoch 0, Meta Loss: 2.3074097633361816, Synthetic Data Grad Norm: 0.0002455567882861942\n",
      "Epoch 0, Meta Loss: 2.276806354522705, Synthetic Data Grad Norm: 0.00024095042317640036\n",
      "Epoch 0, Meta Loss: 2.2935428619384766, Synthetic Data Grad Norm: 0.00025534912128932774\n",
      "Epoch 0, Meta Loss: 2.3052144050598145, Synthetic Data Grad Norm: 0.0002669673121999949\n",
      "Epoch 0, Meta Loss: 2.2878775596618652, Synthetic Data Grad Norm: 0.0002851905592251569\n",
      "Epoch 0, Meta Loss: 2.303699016571045, Synthetic Data Grad Norm: 0.00020502634288277477\n",
      "Epoch 0, Meta Loss: 2.2947254180908203, Synthetic Data Grad Norm: 0.00023590847558807582\n",
      "Epoch 0, Meta Loss: 2.297819137573242, Synthetic Data Grad Norm: 0.00030866614542901516\n",
      "Epoch 0, Meta Loss: 2.3065719604492188, Synthetic Data Grad Norm: 0.0002605241315905005\n",
      "Epoch 0, Meta Loss: 2.3043670654296875, Synthetic Data Grad Norm: 0.00037524860817939043\n",
      "Epoch 0, Meta Loss: 2.2999699115753174, Synthetic Data Grad Norm: 0.0002641119353938848\n",
      "Epoch 0, Meta Loss: 2.300999402999878, Synthetic Data Grad Norm: 0.00021177591406740248\n",
      "Epoch 0, Meta Loss: 2.2966341972351074, Synthetic Data Grad Norm: 0.00022721845016349107\n",
      "Epoch 0, Meta Loss: 2.2793312072753906, Synthetic Data Grad Norm: 0.00032149822800420225\n",
      "Epoch 0, Meta Loss: 2.28334379196167, Synthetic Data Grad Norm: 0.00030497147236019373\n",
      "Epoch 0, Meta Loss: 2.297663927078247, Synthetic Data Grad Norm: 0.0003073867701459676\n",
      "Epoch 0, Meta Loss: 2.3054141998291016, Synthetic Data Grad Norm: 0.0003123888745903969\n",
      "Epoch 0, Meta Loss: 2.3016932010650635, Synthetic Data Grad Norm: 0.0002830060839187354\n",
      "Epoch 0, Meta Loss: 2.2866342067718506, Synthetic Data Grad Norm: 0.00028334406670182943\n",
      "Epoch 0, Meta Loss: 2.3031539916992188, Synthetic Data Grad Norm: 0.0003358634712640196\n",
      "Epoch 0, Meta Loss: 2.2995123863220215, Synthetic Data Grad Norm: 0.00027912622317671776\n",
      "Epoch 0, Meta Loss: 2.2810566425323486, Synthetic Data Grad Norm: 0.00035737172584049404\n",
      "Epoch 0, Meta Loss: 2.3152318000793457, Synthetic Data Grad Norm: 0.0001977024949155748\n",
      "Epoch 0, Meta Loss: 2.301212787628174, Synthetic Data Grad Norm: 0.00025495936279185116\n",
      "Epoch 0, Meta Loss: 2.3234939575195312, Synthetic Data Grad Norm: 0.0003081797913182527\n",
      "Epoch 0, Meta Loss: 2.293776512145996, Synthetic Data Grad Norm: 0.00020397533080540597\n",
      "Epoch 0, Meta Loss: 2.2914514541625977, Synthetic Data Grad Norm: 0.00037551153218373656\n",
      "Epoch 0, Meta Loss: 2.291311740875244, Synthetic Data Grad Norm: 0.00032690970692783594\n",
      "Epoch 0, Meta Loss: 2.2998206615448, Synthetic Data Grad Norm: 0.00030968524515628815\n",
      "Epoch 0, Meta Loss: 2.3326210975646973, Synthetic Data Grad Norm: 0.0004086069529876113\n",
      "Epoch 0, Meta Loss: 2.2905490398406982, Synthetic Data Grad Norm: 0.0002295792946824804\n",
      "Epoch 0, Meta Loss: 2.2819321155548096, Synthetic Data Grad Norm: 0.0002215274580521509\n",
      "Epoch 0, Meta Loss: 2.2924160957336426, Synthetic Data Grad Norm: 0.0002852879115380347\n",
      "Epoch 0, Meta Loss: 2.2951128482818604, Synthetic Data Grad Norm: 0.0002470706240274012\n",
      "Epoch 0, Meta Loss: 2.2747883796691895, Synthetic Data Grad Norm: 0.0002567479095887393\n",
      "Epoch 0, Meta Loss: 2.2999215126037598, Synthetic Data Grad Norm: 0.0003394623927306384\n",
      "Epoch 0, Meta Loss: 2.296569347381592, Synthetic Data Grad Norm: 0.00027252163272351027\n",
      "Epoch 0, Meta Loss: 2.2939326763153076, Synthetic Data Grad Norm: 0.0002697391901165247\n",
      "Epoch 0, Meta Loss: 2.3152222633361816, Synthetic Data Grad Norm: 0.0002828955475706607\n",
      "Epoch 0, Meta Loss: 2.299572706222534, Synthetic Data Grad Norm: 0.000330860901158303\n",
      "Epoch 0, Meta Loss: 2.302293062210083, Synthetic Data Grad Norm: 0.00025260006077587605\n",
      "Epoch 0, Meta Loss: 2.3137919902801514, Synthetic Data Grad Norm: 0.00034740043338388205\n",
      "Epoch 0, Meta Loss: 2.307465076446533, Synthetic Data Grad Norm: 0.0002632378018461168\n",
      "Epoch 0, Meta Loss: 2.287764072418213, Synthetic Data Grad Norm: 0.00026310610701330006\n",
      "Epoch 0, Meta Loss: 2.2966601848602295, Synthetic Data Grad Norm: 0.00028097990434616804\n",
      "Epoch 0, Meta Loss: 2.309964179992676, Synthetic Data Grad Norm: 0.000286091526504606\n",
      "Epoch 0, Meta Loss: 2.29152250289917, Synthetic Data Grad Norm: 0.00027557031717151403\n",
      "Epoch 0, Meta Loss: 2.3023743629455566, Synthetic Data Grad Norm: 0.00023088554735295475\n",
      "Epoch 0, Meta Loss: 2.3059682846069336, Synthetic Data Grad Norm: 0.0002591789816506207\n",
      "Epoch 0, Meta Loss: 2.2949767112731934, Synthetic Data Grad Norm: 0.00023743431665934622\n",
      "Epoch 0, Meta Loss: 2.297067165374756, Synthetic Data Grad Norm: 0.00026426653494127095\n",
      "Epoch 0, Meta Loss: 2.304919481277466, Synthetic Data Grad Norm: 0.00027947925264015794\n",
      "Epoch 0, Meta Loss: 2.3000991344451904, Synthetic Data Grad Norm: 0.0002978086704388261\n",
      "Epoch 0, Meta Loss: 2.2988944053649902, Synthetic Data Grad Norm: 0.00028625153936445713\n",
      "Epoch 0, Meta Loss: 2.283086061477661, Synthetic Data Grad Norm: 0.00023454008623957634\n",
      "Epoch 0, Meta Loss: 2.296896457672119, Synthetic Data Grad Norm: 0.00028356880648061633\n",
      "Epoch 0, Meta Loss: 2.2863857746124268, Synthetic Data Grad Norm: 0.0002829749428201467\n",
      "Epoch 0, Meta Loss: 2.289106607437134, Synthetic Data Grad Norm: 0.0002095753006869927\n",
      "Epoch 0, Meta Loss: 2.292104959487915, Synthetic Data Grad Norm: 0.00026407084078527987\n",
      "Epoch 0, Meta Loss: 2.2932205200195312, Synthetic Data Grad Norm: 0.000310849049128592\n",
      "Epoch 0, Meta Loss: 2.2776052951812744, Synthetic Data Grad Norm: 0.00028912906418554485\n",
      "Epoch 0, Meta Loss: 2.3119730949401855, Synthetic Data Grad Norm: 0.00028899620519950986\n",
      "Epoch 0, Meta Loss: 2.2915892601013184, Synthetic Data Grad Norm: 0.0003234940813854337\n",
      "Epoch 0, Meta Loss: 2.2958433628082275, Synthetic Data Grad Norm: 0.00020406725525390357\n",
      "Epoch 0, Meta Loss: 2.3114891052246094, Synthetic Data Grad Norm: 0.0003232443705201149\n",
      "Epoch 0, Meta Loss: 2.3020806312561035, Synthetic Data Grad Norm: 0.00035488378489390016\n",
      "Epoch 0, Meta Loss: 2.3051578998565674, Synthetic Data Grad Norm: 0.00027648144168779254\n",
      "Epoch 0, Meta Loss: 2.298618793487549, Synthetic Data Grad Norm: 0.0002734239969868213\n",
      "Epoch 0, Meta Loss: 2.2941408157348633, Synthetic Data Grad Norm: 0.00028841212042607367\n",
      "Epoch 0, Meta Loss: 2.3175110816955566, Synthetic Data Grad Norm: 0.0003664847172331065\n",
      "Epoch 0, Meta Loss: 2.290666103363037, Synthetic Data Grad Norm: 0.00026101915864273906\n",
      "Epoch 0, Meta Loss: 2.291639566421509, Synthetic Data Grad Norm: 0.00028428787481971085\n",
      "Epoch 0, Meta Loss: 2.3141071796417236, Synthetic Data Grad Norm: 0.00021899545390624553\n",
      "Epoch 0, Meta Loss: 2.299118757247925, Synthetic Data Grad Norm: 0.00028707736055366695\n",
      "Epoch 0, Meta Loss: 2.3158507347106934, Synthetic Data Grad Norm: 0.0003141395282000303\n",
      "Epoch 0, Meta Loss: 2.2994039058685303, Synthetic Data Grad Norm: 0.0002602367603685707\n",
      "Epoch 0, Meta Loss: 2.279629945755005, Synthetic Data Grad Norm: 0.0002830936573445797\n",
      "Epoch 0, Meta Loss: 2.300128936767578, Synthetic Data Grad Norm: 0.000263999099843204\n",
      "Epoch 0, Meta Loss: 2.2886195182800293, Synthetic Data Grad Norm: 0.00026144602452404797\n",
      "Epoch 0, Meta Loss: 2.2893335819244385, Synthetic Data Grad Norm: 0.0002610830997582525\n",
      "Epoch 0, Meta Loss: 2.3065185546875, Synthetic Data Grad Norm: 0.0003538145392667502\n",
      "Epoch 0, Meta Loss: 2.3093531131744385, Synthetic Data Grad Norm: 0.00029461446683853865\n",
      "Epoch 0, Meta Loss: 2.287119150161743, Synthetic Data Grad Norm: 0.00019953417358919978\n",
      "Epoch 0, Meta Loss: 2.284173011779785, Synthetic Data Grad Norm: 0.0003025967162102461\n",
      "Epoch 0, Meta Loss: 2.311491012573242, Synthetic Data Grad Norm: 0.00030763211543671787\n",
      "Epoch 0, Meta Loss: 2.2907369136810303, Synthetic Data Grad Norm: 0.0002016745274886489\n",
      "Epoch 0, Meta Loss: 2.296238660812378, Synthetic Data Grad Norm: 0.0003512818948365748\n",
      "Epoch 0, Meta Loss: 2.299755811691284, Synthetic Data Grad Norm: 0.0002698729804251343\n",
      "Epoch 0, Meta Loss: 2.307502269744873, Synthetic Data Grad Norm: 0.000200186186702922\n",
      "Epoch 0, Meta Loss: 2.303318500518799, Synthetic Data Grad Norm: 0.0002866617578547448\n",
      "Epoch 0, Meta Loss: 2.2957887649536133, Synthetic Data Grad Norm: 0.00021861662389710546\n",
      "Epoch 0, Meta Loss: 2.2797443866729736, Synthetic Data Grad Norm: 0.00029741160687990487\n",
      "Epoch 0, Meta Loss: 2.305677652359009, Synthetic Data Grad Norm: 0.00029175911913625896\n",
      "Epoch 0, Meta Loss: 2.2972068786621094, Synthetic Data Grad Norm: 0.00022349126811604947\n",
      "Epoch 0, Meta Loss: 2.2955315113067627, Synthetic Data Grad Norm: 0.00031388673232868314\n",
      "Epoch 0, Meta Loss: 2.3179068565368652, Synthetic Data Grad Norm: 0.00028116998146288097\n",
      "Epoch 0, Meta Loss: 2.2793822288513184, Synthetic Data Grad Norm: 0.0002565592876635492\n",
      "Epoch 0, Meta Loss: 2.2985925674438477, Synthetic Data Grad Norm: 0.00023561528360005468\n",
      "Epoch 0, Meta Loss: 2.306415557861328, Synthetic Data Grad Norm: 0.0003097517183050513\n",
      "Epoch 0, Meta Loss: 2.2826435565948486, Synthetic Data Grad Norm: 0.00024389765167143196\n",
      "Epoch 0, Meta Loss: 2.306002378463745, Synthetic Data Grad Norm: 0.00029182847356423736\n",
      "Epoch 0, Meta Loss: 2.2993011474609375, Synthetic Data Grad Norm: 0.00023791332205291837\n",
      "Epoch 0, Meta Loss: 2.298185348510742, Synthetic Data Grad Norm: 0.0002734969893936068\n",
      "Epoch 0, Meta Loss: 2.304755449295044, Synthetic Data Grad Norm: 0.00032199209090322256\n",
      "Epoch 0, Meta Loss: 2.300532817840576, Synthetic Data Grad Norm: 0.00024689309066161513\n",
      "Epoch 0, Meta Loss: 2.2890615463256836, Synthetic Data Grad Norm: 0.00038946946733631194\n",
      "Epoch 0, Meta Loss: 2.303070545196533, Synthetic Data Grad Norm: 0.0002940197882708162\n",
      "Epoch 0, Meta Loss: 2.323432683944702, Synthetic Data Grad Norm: 0.0002668615779839456\n",
      "Epoch 0, Meta Loss: 2.3033370971679688, Synthetic Data Grad Norm: 0.00028012614347971976\n",
      "Epoch 0, Meta Loss: 2.3040850162506104, Synthetic Data Grad Norm: 0.0002597447601146996\n",
      "Epoch 0, Meta Loss: 2.308729887008667, Synthetic Data Grad Norm: 0.0001968942815437913\n",
      "Epoch 0, Meta Loss: 2.2854080200195312, Synthetic Data Grad Norm: 0.0003943810588680208\n",
      "Epoch 0, Meta Loss: 2.3100457191467285, Synthetic Data Grad Norm: 0.0003023815806955099\n",
      "Epoch 0, Meta Loss: 2.2889766693115234, Synthetic Data Grad Norm: 0.00028924192884005606\n",
      "Epoch 0, Meta Loss: 2.2981293201446533, Synthetic Data Grad Norm: 0.0003190167190041393\n",
      "Epoch 0, Meta Loss: 2.314175844192505, Synthetic Data Grad Norm: 0.00040600518696010113\n",
      "Epoch 0, Meta Loss: 2.3010802268981934, Synthetic Data Grad Norm: 0.0003049122169613838\n",
      "Epoch 0, Meta Loss: 2.2893505096435547, Synthetic Data Grad Norm: 0.0002202468313043937\n",
      "Epoch 0, Meta Loss: 2.3013370037078857, Synthetic Data Grad Norm: 0.0002629744412843138\n",
      "Epoch 0, Meta Loss: 2.3018980026245117, Synthetic Data Grad Norm: 0.0003381116839591414\n",
      "Epoch 0, Meta Loss: 2.28902006149292, Synthetic Data Grad Norm: 0.00026648223865777254\n",
      "Epoch 0, Meta Loss: 2.2846972942352295, Synthetic Data Grad Norm: 0.00039691856363788247\n",
      "Epoch 0, Meta Loss: 2.29498291015625, Synthetic Data Grad Norm: 0.0002723587676882744\n",
      "Epoch 0, Meta Loss: 2.2846829891204834, Synthetic Data Grad Norm: 0.00019936442549806088\n",
      "Epoch 0, Meta Loss: 2.296010971069336, Synthetic Data Grad Norm: 0.0002144939498975873\n",
      "Epoch 0, Meta Loss: 2.2901079654693604, Synthetic Data Grad Norm: 0.0002844512928277254\n",
      "Epoch 0, Meta Loss: 2.284346342086792, Synthetic Data Grad Norm: 0.00032130596810020506\n",
      "Epoch 0, Meta Loss: 2.3022055625915527, Synthetic Data Grad Norm: 0.00023270522069651634\n",
      "Epoch 0, Meta Loss: 2.3000388145446777, Synthetic Data Grad Norm: 0.00023076575598679483\n",
      "Epoch 0, Meta Loss: 2.298007011413574, Synthetic Data Grad Norm: 0.0003244577383156866\n",
      "Epoch 0, Meta Loss: 2.305518627166748, Synthetic Data Grad Norm: 0.0003418306296225637\n",
      "Epoch 0, Meta Loss: 2.3098785877227783, Synthetic Data Grad Norm: 0.00027991575188934803\n",
      "Epoch 0, Meta Loss: 2.301110029220581, Synthetic Data Grad Norm: 0.0002871496544685215\n",
      "Epoch 0, Meta Loss: 2.30194091796875, Synthetic Data Grad Norm: 0.00023041477834340185\n",
      "Epoch 0, Meta Loss: 2.292046308517456, Synthetic Data Grad Norm: 0.0002470571198500693\n",
      "Epoch 0, Meta Loss: 2.3109817504882812, Synthetic Data Grad Norm: 0.00025277771055698395\n",
      "Epoch 0, Meta Loss: 2.3054440021514893, Synthetic Data Grad Norm: 0.000245620496571064\n",
      "Epoch 0, Meta Loss: 2.2943527698516846, Synthetic Data Grad Norm: 0.00018733688921201974\n",
      "Epoch 0, Meta Loss: 2.309028148651123, Synthetic Data Grad Norm: 0.0003522612969391048\n",
      "Epoch 0, Meta Loss: 2.2952678203582764, Synthetic Data Grad Norm: 0.0002546867763157934\n",
      "Epoch 0, Meta Loss: 2.317152500152588, Synthetic Data Grad Norm: 0.0002524169103708118\n",
      "Epoch 0, Meta Loss: 2.2910044193267822, Synthetic Data Grad Norm: 0.00037624171818606555\n",
      "Epoch 0, Meta Loss: 2.3035151958465576, Synthetic Data Grad Norm: 0.00039334053872153163\n",
      "Epoch 0, Meta Loss: 2.295367956161499, Synthetic Data Grad Norm: 0.00030550494557246566\n",
      "Epoch 0, Meta Loss: 2.2838246822357178, Synthetic Data Grad Norm: 0.00026900097145698965\n",
      "Epoch 0, Meta Loss: 2.2963545322418213, Synthetic Data Grad Norm: 0.00030550951487384737\n",
      "Epoch 0, Meta Loss: 2.297161817550659, Synthetic Data Grad Norm: 0.00033078499836847186\n",
      "Epoch 0, Meta Loss: 2.282356023788452, Synthetic Data Grad Norm: 0.0002651715185493231\n",
      "Epoch 0, Meta Loss: 2.3079171180725098, Synthetic Data Grad Norm: 0.000369936169590801\n",
      "Epoch 0, Meta Loss: 2.2989087104797363, Synthetic Data Grad Norm: 0.00021527678472921252\n",
      "Epoch 0, Meta Loss: 2.286785364151001, Synthetic Data Grad Norm: 0.00027721349033527076\n",
      "Epoch 0, Meta Loss: 2.289613962173462, Synthetic Data Grad Norm: 0.00028429002850316465\n",
      "Epoch 0, Meta Loss: 2.285351514816284, Synthetic Data Grad Norm: 0.0003091564285568893\n",
      "Epoch 0, Meta Loss: 2.3140809535980225, Synthetic Data Grad Norm: 0.0002535732928663492\n",
      "Epoch 0, Meta Loss: 2.3042218685150146, Synthetic Data Grad Norm: 0.00038441974902525544\n",
      "Epoch 0, Meta Loss: 2.2959144115448, Synthetic Data Grad Norm: 0.0003610927960835397\n",
      "Epoch 0, Meta Loss: 2.296060085296631, Synthetic Data Grad Norm: 0.00020344408403616399\n",
      "Epoch 0, Meta Loss: 2.306434154510498, Synthetic Data Grad Norm: 0.00025767722399905324\n",
      "Epoch 0, Meta Loss: 2.2998645305633545, Synthetic Data Grad Norm: 0.00027806544676423073\n",
      "Epoch 0, Meta Loss: 2.302124500274658, Synthetic Data Grad Norm: 0.0002342591033084318\n",
      "Epoch 0, Meta Loss: 2.2975692749023438, Synthetic Data Grad Norm: 0.00036917204852215946\n",
      "Epoch 0, Meta Loss: 2.321524143218994, Synthetic Data Grad Norm: 0.0003253553295508027\n",
      "Epoch 0, Meta Loss: 2.2891159057617188, Synthetic Data Grad Norm: 0.00037837884156033397\n",
      "Epoch 0, Meta Loss: 2.28914475440979, Synthetic Data Grad Norm: 0.00020414766913745552\n",
      "Epoch 0, Meta Loss: 2.3087353706359863, Synthetic Data Grad Norm: 0.000427633902290836\n",
      "Epoch 0, Meta Loss: 2.2720348834991455, Synthetic Data Grad Norm: 0.00031478703022003174\n",
      "Epoch 0, Meta Loss: 2.2899844646453857, Synthetic Data Grad Norm: 0.00026864768005907536\n",
      "Epoch 0, Meta Loss: 2.3012335300445557, Synthetic Data Grad Norm: 0.0002901955449488014\n",
      "Epoch 0, Meta Loss: 2.297971725463867, Synthetic Data Grad Norm: 0.0003046104684472084\n",
      "Epoch 0, Meta Loss: 2.293078899383545, Synthetic Data Grad Norm: 0.00031102829962037504\n",
      "Epoch 0, Meta Loss: 2.3155431747436523, Synthetic Data Grad Norm: 0.00030873221112415195\n",
      "Epoch 0, Meta Loss: 2.291273832321167, Synthetic Data Grad Norm: 0.00022021551558282226\n",
      "Epoch 0, Meta Loss: 2.306962728500366, Synthetic Data Grad Norm: 0.00019512654398567975\n",
      "Epoch 0, Meta Loss: 2.3127477169036865, Synthetic Data Grad Norm: 0.000382984580937773\n",
      "Epoch 1, Meta Loss: 2.317847490310669, Synthetic Data Grad Norm: 0.0003166351525578648\n",
      "Epoch 1, Meta Loss: 2.300971508026123, Synthetic Data Grad Norm: 0.0002258839667774737\n",
      "Epoch 1, Meta Loss: 2.2985599040985107, Synthetic Data Grad Norm: 0.00025299517437815666\n",
      "Epoch 1, Meta Loss: 2.2971348762512207, Synthetic Data Grad Norm: 0.0003012662346009165\n",
      "Epoch 1, Meta Loss: 2.297583818435669, Synthetic Data Grad Norm: 0.0002708182146307081\n",
      "Epoch 1, Meta Loss: 2.303717613220215, Synthetic Data Grad Norm: 0.00034534806036390364\n",
      "Epoch 1, Meta Loss: 2.290212631225586, Synthetic Data Grad Norm: 0.0002778483321890235\n",
      "Epoch 1, Meta Loss: 2.262326240539551, Synthetic Data Grad Norm: 0.0003491333918645978\n",
      "Epoch 1, Meta Loss: 2.3177833557128906, Synthetic Data Grad Norm: 0.0003023373428732157\n",
      "Epoch 1, Meta Loss: 2.3071515560150146, Synthetic Data Grad Norm: 0.00019617690122686327\n",
      "Epoch 1, Meta Loss: 2.3068037033081055, Synthetic Data Grad Norm: 0.00022677515516988933\n",
      "Epoch 1, Meta Loss: 2.2939388751983643, Synthetic Data Grad Norm: 0.00030443514697253704\n",
      "Epoch 1, Meta Loss: 2.2925970554351807, Synthetic Data Grad Norm: 0.00019880817853845656\n",
      "Epoch 1, Meta Loss: 2.3025434017181396, Synthetic Data Grad Norm: 0.0003570590924937278\n",
      "Epoch 1, Meta Loss: 2.2969815731048584, Synthetic Data Grad Norm: 0.00022454001009464264\n",
      "Epoch 1, Meta Loss: 2.3115744590759277, Synthetic Data Grad Norm: 0.00017347646644338965\n",
      "Epoch 1, Meta Loss: 2.285475969314575, Synthetic Data Grad Norm: 0.0002911674964707345\n",
      "Epoch 1, Meta Loss: 2.3071129322052, Synthetic Data Grad Norm: 0.00019765051547437906\n",
      "Epoch 1, Meta Loss: 2.2738380432128906, Synthetic Data Grad Norm: 0.0003416618565097451\n",
      "Epoch 1, Meta Loss: 2.3043365478515625, Synthetic Data Grad Norm: 0.0002574533864390105\n",
      "Epoch 1, Meta Loss: 2.297656774520874, Synthetic Data Grad Norm: 0.00025234342319890857\n",
      "Epoch 1, Meta Loss: 2.2988855838775635, Synthetic Data Grad Norm: 0.00031536101596429944\n",
      "Epoch 1, Meta Loss: 2.2930474281311035, Synthetic Data Grad Norm: 0.00019653352501336485\n",
      "Epoch 1, Meta Loss: 2.3053488731384277, Synthetic Data Grad Norm: 0.00023782500647939742\n",
      "Epoch 1, Meta Loss: 2.2857348918914795, Synthetic Data Grad Norm: 0.00018797114898916334\n",
      "Epoch 1, Meta Loss: 2.2966363430023193, Synthetic Data Grad Norm: 0.00029853693558834493\n",
      "Epoch 1, Meta Loss: 2.2916014194488525, Synthetic Data Grad Norm: 0.0002579271967988461\n",
      "Epoch 1, Meta Loss: 2.300565481185913, Synthetic Data Grad Norm: 0.00024156467407010496\n",
      "Epoch 1, Meta Loss: 2.2955195903778076, Synthetic Data Grad Norm: 0.00018942877068184316\n",
      "Epoch 1, Meta Loss: 2.2963221073150635, Synthetic Data Grad Norm: 0.00021678672055713832\n",
      "Epoch 1, Meta Loss: 2.3087594509124756, Synthetic Data Grad Norm: 0.00023030376178212464\n",
      "Epoch 1, Meta Loss: 2.292314291000366, Synthetic Data Grad Norm: 0.0002035152429016307\n",
      "Epoch 1, Meta Loss: 2.3069095611572266, Synthetic Data Grad Norm: 0.00032401204225607216\n",
      "Epoch 1, Meta Loss: 2.2844655513763428, Synthetic Data Grad Norm: 0.00027769789448939264\n",
      "Epoch 1, Meta Loss: 2.274698257446289, Synthetic Data Grad Norm: 0.0003938732552342117\n",
      "Epoch 1, Meta Loss: 2.2900147438049316, Synthetic Data Grad Norm: 0.00022322985751088709\n",
      "Epoch 1, Meta Loss: 2.3099236488342285, Synthetic Data Grad Norm: 0.0002990484645124525\n",
      "Epoch 1, Meta Loss: 2.307206153869629, Synthetic Data Grad Norm: 0.00026974681532010436\n",
      "Epoch 1, Meta Loss: 2.295377016067505, Synthetic Data Grad Norm: 0.0002464683202560991\n",
      "Epoch 1, Meta Loss: 2.3015027046203613, Synthetic Data Grad Norm: 0.000271050026640296\n",
      "Epoch 1, Meta Loss: 2.312394380569458, Synthetic Data Grad Norm: 0.0002959909907076508\n",
      "Epoch 1, Meta Loss: 2.314504384994507, Synthetic Data Grad Norm: 0.00029919217922724783\n",
      "Epoch 1, Meta Loss: 2.2832000255584717, Synthetic Data Grad Norm: 0.0003032399690710008\n",
      "Epoch 1, Meta Loss: 2.2951958179473877, Synthetic Data Grad Norm: 0.0002445056743454188\n",
      "Epoch 1, Meta Loss: 2.2995781898498535, Synthetic Data Grad Norm: 0.00027565666823647916\n",
      "Epoch 1, Meta Loss: 2.299438238143921, Synthetic Data Grad Norm: 0.0002674947609193623\n",
      "Epoch 1, Meta Loss: 2.2896265983581543, Synthetic Data Grad Norm: 0.00023728341329842806\n",
      "Epoch 1, Meta Loss: 2.30818247795105, Synthetic Data Grad Norm: 0.00028781581204384565\n",
      "Epoch 1, Meta Loss: 2.2929985523223877, Synthetic Data Grad Norm: 0.0002785618999041617\n",
      "Epoch 1, Meta Loss: 2.290628433227539, Synthetic Data Grad Norm: 0.0003373346116859466\n",
      "Epoch 1, Meta Loss: 2.302947759628296, Synthetic Data Grad Norm: 0.00022050751431379467\n",
      "Epoch 1, Meta Loss: 2.305636167526245, Synthetic Data Grad Norm: 0.00022684728901367635\n",
      "Epoch 1, Meta Loss: 2.292584180831909, Synthetic Data Grad Norm: 0.00024888067855499685\n",
      "Epoch 1, Meta Loss: 2.2897872924804688, Synthetic Data Grad Norm: 0.00034087663516402245\n",
      "Epoch 1, Meta Loss: 2.291992425918579, Synthetic Data Grad Norm: 0.0003506008943077177\n",
      "Epoch 1, Meta Loss: 2.2950730323791504, Synthetic Data Grad Norm: 0.0002843565889634192\n",
      "Epoch 1, Meta Loss: 2.291066884994507, Synthetic Data Grad Norm: 0.00020472555479500443\n",
      "Epoch 1, Meta Loss: 2.2891526222229004, Synthetic Data Grad Norm: 0.0002876758517231792\n",
      "Epoch 1, Meta Loss: 2.302839994430542, Synthetic Data Grad Norm: 0.00025153218302875757\n",
      "Epoch 1, Meta Loss: 2.315964698791504, Synthetic Data Grad Norm: 0.00024215015582740307\n",
      "Epoch 1, Meta Loss: 2.320927619934082, Synthetic Data Grad Norm: 0.0003176601603627205\n",
      "Epoch 1, Meta Loss: 2.308326244354248, Synthetic Data Grad Norm: 0.00024663936346769333\n",
      "Epoch 1, Meta Loss: 2.291792392730713, Synthetic Data Grad Norm: 0.0002346363035030663\n",
      "Epoch 1, Meta Loss: 2.301633596420288, Synthetic Data Grad Norm: 0.00023423059610649943\n",
      "Epoch 1, Meta Loss: 2.3073577880859375, Synthetic Data Grad Norm: 0.0002756273315753788\n",
      "Epoch 1, Meta Loss: 2.2860147953033447, Synthetic Data Grad Norm: 0.00019990422879345715\n",
      "Epoch 1, Meta Loss: 2.3008711338043213, Synthetic Data Grad Norm: 0.00028221699176356196\n",
      "Epoch 1, Meta Loss: 2.2970643043518066, Synthetic Data Grad Norm: 0.00034708654857240617\n",
      "Epoch 1, Meta Loss: 2.3042495250701904, Synthetic Data Grad Norm: 0.00030426130979321897\n",
      "Epoch 1, Meta Loss: 2.2897748947143555, Synthetic Data Grad Norm: 0.00023381106439046562\n",
      "Epoch 1, Meta Loss: 2.325087785720825, Synthetic Data Grad Norm: 0.0002476742083672434\n",
      "Epoch 1, Meta Loss: 2.3021583557128906, Synthetic Data Grad Norm: 0.0002426014980301261\n",
      "Epoch 1, Meta Loss: 2.2826404571533203, Synthetic Data Grad Norm: 0.00020845804829150438\n",
      "Epoch 1, Meta Loss: 2.2934203147888184, Synthetic Data Grad Norm: 0.0002457374066580087\n",
      "Epoch 1, Meta Loss: 2.3044240474700928, Synthetic Data Grad Norm: 0.00025190450833179057\n",
      "Epoch 1, Meta Loss: 2.2782773971557617, Synthetic Data Grad Norm: 0.0003038217837456614\n",
      "Epoch 1, Meta Loss: 2.2834513187408447, Synthetic Data Grad Norm: 0.0002710562839638442\n",
      "Epoch 1, Meta Loss: 2.293001890182495, Synthetic Data Grad Norm: 0.00024929281789809465\n",
      "Epoch 1, Meta Loss: 2.3045156002044678, Synthetic Data Grad Norm: 0.00039891048800200224\n",
      "Epoch 1, Meta Loss: 2.2940433025360107, Synthetic Data Grad Norm: 0.0003013351815752685\n",
      "Epoch 1, Meta Loss: 2.2853240966796875, Synthetic Data Grad Norm: 0.0002627632347866893\n",
      "Epoch 1, Meta Loss: 2.306870222091675, Synthetic Data Grad Norm: 0.00027230518753640354\n",
      "Epoch 1, Meta Loss: 2.2931954860687256, Synthetic Data Grad Norm: 0.00022254334180615842\n",
      "Epoch 1, Meta Loss: 2.2803845405578613, Synthetic Data Grad Norm: 0.0003031410451512784\n",
      "Epoch 1, Meta Loss: 2.300079345703125, Synthetic Data Grad Norm: 0.00014743917563464493\n",
      "Epoch 1, Meta Loss: 2.3265349864959717, Synthetic Data Grad Norm: 0.00030989048536866903\n",
      "Epoch 1, Meta Loss: 2.2972700595855713, Synthetic Data Grad Norm: 0.00023596342361997813\n",
      "Epoch 1, Meta Loss: 2.2888686656951904, Synthetic Data Grad Norm: 0.00022329580679070204\n",
      "Epoch 1, Meta Loss: 2.308842897415161, Synthetic Data Grad Norm: 0.0002663127379491925\n",
      "Epoch 1, Meta Loss: 2.3017895221710205, Synthetic Data Grad Norm: 0.00027927124756388366\n",
      "Epoch 1, Meta Loss: 2.2850122451782227, Synthetic Data Grad Norm: 0.00032222026493400335\n",
      "Epoch 1, Meta Loss: 2.2693262100219727, Synthetic Data Grad Norm: 0.0002700269687920809\n",
      "Epoch 1, Meta Loss: 2.293048858642578, Synthetic Data Grad Norm: 0.0003350781335029751\n",
      "Epoch 1, Meta Loss: 2.2993459701538086, Synthetic Data Grad Norm: 0.0002128857304342091\n",
      "Epoch 1, Meta Loss: 2.3061821460723877, Synthetic Data Grad Norm: 0.0002470382605679333\n",
      "Epoch 1, Meta Loss: 2.2740375995635986, Synthetic Data Grad Norm: 0.0002319349441677332\n",
      "Epoch 1, Meta Loss: 2.2806155681610107, Synthetic Data Grad Norm: 0.000246803363552317\n",
      "Epoch 1, Meta Loss: 2.286428213119507, Synthetic Data Grad Norm: 0.0002272938727401197\n",
      "Epoch 1, Meta Loss: 2.308211088180542, Synthetic Data Grad Norm: 0.00035236740950495005\n",
      "Epoch 1, Meta Loss: 2.2726683616638184, Synthetic Data Grad Norm: 0.0002977548283524811\n",
      "Epoch 1, Meta Loss: 2.285029888153076, Synthetic Data Grad Norm: 0.0002277195017086342\n",
      "Epoch 1, Meta Loss: 2.302824020385742, Synthetic Data Grad Norm: 0.0002852673060260713\n",
      "Epoch 1, Meta Loss: 2.3161673545837402, Synthetic Data Grad Norm: 0.00023890806187409908\n",
      "Epoch 1, Meta Loss: 2.2865419387817383, Synthetic Data Grad Norm: 0.00037883699405938387\n",
      "Epoch 1, Meta Loss: 2.2952375411987305, Synthetic Data Grad Norm: 0.00028173686587251723\n",
      "Epoch 1, Meta Loss: 2.3038856983184814, Synthetic Data Grad Norm: 0.0003175678721163422\n",
      "Epoch 1, Meta Loss: 2.3061912059783936, Synthetic Data Grad Norm: 0.0002792546001728624\n",
      "Epoch 1, Meta Loss: 2.2852783203125, Synthetic Data Grad Norm: 0.00021519247093237936\n",
      "Epoch 1, Meta Loss: 2.296970844268799, Synthetic Data Grad Norm: 0.0001565219572512433\n",
      "Epoch 1, Meta Loss: 2.3108975887298584, Synthetic Data Grad Norm: 0.0002887157606892288\n",
      "Epoch 1, Meta Loss: 2.2861578464508057, Synthetic Data Grad Norm: 0.0003046187630388886\n",
      "Epoch 1, Meta Loss: 2.316823720932007, Synthetic Data Grad Norm: 0.00019901299674529582\n",
      "Epoch 1, Meta Loss: 2.2959866523742676, Synthetic Data Grad Norm: 0.00021769804880023003\n",
      "Epoch 1, Meta Loss: 2.297776937484741, Synthetic Data Grad Norm: 0.00020622118609026074\n",
      "Epoch 1, Meta Loss: 2.296675205230713, Synthetic Data Grad Norm: 0.0002748257538769394\n",
      "Epoch 1, Meta Loss: 2.2940237522125244, Synthetic Data Grad Norm: 0.0002953167713712901\n",
      "Epoch 1, Meta Loss: 2.2984936237335205, Synthetic Data Grad Norm: 0.00021364913845900446\n",
      "Epoch 1, Meta Loss: 2.305819511413574, Synthetic Data Grad Norm: 0.0002868111478164792\n",
      "Epoch 1, Meta Loss: 2.2797250747680664, Synthetic Data Grad Norm: 0.0002802503004204482\n",
      "Epoch 1, Meta Loss: 2.304028272628784, Synthetic Data Grad Norm: 0.0002725538215599954\n",
      "Epoch 1, Meta Loss: 2.2920613288879395, Synthetic Data Grad Norm: 0.00028798909625038505\n",
      "Epoch 1, Meta Loss: 2.293515682220459, Synthetic Data Grad Norm: 0.0002724635414779186\n",
      "Epoch 1, Meta Loss: 2.2872345447540283, Synthetic Data Grad Norm: 0.0003072036779485643\n",
      "Epoch 1, Meta Loss: 2.2876410484313965, Synthetic Data Grad Norm: 0.00029109884053468704\n",
      "Epoch 1, Meta Loss: 2.317257881164551, Synthetic Data Grad Norm: 0.0003228468412999064\n",
      "Epoch 1, Meta Loss: 2.3108348846435547, Synthetic Data Grad Norm: 0.00027393244090490043\n",
      "Epoch 1, Meta Loss: 2.2968311309814453, Synthetic Data Grad Norm: 0.00027016145759262145\n",
      "Epoch 1, Meta Loss: 2.2959842681884766, Synthetic Data Grad Norm: 0.00026375969173386693\n",
      "Epoch 1, Meta Loss: 2.306375026702881, Synthetic Data Grad Norm: 0.0002421101089566946\n",
      "Epoch 1, Meta Loss: 2.300839900970459, Synthetic Data Grad Norm: 0.00023744675854686648\n",
      "Epoch 1, Meta Loss: 2.2959232330322266, Synthetic Data Grad Norm: 0.00016375935229007155\n",
      "Epoch 1, Meta Loss: 2.310540199279785, Synthetic Data Grad Norm: 0.0002563768357504159\n",
      "Epoch 1, Meta Loss: 2.304699182510376, Synthetic Data Grad Norm: 0.00016772480739746243\n",
      "Epoch 1, Meta Loss: 2.285349130630493, Synthetic Data Grad Norm: 0.00022037653252482414\n",
      "Epoch 1, Meta Loss: 2.291323661804199, Synthetic Data Grad Norm: 0.0003668346325866878\n",
      "Epoch 1, Meta Loss: 2.2716498374938965, Synthetic Data Grad Norm: 0.0003902973548974842\n",
      "Epoch 1, Meta Loss: 2.3137731552124023, Synthetic Data Grad Norm: 0.00021783128613606095\n",
      "Epoch 1, Meta Loss: 2.295443296432495, Synthetic Data Grad Norm: 0.0003368640027474612\n",
      "Epoch 1, Meta Loss: 2.3086729049682617, Synthetic Data Grad Norm: 0.0003024709003511816\n",
      "Epoch 1, Meta Loss: 2.3001840114593506, Synthetic Data Grad Norm: 0.0002497444802429527\n",
      "Epoch 1, Meta Loss: 2.2807116508483887, Synthetic Data Grad Norm: 0.00037426475319080055\n",
      "Epoch 1, Meta Loss: 2.2861995697021484, Synthetic Data Grad Norm: 0.00029120754334144294\n",
      "Epoch 1, Meta Loss: 2.292875051498413, Synthetic Data Grad Norm: 0.00029314967105165124\n",
      "Epoch 1, Meta Loss: 2.2994863986968994, Synthetic Data Grad Norm: 0.0002617299905978143\n",
      "Epoch 1, Meta Loss: 2.275212049484253, Synthetic Data Grad Norm: 0.0004577810759656131\n",
      "Epoch 1, Meta Loss: 2.2985734939575195, Synthetic Data Grad Norm: 0.0003605888632591814\n",
      "Epoch 1, Meta Loss: 2.314974546432495, Synthetic Data Grad Norm: 0.0002627177454996854\n",
      "Epoch 1, Meta Loss: 2.287374973297119, Synthetic Data Grad Norm: 0.0002593413810245693\n",
      "Epoch 1, Meta Loss: 2.2987146377563477, Synthetic Data Grad Norm: 0.0002251674741273746\n",
      "Epoch 1, Meta Loss: 2.3103833198547363, Synthetic Data Grad Norm: 0.00023704285558778793\n",
      "Epoch 1, Meta Loss: 2.3060994148254395, Synthetic Data Grad Norm: 0.00031375911203213036\n",
      "Epoch 1, Meta Loss: 2.2958109378814697, Synthetic Data Grad Norm: 0.0004050736897625029\n",
      "Epoch 1, Meta Loss: 2.3074800968170166, Synthetic Data Grad Norm: 0.00023307872470468283\n",
      "Epoch 1, Meta Loss: 2.2821767330169678, Synthetic Data Grad Norm: 0.0003109616518486291\n",
      "Epoch 1, Meta Loss: 2.2746422290802, Synthetic Data Grad Norm: 0.000248292344622314\n",
      "Epoch 1, Meta Loss: 2.299647331237793, Synthetic Data Grad Norm: 0.0002069052425213158\n",
      "Epoch 1, Meta Loss: 2.2906839847564697, Synthetic Data Grad Norm: 0.0003412782389204949\n",
      "Epoch 1, Meta Loss: 2.2951791286468506, Synthetic Data Grad Norm: 0.0002492514031473547\n",
      "Epoch 1, Meta Loss: 2.299147844314575, Synthetic Data Grad Norm: 0.00034370101639069617\n",
      "Epoch 1, Meta Loss: 2.2964911460876465, Synthetic Data Grad Norm: 0.0002473277854733169\n",
      "Epoch 1, Meta Loss: 2.2882471084594727, Synthetic Data Grad Norm: 0.0002532322541810572\n",
      "Epoch 1, Meta Loss: 2.2929534912109375, Synthetic Data Grad Norm: 0.00023644542670808733\n",
      "Epoch 1, Meta Loss: 2.292555093765259, Synthetic Data Grad Norm: 0.0002656080177985132\n",
      "Epoch 1, Meta Loss: 2.294264554977417, Synthetic Data Grad Norm: 0.0002601977321319282\n",
      "Epoch 1, Meta Loss: 2.2982470989227295, Synthetic Data Grad Norm: 0.0002459640963934362\n",
      "Epoch 1, Meta Loss: 2.293795347213745, Synthetic Data Grad Norm: 0.00022094056475907564\n",
      "Epoch 1, Meta Loss: 2.300629138946533, Synthetic Data Grad Norm: 0.00023855613835621625\n",
      "Epoch 1, Meta Loss: 2.301675796508789, Synthetic Data Grad Norm: 0.0004013767174910754\n",
      "Epoch 1, Meta Loss: 2.296699047088623, Synthetic Data Grad Norm: 0.0003252411261200905\n",
      "Epoch 1, Meta Loss: 2.277348756790161, Synthetic Data Grad Norm: 0.00024207978276535869\n",
      "Epoch 1, Meta Loss: 2.2921600341796875, Synthetic Data Grad Norm: 0.0002936467353720218\n",
      "Epoch 1, Meta Loss: 2.3148586750030518, Synthetic Data Grad Norm: 0.0003273061302024871\n",
      "Epoch 1, Meta Loss: 2.2973127365112305, Synthetic Data Grad Norm: 0.0003572892164811492\n",
      "Epoch 1, Meta Loss: 2.312556743621826, Synthetic Data Grad Norm: 0.0003742427215911448\n",
      "Epoch 1, Meta Loss: 2.294121265411377, Synthetic Data Grad Norm: 0.0001821516634663567\n",
      "Epoch 1, Meta Loss: 2.303377628326416, Synthetic Data Grad Norm: 0.00025007789372466505\n",
      "Epoch 1, Meta Loss: 2.291330337524414, Synthetic Data Grad Norm: 0.0002784189418889582\n",
      "Epoch 1, Meta Loss: 2.307006597518921, Synthetic Data Grad Norm: 0.0003118949825875461\n",
      "Epoch 1, Meta Loss: 2.293504238128662, Synthetic Data Grad Norm: 0.00019500439520925283\n",
      "Epoch 1, Meta Loss: 2.3042049407958984, Synthetic Data Grad Norm: 0.0002475270885042846\n",
      "Epoch 1, Meta Loss: 2.2886767387390137, Synthetic Data Grad Norm: 0.0002594411780592054\n",
      "Epoch 1, Meta Loss: 2.307840347290039, Synthetic Data Grad Norm: 0.0002491525956429541\n",
      "Epoch 1, Meta Loss: 2.3011176586151123, Synthetic Data Grad Norm: 0.0002961009740829468\n",
      "Epoch 1, Meta Loss: 2.290745258331299, Synthetic Data Grad Norm: 0.00030561041785404086\n",
      "Epoch 1, Meta Loss: 2.301356077194214, Synthetic Data Grad Norm: 0.00019619880185928196\n",
      "Epoch 1, Meta Loss: 2.339452028274536, Synthetic Data Grad Norm: 0.00033804355189204216\n",
      "Epoch 1, Meta Loss: 2.305309534072876, Synthetic Data Grad Norm: 0.00022122029622551054\n",
      "Epoch 1, Meta Loss: 2.2988038063049316, Synthetic Data Grad Norm: 0.0002845798444468528\n",
      "Epoch 1, Meta Loss: 2.3006882667541504, Synthetic Data Grad Norm: 0.00025182697572745383\n",
      "Epoch 1, Meta Loss: 2.331711769104004, Synthetic Data Grad Norm: 0.0002887780428864062\n",
      "Epoch 1, Meta Loss: 2.3054311275482178, Synthetic Data Grad Norm: 0.00026024720864370465\n",
      "Epoch 1, Meta Loss: 2.2955429553985596, Synthetic Data Grad Norm: 0.00030885031446814537\n",
      "Epoch 1, Meta Loss: 2.2826437950134277, Synthetic Data Grad Norm: 0.00021167872182559222\n",
      "Epoch 1, Meta Loss: 2.2839651107788086, Synthetic Data Grad Norm: 0.0002828120777849108\n",
      "Epoch 1, Meta Loss: 2.280421495437622, Synthetic Data Grad Norm: 0.0004279778804630041\n",
      "Epoch 1, Meta Loss: 2.2999556064605713, Synthetic Data Grad Norm: 0.0003401889989618212\n",
      "Epoch 1, Meta Loss: 2.3069043159484863, Synthetic Data Grad Norm: 0.0003312082262709737\n",
      "Epoch 1, Meta Loss: 2.2957706451416016, Synthetic Data Grad Norm: 0.00022772733063902706\n",
      "Epoch 1, Meta Loss: 2.2698256969451904, Synthetic Data Grad Norm: 0.0003425577888265252\n",
      "Epoch 1, Meta Loss: 2.2822911739349365, Synthetic Data Grad Norm: 0.0002894486824516207\n",
      "Epoch 1, Meta Loss: 2.301182270050049, Synthetic Data Grad Norm: 0.0002992121153511107\n",
      "Epoch 1, Meta Loss: 2.294795036315918, Synthetic Data Grad Norm: 0.0003571807174012065\n",
      "Epoch 1, Meta Loss: 2.292827606201172, Synthetic Data Grad Norm: 0.0002248680539196357\n",
      "Epoch 1, Meta Loss: 2.317957639694214, Synthetic Data Grad Norm: 0.000302317610476166\n",
      "Epoch 1, Meta Loss: 2.3012170791625977, Synthetic Data Grad Norm: 0.00023210373183246702\n",
      "Epoch 1, Meta Loss: 2.27382755279541, Synthetic Data Grad Norm: 0.00033110869117081165\n",
      "Epoch 1, Meta Loss: 2.2938289642333984, Synthetic Data Grad Norm: 0.00023261540627572685\n",
      "Epoch 1, Meta Loss: 2.2975564002990723, Synthetic Data Grad Norm: 0.00020049067097716033\n",
      "Epoch 1, Meta Loss: 2.2803008556365967, Synthetic Data Grad Norm: 0.0002309510891791433\n",
      "Epoch 1, Meta Loss: 2.2956290245056152, Synthetic Data Grad Norm: 0.0003451965458225459\n",
      "Epoch 1, Meta Loss: 2.2914023399353027, Synthetic Data Grad Norm: 0.00027398948441259563\n",
      "Epoch 1, Meta Loss: 2.2784669399261475, Synthetic Data Grad Norm: 0.0002668155066203326\n",
      "Epoch 1, Meta Loss: 2.2914390563964844, Synthetic Data Grad Norm: 0.0002858193765860051\n",
      "Epoch 1, Meta Loss: 2.2982702255249023, Synthetic Data Grad Norm: 0.00027695533935911953\n",
      "Epoch 1, Meta Loss: 2.29306697845459, Synthetic Data Grad Norm: 0.00031443979241885245\n",
      "Epoch 1, Meta Loss: 2.3131566047668457, Synthetic Data Grad Norm: 0.0003803007712122053\n",
      "Epoch 1, Meta Loss: 2.284605026245117, Synthetic Data Grad Norm: 0.000207369594136253\n",
      "Epoch 1, Meta Loss: 2.2883591651916504, Synthetic Data Grad Norm: 0.00018749431183096021\n",
      "Epoch 1, Meta Loss: 2.3024330139160156, Synthetic Data Grad Norm: 0.00028739203116856515\n",
      "Epoch 1, Meta Loss: 2.3116049766540527, Synthetic Data Grad Norm: 0.00031122457585297525\n",
      "Epoch 1, Meta Loss: 2.2766661643981934, Synthetic Data Grad Norm: 0.0003159384068567306\n",
      "Epoch 1, Meta Loss: 2.304212808609009, Synthetic Data Grad Norm: 0.00028117027250118554\n",
      "Epoch 1, Meta Loss: 2.2819576263427734, Synthetic Data Grad Norm: 0.00036012171767652035\n",
      "Epoch 1, Meta Loss: 2.2930195331573486, Synthetic Data Grad Norm: 0.00020764232613146305\n",
      "Epoch 1, Meta Loss: 2.303143262863159, Synthetic Data Grad Norm: 0.0002956819662358612\n",
      "Epoch 1, Meta Loss: 2.2846734523773193, Synthetic Data Grad Norm: 0.00027909071650356054\n",
      "Epoch 1, Meta Loss: 2.2967188358306885, Synthetic Data Grad Norm: 0.0003609406412579119\n",
      "Epoch 1, Meta Loss: 2.295290946960449, Synthetic Data Grad Norm: 0.00024201793712563813\n",
      "Epoch 1, Meta Loss: 2.296581506729126, Synthetic Data Grad Norm: 0.00031208762084133923\n",
      "Epoch 1, Meta Loss: 2.282125949859619, Synthetic Data Grad Norm: 0.00037304204306565225\n",
      "Epoch 1, Meta Loss: 2.2908318042755127, Synthetic Data Grad Norm: 0.0002620645973365754\n",
      "Epoch 1, Meta Loss: 2.2833189964294434, Synthetic Data Grad Norm: 0.0004021301865577698\n",
      "Epoch 1, Meta Loss: 2.3046703338623047, Synthetic Data Grad Norm: 0.00030618003802374005\n",
      "Epoch 1, Meta Loss: 2.284475326538086, Synthetic Data Grad Norm: 0.00018454747623763978\n",
      "Epoch 1, Meta Loss: 2.29069185256958, Synthetic Data Grad Norm: 0.00031309499172493815\n",
      "Epoch 1, Meta Loss: 2.2869443893432617, Synthetic Data Grad Norm: 0.00023758616589475423\n",
      "Epoch 1, Meta Loss: 2.2875137329101562, Synthetic Data Grad Norm: 0.0002626773784868419\n",
      "Epoch 1, Meta Loss: 2.2979536056518555, Synthetic Data Grad Norm: 0.00016515489551238716\n",
      "Epoch 1, Meta Loss: 2.2848846912384033, Synthetic Data Grad Norm: 0.00019305761088617146\n",
      "Epoch 1, Meta Loss: 2.2953028678894043, Synthetic Data Grad Norm: 0.00023159963893704116\n",
      "Epoch 1, Meta Loss: 2.2898573875427246, Synthetic Data Grad Norm: 0.0003385250747669488\n",
      "Epoch 1, Meta Loss: 2.287902355194092, Synthetic Data Grad Norm: 0.00023210416838992387\n",
      "Epoch 1, Meta Loss: 2.281057596206665, Synthetic Data Grad Norm: 0.00026127020828425884\n",
      "Epoch 1, Meta Loss: 2.286184310913086, Synthetic Data Grad Norm: 0.00022078221081756055\n",
      "Epoch 1, Meta Loss: 2.312185525894165, Synthetic Data Grad Norm: 0.00026549084577709436\n",
      "Epoch 1, Meta Loss: 2.292266845703125, Synthetic Data Grad Norm: 0.0002626421337481588\n",
      "Epoch 1, Meta Loss: 2.303776741027832, Synthetic Data Grad Norm: 0.0002867050643544644\n",
      "Epoch 1, Meta Loss: 2.3019397258758545, Synthetic Data Grad Norm: 0.00023205525940284133\n",
      "Epoch 1, Meta Loss: 2.299682378768921, Synthetic Data Grad Norm: 0.000372081995010376\n",
      "Epoch 1, Meta Loss: 2.2857720851898193, Synthetic Data Grad Norm: 0.0003071411629207432\n",
      "Epoch 1, Meta Loss: 2.2942028045654297, Synthetic Data Grad Norm: 0.0002286040544277057\n",
      "Epoch 1, Meta Loss: 2.2872812747955322, Synthetic Data Grad Norm: 0.000271855853497982\n",
      "Epoch 1, Meta Loss: 2.2916393280029297, Synthetic Data Grad Norm: 0.00020616342953871936\n",
      "Epoch 1, Meta Loss: 2.2893640995025635, Synthetic Data Grad Norm: 0.0002259849279653281\n",
      "Epoch 1, Meta Loss: 2.302259683609009, Synthetic Data Grad Norm: 0.0002635273558553308\n",
      "Epoch 1, Meta Loss: 2.281176805496216, Synthetic Data Grad Norm: 0.0002707818930502981\n",
      "Epoch 1, Meta Loss: 2.294435501098633, Synthetic Data Grad Norm: 0.00024050878710113466\n",
      "Epoch 1, Meta Loss: 2.317451000213623, Synthetic Data Grad Norm: 0.00030509469797834754\n",
      "Epoch 1, Meta Loss: 2.287930965423584, Synthetic Data Grad Norm: 0.0003488004731480032\n",
      "Epoch 1, Meta Loss: 2.287588357925415, Synthetic Data Grad Norm: 0.0002573478559497744\n",
      "Epoch 1, Meta Loss: 2.285128593444824, Synthetic Data Grad Norm: 0.00023980285914149135\n",
      "Epoch 1, Meta Loss: 2.2877442836761475, Synthetic Data Grad Norm: 0.0002599070721771568\n",
      "Epoch 1, Meta Loss: 2.3117597103118896, Synthetic Data Grad Norm: 0.0003524842031765729\n",
      "Epoch 1, Meta Loss: 2.289262533187866, Synthetic Data Grad Norm: 0.00023553315259050578\n",
      "Epoch 1, Meta Loss: 2.317598581314087, Synthetic Data Grad Norm: 0.00032030834699980915\n",
      "Epoch 1, Meta Loss: 2.292778491973877, Synthetic Data Grad Norm: 0.0003265857230871916\n",
      "Epoch 1, Meta Loss: 2.296022653579712, Synthetic Data Grad Norm: 0.0002913638309109956\n",
      "Epoch 1, Meta Loss: 2.285557508468628, Synthetic Data Grad Norm: 0.00039658331661485136\n",
      "Epoch 1, Meta Loss: 2.2868475914001465, Synthetic Data Grad Norm: 0.00026159954722970724\n",
      "Epoch 1, Meta Loss: 2.292170286178589, Synthetic Data Grad Norm: 0.0002262205962324515\n",
      "Epoch 1, Meta Loss: 2.2880773544311523, Synthetic Data Grad Norm: 0.00029069746960885823\n",
      "Epoch 1, Meta Loss: 2.284621238708496, Synthetic Data Grad Norm: 0.0002820411464199424\n",
      "Epoch 1, Meta Loss: 2.2878804206848145, Synthetic Data Grad Norm: 0.00026009060093201697\n",
      "Epoch 1, Meta Loss: 2.282104015350342, Synthetic Data Grad Norm: 0.0002775939356070012\n",
      "Epoch 1, Meta Loss: 2.283036470413208, Synthetic Data Grad Norm: 0.00029561424162238836\n",
      "Epoch 1, Meta Loss: 2.287992000579834, Synthetic Data Grad Norm: 0.00029803375946357846\n",
      "Epoch 1, Meta Loss: 2.310903549194336, Synthetic Data Grad Norm: 0.0003009734791703522\n",
      "Epoch 1, Meta Loss: 2.2940030097961426, Synthetic Data Grad Norm: 0.0002653441042639315\n",
      "Epoch 1, Meta Loss: 2.297811985015869, Synthetic Data Grad Norm: 0.00025966615066863596\n",
      "Epoch 1, Meta Loss: 2.321363687515259, Synthetic Data Grad Norm: 0.00023986460291780531\n",
      "Epoch 1, Meta Loss: 2.3170111179351807, Synthetic Data Grad Norm: 0.0003069161612074822\n",
      "Epoch 1, Meta Loss: 2.299042224884033, Synthetic Data Grad Norm: 0.0002303518122062087\n",
      "Epoch 1, Meta Loss: 2.299523115158081, Synthetic Data Grad Norm: 0.0002124052116414532\n",
      "Epoch 1, Meta Loss: 2.30108642578125, Synthetic Data Grad Norm: 0.00025753010413609445\n",
      "Epoch 1, Meta Loss: 2.295609951019287, Synthetic Data Grad Norm: 0.0003053387044928968\n",
      "Epoch 1, Meta Loss: 2.2811031341552734, Synthetic Data Grad Norm: 0.00032642451697029173\n",
      "Epoch 1, Meta Loss: 2.2679991722106934, Synthetic Data Grad Norm: 0.000368608336430043\n",
      "Epoch 1, Meta Loss: 2.318826198577881, Synthetic Data Grad Norm: 0.0003055756678804755\n",
      "Epoch 1, Meta Loss: 2.3101024627685547, Synthetic Data Grad Norm: 0.00023404663079418242\n",
      "Epoch 1, Meta Loss: 2.2843730449676514, Synthetic Data Grad Norm: 0.00032694858964532614\n",
      "Epoch 1, Meta Loss: 2.300750732421875, Synthetic Data Grad Norm: 0.000247897463850677\n",
      "Epoch 1, Meta Loss: 2.3070666790008545, Synthetic Data Grad Norm: 0.00023594159574713558\n",
      "Epoch 1, Meta Loss: 2.3324944972991943, Synthetic Data Grad Norm: 0.0002164445468224585\n",
      "Epoch 1, Meta Loss: 2.2870304584503174, Synthetic Data Grad Norm: 0.000275976286502555\n",
      "Epoch 1, Meta Loss: 2.2996127605438232, Synthetic Data Grad Norm: 0.000349526759237051\n",
      "Epoch 1, Meta Loss: 2.2915291786193848, Synthetic Data Grad Norm: 0.00022864814673084766\n",
      "Epoch 1, Meta Loss: 2.2840211391448975, Synthetic Data Grad Norm: 0.00020359882910270244\n",
      "Epoch 1, Meta Loss: 2.291372060775757, Synthetic Data Grad Norm: 0.0002593021490611136\n",
      "Epoch 1, Meta Loss: 2.308422803878784, Synthetic Data Grad Norm: 0.0002752193540800363\n",
      "Epoch 1, Meta Loss: 2.2844767570495605, Synthetic Data Grad Norm: 0.0002602804743219167\n",
      "Epoch 1, Meta Loss: 2.2881438732147217, Synthetic Data Grad Norm: 0.0003100424073636532\n",
      "Epoch 1, Meta Loss: 2.334498643875122, Synthetic Data Grad Norm: 0.00033869341132231057\n",
      "Epoch 1, Meta Loss: 2.3098864555358887, Synthetic Data Grad Norm: 0.00025306225870735943\n",
      "Epoch 1, Meta Loss: 2.2925853729248047, Synthetic Data Grad Norm: 0.000299253937555477\n",
      "Epoch 1, Meta Loss: 2.3340048789978027, Synthetic Data Grad Norm: 0.0003995945444330573\n",
      "Epoch 1, Meta Loss: 2.3081164360046387, Synthetic Data Grad Norm: 0.00021187475067563355\n",
      "Epoch 1, Meta Loss: 2.2996537685394287, Synthetic Data Grad Norm: 0.00023258192231878638\n",
      "Epoch 1, Meta Loss: 2.312957525253296, Synthetic Data Grad Norm: 0.00022836349671706557\n",
      "Epoch 1, Meta Loss: 2.292983293533325, Synthetic Data Grad Norm: 0.00023970534675754607\n",
      "Epoch 1, Meta Loss: 2.297968864440918, Synthetic Data Grad Norm: 0.00025586268748156726\n",
      "Epoch 1, Meta Loss: 2.2854533195495605, Synthetic Data Grad Norm: 0.00026079328381456435\n",
      "Epoch 1, Meta Loss: 2.2940306663513184, Synthetic Data Grad Norm: 0.0002560573921073228\n",
      "Epoch 1, Meta Loss: 2.2811009883880615, Synthetic Data Grad Norm: 0.0002683261700440198\n",
      "Epoch 1, Meta Loss: 2.2934839725494385, Synthetic Data Grad Norm: 0.0002378023200435564\n",
      "Epoch 1, Meta Loss: 2.269291400909424, Synthetic Data Grad Norm: 0.00031055277213454247\n",
      "Epoch 1, Meta Loss: 2.2923922538757324, Synthetic Data Grad Norm: 0.00037163039087317884\n",
      "Epoch 1, Meta Loss: 2.2648065090179443, Synthetic Data Grad Norm: 0.0003574352595023811\n",
      "Epoch 1, Meta Loss: 2.280670404434204, Synthetic Data Grad Norm: 0.00022411698591895401\n",
      "Epoch 1, Meta Loss: 2.303133249282837, Synthetic Data Grad Norm: 0.0002177115238737315\n",
      "Epoch 1, Meta Loss: 2.2916243076324463, Synthetic Data Grad Norm: 0.0002553157682996243\n",
      "Epoch 1, Meta Loss: 2.2821433544158936, Synthetic Data Grad Norm: 0.0002771200379356742\n",
      "Epoch 1, Meta Loss: 2.2992732524871826, Synthetic Data Grad Norm: 0.00039373518666252494\n",
      "Epoch 1, Meta Loss: 2.2785227298736572, Synthetic Data Grad Norm: 0.00028239464154466987\n",
      "Epoch 1, Meta Loss: 2.291686773300171, Synthetic Data Grad Norm: 0.00022593926405534148\n",
      "Epoch 1, Meta Loss: 2.295264482498169, Synthetic Data Grad Norm: 0.00018800454563461244\n",
      "Epoch 1, Meta Loss: 2.2888402938842773, Synthetic Data Grad Norm: 0.0003403443843126297\n",
      "Epoch 1, Meta Loss: 2.290558338165283, Synthetic Data Grad Norm: 0.0002631722891237587\n",
      "Epoch 1, Meta Loss: 2.2699670791625977, Synthetic Data Grad Norm: 0.00027978463913314044\n",
      "Epoch 1, Meta Loss: 2.294597625732422, Synthetic Data Grad Norm: 0.0003692787722684443\n",
      "Epoch 1, Meta Loss: 2.2979297637939453, Synthetic Data Grad Norm: 0.0003021591401193291\n",
      "Epoch 1, Meta Loss: 2.311487913131714, Synthetic Data Grad Norm: 0.00030929583590477705\n",
      "Epoch 1, Meta Loss: 2.2938008308410645, Synthetic Data Grad Norm: 0.0002740035706665367\n",
      "Epoch 1, Meta Loss: 2.2947282791137695, Synthetic Data Grad Norm: 0.00025964100495912135\n",
      "Epoch 1, Meta Loss: 2.296828508377075, Synthetic Data Grad Norm: 0.0004073481250088662\n",
      "Epoch 1, Meta Loss: 2.3026342391967773, Synthetic Data Grad Norm: 0.0003271459136158228\n",
      "Epoch 1, Meta Loss: 2.3142926692962646, Synthetic Data Grad Norm: 0.0003702897229231894\n",
      "Epoch 1, Meta Loss: 2.27439022064209, Synthetic Data Grad Norm: 0.0002757687179837376\n",
      "Epoch 1, Meta Loss: 2.280149459838867, Synthetic Data Grad Norm: 0.0002405720588285476\n",
      "Epoch 1, Meta Loss: 2.2825069427490234, Synthetic Data Grad Norm: 0.0004031663411296904\n",
      "Epoch 1, Meta Loss: 2.28448486328125, Synthetic Data Grad Norm: 0.00032303479383699596\n",
      "Epoch 1, Meta Loss: 2.2956080436706543, Synthetic Data Grad Norm: 0.00032129601459018886\n",
      "Epoch 1, Meta Loss: 2.2990801334381104, Synthetic Data Grad Norm: 0.00030905005405656993\n",
      "Epoch 1, Meta Loss: 2.2918403148651123, Synthetic Data Grad Norm: 0.00031887192744761705\n",
      "Epoch 1, Meta Loss: 2.276977300643921, Synthetic Data Grad Norm: 0.0003349099133629352\n",
      "Epoch 1, Meta Loss: 2.2936532497406006, Synthetic Data Grad Norm: 0.0003580384945962578\n",
      "Epoch 1, Meta Loss: 2.2940099239349365, Synthetic Data Grad Norm: 0.00023695202253293246\n",
      "Epoch 1, Meta Loss: 2.2863950729370117, Synthetic Data Grad Norm: 0.0002528320765122771\n",
      "Epoch 1, Meta Loss: 2.2960212230682373, Synthetic Data Grad Norm: 0.00021286087576299906\n",
      "Epoch 1, Meta Loss: 2.2956526279449463, Synthetic Data Grad Norm: 0.00023568299366161227\n",
      "Epoch 1, Meta Loss: 2.2926886081695557, Synthetic Data Grad Norm: 0.0002716706076171249\n",
      "Epoch 1, Meta Loss: 2.303124189376831, Synthetic Data Grad Norm: 0.00022805568005423993\n",
      "Epoch 1, Meta Loss: 2.2894365787506104, Synthetic Data Grad Norm: 0.000294815341476351\n",
      "Epoch 1, Meta Loss: 2.3001818656921387, Synthetic Data Grad Norm: 0.00019317363330628723\n",
      "Epoch 1, Meta Loss: 2.2989025115966797, Synthetic Data Grad Norm: 0.0003027510247193277\n",
      "Epoch 1, Meta Loss: 2.3140454292297363, Synthetic Data Grad Norm: 0.00027776428032666445\n",
      "Epoch 1, Meta Loss: 2.3051598072052, Synthetic Data Grad Norm: 0.00026439601788297296\n",
      "Epoch 1, Meta Loss: 2.298250913619995, Synthetic Data Grad Norm: 0.00031668448355048895\n",
      "Epoch 1, Meta Loss: 2.28989315032959, Synthetic Data Grad Norm: 0.00028349837521091104\n",
      "Epoch 1, Meta Loss: 2.2793869972229004, Synthetic Data Grad Norm: 0.00024474228848703206\n",
      "Epoch 1, Meta Loss: 2.3070547580718994, Synthetic Data Grad Norm: 0.00029291631653904915\n",
      "Epoch 1, Meta Loss: 2.2858164310455322, Synthetic Data Grad Norm: 0.00020372122526168823\n",
      "Epoch 1, Meta Loss: 2.293719530105591, Synthetic Data Grad Norm: 0.00032650004141032696\n",
      "Epoch 1, Meta Loss: 2.294727087020874, Synthetic Data Grad Norm: 0.0002888416638597846\n",
      "Epoch 1, Meta Loss: 2.2865381240844727, Synthetic Data Grad Norm: 0.0002029373135883361\n",
      "Epoch 1, Meta Loss: 2.28218150138855, Synthetic Data Grad Norm: 0.00027766491984948516\n",
      "Epoch 1, Meta Loss: 2.2600600719451904, Synthetic Data Grad Norm: 0.00032349713728763163\n",
      "Epoch 1, Meta Loss: 2.294212579727173, Synthetic Data Grad Norm: 0.000245215545874089\n",
      "Epoch 1, Meta Loss: 2.2907869815826416, Synthetic Data Grad Norm: 0.00020793943258468062\n",
      "Epoch 1, Meta Loss: 2.2982404232025146, Synthetic Data Grad Norm: 0.00030057632829993963\n",
      "Epoch 1, Meta Loss: 2.289336919784546, Synthetic Data Grad Norm: 0.0002022994594881311\n",
      "Epoch 1, Meta Loss: 2.2969372272491455, Synthetic Data Grad Norm: 0.00031362357549369335\n",
      "Epoch 1, Meta Loss: 2.2962217330932617, Synthetic Data Grad Norm: 0.0003567445382941514\n",
      "Epoch 1, Meta Loss: 2.2871339321136475, Synthetic Data Grad Norm: 0.00020457325445022434\n",
      "Epoch 1, Meta Loss: 2.3070356845855713, Synthetic Data Grad Norm: 0.00029682155582122505\n",
      "Epoch 1, Meta Loss: 2.2989327907562256, Synthetic Data Grad Norm: 0.0002509289188310504\n",
      "Epoch 1, Meta Loss: 2.284684658050537, Synthetic Data Grad Norm: 0.0003310837200842798\n",
      "Epoch 1, Meta Loss: 2.280272960662842, Synthetic Data Grad Norm: 0.00031583989039063454\n",
      "Epoch 1, Meta Loss: 2.2897839546203613, Synthetic Data Grad Norm: 0.00020577825489453971\n",
      "Epoch 1, Meta Loss: 2.298992395401001, Synthetic Data Grad Norm: 0.0002562036970630288\n",
      "Epoch 1, Meta Loss: 2.314060926437378, Synthetic Data Grad Norm: 0.0002731176500674337\n",
      "Epoch 1, Meta Loss: 2.2828855514526367, Synthetic Data Grad Norm: 0.00029379644547589123\n",
      "Epoch 1, Meta Loss: 2.302347183227539, Synthetic Data Grad Norm: 0.0002767183177638799\n",
      "Epoch 1, Meta Loss: 2.2872469425201416, Synthetic Data Grad Norm: 0.00034401266020722687\n",
      "Epoch 1, Meta Loss: 2.312368869781494, Synthetic Data Grad Norm: 0.0003358946705702692\n",
      "Epoch 1, Meta Loss: 2.2960243225097656, Synthetic Data Grad Norm: 0.00023899691586848348\n",
      "Epoch 1, Meta Loss: 2.3083860874176025, Synthetic Data Grad Norm: 0.0002229269884992391\n",
      "Epoch 1, Meta Loss: 2.29148268699646, Synthetic Data Grad Norm: 0.0002091383357765153\n",
      "Epoch 1, Meta Loss: 2.2985754013061523, Synthetic Data Grad Norm: 0.0002625178312882781\n",
      "Epoch 1, Meta Loss: 2.307037830352783, Synthetic Data Grad Norm: 0.0002470861654728651\n",
      "Epoch 1, Meta Loss: 2.3007352352142334, Synthetic Data Grad Norm: 0.00017276780272368342\n",
      "Epoch 1, Meta Loss: 2.293992042541504, Synthetic Data Grad Norm: 0.0001948627468664199\n",
      "Epoch 1, Meta Loss: 2.280731201171875, Synthetic Data Grad Norm: 0.00022974007879383862\n",
      "Epoch 1, Meta Loss: 2.3271684646606445, Synthetic Data Grad Norm: 0.0004684025188907981\n",
      "Epoch 1, Meta Loss: 2.2881081104278564, Synthetic Data Grad Norm: 0.0001993071782635525\n",
      "Epoch 1, Meta Loss: 2.2888832092285156, Synthetic Data Grad Norm: 0.0002540508867241442\n",
      "Epoch 1, Meta Loss: 2.303058385848999, Synthetic Data Grad Norm: 0.00030112353852018714\n",
      "Epoch 1, Meta Loss: 2.2818543910980225, Synthetic Data Grad Norm: 0.00027302646776661277\n",
      "Epoch 1, Meta Loss: 2.292537212371826, Synthetic Data Grad Norm: 0.00032467400887981057\n",
      "Epoch 1, Meta Loss: 2.30332350730896, Synthetic Data Grad Norm: 0.0002887927112169564\n",
      "Epoch 1, Meta Loss: 2.2895290851593018, Synthetic Data Grad Norm: 0.0002070723130600527\n",
      "Epoch 1, Meta Loss: 2.2889466285705566, Synthetic Data Grad Norm: 0.0002773660817183554\n",
      "Epoch 1, Meta Loss: 2.291851043701172, Synthetic Data Grad Norm: 0.00024446225143037736\n",
      "Epoch 1, Meta Loss: 2.2970328330993652, Synthetic Data Grad Norm: 0.0002622951287776232\n",
      "Epoch 1, Meta Loss: 2.2933619022369385, Synthetic Data Grad Norm: 0.0002953646471723914\n",
      "Epoch 1, Meta Loss: 2.294970989227295, Synthetic Data Grad Norm: 0.000323018612107262\n",
      "Epoch 1, Meta Loss: 2.297295331954956, Synthetic Data Grad Norm: 0.0002172343956772238\n",
      "Epoch 1, Meta Loss: 2.291994571685791, Synthetic Data Grad Norm: 0.00023995572701096535\n",
      "Epoch 1, Meta Loss: 2.2870447635650635, Synthetic Data Grad Norm: 0.0002841723326127976\n",
      "Epoch 1, Meta Loss: 2.302867889404297, Synthetic Data Grad Norm: 0.00024082526215352118\n",
      "Epoch 1, Meta Loss: 2.293710708618164, Synthetic Data Grad Norm: 0.00018749944865703583\n",
      "Epoch 1, Meta Loss: 2.304973840713501, Synthetic Data Grad Norm: 0.00041586061706766486\n",
      "Epoch 1, Meta Loss: 2.301259994506836, Synthetic Data Grad Norm: 0.0003909394727088511\n",
      "Epoch 1, Meta Loss: 2.2954394817352295, Synthetic Data Grad Norm: 0.00022689212346449494\n",
      "Epoch 1, Meta Loss: 2.281561851501465, Synthetic Data Grad Norm: 0.00032986002042889595\n",
      "Epoch 1, Meta Loss: 2.2916319370269775, Synthetic Data Grad Norm: 0.0001895610912470147\n",
      "Epoch 1, Meta Loss: 2.301097869873047, Synthetic Data Grad Norm: 0.00023238654830493033\n",
      "Epoch 1, Meta Loss: 2.301748752593994, Synthetic Data Grad Norm: 0.00023038772633299232\n",
      "Epoch 1, Meta Loss: 2.3022055625915527, Synthetic Data Grad Norm: 0.00022790796356275678\n",
      "Epoch 1, Meta Loss: 2.271422863006592, Synthetic Data Grad Norm: 0.00024659468908794224\n",
      "Epoch 1, Meta Loss: 2.3015363216400146, Synthetic Data Grad Norm: 0.00026503001572564244\n",
      "Epoch 1, Meta Loss: 2.3130970001220703, Synthetic Data Grad Norm: 0.00027189787942916155\n",
      "Epoch 1, Meta Loss: 2.2809700965881348, Synthetic Data Grad Norm: 0.0002416612405795604\n",
      "Epoch 1, Meta Loss: 2.280801773071289, Synthetic Data Grad Norm: 0.00028989629936404526\n",
      "Epoch 1, Meta Loss: 2.2853097915649414, Synthetic Data Grad Norm: 0.00022525640088133514\n",
      "Epoch 1, Meta Loss: 2.281872510910034, Synthetic Data Grad Norm: 0.00046103072236292064\n",
      "Epoch 1, Meta Loss: 2.288105010986328, Synthetic Data Grad Norm: 0.00023876201885286719\n",
      "Epoch 1, Meta Loss: 2.279595375061035, Synthetic Data Grad Norm: 0.00037229558802209795\n",
      "Epoch 1, Meta Loss: 2.293360471725464, Synthetic Data Grad Norm: 0.0002732495777308941\n",
      "Epoch 1, Meta Loss: 2.271693706512451, Synthetic Data Grad Norm: 0.00029848419944755733\n",
      "Epoch 1, Meta Loss: 2.291724920272827, Synthetic Data Grad Norm: 0.0004546564887277782\n",
      "Epoch 1, Meta Loss: 2.284635543823242, Synthetic Data Grad Norm: 0.0003652721061371267\n",
      "Epoch 1, Meta Loss: 2.2949612140655518, Synthetic Data Grad Norm: 0.0002783722593449056\n",
      "Epoch 1, Meta Loss: 2.2856764793395996, Synthetic Data Grad Norm: 0.00025540468050166965\n",
      "Epoch 1, Meta Loss: 2.3032732009887695, Synthetic Data Grad Norm: 0.0002475065120961517\n",
      "Epoch 1, Meta Loss: 2.3032193183898926, Synthetic Data Grad Norm: 0.0001978607615455985\n",
      "Epoch 1, Meta Loss: 2.2961983680725098, Synthetic Data Grad Norm: 0.000195154789253138\n",
      "Epoch 1, Meta Loss: 2.30686092376709, Synthetic Data Grad Norm: 0.0002614819968584925\n",
      "Epoch 1, Meta Loss: 2.2949697971343994, Synthetic Data Grad Norm: 0.00022876291768625379\n",
      "Epoch 1, Meta Loss: 2.3115763664245605, Synthetic Data Grad Norm: 0.00025286697200499475\n",
      "Epoch 1, Meta Loss: 2.293541431427002, Synthetic Data Grad Norm: 0.00024222735373768955\n",
      "Epoch 1, Meta Loss: 2.3062164783477783, Synthetic Data Grad Norm: 0.00031135830795392394\n",
      "Epoch 1, Meta Loss: 2.288774013519287, Synthetic Data Grad Norm: 0.00027173213311471045\n",
      "Epoch 1, Meta Loss: 2.302081346511841, Synthetic Data Grad Norm: 0.00030120802694000304\n",
      "Epoch 1, Meta Loss: 2.289547920227051, Synthetic Data Grad Norm: 0.0002866020950023085\n",
      "Epoch 1, Meta Loss: 2.28407621383667, Synthetic Data Grad Norm: 0.00032488597207702696\n",
      "Epoch 1, Meta Loss: 2.2853119373321533, Synthetic Data Grad Norm: 0.0002218429435743019\n",
      "Epoch 1, Meta Loss: 2.2989823818206787, Synthetic Data Grad Norm: 0.00040505145443603396\n",
      "Epoch 1, Meta Loss: 2.289188861846924, Synthetic Data Grad Norm: 0.00024927666527219117\n",
      "Epoch 1, Meta Loss: 2.292280435562134, Synthetic Data Grad Norm: 0.0002804518735501915\n",
      "Epoch 1, Meta Loss: 2.2951736450195312, Synthetic Data Grad Norm: 0.00031132009462453425\n",
      "Epoch 1, Meta Loss: 2.281480073928833, Synthetic Data Grad Norm: 0.0002401688543614\n",
      "Epoch 1, Meta Loss: 2.3087987899780273, Synthetic Data Grad Norm: 0.00028664187993854284\n",
      "Epoch 1, Meta Loss: 2.2855007648468018, Synthetic Data Grad Norm: 0.00027919758576899767\n",
      "Epoch 1, Meta Loss: 2.2720627784729004, Synthetic Data Grad Norm: 0.00029325473587960005\n",
      "Epoch 1, Meta Loss: 2.298835039138794, Synthetic Data Grad Norm: 0.00031057270825840533\n",
      "Epoch 1, Meta Loss: 2.300126314163208, Synthetic Data Grad Norm: 0.0003155282756779343\n",
      "Epoch 1, Meta Loss: 2.294740676879883, Synthetic Data Grad Norm: 0.0002667386725079268\n",
      "Epoch 1, Meta Loss: 2.3126320838928223, Synthetic Data Grad Norm: 0.00022913188149686903\n",
      "Epoch 1, Meta Loss: 2.3081014156341553, Synthetic Data Grad Norm: 0.0003116029838565737\n",
      "Epoch 1, Meta Loss: 2.308878183364868, Synthetic Data Grad Norm: 0.0002861994144041091\n",
      "Epoch 1, Meta Loss: 2.2794737815856934, Synthetic Data Grad Norm: 0.0002063517749775201\n",
      "Epoch 1, Meta Loss: 2.281965970993042, Synthetic Data Grad Norm: 0.0002350046852370724\n",
      "Epoch 1, Meta Loss: 2.284730911254883, Synthetic Data Grad Norm: 0.00046812024083919823\n",
      "Epoch 1, Meta Loss: 2.287163734436035, Synthetic Data Grad Norm: 0.00027152796974405646\n",
      "Epoch 1, Meta Loss: 2.291747808456421, Synthetic Data Grad Norm: 0.0003530466929078102\n",
      "Epoch 1, Meta Loss: 2.299124240875244, Synthetic Data Grad Norm: 0.00020304805366322398\n",
      "Epoch 1, Meta Loss: 2.2977423667907715, Synthetic Data Grad Norm: 0.0002707552339415997\n",
      "Epoch 1, Meta Loss: 2.289130687713623, Synthetic Data Grad Norm: 0.00023833040904719383\n",
      "Epoch 1, Meta Loss: 2.2775158882141113, Synthetic Data Grad Norm: 0.0002840706438291818\n",
      "Epoch 1, Meta Loss: 2.311350107192993, Synthetic Data Grad Norm: 0.00041418231558054686\n",
      "Epoch 1, Meta Loss: 2.3008596897125244, Synthetic Data Grad Norm: 0.0002351122093386948\n",
      "Epoch 1, Meta Loss: 2.2948670387268066, Synthetic Data Grad Norm: 0.0003043408505618572\n",
      "Epoch 1, Meta Loss: 2.288254499435425, Synthetic Data Grad Norm: 0.00030838989187031984\n",
      "Epoch 1, Meta Loss: 2.2821366786956787, Synthetic Data Grad Norm: 0.00031990784918889403\n",
      "Epoch 1, Meta Loss: 2.3032801151275635, Synthetic Data Grad Norm: 0.0003191718424204737\n",
      "Epoch 1, Meta Loss: 2.293182611465454, Synthetic Data Grad Norm: 0.00036338146310299635\n",
      "Epoch 1, Meta Loss: 2.2938921451568604, Synthetic Data Grad Norm: 0.0002670888788998127\n",
      "Epoch 1, Meta Loss: 2.2751855850219727, Synthetic Data Grad Norm: 0.0002604109758976847\n",
      "Epoch 1, Meta Loss: 2.2925150394439697, Synthetic Data Grad Norm: 0.0002944240113720298\n",
      "Epoch 1, Meta Loss: 2.3013219833374023, Synthetic Data Grad Norm: 0.0002450890897307545\n",
      "Epoch 1, Meta Loss: 2.2889351844787598, Synthetic Data Grad Norm: 0.0002744078228715807\n",
      "Epoch 1, Meta Loss: 2.298319101333618, Synthetic Data Grad Norm: 0.000250834331382066\n",
      "Epoch 1, Meta Loss: 2.2899692058563232, Synthetic Data Grad Norm: 0.0002441422257106751\n",
      "Epoch 1, Meta Loss: 2.281038761138916, Synthetic Data Grad Norm: 0.0005170821095816791\n",
      "Epoch 1, Meta Loss: 2.3040637969970703, Synthetic Data Grad Norm: 0.0002087826287606731\n",
      "Epoch 1, Meta Loss: 2.2977514266967773, Synthetic Data Grad Norm: 0.0002402037789579481\n",
      "Epoch 1, Meta Loss: 2.2990615367889404, Synthetic Data Grad Norm: 0.00031245159334503114\n",
      "Epoch 1, Meta Loss: 2.3004066944122314, Synthetic Data Grad Norm: 0.000274586578598246\n",
      "Epoch 1, Meta Loss: 2.2858853340148926, Synthetic Data Grad Norm: 0.00023928337031975389\n",
      "Epoch 1, Meta Loss: 2.28206467628479, Synthetic Data Grad Norm: 0.0002891291514970362\n",
      "Epoch 1, Meta Loss: 2.2916626930236816, Synthetic Data Grad Norm: 0.0003320523537695408\n",
      "Epoch 1, Meta Loss: 2.297638177871704, Synthetic Data Grad Norm: 0.0003740994434338063\n",
      "Epoch 1, Meta Loss: 2.296617031097412, Synthetic Data Grad Norm: 0.00033325221738778055\n",
      "Epoch 1, Meta Loss: 2.2923014163970947, Synthetic Data Grad Norm: 0.00028305064188316464\n",
      "Epoch 1, Meta Loss: 2.296299934387207, Synthetic Data Grad Norm: 0.0002521094575058669\n",
      "Epoch 1, Meta Loss: 2.2916901111602783, Synthetic Data Grad Norm: 0.00023802564828656614\n",
      "Epoch 1, Meta Loss: 2.293839693069458, Synthetic Data Grad Norm: 0.000263136433204636\n",
      "Epoch 1, Meta Loss: 2.28731369972229, Synthetic Data Grad Norm: 0.00020330851839389652\n",
      "Epoch 1, Meta Loss: 2.3086016178131104, Synthetic Data Grad Norm: 0.00034552073339000344\n",
      "Epoch 1, Meta Loss: 2.3039939403533936, Synthetic Data Grad Norm: 0.00024930332438088953\n",
      "Epoch 1, Meta Loss: 2.3058664798736572, Synthetic Data Grad Norm: 0.0002911047195084393\n",
      "Epoch 1, Meta Loss: 2.294640302658081, Synthetic Data Grad Norm: 0.0002897918748203665\n",
      "Epoch 1, Meta Loss: 2.2859439849853516, Synthetic Data Grad Norm: 0.00022106236428953707\n",
      "Epoch 1, Meta Loss: 2.3123691082000732, Synthetic Data Grad Norm: 0.0002509463229216635\n",
      "Epoch 1, Meta Loss: 2.294163465499878, Synthetic Data Grad Norm: 0.00026903708931058645\n",
      "Epoch 1, Meta Loss: 2.2951629161834717, Synthetic Data Grad Norm: 0.00030398278613574803\n",
      "Epoch 1, Meta Loss: 2.2774393558502197, Synthetic Data Grad Norm: 0.00025041986373253167\n",
      "Epoch 1, Meta Loss: 2.2891931533813477, Synthetic Data Grad Norm: 0.00027817708905786276\n",
      "Epoch 1, Meta Loss: 2.2757680416107178, Synthetic Data Grad Norm: 0.00027100194711238146\n",
      "Epoch 1, Meta Loss: 2.291290044784546, Synthetic Data Grad Norm: 0.0002545464667491615\n",
      "Epoch 1, Meta Loss: 2.298887014389038, Synthetic Data Grad Norm: 0.00026102972333319485\n",
      "Epoch 1, Meta Loss: 2.2946674823760986, Synthetic Data Grad Norm: 0.0003445052425377071\n",
      "Epoch 1, Meta Loss: 2.2940287590026855, Synthetic Data Grad Norm: 0.0003268475120421499\n",
      "Epoch 1, Meta Loss: 2.2779428958892822, Synthetic Data Grad Norm: 0.00023382416111417115\n",
      "Epoch 1, Meta Loss: 2.3110084533691406, Synthetic Data Grad Norm: 0.00025143081438727677\n",
      "Epoch 1, Meta Loss: 2.275059700012207, Synthetic Data Grad Norm: 0.000263548077782616\n",
      "Epoch 1, Meta Loss: 2.3101155757904053, Synthetic Data Grad Norm: 0.00027684582164511085\n",
      "Epoch 1, Meta Loss: 2.276376247406006, Synthetic Data Grad Norm: 0.00029272318352013826\n",
      "Epoch 1, Meta Loss: 2.3028626441955566, Synthetic Data Grad Norm: 0.00035242666490375996\n",
      "Epoch 1, Meta Loss: 2.295380115509033, Synthetic Data Grad Norm: 0.0003231550217606127\n",
      "Epoch 1, Meta Loss: 2.30293869972229, Synthetic Data Grad Norm: 0.00033519507269375026\n",
      "Epoch 1, Meta Loss: 2.3063440322875977, Synthetic Data Grad Norm: 0.00035925896372646093\n",
      "Epoch 1, Meta Loss: 2.312883138656616, Synthetic Data Grad Norm: 0.00022213569900486618\n",
      "Epoch 1, Meta Loss: 2.3130714893341064, Synthetic Data Grad Norm: 0.0002458362141624093\n",
      "Epoch 1, Meta Loss: 2.289788007736206, Synthetic Data Grad Norm: 0.0002606357156764716\n",
      "Epoch 1, Meta Loss: 2.3023176193237305, Synthetic Data Grad Norm: 0.0001996456558117643\n",
      "Epoch 1, Meta Loss: 2.3040785789489746, Synthetic Data Grad Norm: 0.00033585887285880744\n",
      "Epoch 1, Meta Loss: 2.290045738220215, Synthetic Data Grad Norm: 0.00032065785489976406\n",
      "Epoch 1, Meta Loss: 2.2839486598968506, Synthetic Data Grad Norm: 0.00021728366846218705\n",
      "Epoch 1, Meta Loss: 2.301069974899292, Synthetic Data Grad Norm: 0.00034601084189489484\n",
      "Epoch 1, Meta Loss: 2.3005781173706055, Synthetic Data Grad Norm: 0.0002215662825619802\n",
      "Epoch 1, Meta Loss: 2.3000845909118652, Synthetic Data Grad Norm: 0.0003340149123687297\n",
      "Epoch 1, Meta Loss: 2.3078501224517822, Synthetic Data Grad Norm: 0.00027518029673956335\n",
      "Epoch 1, Meta Loss: 2.287968158721924, Synthetic Data Grad Norm: 0.00026863315724767745\n",
      "Epoch 1, Meta Loss: 2.305586099624634, Synthetic Data Grad Norm: 0.00041330838575959206\n",
      "Epoch 1, Meta Loss: 2.2798731327056885, Synthetic Data Grad Norm: 0.0002734161098487675\n",
      "Epoch 1, Meta Loss: 2.287001609802246, Synthetic Data Grad Norm: 0.00024925527395680547\n",
      "Epoch 1, Meta Loss: 2.2895116806030273, Synthetic Data Grad Norm: 0.0002669126552063972\n",
      "Epoch 1, Meta Loss: 2.296708106994629, Synthetic Data Grad Norm: 0.00022683164570480585\n",
      "Epoch 1, Meta Loss: 2.295858860015869, Synthetic Data Grad Norm: 0.00027787400176748633\n",
      "Epoch 1, Meta Loss: 2.293698787689209, Synthetic Data Grad Norm: 0.00027086041518487036\n",
      "Epoch 1, Meta Loss: 2.293579578399658, Synthetic Data Grad Norm: 0.00032715185079723597\n",
      "Epoch 1, Meta Loss: 2.3016834259033203, Synthetic Data Grad Norm: 0.00032716194982640445\n",
      "Epoch 1, Meta Loss: 2.2894740104675293, Synthetic Data Grad Norm: 0.0001873135333880782\n",
      "Epoch 1, Meta Loss: 2.3056893348693848, Synthetic Data Grad Norm: 0.00020716761355288327\n",
      "Epoch 1, Meta Loss: 2.2939324378967285, Synthetic Data Grad Norm: 0.0002453538472764194\n",
      "Epoch 1, Meta Loss: 2.307111978530884, Synthetic Data Grad Norm: 0.0002932023780886084\n",
      "Epoch 1, Meta Loss: 2.301239490509033, Synthetic Data Grad Norm: 0.0001833056885516271\n",
      "Epoch 1, Meta Loss: 2.3125014305114746, Synthetic Data Grad Norm: 0.00019670321489684284\n",
      "Epoch 1, Meta Loss: 2.312696695327759, Synthetic Data Grad Norm: 0.0002626661735121161\n",
      "Epoch 1, Meta Loss: 2.2979280948638916, Synthetic Data Grad Norm: 0.00039940440910868347\n",
      "Epoch 1, Meta Loss: 2.295025110244751, Synthetic Data Grad Norm: 0.00027183222118765116\n",
      "Epoch 1, Meta Loss: 2.3040859699249268, Synthetic Data Grad Norm: 0.00032398439361713827\n",
      "Epoch 1, Meta Loss: 2.301607847213745, Synthetic Data Grad Norm: 0.0002989224449265748\n",
      "Epoch 1, Meta Loss: 2.2998828887939453, Synthetic Data Grad Norm: 0.0003787039313465357\n",
      "Epoch 1, Meta Loss: 2.2853662967681885, Synthetic Data Grad Norm: 0.0003627964179031551\n",
      "Epoch 1, Meta Loss: 2.292562961578369, Synthetic Data Grad Norm: 0.00028132303850725293\n",
      "Epoch 1, Meta Loss: 2.2798609733581543, Synthetic Data Grad Norm: 0.00027154022245667875\n",
      "Epoch 1, Meta Loss: 2.291614055633545, Synthetic Data Grad Norm: 0.00021026925242040306\n",
      "Epoch 1, Meta Loss: 2.2823069095611572, Synthetic Data Grad Norm: 0.0003807862813118845\n",
      "Epoch 1, Meta Loss: 2.2859303951263428, Synthetic Data Grad Norm: 0.0002718208124861121\n",
      "Epoch 1, Meta Loss: 2.2965991497039795, Synthetic Data Grad Norm: 0.00022983858070801944\n",
      "Epoch 1, Meta Loss: 2.2984836101531982, Synthetic Data Grad Norm: 0.0002815060433931649\n",
      "Epoch 1, Meta Loss: 2.295325756072998, Synthetic Data Grad Norm: 0.00023691447859164327\n",
      "Epoch 1, Meta Loss: 2.297642469406128, Synthetic Data Grad Norm: 0.00021867314353585243\n",
      "Epoch 1, Meta Loss: 2.28307843208313, Synthetic Data Grad Norm: 0.00032260367879644036\n",
      "Epoch 1, Meta Loss: 2.309616804122925, Synthetic Data Grad Norm: 0.0002943431318271905\n",
      "Epoch 1, Meta Loss: 2.2934200763702393, Synthetic Data Grad Norm: 0.0001916917390190065\n",
      "Epoch 1, Meta Loss: 2.2895424365997314, Synthetic Data Grad Norm: 0.00023326397058553994\n",
      "Epoch 1, Meta Loss: 2.29135799407959, Synthetic Data Grad Norm: 0.00027368924929760396\n",
      "Epoch 1, Meta Loss: 2.2859854698181152, Synthetic Data Grad Norm: 0.0003113939892500639\n",
      "Epoch 1, Meta Loss: 2.2524726390838623, Synthetic Data Grad Norm: 0.00046211876906454563\n",
      "Epoch 1, Meta Loss: 2.292367458343506, Synthetic Data Grad Norm: 0.00026446397532708943\n",
      "Epoch 1, Meta Loss: 2.282125949859619, Synthetic Data Grad Norm: 0.00024261070939246565\n",
      "Epoch 1, Meta Loss: 2.281216621398926, Synthetic Data Grad Norm: 0.0002580169530119747\n",
      "Epoch 1, Meta Loss: 2.305999994277954, Synthetic Data Grad Norm: 0.000298489787383005\n",
      "Epoch 1, Meta Loss: 2.2863452434539795, Synthetic Data Grad Norm: 0.00024452386423945427\n",
      "Epoch 1, Meta Loss: 2.3460636138916016, Synthetic Data Grad Norm: 0.0002790743310470134\n",
      "Epoch 1, Meta Loss: 2.283405065536499, Synthetic Data Grad Norm: 0.0003674523322843015\n",
      "Epoch 1, Meta Loss: 2.28407621383667, Synthetic Data Grad Norm: 0.0002846058632712811\n",
      "Epoch 1, Meta Loss: 2.300107002258301, Synthetic Data Grad Norm: 0.00029488347354345024\n",
      "Epoch 1, Meta Loss: 2.292957305908203, Synthetic Data Grad Norm: 0.0002876024809665978\n",
      "Epoch 1, Meta Loss: 2.2819628715515137, Synthetic Data Grad Norm: 0.000341149017913267\n",
      "Epoch 1, Meta Loss: 2.294203996658325, Synthetic Data Grad Norm: 0.00022468456882052124\n",
      "Epoch 1, Meta Loss: 2.2866411209106445, Synthetic Data Grad Norm: 0.0004145911952946335\n",
      "Epoch 1, Meta Loss: 2.2892725467681885, Synthetic Data Grad Norm: 0.00023190623323898762\n",
      "Epoch 1, Meta Loss: 2.2991950511932373, Synthetic Data Grad Norm: 0.00027820694958791137\n",
      "Epoch 1, Meta Loss: 2.300956964492798, Synthetic Data Grad Norm: 0.0003195174504071474\n",
      "Epoch 1, Meta Loss: 2.286222219467163, Synthetic Data Grad Norm: 0.0002863709523808211\n",
      "Epoch 1, Meta Loss: 2.2919962406158447, Synthetic Data Grad Norm: 0.00024384107382502407\n",
      "Epoch 1, Meta Loss: 2.305903434753418, Synthetic Data Grad Norm: 0.00021680149075109512\n",
      "Epoch 1, Meta Loss: 2.268237590789795, Synthetic Data Grad Norm: 0.0002597356797195971\n",
      "Epoch 1, Meta Loss: 2.2864558696746826, Synthetic Data Grad Norm: 0.00034462125040590763\n",
      "Epoch 1, Meta Loss: 2.2841668128967285, Synthetic Data Grad Norm: 0.00029257958522066474\n",
      "Epoch 1, Meta Loss: 2.2762889862060547, Synthetic Data Grad Norm: 0.000241745583480224\n",
      "Epoch 1, Meta Loss: 2.298008918762207, Synthetic Data Grad Norm: 0.0002610905794426799\n",
      "Epoch 1, Meta Loss: 2.2953975200653076, Synthetic Data Grad Norm: 0.0002918810350820422\n",
      "Epoch 1, Meta Loss: 2.300499200820923, Synthetic Data Grad Norm: 0.0003128398966509849\n",
      "Epoch 1, Meta Loss: 2.294182062149048, Synthetic Data Grad Norm: 0.00023297090956475586\n",
      "Epoch 1, Meta Loss: 2.287135601043701, Synthetic Data Grad Norm: 0.0002780062786769122\n",
      "Epoch 1, Meta Loss: 2.2840654850006104, Synthetic Data Grad Norm: 0.00029239393188618124\n",
      "Epoch 1, Meta Loss: 2.301964282989502, Synthetic Data Grad Norm: 0.00031402826425619423\n",
      "Epoch 1, Meta Loss: 2.2952847480773926, Synthetic Data Grad Norm: 0.0003772866912186146\n",
      "Epoch 1, Meta Loss: 2.2880916595458984, Synthetic Data Grad Norm: 0.00023044407134875655\n",
      "Epoch 1, Meta Loss: 2.304532289505005, Synthetic Data Grad Norm: 0.000341450038831681\n",
      "Epoch 1, Meta Loss: 2.2914881706237793, Synthetic Data Grad Norm: 0.00023184189922176301\n",
      "Epoch 1, Meta Loss: 2.2928192615509033, Synthetic Data Grad Norm: 0.0003074273990932852\n",
      "Epoch 1, Meta Loss: 2.3009390830993652, Synthetic Data Grad Norm: 0.00035594345536082983\n",
      "Epoch 1, Meta Loss: 2.2958788871765137, Synthetic Data Grad Norm: 0.0002766053075902164\n",
      "Epoch 1, Meta Loss: 2.299520254135132, Synthetic Data Grad Norm: 0.00022190580784808844\n",
      "Epoch 1, Meta Loss: 2.288475275039673, Synthetic Data Grad Norm: 0.00032245152397081256\n",
      "Epoch 1, Meta Loss: 2.3004424571990967, Synthetic Data Grad Norm: 0.0003130376571789384\n",
      "Epoch 1, Meta Loss: 2.279613494873047, Synthetic Data Grad Norm: 0.00034667196450755\n",
      "Epoch 1, Meta Loss: 2.301269054412842, Synthetic Data Grad Norm: 0.0003184349334333092\n",
      "Epoch 1, Meta Loss: 2.3039920330047607, Synthetic Data Grad Norm: 0.0002188475482398644\n",
      "Epoch 1, Meta Loss: 2.2906787395477295, Synthetic Data Grad Norm: 0.00024322971876244992\n",
      "Epoch 1, Meta Loss: 2.2949604988098145, Synthetic Data Grad Norm: 0.00020231389498803765\n",
      "Epoch 1, Meta Loss: 2.306774377822876, Synthetic Data Grad Norm: 0.00032948661828413606\n",
      "Epoch 1, Meta Loss: 2.275468111038208, Synthetic Data Grad Norm: 0.0003216769837308675\n",
      "Epoch 1, Meta Loss: 2.3114328384399414, Synthetic Data Grad Norm: 0.0002858795924112201\n",
      "Epoch 1, Meta Loss: 2.2867958545684814, Synthetic Data Grad Norm: 0.0002453960187267512\n",
      "Epoch 1, Meta Loss: 2.278014659881592, Synthetic Data Grad Norm: 0.0002755354798864573\n",
      "Epoch 1, Meta Loss: 2.310699701309204, Synthetic Data Grad Norm: 0.0003123197820968926\n",
      "Epoch 1, Meta Loss: 2.278639078140259, Synthetic Data Grad Norm: 0.0003661600057967007\n",
      "Epoch 1, Meta Loss: 2.2802720069885254, Synthetic Data Grad Norm: 0.0003065986093133688\n",
      "Epoch 1, Meta Loss: 2.2917914390563965, Synthetic Data Grad Norm: 0.00028509573894552886\n",
      "Epoch 1, Meta Loss: 2.2693798542022705, Synthetic Data Grad Norm: 0.0003000834840349853\n",
      "Epoch 1, Meta Loss: 2.2911949157714844, Synthetic Data Grad Norm: 0.00025079090846702456\n",
      "Epoch 1, Meta Loss: 2.2912425994873047, Synthetic Data Grad Norm: 0.00030941684963181615\n",
      "Epoch 1, Meta Loss: 2.30208683013916, Synthetic Data Grad Norm: 0.00023977557430043817\n",
      "Epoch 1, Meta Loss: 2.2730348110198975, Synthetic Data Grad Norm: 0.0003912916872650385\n",
      "Epoch 1, Meta Loss: 2.2984461784362793, Synthetic Data Grad Norm: 0.0003119992034044117\n",
      "Epoch 1, Meta Loss: 2.2968320846557617, Synthetic Data Grad Norm: 0.00029735962743870914\n",
      "Epoch 1, Meta Loss: 2.2821929454803467, Synthetic Data Grad Norm: 0.00024705598480068147\n",
      "Epoch 1, Meta Loss: 2.2614822387695312, Synthetic Data Grad Norm: 0.0003112656995654106\n",
      "Epoch 1, Meta Loss: 2.2720344066619873, Synthetic Data Grad Norm: 0.0002476088993716985\n",
      "Epoch 1, Meta Loss: 2.302574872970581, Synthetic Data Grad Norm: 0.00030331293237395585\n",
      "Epoch 1, Meta Loss: 2.289274215698242, Synthetic Data Grad Norm: 0.0003033048997167498\n",
      "Epoch 1, Meta Loss: 2.2892394065856934, Synthetic Data Grad Norm: 0.0002193646942032501\n",
      "Epoch 1, Meta Loss: 2.290335178375244, Synthetic Data Grad Norm: 0.0002446477592457086\n",
      "Epoch 1, Meta Loss: 2.305253267288208, Synthetic Data Grad Norm: 0.00022640077804680914\n",
      "Epoch 1, Meta Loss: 2.2994511127471924, Synthetic Data Grad Norm: 0.00029281858587637544\n",
      "Epoch 1, Meta Loss: 2.2817983627319336, Synthetic Data Grad Norm: 0.00026132602943107486\n",
      "Epoch 1, Meta Loss: 2.2854197025299072, Synthetic Data Grad Norm: 0.0002619735896587372\n",
      "Epoch 1, Meta Loss: 2.3074774742126465, Synthetic Data Grad Norm: 0.00039574370021000504\n",
      "Epoch 1, Meta Loss: 2.279012680053711, Synthetic Data Grad Norm: 0.00032396710594184697\n",
      "Epoch 1, Meta Loss: 2.2907209396362305, Synthetic Data Grad Norm: 0.0002198938891524449\n",
      "Epoch 1, Meta Loss: 2.2781052589416504, Synthetic Data Grad Norm: 0.0002453820197843015\n",
      "Epoch 1, Meta Loss: 2.287358045578003, Synthetic Data Grad Norm: 0.0002106056927004829\n",
      "Epoch 1, Meta Loss: 2.2890796661376953, Synthetic Data Grad Norm: 0.00023243346367962658\n",
      "Epoch 1, Meta Loss: 2.2617104053497314, Synthetic Data Grad Norm: 0.0002577143895905465\n",
      "Epoch 1, Meta Loss: 2.3067564964294434, Synthetic Data Grad Norm: 0.0003376808308530599\n",
      "Epoch 1, Meta Loss: 2.2945799827575684, Synthetic Data Grad Norm: 0.0002107657492160797\n",
      "Epoch 1, Meta Loss: 2.2977077960968018, Synthetic Data Grad Norm: 0.0003480060549918562\n",
      "Epoch 1, Meta Loss: 2.3020431995391846, Synthetic Data Grad Norm: 0.00021850135817658156\n",
      "Epoch 1, Meta Loss: 2.2987430095672607, Synthetic Data Grad Norm: 0.000340973143465817\n",
      "Epoch 1, Meta Loss: 2.286482334136963, Synthetic Data Grad Norm: 0.00020829208369832486\n",
      "Epoch 1, Meta Loss: 2.294161796569824, Synthetic Data Grad Norm: 0.0002792387967929244\n",
      "Epoch 1, Meta Loss: 2.282000780105591, Synthetic Data Grad Norm: 0.00035169461625628173\n",
      "Epoch 1, Meta Loss: 2.2915797233581543, Synthetic Data Grad Norm: 0.0002153298119083047\n",
      "Epoch 1, Meta Loss: 2.2956008911132812, Synthetic Data Grad Norm: 0.00025131195434369147\n",
      "Epoch 1, Meta Loss: 2.2793314456939697, Synthetic Data Grad Norm: 0.0002343900123378262\n",
      "Epoch 1, Meta Loss: 2.3021092414855957, Synthetic Data Grad Norm: 0.00021101614402141422\n",
      "Epoch 1, Meta Loss: 2.29756760597229, Synthetic Data Grad Norm: 0.00032417583861388266\n",
      "Epoch 1, Meta Loss: 2.2828032970428467, Synthetic Data Grad Norm: 0.00031781091820448637\n",
      "Epoch 1, Meta Loss: 2.3109374046325684, Synthetic Data Grad Norm: 0.00028199978987686336\n",
      "Epoch 1, Meta Loss: 2.289647102355957, Synthetic Data Grad Norm: 0.00028870211099274457\n",
      "Epoch 1, Meta Loss: 2.2790181636810303, Synthetic Data Grad Norm: 0.00033018243266269565\n",
      "Epoch 1, Meta Loss: 2.2889108657836914, Synthetic Data Grad Norm: 0.00035294939880259335\n",
      "Epoch 1, Meta Loss: 2.2943150997161865, Synthetic Data Grad Norm: 0.0002446291910018772\n",
      "Epoch 1, Meta Loss: 2.2870750427246094, Synthetic Data Grad Norm: 0.00021606907830573618\n",
      "Epoch 1, Meta Loss: 2.3118889331817627, Synthetic Data Grad Norm: 0.0002579117426648736\n",
      "Epoch 1, Meta Loss: 2.278543710708618, Synthetic Data Grad Norm: 0.00023796503955964\n",
      "Epoch 1, Meta Loss: 2.2790462970733643, Synthetic Data Grad Norm: 0.00025447248481214046\n",
      "Epoch 1, Meta Loss: 2.3096871376037598, Synthetic Data Grad Norm: 0.0002273403515573591\n",
      "Epoch 1, Meta Loss: 2.304957628250122, Synthetic Data Grad Norm: 0.0002672277332749218\n",
      "Epoch 1, Meta Loss: 2.294992446899414, Synthetic Data Grad Norm: 0.00031882821349427104\n",
      "Epoch 1, Meta Loss: 2.276231050491333, Synthetic Data Grad Norm: 0.00024951796513050795\n",
      "Epoch 1, Meta Loss: 2.2756950855255127, Synthetic Data Grad Norm: 0.0003043639881070703\n",
      "Epoch 1, Meta Loss: 2.285398006439209, Synthetic Data Grad Norm: 0.00016786086780484766\n",
      "Epoch 1, Meta Loss: 2.310343027114868, Synthetic Data Grad Norm: 0.0002659596793819219\n",
      "Epoch 1, Meta Loss: 2.28889799118042, Synthetic Data Grad Norm: 0.0004063721280544996\n",
      "Epoch 1, Meta Loss: 2.315624237060547, Synthetic Data Grad Norm: 0.0003859656280837953\n",
      "Epoch 1, Meta Loss: 2.2831902503967285, Synthetic Data Grad Norm: 0.00019235820218455046\n",
      "Epoch 1, Meta Loss: 2.3219850063323975, Synthetic Data Grad Norm: 0.00034005974885076284\n",
      "Epoch 1, Meta Loss: 2.3210580348968506, Synthetic Data Grad Norm: 0.0002810510341078043\n",
      "Epoch 1, Meta Loss: 2.28621768951416, Synthetic Data Grad Norm: 0.00032440139329992235\n",
      "Epoch 1, Meta Loss: 2.2848060131073, Synthetic Data Grad Norm: 0.000351806782418862\n",
      "Epoch 1, Meta Loss: 2.309461832046509, Synthetic Data Grad Norm: 0.0003423398011364043\n",
      "Epoch 1, Meta Loss: 2.2949657440185547, Synthetic Data Grad Norm: 0.0002159729046979919\n",
      "Epoch 1, Meta Loss: 2.287943124771118, Synthetic Data Grad Norm: 0.00027871091151610017\n",
      "Epoch 1, Meta Loss: 2.3003597259521484, Synthetic Data Grad Norm: 0.0002402156387688592\n",
      "Epoch 1, Meta Loss: 2.275850534439087, Synthetic Data Grad Norm: 0.0003506441425997764\n",
      "Epoch 1, Meta Loss: 2.3019421100616455, Synthetic Data Grad Norm: 0.00029509325395338237\n",
      "Epoch 1, Meta Loss: 2.279973030090332, Synthetic Data Grad Norm: 0.00025208364240825176\n",
      "Epoch 1, Meta Loss: 2.28385853767395, Synthetic Data Grad Norm: 0.00029018224449828267\n",
      "Epoch 1, Meta Loss: 2.2888076305389404, Synthetic Data Grad Norm: 0.00030941952718421817\n",
      "Epoch 1, Meta Loss: 2.291084051132202, Synthetic Data Grad Norm: 0.00032291581737808883\n",
      "Epoch 1, Meta Loss: 2.287235975265503, Synthetic Data Grad Norm: 0.0003359555557835847\n",
      "Epoch 1, Meta Loss: 2.2890098094940186, Synthetic Data Grad Norm: 0.0002529411285649985\n",
      "Epoch 1, Meta Loss: 2.3009274005889893, Synthetic Data Grad Norm: 0.00038190785562619567\n",
      "Epoch 1, Meta Loss: 2.3053555488586426, Synthetic Data Grad Norm: 0.0002451762557029724\n",
      "Epoch 1, Meta Loss: 2.2885849475860596, Synthetic Data Grad Norm: 0.0002168644277844578\n",
      "Epoch 1, Meta Loss: 2.3322372436523438, Synthetic Data Grad Norm: 0.00028105214005336165\n",
      "Epoch 1, Meta Loss: 2.293567419052124, Synthetic Data Grad Norm: 0.0002753585285972804\n",
      "Epoch 1, Meta Loss: 2.2966296672821045, Synthetic Data Grad Norm: 0.0002154436515411362\n",
      "Epoch 1, Meta Loss: 2.2689905166625977, Synthetic Data Grad Norm: 0.00027643272187560797\n",
      "Epoch 1, Meta Loss: 2.278196096420288, Synthetic Data Grad Norm: 0.00028564754757098854\n",
      "Epoch 1, Meta Loss: 2.296757221221924, Synthetic Data Grad Norm: 0.0002543071750551462\n",
      "Epoch 1, Meta Loss: 2.285320520401001, Synthetic Data Grad Norm: 0.00022605950653087348\n",
      "Epoch 1, Meta Loss: 2.2826123237609863, Synthetic Data Grad Norm: 0.00024356707581318915\n",
      "Epoch 1, Meta Loss: 2.284458875656128, Synthetic Data Grad Norm: 0.00026024336693808436\n",
      "Epoch 1, Meta Loss: 2.302443742752075, Synthetic Data Grad Norm: 0.0002445595746394247\n",
      "Epoch 1, Meta Loss: 2.297889232635498, Synthetic Data Grad Norm: 0.00025754718808457255\n",
      "Epoch 1, Meta Loss: 2.2800962924957275, Synthetic Data Grad Norm: 0.000396791729144752\n",
      "Epoch 1, Meta Loss: 2.268343925476074, Synthetic Data Grad Norm: 0.00034446982317604125\n",
      "Epoch 1, Meta Loss: 2.282252550125122, Synthetic Data Grad Norm: 0.000271140830591321\n",
      "Epoch 1, Meta Loss: 2.3061656951904297, Synthetic Data Grad Norm: 0.0002642028557602316\n",
      "Epoch 1, Meta Loss: 2.288835287094116, Synthetic Data Grad Norm: 0.000268986274022609\n",
      "Epoch 1, Meta Loss: 2.2928073406219482, Synthetic Data Grad Norm: 0.00026831464492715895\n",
      "Epoch 1, Meta Loss: 2.298020124435425, Synthetic Data Grad Norm: 0.0003001402656082064\n",
      "Epoch 1, Meta Loss: 2.2856738567352295, Synthetic Data Grad Norm: 0.0002454065252095461\n",
      "Epoch 1, Meta Loss: 2.278470039367676, Synthetic Data Grad Norm: 0.00024810590548440814\n",
      "Epoch 1, Meta Loss: 2.271583080291748, Synthetic Data Grad Norm: 0.000317872385494411\n",
      "Epoch 1, Meta Loss: 2.289574384689331, Synthetic Data Grad Norm: 0.0003264783008489758\n",
      "Epoch 1, Meta Loss: 2.258761405944824, Synthetic Data Grad Norm: 0.00029602713766507804\n",
      "Epoch 1, Meta Loss: 2.2945234775543213, Synthetic Data Grad Norm: 0.00035909126745536923\n",
      "Epoch 1, Meta Loss: 2.2935967445373535, Synthetic Data Grad Norm: 0.00027077371487393975\n",
      "Epoch 1, Meta Loss: 2.290658712387085, Synthetic Data Grad Norm: 0.00027906332979910076\n",
      "Epoch 1, Meta Loss: 2.3016226291656494, Synthetic Data Grad Norm: 0.00024986546486616135\n",
      "Epoch 1, Meta Loss: 2.276169776916504, Synthetic Data Grad Norm: 0.00033002023701556027\n",
      "Epoch 1, Meta Loss: 2.2939977645874023, Synthetic Data Grad Norm: 0.0002640541351865977\n",
      "Epoch 1, Meta Loss: 2.296318292617798, Synthetic Data Grad Norm: 0.00030266973772086203\n",
      "Epoch 1, Meta Loss: 2.2828593254089355, Synthetic Data Grad Norm: 0.00023608120682183653\n",
      "Epoch 1, Meta Loss: 2.2931928634643555, Synthetic Data Grad Norm: 0.00022728042677044868\n",
      "Epoch 1, Meta Loss: 2.2921159267425537, Synthetic Data Grad Norm: 0.00024124293122440577\n",
      "Epoch 1, Meta Loss: 2.2730135917663574, Synthetic Data Grad Norm: 0.0002710241824388504\n",
      "Epoch 1, Meta Loss: 2.276606798171997, Synthetic Data Grad Norm: 0.00032878582715056837\n",
      "Epoch 1, Meta Loss: 2.2930474281311035, Synthetic Data Grad Norm: 0.00022837947471998632\n",
      "Epoch 1, Meta Loss: 2.2934062480926514, Synthetic Data Grad Norm: 0.0002162332966690883\n",
      "Epoch 1, Meta Loss: 2.3106555938720703, Synthetic Data Grad Norm: 0.000357476354110986\n",
      "Epoch 1, Meta Loss: 2.300642490386963, Synthetic Data Grad Norm: 0.00029435803298838437\n",
      "Epoch 1, Meta Loss: 2.2765841484069824, Synthetic Data Grad Norm: 0.00026341862394474447\n",
      "Epoch 1, Meta Loss: 2.2866504192352295, Synthetic Data Grad Norm: 0.0002900984254665673\n",
      "Epoch 1, Meta Loss: 2.297741413116455, Synthetic Data Grad Norm: 0.00026526564033702016\n",
      "Epoch 1, Meta Loss: 2.286741018295288, Synthetic Data Grad Norm: 0.0003227895067539066\n",
      "Epoch 1, Meta Loss: 2.2922089099884033, Synthetic Data Grad Norm: 0.00025913413264788687\n",
      "Epoch 1, Meta Loss: 2.283874034881592, Synthetic Data Grad Norm: 0.0002763692173175514\n",
      "Epoch 1, Meta Loss: 2.2723536491394043, Synthetic Data Grad Norm: 0.0002799979120027274\n",
      "Epoch 1, Meta Loss: 2.289095640182495, Synthetic Data Grad Norm: 0.00023531106126029044\n",
      "Epoch 1, Meta Loss: 2.281080722808838, Synthetic Data Grad Norm: 0.00024467791081406176\n",
      "Epoch 1, Meta Loss: 2.3062338829040527, Synthetic Data Grad Norm: 0.00028015070711262524\n",
      "Epoch 1, Meta Loss: 2.2949180603027344, Synthetic Data Grad Norm: 0.0002831000310834497\n",
      "Epoch 1, Meta Loss: 2.298753023147583, Synthetic Data Grad Norm: 0.00019738871196750551\n",
      "Epoch 1, Meta Loss: 2.2888598442077637, Synthetic Data Grad Norm: 0.0002932838106062263\n",
      "Epoch 1, Meta Loss: 2.306701421737671, Synthetic Data Grad Norm: 0.0003085492935497314\n",
      "Epoch 1, Meta Loss: 2.291167974472046, Synthetic Data Grad Norm: 0.0003182904329150915\n",
      "Epoch 1, Meta Loss: 2.292696952819824, Synthetic Data Grad Norm: 0.0002600063744466752\n",
      "Epoch 1, Meta Loss: 2.2899370193481445, Synthetic Data Grad Norm: 0.00024678665795363486\n",
      "Epoch 1, Meta Loss: 2.303189277648926, Synthetic Data Grad Norm: 0.00027480069547891617\n",
      "Epoch 1, Meta Loss: 2.303675651550293, Synthetic Data Grad Norm: 0.00019812860409729183\n",
      "Epoch 1, Meta Loss: 2.3025944232940674, Synthetic Data Grad Norm: 0.00025361691950820386\n",
      "Epoch 1, Meta Loss: 2.29967999458313, Synthetic Data Grad Norm: 0.00022720216657035053\n",
      "Epoch 1, Meta Loss: 2.2997617721557617, Synthetic Data Grad Norm: 0.0002482775889802724\n",
      "Epoch 1, Meta Loss: 2.298950433731079, Synthetic Data Grad Norm: 0.0002128245832864195\n",
      "Epoch 1, Meta Loss: 2.2930238246917725, Synthetic Data Grad Norm: 0.00030326354317367077\n",
      "Epoch 1, Meta Loss: 2.303417205810547, Synthetic Data Grad Norm: 0.00038014116580598056\n",
      "Epoch 1, Meta Loss: 2.2973968982696533, Synthetic Data Grad Norm: 0.0002464672434143722\n",
      "Epoch 1, Meta Loss: 2.2979061603546143, Synthetic Data Grad Norm: 0.0003110703837592155\n",
      "Epoch 1, Meta Loss: 2.2967495918273926, Synthetic Data Grad Norm: 0.00022367705241777003\n",
      "Epoch 1, Meta Loss: 2.2865653038024902, Synthetic Data Grad Norm: 0.0002543199516367167\n",
      "Epoch 1, Meta Loss: 2.290971279144287, Synthetic Data Grad Norm: 0.00030082996818237007\n",
      "Epoch 1, Meta Loss: 2.286555528640747, Synthetic Data Grad Norm: 0.00031974035664461553\n",
      "Epoch 1, Meta Loss: 2.292431116104126, Synthetic Data Grad Norm: 0.00032039376674219966\n",
      "Epoch 1, Meta Loss: 2.2762842178344727, Synthetic Data Grad Norm: 0.0002657990262378007\n",
      "Epoch 1, Meta Loss: 2.3044979572296143, Synthetic Data Grad Norm: 0.000248607131652534\n",
      "Epoch 1, Meta Loss: 2.270977020263672, Synthetic Data Grad Norm: 0.0003639037604443729\n",
      "Epoch 1, Meta Loss: 2.2894136905670166, Synthetic Data Grad Norm: 0.0002762400545179844\n",
      "Epoch 1, Meta Loss: 2.284740924835205, Synthetic Data Grad Norm: 0.00022176498896442354\n",
      "Epoch 1, Meta Loss: 2.303171157836914, Synthetic Data Grad Norm: 0.000309914379613474\n",
      "Epoch 1, Meta Loss: 2.292654037475586, Synthetic Data Grad Norm: 0.0002676132135093212\n",
      "Epoch 1, Meta Loss: 2.2815158367156982, Synthetic Data Grad Norm: 0.000229360768571496\n",
      "Epoch 1, Meta Loss: 2.283893346786499, Synthetic Data Grad Norm: 0.0002500640694051981\n",
      "Epoch 1, Meta Loss: 2.271988868713379, Synthetic Data Grad Norm: 0.00029429784626699984\n",
      "Epoch 1, Meta Loss: 2.296903371810913, Synthetic Data Grad Norm: 0.00042611928074620664\n",
      "Epoch 1, Meta Loss: 2.314135789871216, Synthetic Data Grad Norm: 0.00033209050889126956\n",
      "Epoch 1, Meta Loss: 2.2884862422943115, Synthetic Data Grad Norm: 0.0002463111304678023\n",
      "Epoch 1, Meta Loss: 2.32218074798584, Synthetic Data Grad Norm: 0.00033912129583768547\n",
      "Epoch 1, Meta Loss: 2.290347099304199, Synthetic Data Grad Norm: 0.0002280978369526565\n",
      "Epoch 1, Meta Loss: 2.296517848968506, Synthetic Data Grad Norm: 0.00023076859361026436\n",
      "Epoch 1, Meta Loss: 2.276970863342285, Synthetic Data Grad Norm: 0.000320280872983858\n",
      "Epoch 1, Meta Loss: 2.2897133827209473, Synthetic Data Grad Norm: 0.00041721289744600654\n",
      "Epoch 1, Meta Loss: 2.2780966758728027, Synthetic Data Grad Norm: 0.0003466217021923512\n",
      "Epoch 1, Meta Loss: 2.2846474647521973, Synthetic Data Grad Norm: 0.00026243424508720636\n",
      "Epoch 1, Meta Loss: 2.274068593978882, Synthetic Data Grad Norm: 0.00035696945269592106\n",
      "Epoch 1, Meta Loss: 2.3014726638793945, Synthetic Data Grad Norm: 0.0001896314788609743\n",
      "Epoch 1, Meta Loss: 2.286620616912842, Synthetic Data Grad Norm: 0.00024631671840325\n",
      "Epoch 1, Meta Loss: 2.269123077392578, Synthetic Data Grad Norm: 0.0003602537326514721\n",
      "Epoch 1, Meta Loss: 2.287092924118042, Synthetic Data Grad Norm: 0.00024901796132326126\n",
      "Epoch 1, Meta Loss: 2.2727513313293457, Synthetic Data Grad Norm: 0.0003600326308514923\n",
      "Epoch 1, Meta Loss: 2.2847301959991455, Synthetic Data Grad Norm: 0.000350836431607604\n",
      "Epoch 1, Meta Loss: 2.317091703414917, Synthetic Data Grad Norm: 0.00021561008179560304\n",
      "Epoch 1, Meta Loss: 2.2958247661590576, Synthetic Data Grad Norm: 0.00031424223561771214\n",
      "Epoch 1, Meta Loss: 2.2920830249786377, Synthetic Data Grad Norm: 0.0002516143140383065\n",
      "Epoch 1, Meta Loss: 2.2804436683654785, Synthetic Data Grad Norm: 0.00026055873604491353\n",
      "Epoch 1, Meta Loss: 2.272597074508667, Synthetic Data Grad Norm: 0.00029485271079465747\n",
      "Epoch 1, Meta Loss: 2.296006679534912, Synthetic Data Grad Norm: 0.0002769310085568577\n",
      "Epoch 1, Meta Loss: 2.3000333309173584, Synthetic Data Grad Norm: 0.0002726226521190256\n",
      "Epoch 1, Meta Loss: 2.289443254470825, Synthetic Data Grad Norm: 0.0002726132224779576\n",
      "Epoch 1, Meta Loss: 2.288905143737793, Synthetic Data Grad Norm: 0.000265798851614818\n",
      "Epoch 1, Meta Loss: 2.272958755493164, Synthetic Data Grad Norm: 0.0002918431127909571\n",
      "Epoch 1, Meta Loss: 2.308206558227539, Synthetic Data Grad Norm: 0.00028980354545637965\n",
      "Epoch 1, Meta Loss: 2.293778419494629, Synthetic Data Grad Norm: 0.00023876558407209814\n",
      "Epoch 1, Meta Loss: 2.2854814529418945, Synthetic Data Grad Norm: 0.00035759189631789923\n",
      "Epoch 1, Meta Loss: 2.2733819484710693, Synthetic Data Grad Norm: 0.0005105744930915534\n",
      "Epoch 1, Meta Loss: 2.2805733680725098, Synthetic Data Grad Norm: 0.00023838310153223574\n",
      "Epoch 1, Meta Loss: 2.2848598957061768, Synthetic Data Grad Norm: 0.00028951524291187525\n",
      "Epoch 1, Meta Loss: 2.2846872806549072, Synthetic Data Grad Norm: 0.00036916157114319503\n",
      "Epoch 1, Meta Loss: 2.288695812225342, Synthetic Data Grad Norm: 0.0003000584547407925\n",
      "Epoch 1, Meta Loss: 2.287263870239258, Synthetic Data Grad Norm: 0.0002615504199638963\n",
      "Epoch 1, Meta Loss: 2.2844157218933105, Synthetic Data Grad Norm: 0.00025357407866977155\n",
      "Epoch 1, Meta Loss: 2.2875850200653076, Synthetic Data Grad Norm: 0.00019408497610129416\n",
      "Epoch 1, Meta Loss: 2.2839062213897705, Synthetic Data Grad Norm: 0.00033982834429480135\n",
      "Epoch 1, Meta Loss: 2.277953624725342, Synthetic Data Grad Norm: 0.00023282773327082396\n",
      "Epoch 1, Meta Loss: 2.291895627975464, Synthetic Data Grad Norm: 0.00021644461958203465\n",
      "Epoch 1, Meta Loss: 2.2799413204193115, Synthetic Data Grad Norm: 0.0002279270120197907\n",
      "Epoch 1, Meta Loss: 2.288330078125, Synthetic Data Grad Norm: 0.000247857446083799\n",
      "Epoch 1, Meta Loss: 2.275690793991089, Synthetic Data Grad Norm: 0.00026668954524211586\n",
      "Epoch 1, Meta Loss: 2.2847518920898438, Synthetic Data Grad Norm: 0.0001951893063960597\n",
      "Epoch 1, Meta Loss: 2.3297879695892334, Synthetic Data Grad Norm: 0.0002833888283930719\n",
      "Epoch 1, Meta Loss: 2.2932076454162598, Synthetic Data Grad Norm: 0.0003132084966637194\n",
      "Epoch 1, Meta Loss: 2.2793521881103516, Synthetic Data Grad Norm: 0.00034035934368148446\n",
      "Epoch 1, Meta Loss: 2.287997007369995, Synthetic Data Grad Norm: 0.00024083956668619066\n",
      "Epoch 1, Meta Loss: 2.2891480922698975, Synthetic Data Grad Norm: 0.00027115887496620417\n",
      "Epoch 1, Meta Loss: 2.2839629650115967, Synthetic Data Grad Norm: 0.0002747825055848807\n",
      "Epoch 1, Meta Loss: 2.278562068939209, Synthetic Data Grad Norm: 0.0003278608783148229\n",
      "Epoch 1, Meta Loss: 2.3110103607177734, Synthetic Data Grad Norm: 0.00027922753361053765\n",
      "Epoch 1, Meta Loss: 2.2899281978607178, Synthetic Data Grad Norm: 0.00041384162614122033\n",
      "Epoch 1, Meta Loss: 2.289233684539795, Synthetic Data Grad Norm: 0.00026627114857546985\n",
      "Epoch 1, Meta Loss: 2.266556739807129, Synthetic Data Grad Norm: 0.0002626781351864338\n",
      "Epoch 1, Meta Loss: 2.2781529426574707, Synthetic Data Grad Norm: 0.00025882330373860896\n",
      "Epoch 1, Meta Loss: 2.2936654090881348, Synthetic Data Grad Norm: 0.00019475510634947568\n",
      "Epoch 1, Meta Loss: 2.2879250049591064, Synthetic Data Grad Norm: 0.00019351043738424778\n",
      "Epoch 1, Meta Loss: 2.265623092651367, Synthetic Data Grad Norm: 0.0003027523634955287\n",
      "Epoch 1, Meta Loss: 2.295281410217285, Synthetic Data Grad Norm: 0.0003029392391908914\n",
      "Epoch 1, Meta Loss: 2.2831871509552, Synthetic Data Grad Norm: 0.00032216403633356094\n",
      "Epoch 1, Meta Loss: 2.3292269706726074, Synthetic Data Grad Norm: 0.0002841222449205816\n",
      "Epoch 1, Meta Loss: 2.2900633811950684, Synthetic Data Grad Norm: 0.0002624195476528257\n",
      "Epoch 1, Meta Loss: 2.2857253551483154, Synthetic Data Grad Norm: 0.00026291425456292927\n",
      "Epoch 1, Meta Loss: 2.28340482711792, Synthetic Data Grad Norm: 0.00030392719781957567\n",
      "Epoch 1, Meta Loss: 2.2783851623535156, Synthetic Data Grad Norm: 0.00022584978432860225\n",
      "Epoch 1, Meta Loss: 2.293266773223877, Synthetic Data Grad Norm: 0.00018725139671005309\n",
      "Epoch 1, Meta Loss: 2.2774012088775635, Synthetic Data Grad Norm: 0.0003299478266853839\n",
      "Epoch 1, Meta Loss: 2.2956666946411133, Synthetic Data Grad Norm: 0.00023934732598718256\n",
      "Epoch 1, Meta Loss: 2.2850711345672607, Synthetic Data Grad Norm: 0.00033778772922232747\n",
      "Epoch 1, Meta Loss: 2.281536102294922, Synthetic Data Grad Norm: 0.00025262864073738456\n",
      "Epoch 1, Meta Loss: 2.3057966232299805, Synthetic Data Grad Norm: 0.00029974456992931664\n",
      "Epoch 1, Meta Loss: 2.2998783588409424, Synthetic Data Grad Norm: 0.00018384293070994318\n",
      "Epoch 1, Meta Loss: 2.2866744995117188, Synthetic Data Grad Norm: 0.0003407443582545966\n",
      "Epoch 1, Meta Loss: 2.2978546619415283, Synthetic Data Grad Norm: 0.00034318669349886477\n",
      "Epoch 1, Meta Loss: 2.2811472415924072, Synthetic Data Grad Norm: 0.0003343577263876796\n",
      "Epoch 1, Meta Loss: 2.2742295265197754, Synthetic Data Grad Norm: 0.00023960744147188962\n",
      "Epoch 1, Meta Loss: 2.2963833808898926, Synthetic Data Grad Norm: 0.00021061072766315192\n",
      "Epoch 1, Meta Loss: 2.290506601333618, Synthetic Data Grad Norm: 0.00020819985365960747\n",
      "Epoch 1, Meta Loss: 2.2961719036102295, Synthetic Data Grad Norm: 0.00024311020388267934\n",
      "Epoch 1, Meta Loss: 2.2913312911987305, Synthetic Data Grad Norm: 0.00032576205558143556\n",
      "Epoch 1, Meta Loss: 2.293151378631592, Synthetic Data Grad Norm: 0.00028209909214638174\n",
      "Epoch 1, Meta Loss: 2.3007972240448, Synthetic Data Grad Norm: 0.00019353504467289895\n",
      "Epoch 1, Meta Loss: 2.275238275527954, Synthetic Data Grad Norm: 0.0003548662061803043\n",
      "Epoch 1, Meta Loss: 2.2853143215179443, Synthetic Data Grad Norm: 0.0002223910705652088\n",
      "Epoch 1, Meta Loss: 2.2874937057495117, Synthetic Data Grad Norm: 0.0002454880450386554\n",
      "Epoch 1, Meta Loss: 2.27728271484375, Synthetic Data Grad Norm: 0.0002790121652651578\n",
      "Epoch 1, Meta Loss: 2.292356252670288, Synthetic Data Grad Norm: 0.0002596609410829842\n",
      "Epoch 1, Meta Loss: 2.306874990463257, Synthetic Data Grad Norm: 0.00029251541127450764\n",
      "Epoch 1, Meta Loss: 2.2949235439300537, Synthetic Data Grad Norm: 0.0003532560367602855\n",
      "Epoch 1, Meta Loss: 2.293520450592041, Synthetic Data Grad Norm: 0.00028360571013763547\n",
      "Epoch 1, Meta Loss: 2.285740613937378, Synthetic Data Grad Norm: 0.00023393628362100571\n",
      "Epoch 1, Meta Loss: 2.2781107425689697, Synthetic Data Grad Norm: 0.00031973616569302976\n",
      "Epoch 1, Meta Loss: 2.279629707336426, Synthetic Data Grad Norm: 0.00027412347844801843\n",
      "Epoch 1, Meta Loss: 2.2955386638641357, Synthetic Data Grad Norm: 0.0002512421051505953\n",
      "Epoch 1, Meta Loss: 2.276780366897583, Synthetic Data Grad Norm: 0.00032484365510754287\n",
      "Epoch 1, Meta Loss: 2.288703680038452, Synthetic Data Grad Norm: 0.0002657138684298843\n",
      "Epoch 1, Meta Loss: 2.291289806365967, Synthetic Data Grad Norm: 0.0002809248398989439\n",
      "Epoch 1, Meta Loss: 2.284881353378296, Synthetic Data Grad Norm: 0.0003643769887275994\n",
      "Epoch 1, Meta Loss: 2.277446746826172, Synthetic Data Grad Norm: 0.0002900666440837085\n",
      "Epoch 1, Meta Loss: 2.2946577072143555, Synthetic Data Grad Norm: 0.0002781437069643289\n",
      "Epoch 1, Meta Loss: 2.277557134628296, Synthetic Data Grad Norm: 0.0002538880507927388\n",
      "Epoch 1, Meta Loss: 2.2766146659851074, Synthetic Data Grad Norm: 0.00028750448836945\n",
      "Epoch 1, Meta Loss: 2.2943241596221924, Synthetic Data Grad Norm: 0.00023706532374490052\n",
      "Epoch 1, Meta Loss: 2.305757999420166, Synthetic Data Grad Norm: 0.0002880396496038884\n",
      "Epoch 1, Meta Loss: 2.277409791946411, Synthetic Data Grad Norm: 0.0003204795648343861\n",
      "Epoch 1, Meta Loss: 2.29060959815979, Synthetic Data Grad Norm: 0.0002334930031793192\n",
      "Epoch 1, Meta Loss: 2.278881311416626, Synthetic Data Grad Norm: 0.00026840323698706925\n",
      "Epoch 1, Meta Loss: 2.2900798320770264, Synthetic Data Grad Norm: 0.00025896605802699924\n",
      "Epoch 1, Meta Loss: 2.2508504390716553, Synthetic Data Grad Norm: 0.00042960632708854973\n",
      "Epoch 1, Meta Loss: 2.281921148300171, Synthetic Data Grad Norm: 0.0002415448980173096\n",
      "Epoch 1, Meta Loss: 2.2922847270965576, Synthetic Data Grad Norm: 0.0003205731336493045\n",
      "Epoch 1, Meta Loss: 2.2840139865875244, Synthetic Data Grad Norm: 0.0002751091669779271\n",
      "Epoch 1, Meta Loss: 2.274146795272827, Synthetic Data Grad Norm: 0.00029391999123618007\n",
      "Epoch 1, Meta Loss: 2.282288074493408, Synthetic Data Grad Norm: 0.0002751071297097951\n",
      "Epoch 1, Meta Loss: 2.291991710662842, Synthetic Data Grad Norm: 0.00019292168144602329\n",
      "Epoch 1, Meta Loss: 2.303730010986328, Synthetic Data Grad Norm: 0.0002491369959898293\n",
      "Epoch 1, Meta Loss: 2.2883217334747314, Synthetic Data Grad Norm: 0.0003572544374037534\n",
      "Epoch 1, Meta Loss: 2.295667886734009, Synthetic Data Grad Norm: 0.00028749718330800533\n",
      "Epoch 1, Meta Loss: 2.2912750244140625, Synthetic Data Grad Norm: 0.0003373390936758369\n",
      "Epoch 1, Meta Loss: 2.2909443378448486, Synthetic Data Grad Norm: 0.0002777414920274168\n",
      "Epoch 1, Meta Loss: 2.278061866760254, Synthetic Data Grad Norm: 0.00018124257621821016\n",
      "Epoch 1, Meta Loss: 2.289005756378174, Synthetic Data Grad Norm: 0.00022428069496527314\n",
      "Epoch 1, Meta Loss: 2.293579339981079, Synthetic Data Grad Norm: 0.00023446134582627565\n",
      "Epoch 1, Meta Loss: 2.304872989654541, Synthetic Data Grad Norm: 0.00032925771665759385\n",
      "Epoch 1, Meta Loss: 2.271801710128784, Synthetic Data Grad Norm: 0.000342923536663875\n",
      "Epoch 1, Meta Loss: 2.2747437953948975, Synthetic Data Grad Norm: 0.0004164153942838311\n",
      "Epoch 1, Meta Loss: 2.2868168354034424, Synthetic Data Grad Norm: 0.00029701541643589735\n",
      "Epoch 1, Meta Loss: 2.3013107776641846, Synthetic Data Grad Norm: 0.0001613850618014112\n",
      "Epoch 1, Meta Loss: 2.2827212810516357, Synthetic Data Grad Norm: 0.0002617684658616781\n",
      "Epoch 1, Meta Loss: 2.2899909019470215, Synthetic Data Grad Norm: 0.00028552222647704184\n",
      "Epoch 1, Meta Loss: 2.2791459560394287, Synthetic Data Grad Norm: 0.00025196486967615783\n",
      "Epoch 1, Meta Loss: 2.2997641563415527, Synthetic Data Grad Norm: 0.00021870176715310663\n",
      "Epoch 1, Meta Loss: 2.2843663692474365, Synthetic Data Grad Norm: 0.000280712207313627\n",
      "Epoch 1, Meta Loss: 2.3104612827301025, Synthetic Data Grad Norm: 0.0002196685818489641\n",
      "Epoch 1, Meta Loss: 2.2873103618621826, Synthetic Data Grad Norm: 0.00036236923187971115\n",
      "Epoch 1, Meta Loss: 2.2839841842651367, Synthetic Data Grad Norm: 0.00026832366711460054\n",
      "Epoch 1, Meta Loss: 2.2955503463745117, Synthetic Data Grad Norm: 0.00025978207122534513\n",
      "Epoch 1, Meta Loss: 2.299736261367798, Synthetic Data Grad Norm: 0.00022734032245352864\n",
      "Epoch 1, Meta Loss: 2.26686429977417, Synthetic Data Grad Norm: 0.0003101583570241928\n",
      "Epoch 1, Meta Loss: 2.292229413986206, Synthetic Data Grad Norm: 0.000274862366495654\n",
      "Epoch 1, Meta Loss: 2.2829244136810303, Synthetic Data Grad Norm: 0.00029943857225589454\n",
      "Epoch 1, Meta Loss: 2.2824201583862305, Synthetic Data Grad Norm: 0.00033106261980719864\n",
      "Epoch 1, Meta Loss: 2.273451089859009, Synthetic Data Grad Norm: 0.00028995060711167753\n",
      "Epoch 1, Meta Loss: 2.2982535362243652, Synthetic Data Grad Norm: 0.00026825853274203837\n",
      "Epoch 1, Meta Loss: 2.2682719230651855, Synthetic Data Grad Norm: 0.0002959768462460488\n",
      "Epoch 1, Meta Loss: 2.288891077041626, Synthetic Data Grad Norm: 0.0003002629382535815\n",
      "Epoch 1, Meta Loss: 2.2952325344085693, Synthetic Data Grad Norm: 0.00022033297864254564\n",
      "Epoch 1, Meta Loss: 2.2897074222564697, Synthetic Data Grad Norm: 0.00026036298368126154\n",
      "Epoch 1, Meta Loss: 2.2847087383270264, Synthetic Data Grad Norm: 0.00024181639309972525\n",
      "Epoch 1, Meta Loss: 2.3035335540771484, Synthetic Data Grad Norm: 0.0004275657411199063\n",
      "Epoch 1, Meta Loss: 2.269763946533203, Synthetic Data Grad Norm: 0.0002486908342689276\n",
      "Epoch 1, Meta Loss: 2.305185079574585, Synthetic Data Grad Norm: 0.0004929093993268907\n",
      "Epoch 2, Meta Loss: 2.2834105491638184, Synthetic Data Grad Norm: 0.00036399628152139485\n",
      "Epoch 2, Meta Loss: 2.303241729736328, Synthetic Data Grad Norm: 0.0003289190644863993\n",
      "Epoch 2, Meta Loss: 2.2779829502105713, Synthetic Data Grad Norm: 0.0003127714153379202\n",
      "Epoch 2, Meta Loss: 2.294936418533325, Synthetic Data Grad Norm: 0.00030882316059432924\n",
      "Epoch 2, Meta Loss: 2.2754733562469482, Synthetic Data Grad Norm: 0.0002483855641912669\n",
      "Epoch 2, Meta Loss: 2.286808490753174, Synthetic Data Grad Norm: 0.0002234743587905541\n",
      "Epoch 2, Meta Loss: 2.2940754890441895, Synthetic Data Grad Norm: 0.00024374204804189503\n",
      "Epoch 2, Meta Loss: 2.273648738861084, Synthetic Data Grad Norm: 0.00030305824475362897\n",
      "Epoch 2, Meta Loss: 2.285867929458618, Synthetic Data Grad Norm: 0.0001961397792911157\n",
      "Epoch 2, Meta Loss: 2.2710628509521484, Synthetic Data Grad Norm: 0.00029592469218187034\n",
      "Epoch 2, Meta Loss: 2.287628412246704, Synthetic Data Grad Norm: 0.0002623578766360879\n",
      "Epoch 2, Meta Loss: 2.2802276611328125, Synthetic Data Grad Norm: 0.00030328563298098743\n",
      "Epoch 2, Meta Loss: 2.293591022491455, Synthetic Data Grad Norm: 0.00027874778606928885\n",
      "Epoch 2, Meta Loss: 2.2918150424957275, Synthetic Data Grad Norm: 0.00024354916240554303\n",
      "Epoch 2, Meta Loss: 2.2757818698883057, Synthetic Data Grad Norm: 0.0002713999419938773\n",
      "Epoch 2, Meta Loss: 2.2657418251037598, Synthetic Data Grad Norm: 0.0002636333811096847\n",
      "Epoch 2, Meta Loss: 2.318324327468872, Synthetic Data Grad Norm: 0.0003061413299292326\n",
      "Epoch 2, Meta Loss: 2.2859673500061035, Synthetic Data Grad Norm: 0.0002337261103093624\n",
      "Epoch 2, Meta Loss: 2.2819173336029053, Synthetic Data Grad Norm: 0.00023755583970341831\n",
      "Epoch 2, Meta Loss: 2.287116289138794, Synthetic Data Grad Norm: 0.00023621552099939436\n",
      "Epoch 2, Meta Loss: 2.281386613845825, Synthetic Data Grad Norm: 0.00023023980611469597\n",
      "Epoch 2, Meta Loss: 2.2890844345092773, Synthetic Data Grad Norm: 0.0003035471308976412\n",
      "Epoch 2, Meta Loss: 2.2765791416168213, Synthetic Data Grad Norm: 0.00024814638891257346\n",
      "Epoch 2, Meta Loss: 2.2847888469696045, Synthetic Data Grad Norm: 0.00026100222021341324\n",
      "Epoch 2, Meta Loss: 2.2776098251342773, Synthetic Data Grad Norm: 0.00031416985439136624\n",
      "Epoch 2, Meta Loss: 2.2911782264709473, Synthetic Data Grad Norm: 0.00023072297335602343\n",
      "Epoch 2, Meta Loss: 2.3025929927825928, Synthetic Data Grad Norm: 0.0003322205157019198\n",
      "Epoch 2, Meta Loss: 2.286864757537842, Synthetic Data Grad Norm: 0.00027848934405483305\n",
      "Epoch 2, Meta Loss: 2.2824294567108154, Synthetic Data Grad Norm: 0.0002658978628460318\n",
      "Epoch 2, Meta Loss: 2.264248847961426, Synthetic Data Grad Norm: 0.00025579615612514317\n",
      "Epoch 2, Meta Loss: 2.2948904037475586, Synthetic Data Grad Norm: 0.0002485759905539453\n",
      "Epoch 2, Meta Loss: 2.3090412616729736, Synthetic Data Grad Norm: 0.00025159228243865073\n",
      "Epoch 2, Meta Loss: 2.2882399559020996, Synthetic Data Grad Norm: 0.00020075977954547852\n",
      "Epoch 2, Meta Loss: 2.2863261699676514, Synthetic Data Grad Norm: 0.000287693488644436\n",
      "Epoch 2, Meta Loss: 2.274052143096924, Synthetic Data Grad Norm: 0.0004553853941615671\n",
      "Epoch 2, Meta Loss: 2.290046215057373, Synthetic Data Grad Norm: 0.0002991253277286887\n",
      "Epoch 2, Meta Loss: 2.3121018409729004, Synthetic Data Grad Norm: 0.0002862780529540032\n",
      "Epoch 2, Meta Loss: 2.2734382152557373, Synthetic Data Grad Norm: 0.00025705856387503445\n",
      "Epoch 2, Meta Loss: 2.2936015129089355, Synthetic Data Grad Norm: 0.00021349434973672032\n",
      "Epoch 2, Meta Loss: 2.284421682357788, Synthetic Data Grad Norm: 0.00021996235591359437\n",
      "Epoch 2, Meta Loss: 2.27872896194458, Synthetic Data Grad Norm: 0.00023069616872817278\n",
      "Epoch 2, Meta Loss: 2.2929046154022217, Synthetic Data Grad Norm: 0.00025506282690912485\n",
      "Epoch 2, Meta Loss: 2.280942440032959, Synthetic Data Grad Norm: 0.0002611241361591965\n",
      "Epoch 2, Meta Loss: 2.2965049743652344, Synthetic Data Grad Norm: 0.00029403867665678263\n",
      "Epoch 2, Meta Loss: 2.2978553771972656, Synthetic Data Grad Norm: 0.0003252853930462152\n",
      "Epoch 2, Meta Loss: 2.297065258026123, Synthetic Data Grad Norm: 0.0002528004115447402\n",
      "Epoch 2, Meta Loss: 2.293442726135254, Synthetic Data Grad Norm: 0.00023899301595520228\n",
      "Epoch 2, Meta Loss: 2.288332939147949, Synthetic Data Grad Norm: 0.0003650161961559206\n",
      "Epoch 2, Meta Loss: 2.2909138202667236, Synthetic Data Grad Norm: 0.0003513131814543158\n",
      "Epoch 2, Meta Loss: 2.288703680038452, Synthetic Data Grad Norm: 0.00038869291893206537\n",
      "Epoch 2, Meta Loss: 2.282766342163086, Synthetic Data Grad Norm: 0.0002525297168176621\n",
      "Epoch 2, Meta Loss: 2.2782154083251953, Synthetic Data Grad Norm: 0.00027234043227508664\n",
      "Epoch 2, Meta Loss: 2.2706174850463867, Synthetic Data Grad Norm: 0.00040901274769566953\n",
      "Epoch 2, Meta Loss: 2.29384708404541, Synthetic Data Grad Norm: 0.00023106874141376466\n",
      "Epoch 2, Meta Loss: 2.2870407104492188, Synthetic Data Grad Norm: 0.0003437420818954706\n",
      "Epoch 2, Meta Loss: 2.307671070098877, Synthetic Data Grad Norm: 0.00026614239322952926\n",
      "Epoch 2, Meta Loss: 2.291027545928955, Synthetic Data Grad Norm: 0.000254610029514879\n",
      "Epoch 2, Meta Loss: 2.2995095252990723, Synthetic Data Grad Norm: 0.00020233888062648475\n",
      "Epoch 2, Meta Loss: 2.281564712524414, Synthetic Data Grad Norm: 0.0004314799152780324\n",
      "Epoch 2, Meta Loss: 2.2774336338043213, Synthetic Data Grad Norm: 0.00025538503541611135\n",
      "Epoch 2, Meta Loss: 2.27923583984375, Synthetic Data Grad Norm: 0.0003152483550366014\n",
      "Epoch 2, Meta Loss: 2.2834293842315674, Synthetic Data Grad Norm: 0.0002759265771601349\n",
      "Epoch 2, Meta Loss: 2.2819013595581055, Synthetic Data Grad Norm: 0.0002793336461763829\n",
      "Epoch 2, Meta Loss: 2.280764579772949, Synthetic Data Grad Norm: 0.0003155156737193465\n",
      "Epoch 2, Meta Loss: 2.281341314315796, Synthetic Data Grad Norm: 0.000300497718853876\n",
      "Epoch 2, Meta Loss: 2.304133653640747, Synthetic Data Grad Norm: 0.00026430937577970326\n",
      "Epoch 2, Meta Loss: 2.292717695236206, Synthetic Data Grad Norm: 0.00023011893790680915\n",
      "Epoch 2, Meta Loss: 2.279109477996826, Synthetic Data Grad Norm: 0.0003145206719636917\n",
      "Epoch 2, Meta Loss: 2.2910540103912354, Synthetic Data Grad Norm: 0.0003133246791549027\n",
      "Epoch 2, Meta Loss: 2.287663459777832, Synthetic Data Grad Norm: 0.0002721303317230195\n",
      "Epoch 2, Meta Loss: 2.2810022830963135, Synthetic Data Grad Norm: 0.00029766306397505105\n",
      "Epoch 2, Meta Loss: 2.291267156600952, Synthetic Data Grad Norm: 0.0003167237155139446\n",
      "Epoch 2, Meta Loss: 2.2870898246765137, Synthetic Data Grad Norm: 0.0002525460149627179\n",
      "Epoch 2, Meta Loss: 2.295375347137451, Synthetic Data Grad Norm: 0.00022840904421173036\n",
      "Epoch 2, Meta Loss: 2.302687168121338, Synthetic Data Grad Norm: 0.00027425147709436715\n",
      "Epoch 2, Meta Loss: 2.275925874710083, Synthetic Data Grad Norm: 0.00038597077946178615\n",
      "Epoch 2, Meta Loss: 2.2652337551116943, Synthetic Data Grad Norm: 0.00033027230529114604\n",
      "Epoch 2, Meta Loss: 2.275798797607422, Synthetic Data Grad Norm: 0.00038548235897906125\n",
      "Epoch 2, Meta Loss: 2.28763747215271, Synthetic Data Grad Norm: 0.00028551570721901953\n",
      "Epoch 2, Meta Loss: 2.2687129974365234, Synthetic Data Grad Norm: 0.00022891152184456587\n",
      "Epoch 2, Meta Loss: 2.2875375747680664, Synthetic Data Grad Norm: 0.00022566392726730555\n",
      "Epoch 2, Meta Loss: 2.276848077774048, Synthetic Data Grad Norm: 0.00029390730196610093\n",
      "Epoch 2, Meta Loss: 2.284515857696533, Synthetic Data Grad Norm: 0.00023032726312521845\n",
      "Epoch 2, Meta Loss: 2.2635653018951416, Synthetic Data Grad Norm: 0.00041990302270278335\n",
      "Epoch 2, Meta Loss: 2.3055779933929443, Synthetic Data Grad Norm: 0.0002950141206383705\n",
      "Epoch 2, Meta Loss: 2.28871488571167, Synthetic Data Grad Norm: 0.00038240663707256317\n",
      "Epoch 2, Meta Loss: 2.3044416904449463, Synthetic Data Grad Norm: 0.00025222680415026844\n",
      "Epoch 2, Meta Loss: 2.2883081436157227, Synthetic Data Grad Norm: 0.000256586994510144\n",
      "Epoch 2, Meta Loss: 2.283043384552002, Synthetic Data Grad Norm: 0.00033204021747224033\n",
      "Epoch 2, Meta Loss: 2.27984356880188, Synthetic Data Grad Norm: 0.0002832785539794713\n",
      "Epoch 2, Meta Loss: 2.277614116668701, Synthetic Data Grad Norm: 0.0002585503680165857\n",
      "Epoch 2, Meta Loss: 2.2900028228759766, Synthetic Data Grad Norm: 0.00032418640330433846\n",
      "Epoch 2, Meta Loss: 2.289757251739502, Synthetic Data Grad Norm: 0.0002452365879435092\n",
      "Epoch 2, Meta Loss: 2.297389268875122, Synthetic Data Grad Norm: 0.0003236726042814553\n",
      "Epoch 2, Meta Loss: 2.2847890853881836, Synthetic Data Grad Norm: 0.0003094859712291509\n",
      "Epoch 2, Meta Loss: 2.30680775642395, Synthetic Data Grad Norm: 0.00035484458203427494\n",
      "Epoch 2, Meta Loss: 2.2835581302642822, Synthetic Data Grad Norm: 0.0002537542604841292\n",
      "Epoch 2, Meta Loss: 2.273216962814331, Synthetic Data Grad Norm: 0.00023837262415327132\n",
      "Epoch 2, Meta Loss: 2.2898240089416504, Synthetic Data Grad Norm: 0.00024550847592763603\n",
      "Epoch 2, Meta Loss: 2.2834482192993164, Synthetic Data Grad Norm: 0.00031690162722952664\n",
      "Epoch 2, Meta Loss: 2.2732205390930176, Synthetic Data Grad Norm: 0.0002874442143365741\n",
      "Epoch 2, Meta Loss: 2.2946131229400635, Synthetic Data Grad Norm: 0.00024689026759006083\n",
      "Epoch 2, Meta Loss: 2.27610182762146, Synthetic Data Grad Norm: 0.0002612837415654212\n",
      "Epoch 2, Meta Loss: 2.2675352096557617, Synthetic Data Grad Norm: 0.000451319181593135\n",
      "Epoch 2, Meta Loss: 2.26523756980896, Synthetic Data Grad Norm: 0.00030619491008110344\n",
      "Epoch 2, Meta Loss: 2.2944962978363037, Synthetic Data Grad Norm: 0.0002479413233231753\n",
      "Epoch 2, Meta Loss: 2.284311294555664, Synthetic Data Grad Norm: 0.00022674586216453463\n",
      "Epoch 2, Meta Loss: 2.2865376472473145, Synthetic Data Grad Norm: 0.000319826474878937\n",
      "Epoch 2, Meta Loss: 2.2754995822906494, Synthetic Data Grad Norm: 0.00040054554119706154\n",
      "Epoch 2, Meta Loss: 2.271408796310425, Synthetic Data Grad Norm: 0.00026354461442679167\n",
      "Epoch 2, Meta Loss: 2.298497438430786, Synthetic Data Grad Norm: 0.0003198365157004446\n",
      "Epoch 2, Meta Loss: 2.2805185317993164, Synthetic Data Grad Norm: 0.00032964316778816283\n",
      "Epoch 2, Meta Loss: 2.2892863750457764, Synthetic Data Grad Norm: 0.0003624922246672213\n",
      "Epoch 2, Meta Loss: 2.2739779949188232, Synthetic Data Grad Norm: 0.0003090573300141841\n",
      "Epoch 2, Meta Loss: 2.2933669090270996, Synthetic Data Grad Norm: 0.00025862158508971334\n",
      "Epoch 2, Meta Loss: 2.276416301727295, Synthetic Data Grad Norm: 0.00026743573835119605\n",
      "Epoch 2, Meta Loss: 2.3023734092712402, Synthetic Data Grad Norm: 0.0002262735943077132\n",
      "Epoch 2, Meta Loss: 2.294499397277832, Synthetic Data Grad Norm: 0.0002547394542489201\n",
      "Epoch 2, Meta Loss: 2.276561975479126, Synthetic Data Grad Norm: 0.0003560339391697198\n",
      "Epoch 2, Meta Loss: 2.2825870513916016, Synthetic Data Grad Norm: 0.00024000348639674485\n",
      "Epoch 2, Meta Loss: 2.28586483001709, Synthetic Data Grad Norm: 0.00027943539316765964\n",
      "Epoch 2, Meta Loss: 2.2854554653167725, Synthetic Data Grad Norm: 0.00033261740463785827\n",
      "Epoch 2, Meta Loss: 2.2817423343658447, Synthetic Data Grad Norm: 0.00022355392866302282\n",
      "Epoch 2, Meta Loss: 2.2935914993286133, Synthetic Data Grad Norm: 0.0003053310210816562\n",
      "Epoch 2, Meta Loss: 2.2820489406585693, Synthetic Data Grad Norm: 0.00026493603945709765\n",
      "Epoch 2, Meta Loss: 2.271876335144043, Synthetic Data Grad Norm: 0.00030881690327078104\n",
      "Epoch 2, Meta Loss: 2.3017473220825195, Synthetic Data Grad Norm: 0.0003111827536486089\n",
      "Epoch 2, Meta Loss: 2.284588575363159, Synthetic Data Grad Norm: 0.0002945800661109388\n",
      "Epoch 2, Meta Loss: 2.2882261276245117, Synthetic Data Grad Norm: 0.0002523822768125683\n",
      "Epoch 2, Meta Loss: 2.2639713287353516, Synthetic Data Grad Norm: 0.0004285442701075226\n",
      "Epoch 2, Meta Loss: 2.2871267795562744, Synthetic Data Grad Norm: 0.0003804584557656199\n",
      "Epoch 2, Meta Loss: 2.287740468978882, Synthetic Data Grad Norm: 0.0002704376820474863\n",
      "Epoch 2, Meta Loss: 2.2784805297851562, Synthetic Data Grad Norm: 0.0003007697523571551\n",
      "Epoch 2, Meta Loss: 2.2936038970947266, Synthetic Data Grad Norm: 0.00026326230727136135\n",
      "Epoch 2, Meta Loss: 2.2749886512756348, Synthetic Data Grad Norm: 0.0002847574942279607\n",
      "Epoch 2, Meta Loss: 2.306323528289795, Synthetic Data Grad Norm: 0.0003260636585764587\n",
      "Epoch 2, Meta Loss: 2.2725069522857666, Synthetic Data Grad Norm: 0.0002523584116715938\n",
      "Epoch 2, Meta Loss: 2.2923848628997803, Synthetic Data Grad Norm: 0.00031680436222814023\n",
      "Epoch 2, Meta Loss: 2.2786645889282227, Synthetic Data Grad Norm: 0.00023551331833004951\n",
      "Epoch 2, Meta Loss: 2.2825024127960205, Synthetic Data Grad Norm: 0.0002923358988482505\n",
      "Epoch 2, Meta Loss: 2.2893903255462646, Synthetic Data Grad Norm: 0.0003264739934820682\n",
      "Epoch 2, Meta Loss: 2.2537221908569336, Synthetic Data Grad Norm: 0.00034322860301472247\n",
      "Epoch 2, Meta Loss: 2.2753500938415527, Synthetic Data Grad Norm: 0.0003256979107391089\n",
      "Epoch 2, Meta Loss: 2.28823184967041, Synthetic Data Grad Norm: 0.00022878902382217348\n",
      "Epoch 2, Meta Loss: 2.2904181480407715, Synthetic Data Grad Norm: 0.0002376783813815564\n",
      "Epoch 2, Meta Loss: 2.292616367340088, Synthetic Data Grad Norm: 0.0002647767250891775\n",
      "Epoch 2, Meta Loss: 2.3030078411102295, Synthetic Data Grad Norm: 0.00026177195832133293\n",
      "Epoch 2, Meta Loss: 2.2832419872283936, Synthetic Data Grad Norm: 0.0003042120370082557\n",
      "Epoch 2, Meta Loss: 2.307976007461548, Synthetic Data Grad Norm: 0.00024891988141462207\n",
      "Epoch 2, Meta Loss: 2.292222261428833, Synthetic Data Grad Norm: 0.0002818848588503897\n",
      "Epoch 2, Meta Loss: 2.2954394817352295, Synthetic Data Grad Norm: 0.00017836403276305646\n",
      "Epoch 2, Meta Loss: 2.3000378608703613, Synthetic Data Grad Norm: 0.0002779129717964679\n",
      "Epoch 2, Meta Loss: 2.298814058303833, Synthetic Data Grad Norm: 0.00028248722082935274\n",
      "Epoch 2, Meta Loss: 2.294015407562256, Synthetic Data Grad Norm: 0.00030603224877268076\n",
      "Epoch 2, Meta Loss: 2.29018235206604, Synthetic Data Grad Norm: 0.00027968749054707587\n",
      "Epoch 2, Meta Loss: 2.290778160095215, Synthetic Data Grad Norm: 0.0002290272241225466\n",
      "Epoch 2, Meta Loss: 2.2881226539611816, Synthetic Data Grad Norm: 0.0003309354360681027\n",
      "Epoch 2, Meta Loss: 2.2848775386810303, Synthetic Data Grad Norm: 0.00023867853451520205\n",
      "Epoch 2, Meta Loss: 2.2898848056793213, Synthetic Data Grad Norm: 0.00030764276743866503\n",
      "Epoch 2, Meta Loss: 2.2876808643341064, Synthetic Data Grad Norm: 0.00021445586753543466\n",
      "Epoch 2, Meta Loss: 2.2956581115722656, Synthetic Data Grad Norm: 0.00021867947361897677\n",
      "Epoch 2, Meta Loss: 2.293267250061035, Synthetic Data Grad Norm: 0.0003171625721734017\n",
      "Epoch 2, Meta Loss: 2.2878401279449463, Synthetic Data Grad Norm: 0.0002596414415165782\n",
      "Epoch 2, Meta Loss: 2.272627115249634, Synthetic Data Grad Norm: 0.0003699955123011023\n",
      "Epoch 2, Meta Loss: 2.301781415939331, Synthetic Data Grad Norm: 0.0002619301958475262\n",
      "Epoch 2, Meta Loss: 2.30424165725708, Synthetic Data Grad Norm: 0.00021476417896337807\n",
      "Epoch 2, Meta Loss: 2.279498815536499, Synthetic Data Grad Norm: 0.00028352279332466424\n",
      "Epoch 2, Meta Loss: 2.295236349105835, Synthetic Data Grad Norm: 0.00028682374977506697\n",
      "Epoch 2, Meta Loss: 2.2864177227020264, Synthetic Data Grad Norm: 0.00034869727096520364\n",
      "Epoch 2, Meta Loss: 2.303189516067505, Synthetic Data Grad Norm: 0.00027460616547614336\n",
      "Epoch 2, Meta Loss: 2.286642551422119, Synthetic Data Grad Norm: 0.00028758717235177755\n",
      "Epoch 2, Meta Loss: 2.2968437671661377, Synthetic Data Grad Norm: 0.00021767189900856465\n",
      "Epoch 2, Meta Loss: 2.2870094776153564, Synthetic Data Grad Norm: 0.0003415253886487335\n",
      "Epoch 2, Meta Loss: 2.2941248416900635, Synthetic Data Grad Norm: 0.00029561223345808685\n",
      "Epoch 2, Meta Loss: 2.2818920612335205, Synthetic Data Grad Norm: 0.0003321330004837364\n",
      "Epoch 2, Meta Loss: 2.2943437099456787, Synthetic Data Grad Norm: 0.00025112112052738667\n",
      "Epoch 2, Meta Loss: 2.2859599590301514, Synthetic Data Grad Norm: 0.0003189917479176074\n",
      "Epoch 2, Meta Loss: 2.2942426204681396, Synthetic Data Grad Norm: 0.00028641673270612955\n",
      "Epoch 2, Meta Loss: 2.287292718887329, Synthetic Data Grad Norm: 0.00020955373474862427\n",
      "Epoch 2, Meta Loss: 2.291522264480591, Synthetic Data Grad Norm: 0.00022308937332127243\n",
      "Epoch 2, Meta Loss: 2.267937183380127, Synthetic Data Grad Norm: 0.0003198720223736018\n",
      "Epoch 2, Meta Loss: 2.2699625492095947, Synthetic Data Grad Norm: 0.0003247890272177756\n",
      "Epoch 2, Meta Loss: 2.286977767944336, Synthetic Data Grad Norm: 0.00027251470601186156\n",
      "Epoch 2, Meta Loss: 2.2882819175720215, Synthetic Data Grad Norm: 0.0003282184188719839\n",
      "Epoch 2, Meta Loss: 2.2928168773651123, Synthetic Data Grad Norm: 0.0002975120733026415\n",
      "Epoch 2, Meta Loss: 2.2923824787139893, Synthetic Data Grad Norm: 0.0003997106687165797\n",
      "Epoch 2, Meta Loss: 2.282064199447632, Synthetic Data Grad Norm: 0.00027728971326723695\n",
      "Epoch 2, Meta Loss: 2.271388530731201, Synthetic Data Grad Norm: 0.0003592809080146253\n",
      "Epoch 2, Meta Loss: 2.281157970428467, Synthetic Data Grad Norm: 0.0002599499130155891\n",
      "Epoch 2, Meta Loss: 2.2870256900787354, Synthetic Data Grad Norm: 0.0003119802277069539\n",
      "Epoch 2, Meta Loss: 2.2956290245056152, Synthetic Data Grad Norm: 0.00031443338957615197\n",
      "Epoch 2, Meta Loss: 2.301215648651123, Synthetic Data Grad Norm: 0.0002519035479053855\n",
      "Epoch 2, Meta Loss: 2.282618999481201, Synthetic Data Grad Norm: 0.0002994044916704297\n",
      "Epoch 2, Meta Loss: 2.274665355682373, Synthetic Data Grad Norm: 0.0002750854764599353\n",
      "Epoch 2, Meta Loss: 2.274928569793701, Synthetic Data Grad Norm: 0.00025973221636377275\n",
      "Epoch 2, Meta Loss: 2.26666259765625, Synthetic Data Grad Norm: 0.0002775777247734368\n",
      "Epoch 2, Meta Loss: 2.2757081985473633, Synthetic Data Grad Norm: 0.00033349671866744757\n",
      "Epoch 2, Meta Loss: 2.2949411869049072, Synthetic Data Grad Norm: 0.00028142379596829414\n",
      "Epoch 2, Meta Loss: 2.2811737060546875, Synthetic Data Grad Norm: 0.0003207260451745242\n",
      "Epoch 2, Meta Loss: 2.284792423248291, Synthetic Data Grad Norm: 0.00020937826775480062\n",
      "Epoch 2, Meta Loss: 2.293895721435547, Synthetic Data Grad Norm: 0.00030092793167568743\n",
      "Epoch 2, Meta Loss: 2.2739810943603516, Synthetic Data Grad Norm: 0.000285235553747043\n",
      "Epoch 2, Meta Loss: 2.300299882888794, Synthetic Data Grad Norm: 0.0003330653125885874\n",
      "Epoch 2, Meta Loss: 2.3010263442993164, Synthetic Data Grad Norm: 0.00022001257457304746\n",
      "Epoch 2, Meta Loss: 2.280917167663574, Synthetic Data Grad Norm: 0.0002475788933224976\n",
      "Epoch 2, Meta Loss: 2.28281307220459, Synthetic Data Grad Norm: 0.00036706190439872444\n",
      "Epoch 2, Meta Loss: 2.2863078117370605, Synthetic Data Grad Norm: 0.00020599905110429972\n",
      "Epoch 2, Meta Loss: 2.277416944503784, Synthetic Data Grad Norm: 0.00038892257725819945\n",
      "Epoch 2, Meta Loss: 2.2723817825317383, Synthetic Data Grad Norm: 0.0002419874508632347\n",
      "Epoch 2, Meta Loss: 2.2833971977233887, Synthetic Data Grad Norm: 0.00024880870478227735\n",
      "Epoch 2, Meta Loss: 2.3022022247314453, Synthetic Data Grad Norm: 0.00024517838028259575\n",
      "Epoch 2, Meta Loss: 2.298442840576172, Synthetic Data Grad Norm: 0.00023734717979095876\n",
      "Epoch 2, Meta Loss: 2.2911438941955566, Synthetic Data Grad Norm: 0.0002483852731529623\n",
      "Epoch 2, Meta Loss: 2.2866525650024414, Synthetic Data Grad Norm: 0.0002779671340249479\n",
      "Epoch 2, Meta Loss: 2.3079798221588135, Synthetic Data Grad Norm: 0.0002216981229139492\n",
      "Epoch 2, Meta Loss: 2.280702590942383, Synthetic Data Grad Norm: 0.00022260840341914445\n",
      "Epoch 2, Meta Loss: 2.309302806854248, Synthetic Data Grad Norm: 0.00023694991250522435\n",
      "Epoch 2, Meta Loss: 2.3020026683807373, Synthetic Data Grad Norm: 0.00020773075812030584\n",
      "Epoch 2, Meta Loss: 2.294823408126831, Synthetic Data Grad Norm: 0.00020333152497187257\n",
      "Epoch 2, Meta Loss: 2.282364845275879, Synthetic Data Grad Norm: 0.00023820683418307453\n",
      "Epoch 2, Meta Loss: 2.289119243621826, Synthetic Data Grad Norm: 0.00025650530005805194\n",
      "Epoch 2, Meta Loss: 2.2622971534729004, Synthetic Data Grad Norm: 0.0003379049594514072\n",
      "Epoch 2, Meta Loss: 2.2782511711120605, Synthetic Data Grad Norm: 0.00030268687987700105\n",
      "Epoch 2, Meta Loss: 2.264723539352417, Synthetic Data Grad Norm: 0.0003729477757588029\n",
      "Epoch 2, Meta Loss: 2.3051235675811768, Synthetic Data Grad Norm: 0.00027329655131325126\n",
      "Epoch 2, Meta Loss: 2.2716867923736572, Synthetic Data Grad Norm: 0.00033673059078864753\n",
      "Epoch 2, Meta Loss: 2.2726540565490723, Synthetic Data Grad Norm: 0.00033075406099669635\n",
      "Epoch 2, Meta Loss: 2.270425319671631, Synthetic Data Grad Norm: 0.00032618470140732825\n",
      "Epoch 2, Meta Loss: 2.291473388671875, Synthetic Data Grad Norm: 0.0003901058516930789\n",
      "Epoch 2, Meta Loss: 2.299771785736084, Synthetic Data Grad Norm: 0.0002506938762962818\n",
      "Epoch 2, Meta Loss: 2.3012382984161377, Synthetic Data Grad Norm: 0.0002947032917290926\n",
      "Epoch 2, Meta Loss: 2.2812001705169678, Synthetic Data Grad Norm: 0.00029981008265167475\n",
      "Epoch 2, Meta Loss: 2.324089527130127, Synthetic Data Grad Norm: 0.00031250269967131317\n",
      "Epoch 2, Meta Loss: 2.2762460708618164, Synthetic Data Grad Norm: 0.0002684059436433017\n",
      "Epoch 2, Meta Loss: 2.2910799980163574, Synthetic Data Grad Norm: 0.00022352043015416712\n",
      "Epoch 2, Meta Loss: 2.2843263149261475, Synthetic Data Grad Norm: 0.0001716114056762308\n",
      "Epoch 2, Meta Loss: 2.3031303882598877, Synthetic Data Grad Norm: 0.00025078089674934745\n",
      "Epoch 2, Meta Loss: 2.2729063034057617, Synthetic Data Grad Norm: 0.0003871715744026005\n",
      "Epoch 2, Meta Loss: 2.2887027263641357, Synthetic Data Grad Norm: 0.0003592727007344365\n",
      "Epoch 2, Meta Loss: 2.287796974182129, Synthetic Data Grad Norm: 0.0003028517821803689\n",
      "Epoch 2, Meta Loss: 2.2874555587768555, Synthetic Data Grad Norm: 0.0003107793745584786\n",
      "Epoch 2, Meta Loss: 2.2910943031311035, Synthetic Data Grad Norm: 0.00030790618620812893\n",
      "Epoch 2, Meta Loss: 2.28477144241333, Synthetic Data Grad Norm: 0.00018653053848538548\n",
      "Epoch 2, Meta Loss: 2.2687041759490967, Synthetic Data Grad Norm: 0.0002778724883683026\n",
      "Epoch 2, Meta Loss: 2.2733564376831055, Synthetic Data Grad Norm: 0.00020138519175816327\n",
      "Epoch 2, Meta Loss: 2.2775845527648926, Synthetic Data Grad Norm: 0.0002461509720887989\n",
      "Epoch 2, Meta Loss: 2.298011541366577, Synthetic Data Grad Norm: 0.00025149385328404605\n",
      "Epoch 2, Meta Loss: 2.2658979892730713, Synthetic Data Grad Norm: 0.00032185399322770536\n",
      "Epoch 2, Meta Loss: 2.292332172393799, Synthetic Data Grad Norm: 0.0003307838342152536\n",
      "Epoch 2, Meta Loss: 2.283376693725586, Synthetic Data Grad Norm: 0.00026894017355516553\n",
      "Epoch 2, Meta Loss: 2.308380365371704, Synthetic Data Grad Norm: 0.0003416326944716275\n",
      "Epoch 2, Meta Loss: 2.284945249557495, Synthetic Data Grad Norm: 0.00022679675021208823\n",
      "Epoch 2, Meta Loss: 2.270442485809326, Synthetic Data Grad Norm: 0.00034441909519955516\n",
      "Epoch 2, Meta Loss: 2.3093011379241943, Synthetic Data Grad Norm: 0.0002089639165205881\n",
      "Epoch 2, Meta Loss: 2.276212692260742, Synthetic Data Grad Norm: 0.0002514054358471185\n",
      "Epoch 2, Meta Loss: 2.283224105834961, Synthetic Data Grad Norm: 0.000416343827964738\n",
      "Epoch 2, Meta Loss: 2.305330276489258, Synthetic Data Grad Norm: 0.00022171737509779632\n",
      "Epoch 2, Meta Loss: 2.2844042778015137, Synthetic Data Grad Norm: 0.0002582989982329309\n",
      "Epoch 2, Meta Loss: 2.2992072105407715, Synthetic Data Grad Norm: 0.0002760357747320086\n",
      "Epoch 2, Meta Loss: 2.2687602043151855, Synthetic Data Grad Norm: 0.00028988945996388793\n",
      "Epoch 2, Meta Loss: 2.2888214588165283, Synthetic Data Grad Norm: 0.0002874878409784287\n",
      "Epoch 2, Meta Loss: 2.2879526615142822, Synthetic Data Grad Norm: 0.00023822070215828717\n",
      "Epoch 2, Meta Loss: 2.268822193145752, Synthetic Data Grad Norm: 0.0003332723572384566\n",
      "Epoch 2, Meta Loss: 2.2780308723449707, Synthetic Data Grad Norm: 0.0002453902270644903\n",
      "Epoch 2, Meta Loss: 2.303354024887085, Synthetic Data Grad Norm: 0.0006151516572572291\n",
      "Epoch 2, Meta Loss: 2.2748961448669434, Synthetic Data Grad Norm: 0.00021682766964659095\n",
      "Epoch 2, Meta Loss: 2.273869037628174, Synthetic Data Grad Norm: 0.0002930652117356658\n",
      "Epoch 2, Meta Loss: 2.2683351039886475, Synthetic Data Grad Norm: 0.00028557557379826903\n",
      "Epoch 2, Meta Loss: 2.2557666301727295, Synthetic Data Grad Norm: 0.0003747324808500707\n",
      "Epoch 2, Meta Loss: 2.27412748336792, Synthetic Data Grad Norm: 0.0003507769724819809\n",
      "Epoch 2, Meta Loss: 2.2986667156219482, Synthetic Data Grad Norm: 0.00024151810794137418\n",
      "Epoch 2, Meta Loss: 2.2942323684692383, Synthetic Data Grad Norm: 0.00015861069550737739\n",
      "Epoch 2, Meta Loss: 2.290013313293457, Synthetic Data Grad Norm: 0.00033373304177075624\n",
      "Epoch 2, Meta Loss: 2.283987283706665, Synthetic Data Grad Norm: 0.00022394940606318414\n",
      "Epoch 2, Meta Loss: 2.2950665950775146, Synthetic Data Grad Norm: 0.00035921874223276973\n",
      "Epoch 2, Meta Loss: 2.289384126663208, Synthetic Data Grad Norm: 0.0003026122285518795\n",
      "Epoch 2, Meta Loss: 2.29575252532959, Synthetic Data Grad Norm: 0.0003249939763918519\n",
      "Epoch 2, Meta Loss: 2.2908358573913574, Synthetic Data Grad Norm: 0.00025593300233595073\n",
      "Epoch 2, Meta Loss: 2.287827968597412, Synthetic Data Grad Norm: 0.00035346572985872626\n",
      "Epoch 2, Meta Loss: 2.292239189147949, Synthetic Data Grad Norm: 0.0003213330637663603\n",
      "Epoch 2, Meta Loss: 2.3010153770446777, Synthetic Data Grad Norm: 0.000285935791907832\n",
      "Epoch 2, Meta Loss: 2.277951240539551, Synthetic Data Grad Norm: 0.0002699017059057951\n",
      "Epoch 2, Meta Loss: 2.291114330291748, Synthetic Data Grad Norm: 0.0002694303693715483\n",
      "Epoch 2, Meta Loss: 2.3206751346588135, Synthetic Data Grad Norm: 0.00031579911592416465\n",
      "Epoch 2, Meta Loss: 2.2880256175994873, Synthetic Data Grad Norm: 0.0002786594268400222\n",
      "Epoch 2, Meta Loss: 2.2772533893585205, Synthetic Data Grad Norm: 0.00026377648464404047\n",
      "Epoch 2, Meta Loss: 2.2964746952056885, Synthetic Data Grad Norm: 0.0003743038687389344\n",
      "Epoch 2, Meta Loss: 2.3214304447174072, Synthetic Data Grad Norm: 0.00020698537991847843\n",
      "Epoch 2, Meta Loss: 2.2768638134002686, Synthetic Data Grad Norm: 0.00027372196200303733\n",
      "Epoch 2, Meta Loss: 2.2825260162353516, Synthetic Data Grad Norm: 0.00033694616286084056\n",
      "Epoch 2, Meta Loss: 2.299630641937256, Synthetic Data Grad Norm: 0.0002877815277315676\n",
      "Epoch 2, Meta Loss: 2.277052164077759, Synthetic Data Grad Norm: 0.0002258105087094009\n",
      "Epoch 2, Meta Loss: 2.295689105987549, Synthetic Data Grad Norm: 0.0002658354351297021\n",
      "Epoch 2, Meta Loss: 2.286905527114868, Synthetic Data Grad Norm: 0.0002834891784004867\n",
      "Epoch 2, Meta Loss: 2.296191692352295, Synthetic Data Grad Norm: 0.0003265871200710535\n",
      "Epoch 2, Meta Loss: 2.2697205543518066, Synthetic Data Grad Norm: 0.0003410049539525062\n",
      "Epoch 2, Meta Loss: 2.290600538253784, Synthetic Data Grad Norm: 0.0002902926062233746\n",
      "Epoch 2, Meta Loss: 2.287677049636841, Synthetic Data Grad Norm: 0.00026790605625137687\n",
      "Epoch 2, Meta Loss: 2.269012689590454, Synthetic Data Grad Norm: 0.0002745679812505841\n",
      "Epoch 2, Meta Loss: 2.284379005432129, Synthetic Data Grad Norm: 0.00030618233722634614\n",
      "Epoch 2, Meta Loss: 2.29695463180542, Synthetic Data Grad Norm: 0.00027061294531449676\n",
      "Epoch 2, Meta Loss: 2.2814857959747314, Synthetic Data Grad Norm: 0.000247916323132813\n",
      "Epoch 2, Meta Loss: 2.2738759517669678, Synthetic Data Grad Norm: 0.00030180829344317317\n",
      "Epoch 2, Meta Loss: 2.2682623863220215, Synthetic Data Grad Norm: 0.0003447631897870451\n",
      "Epoch 2, Meta Loss: 2.2777061462402344, Synthetic Data Grad Norm: 0.00028099166229367256\n",
      "Epoch 2, Meta Loss: 2.286572217941284, Synthetic Data Grad Norm: 0.0002924217260442674\n",
      "Epoch 2, Meta Loss: 2.2796432971954346, Synthetic Data Grad Norm: 0.0003720078384503722\n",
      "Epoch 2, Meta Loss: 2.2893543243408203, Synthetic Data Grad Norm: 0.00038099795347079635\n",
      "Epoch 2, Meta Loss: 2.2857213020324707, Synthetic Data Grad Norm: 0.00026759624597616494\n",
      "Epoch 2, Meta Loss: 2.263746500015259, Synthetic Data Grad Norm: 0.00034395602415315807\n",
      "Epoch 2, Meta Loss: 2.259937047958374, Synthetic Data Grad Norm: 0.0003165723755955696\n",
      "Epoch 2, Meta Loss: 2.309734582901001, Synthetic Data Grad Norm: 0.00041357733425684273\n",
      "Epoch 2, Meta Loss: 2.287853240966797, Synthetic Data Grad Norm: 0.0002455963403917849\n",
      "Epoch 2, Meta Loss: 2.2808918952941895, Synthetic Data Grad Norm: 0.0002750502317212522\n",
      "Epoch 2, Meta Loss: 2.2873241901397705, Synthetic Data Grad Norm: 0.00037263918784447014\n",
      "Epoch 2, Meta Loss: 2.2748663425445557, Synthetic Data Grad Norm: 0.00027012231294065714\n",
      "Epoch 2, Meta Loss: 2.3000097274780273, Synthetic Data Grad Norm: 0.00030551315285265446\n",
      "Epoch 2, Meta Loss: 2.308760166168213, Synthetic Data Grad Norm: 0.00028281693812459707\n",
      "Epoch 2, Meta Loss: 2.2763521671295166, Synthetic Data Grad Norm: 0.00030891396454535425\n",
      "Epoch 2, Meta Loss: 2.2997140884399414, Synthetic Data Grad Norm: 0.00025752082001417875\n",
      "Epoch 2, Meta Loss: 2.2771451473236084, Synthetic Data Grad Norm: 0.0002836284984368831\n",
      "Epoch 2, Meta Loss: 2.2927708625793457, Synthetic Data Grad Norm: 0.00037383841117843986\n",
      "Epoch 2, Meta Loss: 2.2711408138275146, Synthetic Data Grad Norm: 0.00022409114171750844\n",
      "Epoch 2, Meta Loss: 2.308199405670166, Synthetic Data Grad Norm: 0.00027725831023417413\n",
      "Epoch 2, Meta Loss: 2.2707629203796387, Synthetic Data Grad Norm: 0.0003195886965841055\n",
      "Epoch 2, Meta Loss: 2.303067207336426, Synthetic Data Grad Norm: 0.00031959329498931766\n",
      "Epoch 2, Meta Loss: 2.3085055351257324, Synthetic Data Grad Norm: 0.00019342510495334864\n",
      "Epoch 2, Meta Loss: 2.2934792041778564, Synthetic Data Grad Norm: 0.00037885535857640207\n",
      "Epoch 2, Meta Loss: 2.2879369258880615, Synthetic Data Grad Norm: 0.00020690834207925946\n",
      "Epoch 2, Meta Loss: 2.2951931953430176, Synthetic Data Grad Norm: 0.0002606004709377885\n",
      "Epoch 2, Meta Loss: 2.2851991653442383, Synthetic Data Grad Norm: 0.000210096244700253\n",
      "Epoch 2, Meta Loss: 2.277967929840088, Synthetic Data Grad Norm: 0.000246702809818089\n",
      "Epoch 2, Meta Loss: 2.2889163494110107, Synthetic Data Grad Norm: 0.0002685676736291498\n",
      "Epoch 2, Meta Loss: 2.2783758640289307, Synthetic Data Grad Norm: 0.00032295999699272215\n",
      "Epoch 2, Meta Loss: 2.261702537536621, Synthetic Data Grad Norm: 0.00038091864553280175\n",
      "Epoch 2, Meta Loss: 2.2862918376922607, Synthetic Data Grad Norm: 0.00035241033765487373\n",
      "Epoch 2, Meta Loss: 2.2932116985321045, Synthetic Data Grad Norm: 0.00023104982392396778\n",
      "Epoch 2, Meta Loss: 2.2734880447387695, Synthetic Data Grad Norm: 0.00025535174063406885\n",
      "Epoch 2, Meta Loss: 2.3024091720581055, Synthetic Data Grad Norm: 0.0003618630871642381\n",
      "Epoch 2, Meta Loss: 2.2879087924957275, Synthetic Data Grad Norm: 0.0002759938361123204\n",
      "Epoch 2, Meta Loss: 2.2949447631835938, Synthetic Data Grad Norm: 0.00018551839457359165\n",
      "Epoch 2, Meta Loss: 2.297260046005249, Synthetic Data Grad Norm: 0.00029591473867185414\n",
      "Epoch 2, Meta Loss: 2.296539068222046, Synthetic Data Grad Norm: 0.00029956753132864833\n",
      "Epoch 2, Meta Loss: 2.31044864654541, Synthetic Data Grad Norm: 0.000237641143030487\n",
      "Epoch 2, Meta Loss: 2.2925477027893066, Synthetic Data Grad Norm: 0.0002681393234524876\n",
      "Epoch 2, Meta Loss: 2.2571682929992676, Synthetic Data Grad Norm: 0.0004127655120100826\n",
      "Epoch 2, Meta Loss: 2.301091432571411, Synthetic Data Grad Norm: 0.0002839714870788157\n",
      "Epoch 2, Meta Loss: 2.285956859588623, Synthetic Data Grad Norm: 0.0002477913803886622\n",
      "Epoch 2, Meta Loss: 2.3151373863220215, Synthetic Data Grad Norm: 0.00032944983104243875\n",
      "Epoch 2, Meta Loss: 2.2862300872802734, Synthetic Data Grad Norm: 0.0002982428704854101\n",
      "Epoch 2, Meta Loss: 2.2898049354553223, Synthetic Data Grad Norm: 0.0003177344042342156\n",
      "Epoch 2, Meta Loss: 2.2944300174713135, Synthetic Data Grad Norm: 0.00031206110725179315\n",
      "Epoch 2, Meta Loss: 2.2765684127807617, Synthetic Data Grad Norm: 0.00033683699439279735\n",
      "Epoch 2, Meta Loss: 2.289867401123047, Synthetic Data Grad Norm: 0.00029644794994965196\n",
      "Epoch 2, Meta Loss: 2.2988529205322266, Synthetic Data Grad Norm: 0.00017855736950878054\n",
      "Epoch 2, Meta Loss: 2.2859699726104736, Synthetic Data Grad Norm: 0.0002723120560403913\n",
      "Epoch 2, Meta Loss: 2.286116361618042, Synthetic Data Grad Norm: 0.0002302255597896874\n",
      "Epoch 2, Meta Loss: 2.295346736907959, Synthetic Data Grad Norm: 0.00017589823983144015\n",
      "Epoch 2, Meta Loss: 2.3034939765930176, Synthetic Data Grad Norm: 0.00029503327095881104\n",
      "Epoch 2, Meta Loss: 2.285400867462158, Synthetic Data Grad Norm: 0.0002160699077649042\n",
      "Epoch 2, Meta Loss: 2.284062623977661, Synthetic Data Grad Norm: 0.00025655675563029945\n",
      "Epoch 2, Meta Loss: 2.2804760932922363, Synthetic Data Grad Norm: 0.00035326569923199713\n",
      "Epoch 2, Meta Loss: 2.2709076404571533, Synthetic Data Grad Norm: 0.00033797460491769016\n",
      "Epoch 2, Meta Loss: 2.293544292449951, Synthetic Data Grad Norm: 0.0002008634910453111\n",
      "Epoch 2, Meta Loss: 2.2946832180023193, Synthetic Data Grad Norm: 0.00019156868802383542\n",
      "Epoch 2, Meta Loss: 2.2818539142608643, Synthetic Data Grad Norm: 0.00023378351761493832\n",
      "Epoch 2, Meta Loss: 2.2910757064819336, Synthetic Data Grad Norm: 0.00024492942611686885\n",
      "Epoch 2, Meta Loss: 2.2759876251220703, Synthetic Data Grad Norm: 0.0002699019678402692\n",
      "Epoch 2, Meta Loss: 2.283050298690796, Synthetic Data Grad Norm: 0.0002783379459287971\n",
      "Epoch 2, Meta Loss: 2.283740282058716, Synthetic Data Grad Norm: 0.00038522016257047653\n",
      "Epoch 2, Meta Loss: 2.2765085697174072, Synthetic Data Grad Norm: 0.000250343611696735\n",
      "Epoch 2, Meta Loss: 2.273353099822998, Synthetic Data Grad Norm: 0.00038278885767795146\n",
      "Epoch 2, Meta Loss: 2.2844982147216797, Synthetic Data Grad Norm: 0.0003535197756718844\n",
      "Epoch 2, Meta Loss: 2.283696413040161, Synthetic Data Grad Norm: 0.0002969046763610095\n",
      "Epoch 2, Meta Loss: 2.2814676761627197, Synthetic Data Grad Norm: 0.0003056539862882346\n",
      "Epoch 2, Meta Loss: 2.2755730152130127, Synthetic Data Grad Norm: 0.00022608559811487794\n",
      "Epoch 2, Meta Loss: 2.2968297004699707, Synthetic Data Grad Norm: 0.0003108848468400538\n",
      "Epoch 2, Meta Loss: 2.2741684913635254, Synthetic Data Grad Norm: 0.0003047154750674963\n",
      "Epoch 2, Meta Loss: 2.28813099861145, Synthetic Data Grad Norm: 0.0002595716214273125\n",
      "Epoch 2, Meta Loss: 2.310049533843994, Synthetic Data Grad Norm: 0.00022063820506446064\n",
      "Epoch 2, Meta Loss: 2.2842183113098145, Synthetic Data Grad Norm: 0.00024281686637550592\n",
      "Epoch 2, Meta Loss: 2.307508945465088, Synthetic Data Grad Norm: 0.0002666214422788471\n",
      "Epoch 2, Meta Loss: 2.2875826358795166, Synthetic Data Grad Norm: 0.0002612617681734264\n",
      "Epoch 2, Meta Loss: 2.298299789428711, Synthetic Data Grad Norm: 0.00023139659606385976\n",
      "Epoch 2, Meta Loss: 2.2967193126678467, Synthetic Data Grad Norm: 0.0001803855993784964\n",
      "Epoch 2, Meta Loss: 2.290280342102051, Synthetic Data Grad Norm: 0.0002621935273054987\n",
      "Epoch 2, Meta Loss: 2.2756168842315674, Synthetic Data Grad Norm: 0.00034741085255518556\n",
      "Epoch 2, Meta Loss: 2.291172981262207, Synthetic Data Grad Norm: 0.0003980264882557094\n",
      "Epoch 2, Meta Loss: 2.298886299133301, Synthetic Data Grad Norm: 0.0002474220236763358\n",
      "Epoch 2, Meta Loss: 2.274351119995117, Synthetic Data Grad Norm: 0.00025378205464221537\n",
      "Epoch 2, Meta Loss: 2.310171127319336, Synthetic Data Grad Norm: 0.0002642962208483368\n",
      "Epoch 2, Meta Loss: 2.2742807865142822, Synthetic Data Grad Norm: 0.00025125182582996786\n",
      "Epoch 2, Meta Loss: 2.292447328567505, Synthetic Data Grad Norm: 0.00028977557667531073\n",
      "Epoch 2, Meta Loss: 2.300865411758423, Synthetic Data Grad Norm: 0.00034886051435023546\n",
      "Epoch 2, Meta Loss: 2.2872250080108643, Synthetic Data Grad Norm: 0.0002434117195662111\n",
      "Epoch 2, Meta Loss: 2.2959609031677246, Synthetic Data Grad Norm: 0.00025406130589544773\n",
      "Epoch 2, Meta Loss: 2.2958121299743652, Synthetic Data Grad Norm: 0.00023196240363176912\n",
      "Epoch 2, Meta Loss: 2.309844493865967, Synthetic Data Grad Norm: 0.0003211262810509652\n",
      "Epoch 2, Meta Loss: 2.282078742980957, Synthetic Data Grad Norm: 0.0003228284476790577\n",
      "Epoch 2, Meta Loss: 2.2860305309295654, Synthetic Data Grad Norm: 0.00030828817398287356\n",
      "Epoch 2, Meta Loss: 2.279374837875366, Synthetic Data Grad Norm: 0.0002489100443199277\n",
      "Epoch 2, Meta Loss: 2.2782421112060547, Synthetic Data Grad Norm: 0.0003390313358977437\n",
      "Epoch 2, Meta Loss: 2.305449962615967, Synthetic Data Grad Norm: 0.00032488940632902086\n",
      "Epoch 2, Meta Loss: 2.275590419769287, Synthetic Data Grad Norm: 0.00027684899396263063\n",
      "Epoch 2, Meta Loss: 2.283581256866455, Synthetic Data Grad Norm: 0.0002763169177342206\n",
      "Epoch 2, Meta Loss: 2.2897307872772217, Synthetic Data Grad Norm: 0.0003480556479189545\n",
      "Epoch 2, Meta Loss: 2.285726308822632, Synthetic Data Grad Norm: 0.000320185354212299\n",
      "Epoch 2, Meta Loss: 2.276653289794922, Synthetic Data Grad Norm: 0.0002561266301199794\n",
      "Epoch 2, Meta Loss: 2.2840282917022705, Synthetic Data Grad Norm: 0.00023560028057545424\n",
      "Epoch 2, Meta Loss: 2.2796056270599365, Synthetic Data Grad Norm: 0.00017966596351470798\n",
      "Epoch 2, Meta Loss: 2.2869434356689453, Synthetic Data Grad Norm: 0.0003249309665989131\n",
      "Epoch 2, Meta Loss: 2.282680034637451, Synthetic Data Grad Norm: 0.00028371764346957207\n",
      "Epoch 2, Meta Loss: 2.2745120525360107, Synthetic Data Grad Norm: 0.0002726949460338801\n",
      "Epoch 2, Meta Loss: 2.290710926055908, Synthetic Data Grad Norm: 0.0002561149012763053\n",
      "Epoch 2, Meta Loss: 2.268312931060791, Synthetic Data Grad Norm: 0.00033788522705435753\n",
      "Epoch 2, Meta Loss: 2.292799711227417, Synthetic Data Grad Norm: 0.00020248049986548722\n",
      "Epoch 2, Meta Loss: 2.301398515701294, Synthetic Data Grad Norm: 0.00020560124539770186\n",
      "Epoch 2, Meta Loss: 2.296673059463501, Synthetic Data Grad Norm: 0.0002486303565092385\n",
      "Epoch 2, Meta Loss: 2.277942180633545, Synthetic Data Grad Norm: 0.00024303725513163954\n",
      "Epoch 2, Meta Loss: 2.293363571166992, Synthetic Data Grad Norm: 0.0002279852342326194\n",
      "Epoch 2, Meta Loss: 2.289496421813965, Synthetic Data Grad Norm: 0.000371975009329617\n",
      "Epoch 2, Meta Loss: 2.3069911003112793, Synthetic Data Grad Norm: 0.00025990663561969995\n",
      "Epoch 2, Meta Loss: 2.274508237838745, Synthetic Data Grad Norm: 0.000267202005488798\n",
      "Epoch 2, Meta Loss: 2.2847437858581543, Synthetic Data Grad Norm: 0.00029723308398388326\n",
      "Epoch 2, Meta Loss: 2.286811590194702, Synthetic Data Grad Norm: 0.00022525952954310924\n",
      "Epoch 2, Meta Loss: 2.261017084121704, Synthetic Data Grad Norm: 0.000284654728602618\n",
      "Epoch 2, Meta Loss: 2.290872573852539, Synthetic Data Grad Norm: 0.0002493091160431504\n",
      "Epoch 2, Meta Loss: 2.2817275524139404, Synthetic Data Grad Norm: 0.00021341588580980897\n",
      "Epoch 2, Meta Loss: 2.2605655193328857, Synthetic Data Grad Norm: 0.00027087447233498096\n",
      "Epoch 2, Meta Loss: 2.263564109802246, Synthetic Data Grad Norm: 0.00027547890204004943\n",
      "Epoch 2, Meta Loss: 2.282433271408081, Synthetic Data Grad Norm: 0.0002521073038224131\n",
      "Epoch 2, Meta Loss: 2.2783312797546387, Synthetic Data Grad Norm: 0.0002996244584210217\n",
      "Epoch 2, Meta Loss: 2.282498836517334, Synthetic Data Grad Norm: 0.00025376194389536977\n",
      "Epoch 2, Meta Loss: 2.2814104557037354, Synthetic Data Grad Norm: 0.00035200457205064595\n",
      "Epoch 2, Meta Loss: 2.290764093399048, Synthetic Data Grad Norm: 0.0003057639696635306\n",
      "Epoch 2, Meta Loss: 2.2851738929748535, Synthetic Data Grad Norm: 0.0002765621757134795\n",
      "Epoch 2, Meta Loss: 2.281959295272827, Synthetic Data Grad Norm: 0.00021694008319173008\n",
      "Epoch 2, Meta Loss: 2.287365198135376, Synthetic Data Grad Norm: 0.00033698833431117237\n",
      "Epoch 2, Meta Loss: 2.299076557159424, Synthetic Data Grad Norm: 0.00026844360399991274\n",
      "Epoch 2, Meta Loss: 2.2869701385498047, Synthetic Data Grad Norm: 0.0002508491452317685\n",
      "Epoch 2, Meta Loss: 2.3014395236968994, Synthetic Data Grad Norm: 0.0003111713158432394\n",
      "Epoch 2, Meta Loss: 2.279772996902466, Synthetic Data Grad Norm: 0.0002569227362982929\n",
      "Epoch 2, Meta Loss: 2.2794578075408936, Synthetic Data Grad Norm: 0.00027533152024261653\n",
      "Epoch 2, Meta Loss: 2.2811532020568848, Synthetic Data Grad Norm: 0.00024040388234425336\n",
      "Epoch 2, Meta Loss: 2.2603797912597656, Synthetic Data Grad Norm: 0.00025856911088339984\n",
      "Epoch 2, Meta Loss: 2.2849135398864746, Synthetic Data Grad Norm: 0.00018717619241215289\n",
      "Epoch 2, Meta Loss: 2.2813875675201416, Synthetic Data Grad Norm: 0.0003031585947610438\n",
      "Epoch 2, Meta Loss: 2.289381980895996, Synthetic Data Grad Norm: 0.00018459523562341928\n",
      "Epoch 2, Meta Loss: 2.2818031311035156, Synthetic Data Grad Norm: 0.00025879789609462023\n",
      "Epoch 2, Meta Loss: 2.2868847846984863, Synthetic Data Grad Norm: 0.0002945561136584729\n",
      "Epoch 2, Meta Loss: 2.298283338546753, Synthetic Data Grad Norm: 0.0003915494598913938\n",
      "Epoch 2, Meta Loss: 2.2655885219573975, Synthetic Data Grad Norm: 0.000323677173582837\n",
      "Epoch 2, Meta Loss: 2.276099443435669, Synthetic Data Grad Norm: 0.0002480979892425239\n",
      "Epoch 2, Meta Loss: 2.285496234893799, Synthetic Data Grad Norm: 0.0003718369407579303\n",
      "Epoch 2, Meta Loss: 2.2743518352508545, Synthetic Data Grad Norm: 0.0003585056692827493\n",
      "Epoch 2, Meta Loss: 2.283870220184326, Synthetic Data Grad Norm: 0.00025699776597321033\n",
      "Epoch 2, Meta Loss: 2.2878224849700928, Synthetic Data Grad Norm: 0.00027750153094530106\n",
      "Epoch 2, Meta Loss: 2.2896065711975098, Synthetic Data Grad Norm: 0.0002314836165169254\n",
      "Epoch 2, Meta Loss: 2.286111831665039, Synthetic Data Grad Norm: 0.00024882651632651687\n",
      "Epoch 2, Meta Loss: 2.276003360748291, Synthetic Data Grad Norm: 0.000280308275250718\n",
      "Epoch 2, Meta Loss: 2.287051200866699, Synthetic Data Grad Norm: 0.0002856107021216303\n",
      "Epoch 2, Meta Loss: 2.2968218326568604, Synthetic Data Grad Norm: 0.00023188105842564255\n",
      "Epoch 2, Meta Loss: 2.2768757343292236, Synthetic Data Grad Norm: 0.0002809018478728831\n",
      "Epoch 2, Meta Loss: 2.279651165008545, Synthetic Data Grad Norm: 0.00023918460647109896\n",
      "Epoch 2, Meta Loss: 2.2818384170532227, Synthetic Data Grad Norm: 0.00029574372456409037\n",
      "Epoch 2, Meta Loss: 2.2986834049224854, Synthetic Data Grad Norm: 0.00017678995209280401\n",
      "Epoch 2, Meta Loss: 2.2947700023651123, Synthetic Data Grad Norm: 0.0002601760788820684\n",
      "Epoch 2, Meta Loss: 2.2699520587921143, Synthetic Data Grad Norm: 0.0003028450009878725\n",
      "Epoch 2, Meta Loss: 2.293275833129883, Synthetic Data Grad Norm: 0.0003956348227802664\n",
      "Epoch 2, Meta Loss: 2.302036762237549, Synthetic Data Grad Norm: 0.00030971242813393474\n",
      "Epoch 2, Meta Loss: 2.3009607791900635, Synthetic Data Grad Norm: 0.0002851476601790637\n",
      "Epoch 2, Meta Loss: 2.2946040630340576, Synthetic Data Grad Norm: 0.0002521586720831692\n",
      "Epoch 2, Meta Loss: 2.292539596557617, Synthetic Data Grad Norm: 0.00024223137006629258\n",
      "Epoch 2, Meta Loss: 2.289109468460083, Synthetic Data Grad Norm: 0.0002412716276012361\n",
      "Epoch 2, Meta Loss: 2.287569999694824, Synthetic Data Grad Norm: 0.0002813944884110242\n",
      "Epoch 2, Meta Loss: 2.2755286693573, Synthetic Data Grad Norm: 0.0002955025702249259\n",
      "Epoch 2, Meta Loss: 2.2907297611236572, Synthetic Data Grad Norm: 0.00039165213820524514\n",
      "Epoch 2, Meta Loss: 2.287445068359375, Synthetic Data Grad Norm: 0.0002792778832372278\n",
      "Epoch 2, Meta Loss: 2.279952049255371, Synthetic Data Grad Norm: 0.00030639610486105084\n",
      "Epoch 2, Meta Loss: 2.2791383266448975, Synthetic Data Grad Norm: 0.0004595974460244179\n",
      "Epoch 2, Meta Loss: 2.27718186378479, Synthetic Data Grad Norm: 0.0004461300268303603\n",
      "Epoch 2, Meta Loss: 2.2790260314941406, Synthetic Data Grad Norm: 0.0002774371823761612\n",
      "Epoch 2, Meta Loss: 2.264070987701416, Synthetic Data Grad Norm: 0.00033766322303563356\n",
      "Epoch 2, Meta Loss: 2.3098325729370117, Synthetic Data Grad Norm: 0.00033502106089144945\n",
      "Epoch 2, Meta Loss: 2.282315731048584, Synthetic Data Grad Norm: 0.0002289098920300603\n",
      "Epoch 2, Meta Loss: 2.281050682067871, Synthetic Data Grad Norm: 0.00023433771275449544\n",
      "Epoch 2, Meta Loss: 2.28310489654541, Synthetic Data Grad Norm: 0.0001890200364869088\n",
      "Epoch 2, Meta Loss: 2.2774195671081543, Synthetic Data Grad Norm: 0.0002655840653460473\n",
      "Epoch 2, Meta Loss: 2.2927167415618896, Synthetic Data Grad Norm: 0.00022115766478236765\n",
      "Epoch 2, Meta Loss: 2.289250612258911, Synthetic Data Grad Norm: 0.0003113254497293383\n",
      "Epoch 2, Meta Loss: 2.2967498302459717, Synthetic Data Grad Norm: 0.00029775514849461615\n",
      "Epoch 2, Meta Loss: 2.2846157550811768, Synthetic Data Grad Norm: 0.0002386080304859206\n",
      "Epoch 2, Meta Loss: 2.2781829833984375, Synthetic Data Grad Norm: 0.0002673357375897467\n",
      "Epoch 2, Meta Loss: 2.279677391052246, Synthetic Data Grad Norm: 0.0002186882629757747\n",
      "Epoch 2, Meta Loss: 2.296093225479126, Synthetic Data Grad Norm: 0.0003505452477838844\n",
      "Epoch 2, Meta Loss: 2.272223711013794, Synthetic Data Grad Norm: 0.0003908226790372282\n",
      "Epoch 2, Meta Loss: 2.2736454010009766, Synthetic Data Grad Norm: 0.0003061836468987167\n",
      "Epoch 2, Meta Loss: 2.2780683040618896, Synthetic Data Grad Norm: 0.0002489990438334644\n",
      "Epoch 2, Meta Loss: 2.2754719257354736, Synthetic Data Grad Norm: 0.00025450874818488955\n",
      "Epoch 2, Meta Loss: 2.268585205078125, Synthetic Data Grad Norm: 0.0002894632052630186\n",
      "Epoch 2, Meta Loss: 2.283374071121216, Synthetic Data Grad Norm: 0.00027332009631209075\n",
      "Epoch 2, Meta Loss: 2.2742035388946533, Synthetic Data Grad Norm: 0.0002977375406771898\n",
      "Epoch 2, Meta Loss: 2.2587947845458984, Synthetic Data Grad Norm: 0.0005061787087470293\n",
      "Epoch 2, Meta Loss: 2.2980260848999023, Synthetic Data Grad Norm: 0.00029367170645855367\n",
      "Epoch 2, Meta Loss: 2.3048737049102783, Synthetic Data Grad Norm: 0.00028540377388708293\n",
      "Epoch 2, Meta Loss: 2.277092456817627, Synthetic Data Grad Norm: 0.0003088597732130438\n",
      "Epoch 2, Meta Loss: 2.2957887649536133, Synthetic Data Grad Norm: 0.0003219352220185101\n",
      "Epoch 2, Meta Loss: 2.2799596786499023, Synthetic Data Grad Norm: 0.00033913305378519\n",
      "Epoch 2, Meta Loss: 2.2706387042999268, Synthetic Data Grad Norm: 0.0002857020008377731\n",
      "Epoch 2, Meta Loss: 2.2916982173919678, Synthetic Data Grad Norm: 0.00023214935208670795\n",
      "Epoch 2, Meta Loss: 2.2840147018432617, Synthetic Data Grad Norm: 0.00032492526224814355\n",
      "Epoch 2, Meta Loss: 2.294713258743286, Synthetic Data Grad Norm: 0.00026610924396663904\n",
      "Epoch 2, Meta Loss: 2.2808656692504883, Synthetic Data Grad Norm: 0.00023126973246689886\n",
      "Epoch 2, Meta Loss: 2.2889857292175293, Synthetic Data Grad Norm: 0.0003915561828762293\n",
      "Epoch 2, Meta Loss: 2.2795300483703613, Synthetic Data Grad Norm: 0.0003372942446731031\n",
      "Epoch 2, Meta Loss: 2.2815442085266113, Synthetic Data Grad Norm: 0.00025999106583185494\n",
      "Epoch 2, Meta Loss: 2.284125328063965, Synthetic Data Grad Norm: 0.00031225004931911826\n",
      "Epoch 2, Meta Loss: 2.270794153213501, Synthetic Data Grad Norm: 0.0003544989740476012\n",
      "Epoch 2, Meta Loss: 2.2881357669830322, Synthetic Data Grad Norm: 0.0003245181287638843\n",
      "Epoch 2, Meta Loss: 2.2786200046539307, Synthetic Data Grad Norm: 0.0002469946339260787\n",
      "Epoch 2, Meta Loss: 2.293999671936035, Synthetic Data Grad Norm: 0.0002821329399012029\n",
      "Epoch 2, Meta Loss: 2.2865917682647705, Synthetic Data Grad Norm: 0.00020808396220672876\n",
      "Epoch 2, Meta Loss: 2.282820463180542, Synthetic Data Grad Norm: 0.00021621829364448786\n",
      "Epoch 2, Meta Loss: 2.277533769607544, Synthetic Data Grad Norm: 0.0003092763654422015\n",
      "Epoch 2, Meta Loss: 2.281778573989868, Synthetic Data Grad Norm: 0.0003127021191176027\n",
      "Epoch 2, Meta Loss: 2.2774558067321777, Synthetic Data Grad Norm: 0.00034974131267517805\n",
      "Epoch 2, Meta Loss: 2.2832372188568115, Synthetic Data Grad Norm: 0.0002693581045605242\n",
      "Epoch 2, Meta Loss: 2.282086133956909, Synthetic Data Grad Norm: 0.00025697375531308353\n",
      "Epoch 2, Meta Loss: 2.2844631671905518, Synthetic Data Grad Norm: 0.000405351456720382\n",
      "Epoch 2, Meta Loss: 2.287790536880493, Synthetic Data Grad Norm: 0.00027446725289337337\n",
      "Epoch 2, Meta Loss: 2.2732765674591064, Synthetic Data Grad Norm: 0.00033761729719117284\n",
      "Epoch 2, Meta Loss: 2.298417329788208, Synthetic Data Grad Norm: 0.0002505690208636224\n",
      "Epoch 2, Meta Loss: 2.2875235080718994, Synthetic Data Grad Norm: 0.0003064492193516344\n",
      "Epoch 2, Meta Loss: 2.2765731811523438, Synthetic Data Grad Norm: 0.0003437441773712635\n",
      "Epoch 2, Meta Loss: 2.2816834449768066, Synthetic Data Grad Norm: 0.00025209627347067\n",
      "Epoch 2, Meta Loss: 2.281836986541748, Synthetic Data Grad Norm: 0.00021990298409946263\n",
      "Epoch 2, Meta Loss: 2.2802011966705322, Synthetic Data Grad Norm: 0.00026876869378611445\n",
      "Epoch 2, Meta Loss: 2.2669730186462402, Synthetic Data Grad Norm: 0.000226854084758088\n",
      "Epoch 2, Meta Loss: 2.2703630924224854, Synthetic Data Grad Norm: 0.0003027036727871746\n",
      "Epoch 2, Meta Loss: 2.283245325088501, Synthetic Data Grad Norm: 0.0002840584493242204\n",
      "Epoch 2, Meta Loss: 2.2704758644104004, Synthetic Data Grad Norm: 0.00029688148060813546\n",
      "Epoch 2, Meta Loss: 2.288177967071533, Synthetic Data Grad Norm: 0.0002634560805745423\n",
      "Epoch 2, Meta Loss: 2.2818102836608887, Synthetic Data Grad Norm: 0.00030754090403206646\n",
      "Epoch 2, Meta Loss: 2.2651150226593018, Synthetic Data Grad Norm: 0.00036237563472241163\n",
      "Epoch 2, Meta Loss: 2.2709603309631348, Synthetic Data Grad Norm: 0.00024795872741378844\n",
      "Epoch 2, Meta Loss: 2.265709638595581, Synthetic Data Grad Norm: 0.0003718735242728144\n",
      "Epoch 2, Meta Loss: 2.2831778526306152, Synthetic Data Grad Norm: 0.0003215017495676875\n",
      "Epoch 2, Meta Loss: 2.2923738956451416, Synthetic Data Grad Norm: 0.00022211279429029673\n",
      "Epoch 2, Meta Loss: 2.2837581634521484, Synthetic Data Grad Norm: 0.0002331231808057055\n",
      "Epoch 2, Meta Loss: 2.2846767902374268, Synthetic Data Grad Norm: 0.000253262318437919\n",
      "Epoch 2, Meta Loss: 2.284435987472534, Synthetic Data Grad Norm: 0.0002822179812937975\n",
      "Epoch 2, Meta Loss: 2.264504909515381, Synthetic Data Grad Norm: 0.00037776181125082076\n",
      "Epoch 2, Meta Loss: 2.291684627532959, Synthetic Data Grad Norm: 0.00021568687225226313\n",
      "Epoch 2, Meta Loss: 2.2540018558502197, Synthetic Data Grad Norm: 0.00035681467852555215\n",
      "Epoch 2, Meta Loss: 2.2896571159362793, Synthetic Data Grad Norm: 0.0002570193028077483\n",
      "Epoch 2, Meta Loss: 2.287637948989868, Synthetic Data Grad Norm: 0.0002713385911192745\n",
      "Epoch 2, Meta Loss: 2.289757251739502, Synthetic Data Grad Norm: 0.00030194022110663354\n",
      "Epoch 2, Meta Loss: 2.2876698970794678, Synthetic Data Grad Norm: 0.0003298404044471681\n",
      "Epoch 2, Meta Loss: 2.2798032760620117, Synthetic Data Grad Norm: 0.0002705847145989537\n",
      "Epoch 2, Meta Loss: 2.289898157119751, Synthetic Data Grad Norm: 0.00022903185163158923\n",
      "Epoch 2, Meta Loss: 2.291774034500122, Synthetic Data Grad Norm: 0.0003289563755970448\n",
      "Epoch 2, Meta Loss: 2.3032758235931396, Synthetic Data Grad Norm: 0.00027652422431856394\n",
      "Epoch 2, Meta Loss: 2.2629237174987793, Synthetic Data Grad Norm: 0.0002958327531814575\n",
      "Epoch 2, Meta Loss: 2.293428659439087, Synthetic Data Grad Norm: 0.00019739380513783544\n",
      "Epoch 2, Meta Loss: 2.2709405422210693, Synthetic Data Grad Norm: 0.0003324119606986642\n",
      "Epoch 2, Meta Loss: 2.291471242904663, Synthetic Data Grad Norm: 0.00023223938478622586\n",
      "Epoch 2, Meta Loss: 2.2881827354431152, Synthetic Data Grad Norm: 0.0002943491272162646\n",
      "Epoch 2, Meta Loss: 2.3004403114318848, Synthetic Data Grad Norm: 0.00034437322756275535\n",
      "Epoch 2, Meta Loss: 2.2919745445251465, Synthetic Data Grad Norm: 0.00025744971935637295\n",
      "Epoch 2, Meta Loss: 2.279806137084961, Synthetic Data Grad Norm: 0.0002640733728185296\n",
      "Epoch 2, Meta Loss: 2.2750132083892822, Synthetic Data Grad Norm: 0.0002603442990221083\n",
      "Epoch 2, Meta Loss: 2.303621530532837, Synthetic Data Grad Norm: 0.00024974721600301564\n",
      "Epoch 2, Meta Loss: 2.289283275604248, Synthetic Data Grad Norm: 0.00027842973941005766\n",
      "Epoch 2, Meta Loss: 2.279531478881836, Synthetic Data Grad Norm: 0.0002747194084804505\n",
      "Epoch 2, Meta Loss: 2.2998459339141846, Synthetic Data Grad Norm: 0.00024701052461750805\n",
      "Epoch 2, Meta Loss: 2.2981510162353516, Synthetic Data Grad Norm: 0.0002565349277574569\n",
      "Epoch 2, Meta Loss: 2.2743332386016846, Synthetic Data Grad Norm: 0.0002844772534444928\n",
      "Epoch 2, Meta Loss: 2.2807059288024902, Synthetic Data Grad Norm: 0.0003633083833847195\n",
      "Epoch 2, Meta Loss: 2.298079490661621, Synthetic Data Grad Norm: 0.0003086743818130344\n",
      "Epoch 2, Meta Loss: 2.291552782058716, Synthetic Data Grad Norm: 0.0002935093070846051\n",
      "Epoch 2, Meta Loss: 2.2910525798797607, Synthetic Data Grad Norm: 0.00046487076906487346\n",
      "Epoch 2, Meta Loss: 2.284550428390503, Synthetic Data Grad Norm: 0.00021569625823758543\n",
      "Epoch 2, Meta Loss: 2.2831032276153564, Synthetic Data Grad Norm: 0.0002818204229697585\n",
      "Epoch 2, Meta Loss: 2.271815061569214, Synthetic Data Grad Norm: 0.000276065431535244\n",
      "Epoch 2, Meta Loss: 2.290811538696289, Synthetic Data Grad Norm: 0.0003646855184342712\n",
      "Epoch 2, Meta Loss: 2.276947498321533, Synthetic Data Grad Norm: 0.0003932995314244181\n",
      "Epoch 2, Meta Loss: 2.287726402282715, Synthetic Data Grad Norm: 0.00026847750996239483\n",
      "Epoch 2, Meta Loss: 2.2815921306610107, Synthetic Data Grad Norm: 0.0002843925030902028\n",
      "Epoch 2, Meta Loss: 2.299194812774658, Synthetic Data Grad Norm: 0.00016570932348258793\n",
      "Epoch 2, Meta Loss: 2.292459726333618, Synthetic Data Grad Norm: 0.0003344154101796448\n",
      "Epoch 2, Meta Loss: 2.2980198860168457, Synthetic Data Grad Norm: 0.0002181560848839581\n",
      "Epoch 2, Meta Loss: 2.298590898513794, Synthetic Data Grad Norm: 0.00021994432609062642\n",
      "Epoch 2, Meta Loss: 2.278947114944458, Synthetic Data Grad Norm: 0.0002977850381284952\n",
      "Epoch 2, Meta Loss: 2.295182228088379, Synthetic Data Grad Norm: 0.00021747598657384515\n",
      "Epoch 2, Meta Loss: 2.2909417152404785, Synthetic Data Grad Norm: 0.00025287599419243634\n",
      "Epoch 2, Meta Loss: 2.2717278003692627, Synthetic Data Grad Norm: 0.0003670005244202912\n",
      "Epoch 2, Meta Loss: 2.276460886001587, Synthetic Data Grad Norm: 0.0003331389161758125\n",
      "Epoch 2, Meta Loss: 2.288769245147705, Synthetic Data Grad Norm: 0.00025619048392400146\n",
      "Epoch 2, Meta Loss: 2.2777254581451416, Synthetic Data Grad Norm: 0.00036148985964246094\n",
      "Epoch 2, Meta Loss: 2.276362419128418, Synthetic Data Grad Norm: 0.0002525512536522001\n",
      "Epoch 2, Meta Loss: 2.2887256145477295, Synthetic Data Grad Norm: 0.00022896431619301438\n",
      "Epoch 2, Meta Loss: 2.2790753841400146, Synthetic Data Grad Norm: 0.00022816561977379024\n",
      "Epoch 2, Meta Loss: 2.2718846797943115, Synthetic Data Grad Norm: 0.00027376599609851837\n",
      "Epoch 2, Meta Loss: 2.280454158782959, Synthetic Data Grad Norm: 0.0002714472939260304\n",
      "Epoch 2, Meta Loss: 2.276045560836792, Synthetic Data Grad Norm: 0.000215919193578884\n",
      "Epoch 2, Meta Loss: 2.288120746612549, Synthetic Data Grad Norm: 0.00023123239225242287\n",
      "Epoch 2, Meta Loss: 2.2809107303619385, Synthetic Data Grad Norm: 0.00029405110399238765\n",
      "Epoch 2, Meta Loss: 2.2713816165924072, Synthetic Data Grad Norm: 0.0002458393864799291\n",
      "Epoch 2, Meta Loss: 2.2711923122406006, Synthetic Data Grad Norm: 0.00028203908004797995\n",
      "Epoch 2, Meta Loss: 2.273526668548584, Synthetic Data Grad Norm: 0.0003241482190787792\n",
      "Epoch 2, Meta Loss: 2.2783362865448, Synthetic Data Grad Norm: 0.00028845848282799125\n",
      "Epoch 2, Meta Loss: 2.267029285430908, Synthetic Data Grad Norm: 0.0002443395496811718\n",
      "Epoch 2, Meta Loss: 2.287095308303833, Synthetic Data Grad Norm: 0.0001933208986883983\n",
      "Epoch 2, Meta Loss: 2.290525197982788, Synthetic Data Grad Norm: 0.00024163362104445696\n",
      "Epoch 2, Meta Loss: 2.270533561706543, Synthetic Data Grad Norm: 0.00034654425689950585\n",
      "Epoch 2, Meta Loss: 2.2806172370910645, Synthetic Data Grad Norm: 0.0002344318781979382\n",
      "Epoch 2, Meta Loss: 2.2955403327941895, Synthetic Data Grad Norm: 0.0003198094782419503\n",
      "Epoch 2, Meta Loss: 2.257835626602173, Synthetic Data Grad Norm: 0.00027865698211826384\n",
      "Epoch 2, Meta Loss: 2.300283193588257, Synthetic Data Grad Norm: 0.0002603063767310232\n",
      "Epoch 2, Meta Loss: 2.2844529151916504, Synthetic Data Grad Norm: 0.00026384787634015083\n",
      "Epoch 2, Meta Loss: 2.2921040058135986, Synthetic Data Grad Norm: 0.00027978280559182167\n",
      "Epoch 2, Meta Loss: 2.2698304653167725, Synthetic Data Grad Norm: 0.0002875943901017308\n",
      "Epoch 2, Meta Loss: 2.2819759845733643, Synthetic Data Grad Norm: 0.00032914240728132427\n",
      "Epoch 2, Meta Loss: 2.2623276710510254, Synthetic Data Grad Norm: 0.00040873538819141686\n",
      "Epoch 2, Meta Loss: 2.283971071243286, Synthetic Data Grad Norm: 0.0002778477210085839\n",
      "Epoch 2, Meta Loss: 2.2754738330841064, Synthetic Data Grad Norm: 0.00024093188403639942\n",
      "Epoch 2, Meta Loss: 2.3006832599639893, Synthetic Data Grad Norm: 0.00034076598240062594\n",
      "Epoch 2, Meta Loss: 2.291386127471924, Synthetic Data Grad Norm: 0.00024254988238681108\n",
      "Epoch 2, Meta Loss: 2.2925479412078857, Synthetic Data Grad Norm: 0.00032132264459505677\n",
      "Epoch 2, Meta Loss: 2.2970757484436035, Synthetic Data Grad Norm: 0.0002808342396747321\n",
      "Epoch 2, Meta Loss: 2.2747232913970947, Synthetic Data Grad Norm: 0.00024203272187151015\n",
      "Epoch 2, Meta Loss: 2.28106689453125, Synthetic Data Grad Norm: 0.00022711972997058183\n",
      "Epoch 2, Meta Loss: 2.2651751041412354, Synthetic Data Grad Norm: 0.00033325894037261605\n",
      "Epoch 2, Meta Loss: 2.2741756439208984, Synthetic Data Grad Norm: 0.0002554412931203842\n",
      "Epoch 2, Meta Loss: 2.273622989654541, Synthetic Data Grad Norm: 0.00027160183526575565\n",
      "Epoch 2, Meta Loss: 2.269280433654785, Synthetic Data Grad Norm: 0.0003621352952904999\n",
      "Epoch 2, Meta Loss: 2.300682306289673, Synthetic Data Grad Norm: 0.0002639485464897007\n",
      "Epoch 2, Meta Loss: 2.238062858581543, Synthetic Data Grad Norm: 0.0004529634607024491\n",
      "Epoch 2, Meta Loss: 2.289444923400879, Synthetic Data Grad Norm: 0.00017928700253833085\n",
      "Epoch 2, Meta Loss: 2.2840828895568848, Synthetic Data Grad Norm: 0.0002653858682606369\n",
      "Epoch 2, Meta Loss: 2.2796568870544434, Synthetic Data Grad Norm: 0.0002827360003720969\n",
      "Epoch 2, Meta Loss: 2.279604196548462, Synthetic Data Grad Norm: 0.000252095254836604\n",
      "Epoch 2, Meta Loss: 2.2749202251434326, Synthetic Data Grad Norm: 0.00030072941444814205\n",
      "Epoch 2, Meta Loss: 2.280076742172241, Synthetic Data Grad Norm: 0.000205083197215572\n",
      "Epoch 2, Meta Loss: 2.2839534282684326, Synthetic Data Grad Norm: 0.00027752845198847353\n",
      "Epoch 2, Meta Loss: 2.2767117023468018, Synthetic Data Grad Norm: 0.0002078759134747088\n",
      "Epoch 2, Meta Loss: 2.2718021869659424, Synthetic Data Grad Norm: 0.00020761963969562203\n",
      "Epoch 2, Meta Loss: 2.2773942947387695, Synthetic Data Grad Norm: 0.00032350412220694125\n",
      "Epoch 2, Meta Loss: 2.3010661602020264, Synthetic Data Grad Norm: 0.0003200731298420578\n",
      "Epoch 2, Meta Loss: 2.2768590450286865, Synthetic Data Grad Norm: 0.00026043684920296073\n",
      "Epoch 2, Meta Loss: 2.289759635925293, Synthetic Data Grad Norm: 0.00028932472923770547\n",
      "Epoch 2, Meta Loss: 2.2832109928131104, Synthetic Data Grad Norm: 0.000236449675867334\n",
      "Epoch 2, Meta Loss: 2.289630174636841, Synthetic Data Grad Norm: 0.0002528236072976142\n",
      "Epoch 2, Meta Loss: 2.2787301540374756, Synthetic Data Grad Norm: 0.00021109767840243876\n",
      "Epoch 2, Meta Loss: 2.2748513221740723, Synthetic Data Grad Norm: 0.0003157677419949323\n",
      "Epoch 2, Meta Loss: 2.277606964111328, Synthetic Data Grad Norm: 0.0004586591967381537\n",
      "Epoch 2, Meta Loss: 2.2921109199523926, Synthetic Data Grad Norm: 0.0002707023813854903\n",
      "Epoch 2, Meta Loss: 2.2682015895843506, Synthetic Data Grad Norm: 0.0004406233783811331\n",
      "Epoch 2, Meta Loss: 2.284173011779785, Synthetic Data Grad Norm: 0.00024954290711320937\n",
      "Epoch 2, Meta Loss: 2.283069133758545, Synthetic Data Grad Norm: 0.0002863591944333166\n",
      "Epoch 2, Meta Loss: 2.2797963619232178, Synthetic Data Grad Norm: 0.00025789422215893865\n",
      "Epoch 2, Meta Loss: 2.285951614379883, Synthetic Data Grad Norm: 0.0002456986403558403\n",
      "Epoch 2, Meta Loss: 2.2771692276000977, Synthetic Data Grad Norm: 0.00027181560290046036\n",
      "Epoch 2, Meta Loss: 2.2747061252593994, Synthetic Data Grad Norm: 0.0002624984481371939\n",
      "Epoch 2, Meta Loss: 2.2935662269592285, Synthetic Data Grad Norm: 0.00027073148521594703\n",
      "Epoch 2, Meta Loss: 2.2832562923431396, Synthetic Data Grad Norm: 0.00022941056522540748\n",
      "Epoch 2, Meta Loss: 2.276007890701294, Synthetic Data Grad Norm: 0.0002673343406058848\n",
      "Epoch 2, Meta Loss: 2.2782528400421143, Synthetic Data Grad Norm: 0.0002850242599379271\n",
      "Epoch 2, Meta Loss: 2.267258882522583, Synthetic Data Grad Norm: 0.00030290443100966513\n",
      "Epoch 2, Meta Loss: 2.291555643081665, Synthetic Data Grad Norm: 0.0003085072967223823\n",
      "Epoch 2, Meta Loss: 2.2667040824890137, Synthetic Data Grad Norm: 0.0003513548581395298\n",
      "Epoch 2, Meta Loss: 2.268155097961426, Synthetic Data Grad Norm: 0.00028406866476871073\n",
      "Epoch 2, Meta Loss: 2.2666449546813965, Synthetic Data Grad Norm: 0.0003862086159642786\n",
      "Epoch 2, Meta Loss: 2.2684671878814697, Synthetic Data Grad Norm: 0.00033115127007476985\n",
      "Epoch 2, Meta Loss: 2.2479093074798584, Synthetic Data Grad Norm: 0.0003306612779852003\n",
      "Epoch 2, Meta Loss: 2.264333724975586, Synthetic Data Grad Norm: 0.00031935874721966684\n",
      "Epoch 2, Meta Loss: 2.3048393726348877, Synthetic Data Grad Norm: 0.0002145653561456129\n",
      "Epoch 2, Meta Loss: 2.2855727672576904, Synthetic Data Grad Norm: 0.00025607587303966284\n",
      "Epoch 2, Meta Loss: 2.2965707778930664, Synthetic Data Grad Norm: 0.0002651675313245505\n",
      "Epoch 2, Meta Loss: 2.2768714427948, Synthetic Data Grad Norm: 0.0002481659466866404\n",
      "Epoch 2, Meta Loss: 2.2842133045196533, Synthetic Data Grad Norm: 0.0003055823326576501\n",
      "Epoch 2, Meta Loss: 2.2960119247436523, Synthetic Data Grad Norm: 0.0002262537891510874\n",
      "Epoch 2, Meta Loss: 2.2774078845977783, Synthetic Data Grad Norm: 0.00034517922904342413\n",
      "Epoch 2, Meta Loss: 2.283118963241577, Synthetic Data Grad Norm: 0.00021752087923232466\n",
      "Epoch 2, Meta Loss: 2.2665090560913086, Synthetic Data Grad Norm: 0.0002832481695804745\n",
      "Epoch 2, Meta Loss: 2.285512924194336, Synthetic Data Grad Norm: 0.00026946651632897556\n",
      "Epoch 2, Meta Loss: 2.2695975303649902, Synthetic Data Grad Norm: 0.00045607308857142925\n",
      "Epoch 2, Meta Loss: 2.277832269668579, Synthetic Data Grad Norm: 0.00025648545124568045\n",
      "Epoch 2, Meta Loss: 2.2943267822265625, Synthetic Data Grad Norm: 0.0003206574183423072\n",
      "Epoch 2, Meta Loss: 2.2731590270996094, Synthetic Data Grad Norm: 0.0003147180541418493\n",
      "Epoch 2, Meta Loss: 2.2857863903045654, Synthetic Data Grad Norm: 0.0002548286283854395\n",
      "Epoch 2, Meta Loss: 2.272355318069458, Synthetic Data Grad Norm: 0.0003141771594528109\n",
      "Epoch 2, Meta Loss: 2.2853176593780518, Synthetic Data Grad Norm: 0.0005051784100942314\n",
      "Epoch 2, Meta Loss: 2.2873728275299072, Synthetic Data Grad Norm: 0.00025483459467068315\n",
      "Epoch 2, Meta Loss: 2.2921135425567627, Synthetic Data Grad Norm: 0.0004337799327913672\n",
      "Epoch 2, Meta Loss: 2.280097484588623, Synthetic Data Grad Norm: 0.0002808076096698642\n",
      "Epoch 2, Meta Loss: 2.2765393257141113, Synthetic Data Grad Norm: 0.0002471655316185206\n",
      "Epoch 2, Meta Loss: 2.2825217247009277, Synthetic Data Grad Norm: 0.000392287241993472\n",
      "Epoch 2, Meta Loss: 2.2749781608581543, Synthetic Data Grad Norm: 0.00033209603861905634\n",
      "Epoch 2, Meta Loss: 2.2710964679718018, Synthetic Data Grad Norm: 0.000246197305386886\n",
      "Epoch 2, Meta Loss: 2.290733814239502, Synthetic Data Grad Norm: 0.0002692290872801095\n",
      "Epoch 2, Meta Loss: 2.265077590942383, Synthetic Data Grad Norm: 0.0002781309303827584\n",
      "Epoch 2, Meta Loss: 2.293447732925415, Synthetic Data Grad Norm: 0.0002661655889824033\n",
      "Epoch 2, Meta Loss: 2.2814486026763916, Synthetic Data Grad Norm: 0.0002989096101373434\n",
      "Epoch 2, Meta Loss: 2.2810065746307373, Synthetic Data Grad Norm: 0.00032637527328915894\n",
      "Epoch 2, Meta Loss: 2.3008813858032227, Synthetic Data Grad Norm: 0.00019709407933987677\n",
      "Epoch 2, Meta Loss: 2.2891781330108643, Synthetic Data Grad Norm: 0.00031327377655543387\n",
      "Epoch 2, Meta Loss: 2.272911310195923, Synthetic Data Grad Norm: 0.00027038439293392\n",
      "Epoch 2, Meta Loss: 2.2806317806243896, Synthetic Data Grad Norm: 0.00023833513841964304\n",
      "Epoch 2, Meta Loss: 2.2707340717315674, Synthetic Data Grad Norm: 0.00041406703530810773\n",
      "Epoch 2, Meta Loss: 2.26448130607605, Synthetic Data Grad Norm: 0.0002960365964099765\n",
      "Epoch 2, Meta Loss: 2.2856009006500244, Synthetic Data Grad Norm: 0.0002424390404485166\n",
      "Epoch 2, Meta Loss: 2.283188819885254, Synthetic Data Grad Norm: 0.00023940768733154982\n",
      "Epoch 2, Meta Loss: 2.297736167907715, Synthetic Data Grad Norm: 0.0002385762782068923\n",
      "Epoch 2, Meta Loss: 2.2595460414886475, Synthetic Data Grad Norm: 0.00029603560687974095\n",
      "Epoch 2, Meta Loss: 2.266986131668091, Synthetic Data Grad Norm: 0.0003070669190492481\n",
      "Epoch 2, Meta Loss: 2.2825424671173096, Synthetic Data Grad Norm: 0.00029861123766750097\n",
      "Epoch 2, Meta Loss: 2.271169900894165, Synthetic Data Grad Norm: 0.00032533687772229314\n",
      "Epoch 2, Meta Loss: 2.3033204078674316, Synthetic Data Grad Norm: 0.0003420733264647424\n",
      "Epoch 2, Meta Loss: 2.2821872234344482, Synthetic Data Grad Norm: 0.0002472082560416311\n",
      "Epoch 2, Meta Loss: 2.2821156978607178, Synthetic Data Grad Norm: 0.0002466475125402212\n",
      "Epoch 2, Meta Loss: 2.2837657928466797, Synthetic Data Grad Norm: 0.000357049866579473\n",
      "Epoch 2, Meta Loss: 2.265303373336792, Synthetic Data Grad Norm: 0.0003552311100065708\n",
      "Epoch 2, Meta Loss: 2.289296865463257, Synthetic Data Grad Norm: 0.0002441613469272852\n",
      "Epoch 2, Meta Loss: 2.288184642791748, Synthetic Data Grad Norm: 0.000297398742986843\n",
      "Epoch 2, Meta Loss: 2.276280641555786, Synthetic Data Grad Norm: 0.0002961182617582381\n",
      "Epoch 2, Meta Loss: 2.301595687866211, Synthetic Data Grad Norm: 0.00033154612174257636\n",
      "Epoch 2, Meta Loss: 2.2778680324554443, Synthetic Data Grad Norm: 0.00030219426844269037\n",
      "Epoch 2, Meta Loss: 2.268683433532715, Synthetic Data Grad Norm: 0.000331278977682814\n",
      "Epoch 2, Meta Loss: 2.2710089683532715, Synthetic Data Grad Norm: 0.00023538712412118912\n",
      "Epoch 2, Meta Loss: 2.2577719688415527, Synthetic Data Grad Norm: 0.0003999988839495927\n",
      "Epoch 2, Meta Loss: 2.2788264751434326, Synthetic Data Grad Norm: 0.00028728728648275137\n",
      "Epoch 2, Meta Loss: 2.295301675796509, Synthetic Data Grad Norm: 0.000257433537626639\n",
      "Epoch 2, Meta Loss: 2.272010564804077, Synthetic Data Grad Norm: 0.0002389104920439422\n",
      "Epoch 2, Meta Loss: 2.278125286102295, Synthetic Data Grad Norm: 0.0003153419238515198\n",
      "Epoch 2, Meta Loss: 2.296567678451538, Synthetic Data Grad Norm: 0.00020204710017424077\n",
      "Epoch 2, Meta Loss: 2.2796661853790283, Synthetic Data Grad Norm: 0.00026132987113669515\n",
      "Epoch 2, Meta Loss: 2.2980732917785645, Synthetic Data Grad Norm: 0.00039761600783094764\n",
      "Epoch 2, Meta Loss: 2.286940813064575, Synthetic Data Grad Norm: 0.00024371537438128144\n",
      "Epoch 2, Meta Loss: 2.269629716873169, Synthetic Data Grad Norm: 0.00026253124815411866\n",
      "Epoch 2, Meta Loss: 2.2761073112487793, Synthetic Data Grad Norm: 0.0002588944917079061\n",
      "Epoch 2, Meta Loss: 2.263216972351074, Synthetic Data Grad Norm: 0.00034706288715824485\n",
      "Epoch 2, Meta Loss: 2.2883126735687256, Synthetic Data Grad Norm: 0.0002398111973889172\n",
      "Epoch 2, Meta Loss: 2.2786355018615723, Synthetic Data Grad Norm: 0.0002909197355620563\n",
      "Epoch 2, Meta Loss: 2.2752654552459717, Synthetic Data Grad Norm: 0.0002520378911867738\n",
      "Epoch 2, Meta Loss: 2.269721508026123, Synthetic Data Grad Norm: 0.0004046382091473788\n",
      "Epoch 2, Meta Loss: 2.2594709396362305, Synthetic Data Grad Norm: 0.00041426828829571605\n",
      "Epoch 2, Meta Loss: 2.2700090408325195, Synthetic Data Grad Norm: 0.00030809539020992815\n",
      "Epoch 2, Meta Loss: 2.2944788932800293, Synthetic Data Grad Norm: 0.00026190964854322374\n",
      "Epoch 2, Meta Loss: 2.271712303161621, Synthetic Data Grad Norm: 0.0002712871937546879\n",
      "Epoch 2, Meta Loss: 2.2963171005249023, Synthetic Data Grad Norm: 0.0002552090445533395\n",
      "Epoch 2, Meta Loss: 2.2884163856506348, Synthetic Data Grad Norm: 0.0002587717608548701\n",
      "Epoch 2, Meta Loss: 2.254138231277466, Synthetic Data Grad Norm: 0.0003337449743412435\n",
      "Epoch 2, Meta Loss: 2.264768362045288, Synthetic Data Grad Norm: 0.00027582774055190384\n",
      "Epoch 2, Meta Loss: 2.2850465774536133, Synthetic Data Grad Norm: 0.00027182817575521767\n",
      "Epoch 2, Meta Loss: 2.2960002422332764, Synthetic Data Grad Norm: 0.0002608762006275356\n",
      "Epoch 2, Meta Loss: 2.2890453338623047, Synthetic Data Grad Norm: 0.00033317002817057073\n",
      "Epoch 2, Meta Loss: 2.2628653049468994, Synthetic Data Grad Norm: 0.00024927244521677494\n",
      "Epoch 2, Meta Loss: 2.283101797103882, Synthetic Data Grad Norm: 0.0002652541734278202\n",
      "Epoch 2, Meta Loss: 2.2779831886291504, Synthetic Data Grad Norm: 0.00029828111291863024\n",
      "Epoch 2, Meta Loss: 2.2706258296966553, Synthetic Data Grad Norm: 0.0003858779964502901\n",
      "Epoch 2, Meta Loss: 2.2888991832733154, Synthetic Data Grad Norm: 0.0003323366108816117\n",
      "Epoch 2, Meta Loss: 2.259974479675293, Synthetic Data Grad Norm: 0.0003718618827406317\n",
      "Epoch 2, Meta Loss: 2.2800843715667725, Synthetic Data Grad Norm: 0.00024280262005049735\n",
      "Epoch 2, Meta Loss: 2.293456792831421, Synthetic Data Grad Norm: 0.0002600250008981675\n",
      "Epoch 2, Meta Loss: 2.288370370864868, Synthetic Data Grad Norm: 0.0002459680545143783\n",
      "Epoch 2, Meta Loss: 2.2889885902404785, Synthetic Data Grad Norm: 0.0002810928563121706\n",
      "Epoch 2, Meta Loss: 2.2717273235321045, Synthetic Data Grad Norm: 0.00023549696197733283\n",
      "Epoch 2, Meta Loss: 2.2881476879119873, Synthetic Data Grad Norm: 0.00024321603996213526\n",
      "Epoch 2, Meta Loss: 2.2734758853912354, Synthetic Data Grad Norm: 0.0003445903130341321\n",
      "Epoch 2, Meta Loss: 2.2827460765838623, Synthetic Data Grad Norm: 0.0002837886568158865\n",
      "Epoch 2, Meta Loss: 2.2954280376434326, Synthetic Data Grad Norm: 0.0003166391688864678\n",
      "Epoch 2, Meta Loss: 2.2801849842071533, Synthetic Data Grad Norm: 0.00024351081810891628\n",
      "Epoch 2, Meta Loss: 2.2812211513519287, Synthetic Data Grad Norm: 0.00028122542425990105\n",
      "Epoch 2, Meta Loss: 2.2869815826416016, Synthetic Data Grad Norm: 0.0002108313055941835\n",
      "Epoch 2, Meta Loss: 2.2678794860839844, Synthetic Data Grad Norm: 0.0005098314140923321\n",
      "Epoch 2, Meta Loss: 2.287935972213745, Synthetic Data Grad Norm: 0.0002476890804246068\n",
      "Epoch 2, Meta Loss: 2.269587993621826, Synthetic Data Grad Norm: 0.00026379607152193785\n",
      "Epoch 2, Meta Loss: 2.284475326538086, Synthetic Data Grad Norm: 0.0002597081183921546\n",
      "Epoch 2, Meta Loss: 2.286595344543457, Synthetic Data Grad Norm: 0.000255682913120836\n",
      "Epoch 2, Meta Loss: 2.2790727615356445, Synthetic Data Grad Norm: 0.0002952701470348984\n",
      "Epoch 2, Meta Loss: 2.276956796646118, Synthetic Data Grad Norm: 0.00031554599991068244\n",
      "Epoch 2, Meta Loss: 2.2826292514801025, Synthetic Data Grad Norm: 0.00034265543217770755\n",
      "Epoch 2, Meta Loss: 2.285278797149658, Synthetic Data Grad Norm: 0.0001678282133070752\n",
      "Epoch 2, Meta Loss: 2.2890899181365967, Synthetic Data Grad Norm: 0.00023961775877978653\n",
      "Epoch 2, Meta Loss: 2.29691219329834, Synthetic Data Grad Norm: 0.000258506101090461\n",
      "Epoch 2, Meta Loss: 2.253304958343506, Synthetic Data Grad Norm: 0.0002241654583485797\n",
      "Epoch 2, Meta Loss: 2.2758607864379883, Synthetic Data Grad Norm: 0.00041558666271157563\n",
      "Epoch 2, Meta Loss: 2.270915985107422, Synthetic Data Grad Norm: 0.0002438697702018544\n",
      "Epoch 2, Meta Loss: 2.250995635986328, Synthetic Data Grad Norm: 0.00038396482705138624\n",
      "Epoch 2, Meta Loss: 2.2829642295837402, Synthetic Data Grad Norm: 0.00029939680825918913\n",
      "Epoch 2, Meta Loss: 2.2986795902252197, Synthetic Data Grad Norm: 0.00026937428629025817\n",
      "Epoch 2, Meta Loss: 2.2861664295196533, Synthetic Data Grad Norm: 0.00033406700822524726\n",
      "Epoch 2, Meta Loss: 2.269488573074341, Synthetic Data Grad Norm: 0.0003507389046717435\n",
      "Epoch 2, Meta Loss: 2.2934224605560303, Synthetic Data Grad Norm: 0.00027298295754007995\n",
      "Epoch 2, Meta Loss: 2.2913856506347656, Synthetic Data Grad Norm: 0.00027548137586563826\n",
      "Epoch 2, Meta Loss: 2.287504196166992, Synthetic Data Grad Norm: 0.00022504580556415021\n",
      "Epoch 2, Meta Loss: 2.2774574756622314, Synthetic Data Grad Norm: 0.00020009191939607263\n",
      "Epoch 2, Meta Loss: 2.262019157409668, Synthetic Data Grad Norm: 0.00030339843942783773\n",
      "Epoch 2, Meta Loss: 2.2819669246673584, Synthetic Data Grad Norm: 0.00025075735175050795\n",
      "Epoch 2, Meta Loss: 2.3076353073120117, Synthetic Data Grad Norm: 0.0002769827551674098\n",
      "Epoch 2, Meta Loss: 2.2864792346954346, Synthetic Data Grad Norm: 0.00023764603247400373\n",
      "Epoch 2, Meta Loss: 2.2869620323181152, Synthetic Data Grad Norm: 0.0003689770819619298\n",
      "Epoch 2, Meta Loss: 2.2951934337615967, Synthetic Data Grad Norm: 0.00025492359418421984\n",
      "Epoch 2, Meta Loss: 2.2768197059631348, Synthetic Data Grad Norm: 0.0002593194367364049\n",
      "Epoch 2, Meta Loss: 2.3008596897125244, Synthetic Data Grad Norm: 0.0002995934628415853\n",
      "Epoch 2, Meta Loss: 2.27634334564209, Synthetic Data Grad Norm: 0.0002974277304019779\n",
      "Epoch 2, Meta Loss: 2.256995439529419, Synthetic Data Grad Norm: 0.0003348472237121314\n",
      "Epoch 2, Meta Loss: 2.278918743133545, Synthetic Data Grad Norm: 0.000207961376872845\n",
      "Epoch 2, Meta Loss: 2.282963514328003, Synthetic Data Grad Norm: 0.0003759705286938697\n",
      "Epoch 2, Meta Loss: 2.2850546836853027, Synthetic Data Grad Norm: 0.00039724435191601515\n",
      "Epoch 2, Meta Loss: 2.312269926071167, Synthetic Data Grad Norm: 0.00020518100063782185\n",
      "Epoch 2, Meta Loss: 2.2965734004974365, Synthetic Data Grad Norm: 0.00025321461725980043\n",
      "Epoch 2, Meta Loss: 2.278897285461426, Synthetic Data Grad Norm: 0.0002850867167580873\n",
      "Epoch 2, Meta Loss: 2.282052516937256, Synthetic Data Grad Norm: 0.00029106088913977146\n",
      "Epoch 2, Meta Loss: 2.270878553390503, Synthetic Data Grad Norm: 0.0002745618112385273\n",
      "Epoch 2, Meta Loss: 2.2683281898498535, Synthetic Data Grad Norm: 0.00026845047250390053\n",
      "Epoch 2, Meta Loss: 2.2941572666168213, Synthetic Data Grad Norm: 0.0001875439629657194\n",
      "Epoch 2, Meta Loss: 2.272075891494751, Synthetic Data Grad Norm: 0.0003151899727527052\n",
      "Epoch 2, Meta Loss: 2.2649073600769043, Synthetic Data Grad Norm: 0.0003118645690847188\n",
      "Epoch 2, Meta Loss: 2.277956008911133, Synthetic Data Grad Norm: 0.00017518545791972429\n",
      "Epoch 2, Meta Loss: 2.2931313514709473, Synthetic Data Grad Norm: 0.00022248088498599827\n",
      "Epoch 2, Meta Loss: 2.2864439487457275, Synthetic Data Grad Norm: 0.0003002125013154\n",
      "Epoch 2, Meta Loss: 2.2768118381500244, Synthetic Data Grad Norm: 0.0002803470124490559\n",
      "Epoch 2, Meta Loss: 2.29492449760437, Synthetic Data Grad Norm: 0.0002756280009634793\n",
      "Epoch 2, Meta Loss: 2.2777023315429688, Synthetic Data Grad Norm: 0.00024805229622870684\n",
      "Epoch 2, Meta Loss: 2.2618768215179443, Synthetic Data Grad Norm: 0.00027766876155510545\n",
      "Epoch 2, Meta Loss: 2.292651414871216, Synthetic Data Grad Norm: 0.0002580675936769694\n",
      "Epoch 2, Meta Loss: 2.2983531951904297, Synthetic Data Grad Norm: 0.0001849303807830438\n",
      "Epoch 2, Meta Loss: 2.273564338684082, Synthetic Data Grad Norm: 0.00024737155763432384\n",
      "Epoch 2, Meta Loss: 2.2820217609405518, Synthetic Data Grad Norm: 0.00025577322230674326\n",
      "Epoch 2, Meta Loss: 2.2823989391326904, Synthetic Data Grad Norm: 0.00019805147894658148\n",
      "Epoch 2, Meta Loss: 2.26896071434021, Synthetic Data Grad Norm: 0.00027964552282355726\n",
      "Epoch 2, Meta Loss: 2.288346529006958, Synthetic Data Grad Norm: 0.0002445597783662379\n",
      "Epoch 2, Meta Loss: 2.2987563610076904, Synthetic Data Grad Norm: 0.00023246125783771276\n",
      "Epoch 2, Meta Loss: 2.2783241271972656, Synthetic Data Grad Norm: 0.0002446349826641381\n",
      "Epoch 2, Meta Loss: 2.259336233139038, Synthetic Data Grad Norm: 0.00038843537913635373\n",
      "Epoch 2, Meta Loss: 2.2827067375183105, Synthetic Data Grad Norm: 0.000307373033137992\n",
      "Epoch 2, Meta Loss: 2.295437812805176, Synthetic Data Grad Norm: 0.00024418928660452366\n",
      "Epoch 2, Meta Loss: 2.292175769805908, Synthetic Data Grad Norm: 0.00025062679196707904\n",
      "Epoch 2, Meta Loss: 2.2844796180725098, Synthetic Data Grad Norm: 0.00037094493745826185\n",
      "Epoch 2, Meta Loss: 2.2761292457580566, Synthetic Data Grad Norm: 0.00022968176926951855\n",
      "Epoch 2, Meta Loss: 2.2782835960388184, Synthetic Data Grad Norm: 0.00033312998129986227\n",
      "Epoch 2, Meta Loss: 2.2765610218048096, Synthetic Data Grad Norm: 0.0002374192263232544\n",
      "Epoch 2, Meta Loss: 2.285013198852539, Synthetic Data Grad Norm: 0.0003157535975333303\n",
      "Epoch 2, Meta Loss: 2.2721922397613525, Synthetic Data Grad Norm: 0.0002578207349870354\n",
      "Epoch 2, Meta Loss: 2.270444869995117, Synthetic Data Grad Norm: 0.0002527614706195891\n",
      "Epoch 2, Meta Loss: 2.2730331420898438, Synthetic Data Grad Norm: 0.00024200712505262345\n",
      "Epoch 2, Meta Loss: 2.284712076187134, Synthetic Data Grad Norm: 0.00023316111764870584\n",
      "Epoch 2, Meta Loss: 2.254692316055298, Synthetic Data Grad Norm: 0.00030195608269423246\n",
      "Epoch 2, Meta Loss: 2.275533437728882, Synthetic Data Grad Norm: 0.0002075610973406583\n",
      "Epoch 2, Meta Loss: 2.2655835151672363, Synthetic Data Grad Norm: 0.00023699326266068965\n",
      "Epoch 2, Meta Loss: 2.286179780960083, Synthetic Data Grad Norm: 0.00031176311313174665\n",
      "Epoch 2, Meta Loss: 2.2737820148468018, Synthetic Data Grad Norm: 0.0003390850033611059\n",
      "Epoch 2, Meta Loss: 2.277634382247925, Synthetic Data Grad Norm: 0.00026182696456089616\n",
      "Epoch 2, Meta Loss: 2.2730636596679688, Synthetic Data Grad Norm: 0.0002553812228143215\n",
      "Epoch 2, Meta Loss: 2.2797482013702393, Synthetic Data Grad Norm: 0.0002804310352075845\n",
      "Epoch 2, Meta Loss: 2.3015658855438232, Synthetic Data Grad Norm: 0.00029846522375009954\n",
      "Epoch 2, Meta Loss: 2.2323288917541504, Synthetic Data Grad Norm: 0.0003112073754891753\n",
      "Epoch 2, Meta Loss: 2.285022258758545, Synthetic Data Grad Norm: 0.0002444105630274862\n",
      "Epoch 2, Meta Loss: 2.2768542766571045, Synthetic Data Grad Norm: 0.00030298272031359375\n",
      "Epoch 2, Meta Loss: 2.2889792919158936, Synthetic Data Grad Norm: 0.00018449407070875168\n",
      "Epoch 2, Meta Loss: 2.261366605758667, Synthetic Data Grad Norm: 0.0003179252380505204\n",
      "Epoch 2, Meta Loss: 2.274915933609009, Synthetic Data Grad Norm: 0.0003450848162174225\n",
      "Epoch 2, Meta Loss: 2.2953102588653564, Synthetic Data Grad Norm: 0.00029813230503350496\n",
      "Epoch 2, Meta Loss: 2.281559944152832, Synthetic Data Grad Norm: 0.00023212497762870044\n",
      "Epoch 2, Meta Loss: 2.2817094326019287, Synthetic Data Grad Norm: 0.0003022087039425969\n",
      "Epoch 2, Meta Loss: 2.279127359390259, Synthetic Data Grad Norm: 0.00026014051400125027\n",
      "Epoch 2, Meta Loss: 2.2851831912994385, Synthetic Data Grad Norm: 0.0001462542568333447\n",
      "Epoch 2, Meta Loss: 2.2663028240203857, Synthetic Data Grad Norm: 0.0002872918266803026\n",
      "Epoch 2, Meta Loss: 2.289238214492798, Synthetic Data Grad Norm: 0.00018950505182147026\n",
      "Epoch 2, Meta Loss: 2.284048080444336, Synthetic Data Grad Norm: 0.0003281295648775995\n",
      "Epoch 2, Meta Loss: 2.2864491939544678, Synthetic Data Grad Norm: 0.00021629866387229413\n",
      "Epoch 2, Meta Loss: 2.2926578521728516, Synthetic Data Grad Norm: 0.0002884279820136726\n",
      "Epoch 2, Meta Loss: 2.3053557872772217, Synthetic Data Grad Norm: 0.00030267066904343665\n",
      "Epoch 2, Meta Loss: 2.2735443115234375, Synthetic Data Grad Norm: 0.0002491945051588118\n",
      "Epoch 2, Meta Loss: 2.2971036434173584, Synthetic Data Grad Norm: 0.0002692096750251949\n",
      "Epoch 2, Meta Loss: 2.2503530979156494, Synthetic Data Grad Norm: 0.00037036629510112107\n",
      "Epoch 2, Meta Loss: 2.297292709350586, Synthetic Data Grad Norm: 0.0002782878000289202\n",
      "Epoch 2, Meta Loss: 2.2789673805236816, Synthetic Data Grad Norm: 0.0002609653165563941\n",
      "Epoch 2, Meta Loss: 2.2922275066375732, Synthetic Data Grad Norm: 0.00028704185388050973\n",
      "Epoch 2, Meta Loss: 2.2735536098480225, Synthetic Data Grad Norm: 0.00021272389858495444\n",
      "Epoch 2, Meta Loss: 2.276188850402832, Synthetic Data Grad Norm: 0.00024078693240880966\n",
      "Epoch 2, Meta Loss: 2.2897732257843018, Synthetic Data Grad Norm: 0.00022918997274246067\n",
      "Epoch 2, Meta Loss: 2.2717504501342773, Synthetic Data Grad Norm: 0.0003694723709486425\n",
      "Epoch 2, Meta Loss: 2.2937076091766357, Synthetic Data Grad Norm: 0.0002631087845657021\n",
      "Epoch 2, Meta Loss: 2.259740114212036, Synthetic Data Grad Norm: 0.00032432485022582114\n",
      "Epoch 2, Meta Loss: 2.2944812774658203, Synthetic Data Grad Norm: 0.00022508090478368104\n",
      "Epoch 2, Meta Loss: 2.268693447113037, Synthetic Data Grad Norm: 0.0002516069798730314\n",
      "Epoch 2, Meta Loss: 2.293543815612793, Synthetic Data Grad Norm: 0.0003888780775014311\n",
      "Epoch 2, Meta Loss: 2.2671351432800293, Synthetic Data Grad Norm: 0.0003036574926227331\n",
      "Epoch 2, Meta Loss: 2.264111042022705, Synthetic Data Grad Norm: 0.00031878810841590166\n",
      "Epoch 2, Meta Loss: 2.2907938957214355, Synthetic Data Grad Norm: 0.00027091766241937876\n",
      "Epoch 2, Meta Loss: 2.2717764377593994, Synthetic Data Grad Norm: 0.00026084642740897834\n",
      "Epoch 2, Meta Loss: 2.2670278549194336, Synthetic Data Grad Norm: 0.0002481810515746474\n",
      "Epoch 2, Meta Loss: 2.279960870742798, Synthetic Data Grad Norm: 0.00025512059801258147\n",
      "Epoch 2, Meta Loss: 2.2762084007263184, Synthetic Data Grad Norm: 0.0002767516125459224\n",
      "Epoch 2, Meta Loss: 2.280498504638672, Synthetic Data Grad Norm: 0.00032225725590251386\n",
      "Epoch 2, Meta Loss: 2.283726215362549, Synthetic Data Grad Norm: 0.00029791370616294444\n",
      "Epoch 2, Meta Loss: 2.290709972381592, Synthetic Data Grad Norm: 0.00024727676645852625\n",
      "Epoch 2, Meta Loss: 2.275123357772827, Synthetic Data Grad Norm: 0.0003430635260883719\n",
      "Epoch 2, Meta Loss: 2.2670085430145264, Synthetic Data Grad Norm: 0.0003102917689830065\n",
      "Epoch 2, Meta Loss: 2.278942584991455, Synthetic Data Grad Norm: 0.00022108519624453038\n",
      "Epoch 2, Meta Loss: 2.294544219970703, Synthetic Data Grad Norm: 0.000544041336979717\n",
      "Epoch 2, Meta Loss: 2.2878518104553223, Synthetic Data Grad Norm: 0.0002940307604148984\n",
      "Epoch 2, Meta Loss: 2.258208990097046, Synthetic Data Grad Norm: 0.00028826610650867224\n",
      "Epoch 2, Meta Loss: 2.2861716747283936, Synthetic Data Grad Norm: 0.00029405378154478967\n",
      "Epoch 2, Meta Loss: 2.279061794281006, Synthetic Data Grad Norm: 0.00029788774554617703\n",
      "Epoch 2, Meta Loss: 2.2792227268218994, Synthetic Data Grad Norm: 0.00028816336998715997\n",
      "Epoch 2, Meta Loss: 2.2964365482330322, Synthetic Data Grad Norm: 0.0003802597348112613\n",
      "Epoch 2, Meta Loss: 2.2658634185791016, Synthetic Data Grad Norm: 0.0003530189278535545\n",
      "Epoch 2, Meta Loss: 2.2710378170013428, Synthetic Data Grad Norm: 0.0003144863876514137\n",
      "Epoch 2, Meta Loss: 2.26804518699646, Synthetic Data Grad Norm: 0.0003140901098959148\n",
      "Epoch 2, Meta Loss: 2.2856032848358154, Synthetic Data Grad Norm: 0.00024879135889932513\n",
      "Epoch 2, Meta Loss: 2.29075288772583, Synthetic Data Grad Norm: 0.00028123316587880254\n",
      "Epoch 2, Meta Loss: 2.2866532802581787, Synthetic Data Grad Norm: 0.00031928965472616255\n",
      "Epoch 2, Meta Loss: 2.251344919204712, Synthetic Data Grad Norm: 0.0003665435069706291\n",
      "Epoch 2, Meta Loss: 2.270787239074707, Synthetic Data Grad Norm: 0.00034583566593937576\n",
      "Epoch 2, Meta Loss: 2.286989688873291, Synthetic Data Grad Norm: 0.00031279458198696375\n",
      "Epoch 2, Meta Loss: 2.289217233657837, Synthetic Data Grad Norm: 0.0003591892309486866\n",
      "Epoch 2, Meta Loss: 2.284191608428955, Synthetic Data Grad Norm: 0.00037427834467962384\n",
      "Epoch 2, Meta Loss: 2.2863693237304688, Synthetic Data Grad Norm: 0.0002773967571556568\n",
      "Epoch 2, Meta Loss: 2.276695966720581, Synthetic Data Grad Norm: 0.0003479532024357468\n",
      "Epoch 2, Meta Loss: 2.270364284515381, Synthetic Data Grad Norm: 0.00032005031243897974\n",
      "Epoch 2, Meta Loss: 2.3041622638702393, Synthetic Data Grad Norm: 0.00023170311760623008\n",
      "Epoch 2, Meta Loss: 2.280547618865967, Synthetic Data Grad Norm: 0.0003545376530382782\n",
      "Epoch 2, Meta Loss: 2.294508934020996, Synthetic Data Grad Norm: 0.0003019188006874174\n",
      "Epoch 2, Meta Loss: 2.277984142303467, Synthetic Data Grad Norm: 0.00027424126164987683\n",
      "Epoch 2, Meta Loss: 2.2658047676086426, Synthetic Data Grad Norm: 0.0002834976476151496\n",
      "Epoch 2, Meta Loss: 2.272526979446411, Synthetic Data Grad Norm: 0.00024809595197439194\n",
      "Epoch 2, Meta Loss: 2.277519464492798, Synthetic Data Grad Norm: 0.00027336933999322355\n",
      "Epoch 2, Meta Loss: 2.2884111404418945, Synthetic Data Grad Norm: 0.00030236950260587037\n",
      "Epoch 2, Meta Loss: 2.2981388568878174, Synthetic Data Grad Norm: 0.00033721158979460597\n",
      "Epoch 2, Meta Loss: 2.2900190353393555, Synthetic Data Grad Norm: 0.000341056875186041\n",
      "Epoch 2, Meta Loss: 2.2706944942474365, Synthetic Data Grad Norm: 0.0002962919243145734\n",
      "Epoch 2, Meta Loss: 2.318969488143921, Synthetic Data Grad Norm: 0.0002517153916414827\n",
      "Epoch 2, Meta Loss: 2.2951416969299316, Synthetic Data Grad Norm: 0.0003541687037795782\n",
      "Epoch 2, Meta Loss: 2.276916027069092, Synthetic Data Grad Norm: 0.00034660042729228735\n",
      "Epoch 3, Meta Loss: 2.2832350730895996, Synthetic Data Grad Norm: 0.00021859158005099744\n",
      "Epoch 3, Meta Loss: 2.29206919670105, Synthetic Data Grad Norm: 0.00021946158085484058\n",
      "Epoch 3, Meta Loss: 2.3005294799804688, Synthetic Data Grad Norm: 0.0002277636667713523\n",
      "Epoch 3, Meta Loss: 2.2818515300750732, Synthetic Data Grad Norm: 0.00032501789974048734\n",
      "Epoch 3, Meta Loss: 2.2875277996063232, Synthetic Data Grad Norm: 0.0002829193836078048\n",
      "Epoch 3, Meta Loss: 2.271897792816162, Synthetic Data Grad Norm: 0.00032843343797139823\n",
      "Epoch 3, Meta Loss: 2.3110992908477783, Synthetic Data Grad Norm: 0.0003094542189501226\n",
      "Epoch 3, Meta Loss: 2.294095754623413, Synthetic Data Grad Norm: 0.0002469513565301895\n",
      "Epoch 3, Meta Loss: 2.2903711795806885, Synthetic Data Grad Norm: 0.0002058338577626273\n",
      "Epoch 3, Meta Loss: 2.2428038120269775, Synthetic Data Grad Norm: 0.00035180558916181326\n",
      "Epoch 3, Meta Loss: 2.276015520095825, Synthetic Data Grad Norm: 0.000295802834443748\n",
      "Epoch 3, Meta Loss: 2.2942824363708496, Synthetic Data Grad Norm: 0.0003711127501446754\n",
      "Epoch 3, Meta Loss: 2.273805618286133, Synthetic Data Grad Norm: 0.00027853529900312424\n",
      "Epoch 3, Meta Loss: 2.2731313705444336, Synthetic Data Grad Norm: 0.00026683034957386553\n",
      "Epoch 3, Meta Loss: 2.271365165710449, Synthetic Data Grad Norm: 0.00024583496269769967\n",
      "Epoch 3, Meta Loss: 2.296562910079956, Synthetic Data Grad Norm: 0.00024199628387577832\n",
      "Epoch 3, Meta Loss: 2.272250175476074, Synthetic Data Grad Norm: 0.00023923107073642313\n",
      "Epoch 3, Meta Loss: 2.2815492153167725, Synthetic Data Grad Norm: 0.00020668240904342383\n",
      "Epoch 3, Meta Loss: 2.2651426792144775, Synthetic Data Grad Norm: 0.00031117023900151253\n",
      "Epoch 3, Meta Loss: 2.2839643955230713, Synthetic Data Grad Norm: 0.0002761087380349636\n",
      "Epoch 3, Meta Loss: 2.2761778831481934, Synthetic Data Grad Norm: 0.00023838818015065044\n",
      "Epoch 3, Meta Loss: 2.2910845279693604, Synthetic Data Grad Norm: 0.00022346354671753943\n",
      "Epoch 3, Meta Loss: 2.2936463356018066, Synthetic Data Grad Norm: 0.00028132120496593416\n",
      "Epoch 3, Meta Loss: 2.2679519653320312, Synthetic Data Grad Norm: 0.00026915440685115755\n",
      "Epoch 3, Meta Loss: 2.2801175117492676, Synthetic Data Grad Norm: 0.000316038029268384\n",
      "Epoch 3, Meta Loss: 2.2979493141174316, Synthetic Data Grad Norm: 0.00025899545289576054\n",
      "Epoch 3, Meta Loss: 2.269012689590454, Synthetic Data Grad Norm: 0.00033580127637833357\n",
      "Epoch 3, Meta Loss: 2.2867343425750732, Synthetic Data Grad Norm: 0.00027379882521927357\n",
      "Epoch 3, Meta Loss: 2.2775394916534424, Synthetic Data Grad Norm: 0.00027459728880785406\n",
      "Epoch 3, Meta Loss: 2.261953592300415, Synthetic Data Grad Norm: 0.00033267211983911693\n",
      "Epoch 3, Meta Loss: 2.2851643562316895, Synthetic Data Grad Norm: 0.00026756548322737217\n",
      "Epoch 3, Meta Loss: 2.281240940093994, Synthetic Data Grad Norm: 0.000275117956334725\n",
      "Epoch 3, Meta Loss: 2.266430377960205, Synthetic Data Grad Norm: 0.0003870429063681513\n",
      "Epoch 3, Meta Loss: 2.297231435775757, Synthetic Data Grad Norm: 0.00026216558762826025\n",
      "Epoch 3, Meta Loss: 2.265646457672119, Synthetic Data Grad Norm: 0.000391784735256806\n",
      "Epoch 3, Meta Loss: 2.2892541885375977, Synthetic Data Grad Norm: 0.0003654411993920803\n",
      "Epoch 3, Meta Loss: 2.2744855880737305, Synthetic Data Grad Norm: 0.000264514033915475\n",
      "Epoch 3, Meta Loss: 2.2760751247406006, Synthetic Data Grad Norm: 0.0002415045746602118\n",
      "Epoch 3, Meta Loss: 2.272480010986328, Synthetic Data Grad Norm: 0.00029253747197799385\n",
      "Epoch 3, Meta Loss: 2.2768900394439697, Synthetic Data Grad Norm: 0.00026792698190547526\n",
      "Epoch 3, Meta Loss: 2.2639286518096924, Synthetic Data Grad Norm: 0.00035738485166803\n",
      "Epoch 3, Meta Loss: 2.2782154083251953, Synthetic Data Grad Norm: 0.0004658276739064604\n",
      "Epoch 3, Meta Loss: 2.2823238372802734, Synthetic Data Grad Norm: 0.0003226261760573834\n",
      "Epoch 3, Meta Loss: 2.290419578552246, Synthetic Data Grad Norm: 0.00027936630067415535\n",
      "Epoch 3, Meta Loss: 2.2814629077911377, Synthetic Data Grad Norm: 0.0002527848700992763\n",
      "Epoch 3, Meta Loss: 2.2834651470184326, Synthetic Data Grad Norm: 0.00028448051307350397\n",
      "Epoch 3, Meta Loss: 2.2808778285980225, Synthetic Data Grad Norm: 0.00024543417384848\n",
      "Epoch 3, Meta Loss: 2.2931342124938965, Synthetic Data Grad Norm: 0.00022266017913352698\n",
      "Epoch 3, Meta Loss: 2.287759304046631, Synthetic Data Grad Norm: 0.0002508690522518009\n",
      "Epoch 3, Meta Loss: 2.288562774658203, Synthetic Data Grad Norm: 0.00029144337167963386\n",
      "Epoch 3, Meta Loss: 2.2789466381073, Synthetic Data Grad Norm: 0.0002553221129346639\n",
      "Epoch 3, Meta Loss: 2.287874698638916, Synthetic Data Grad Norm: 0.00024365310673601925\n",
      "Epoch 3, Meta Loss: 2.2868313789367676, Synthetic Data Grad Norm: 0.00039068330079317093\n",
      "Epoch 3, Meta Loss: 2.2690505981445312, Synthetic Data Grad Norm: 0.0003538549062795937\n",
      "Epoch 3, Meta Loss: 2.275888442993164, Synthetic Data Grad Norm: 0.00027050322387367487\n",
      "Epoch 3, Meta Loss: 2.2612240314483643, Synthetic Data Grad Norm: 0.00032626959728077054\n",
      "Epoch 3, Meta Loss: 2.2864561080932617, Synthetic Data Grad Norm: 0.00023786576639395207\n",
      "Epoch 3, Meta Loss: 2.2780885696411133, Synthetic Data Grad Norm: 0.0002811675367411226\n",
      "Epoch 3, Meta Loss: 2.3025314807891846, Synthetic Data Grad Norm: 0.000263498310232535\n",
      "Epoch 3, Meta Loss: 2.273080587387085, Synthetic Data Grad Norm: 0.00026434092433191836\n",
      "Epoch 3, Meta Loss: 2.259453058242798, Synthetic Data Grad Norm: 0.000311568146571517\n",
      "Epoch 3, Meta Loss: 2.283708095550537, Synthetic Data Grad Norm: 0.00027425558073446155\n",
      "Epoch 3, Meta Loss: 2.289539337158203, Synthetic Data Grad Norm: 0.0002469973696861416\n",
      "Epoch 3, Meta Loss: 2.292283296585083, Synthetic Data Grad Norm: 0.00027656235033646226\n",
      "Epoch 3, Meta Loss: 2.2834885120391846, Synthetic Data Grad Norm: 0.0001919930218718946\n",
      "Epoch 3, Meta Loss: 2.291821002960205, Synthetic Data Grad Norm: 0.00025544827803969383\n",
      "Epoch 3, Meta Loss: 2.2553699016571045, Synthetic Data Grad Norm: 0.0003466795606072992\n",
      "Epoch 3, Meta Loss: 2.270548105239868, Synthetic Data Grad Norm: 0.0002913727075792849\n",
      "Epoch 3, Meta Loss: 2.2684192657470703, Synthetic Data Grad Norm: 0.000333959556883201\n",
      "Epoch 3, Meta Loss: 2.258962392807007, Synthetic Data Grad Norm: 0.00033870895276777446\n",
      "Epoch 3, Meta Loss: 2.278709888458252, Synthetic Data Grad Norm: 0.00030790260643698275\n",
      "Epoch 3, Meta Loss: 2.2767510414123535, Synthetic Data Grad Norm: 0.00028782396111637354\n",
      "Epoch 3, Meta Loss: 2.275639533996582, Synthetic Data Grad Norm: 0.0002707450184971094\n",
      "Epoch 3, Meta Loss: 2.2896604537963867, Synthetic Data Grad Norm: 0.00027080101426690817\n",
      "Epoch 3, Meta Loss: 2.281810998916626, Synthetic Data Grad Norm: 0.00029467567219398916\n",
      "Epoch 3, Meta Loss: 2.257469415664673, Synthetic Data Grad Norm: 0.0002911227638833225\n",
      "Epoch 3, Meta Loss: 2.284761428833008, Synthetic Data Grad Norm: 0.00030023889848962426\n",
      "Epoch 3, Meta Loss: 2.317316770553589, Synthetic Data Grad Norm: 0.00030482426518574357\n",
      "Epoch 3, Meta Loss: 2.2853548526763916, Synthetic Data Grad Norm: 0.00024646861129440367\n",
      "Epoch 3, Meta Loss: 2.264756917953491, Synthetic Data Grad Norm: 0.0003285087295807898\n",
      "Epoch 3, Meta Loss: 2.2926645278930664, Synthetic Data Grad Norm: 0.00023078716185409576\n",
      "Epoch 3, Meta Loss: 2.2871479988098145, Synthetic Data Grad Norm: 0.0003201563376933336\n",
      "Epoch 3, Meta Loss: 2.2662832736968994, Synthetic Data Grad Norm: 0.0002991144428960979\n",
      "Epoch 3, Meta Loss: 2.2649588584899902, Synthetic Data Grad Norm: 0.00030623728525824845\n",
      "Epoch 3, Meta Loss: 2.2788102626800537, Synthetic Data Grad Norm: 0.0003205894317943603\n",
      "Epoch 3, Meta Loss: 2.2792375087738037, Synthetic Data Grad Norm: 0.00032700374140404165\n",
      "Epoch 3, Meta Loss: 2.2702832221984863, Synthetic Data Grad Norm: 0.00022412309772334993\n",
      "Epoch 3, Meta Loss: 2.2616515159606934, Synthetic Data Grad Norm: 0.000314527889713645\n",
      "Epoch 3, Meta Loss: 2.2978076934814453, Synthetic Data Grad Norm: 0.0002783730742521584\n",
      "Epoch 3, Meta Loss: 2.2893943786621094, Synthetic Data Grad Norm: 0.00023558587417937815\n",
      "Epoch 3, Meta Loss: 2.2658846378326416, Synthetic Data Grad Norm: 0.00027558751753531396\n",
      "Epoch 3, Meta Loss: 2.271906852722168, Synthetic Data Grad Norm: 0.00029103673296049237\n",
      "Epoch 3, Meta Loss: 2.2962286472320557, Synthetic Data Grad Norm: 0.00023943348787724972\n",
      "Epoch 3, Meta Loss: 2.272890329360962, Synthetic Data Grad Norm: 0.00021501690207514912\n",
      "Epoch 3, Meta Loss: 2.2813639640808105, Synthetic Data Grad Norm: 0.0002851711760740727\n",
      "Epoch 3, Meta Loss: 2.279139757156372, Synthetic Data Grad Norm: 0.00024812945048324764\n",
      "Epoch 3, Meta Loss: 2.2768301963806152, Synthetic Data Grad Norm: 0.00022723907022736967\n",
      "Epoch 3, Meta Loss: 2.2885522842407227, Synthetic Data Grad Norm: 0.0002989385393448174\n",
      "Epoch 3, Meta Loss: 2.280675172805786, Synthetic Data Grad Norm: 0.00026998980320058763\n",
      "Epoch 3, Meta Loss: 2.2871367931365967, Synthetic Data Grad Norm: 0.00020977755775675178\n",
      "Epoch 3, Meta Loss: 2.283600330352783, Synthetic Data Grad Norm: 0.00018959383305627853\n",
      "Epoch 3, Meta Loss: 2.2756059169769287, Synthetic Data Grad Norm: 0.0003732032491825521\n",
      "Epoch 3, Meta Loss: 2.30415940284729, Synthetic Data Grad Norm: 0.0002752382424660027\n",
      "Epoch 3, Meta Loss: 2.280906915664673, Synthetic Data Grad Norm: 0.0002755581517703831\n",
      "Epoch 3, Meta Loss: 2.2824199199676514, Synthetic Data Grad Norm: 0.00028531713178381324\n",
      "Epoch 3, Meta Loss: 2.263577938079834, Synthetic Data Grad Norm: 0.00023403519298881292\n",
      "Epoch 3, Meta Loss: 2.281572103500366, Synthetic Data Grad Norm: 0.00027599342865869403\n",
      "Epoch 3, Meta Loss: 2.2805635929107666, Synthetic Data Grad Norm: 0.00028731164638884366\n",
      "Epoch 3, Meta Loss: 2.3064675331115723, Synthetic Data Grad Norm: 0.0002647254441399127\n",
      "Epoch 3, Meta Loss: 2.283553123474121, Synthetic Data Grad Norm: 0.00030197721207514405\n",
      "Epoch 3, Meta Loss: 2.2859199047088623, Synthetic Data Grad Norm: 0.00029797651222907007\n",
      "Epoch 3, Meta Loss: 2.296685218811035, Synthetic Data Grad Norm: 0.0003303422126919031\n",
      "Epoch 3, Meta Loss: 2.2543482780456543, Synthetic Data Grad Norm: 0.0003699128865264356\n",
      "Epoch 3, Meta Loss: 2.286048412322998, Synthetic Data Grad Norm: 0.00028631402528844774\n",
      "Epoch 3, Meta Loss: 2.264132022857666, Synthetic Data Grad Norm: 0.00037045509088784456\n",
      "Epoch 3, Meta Loss: 2.2792859077453613, Synthetic Data Grad Norm: 0.00031407809001393616\n",
      "Epoch 3, Meta Loss: 2.2872073650360107, Synthetic Data Grad Norm: 0.00031000529997982085\n",
      "Epoch 3, Meta Loss: 2.286161422729492, Synthetic Data Grad Norm: 0.00025047367671504617\n",
      "Epoch 3, Meta Loss: 2.278984546661377, Synthetic Data Grad Norm: 0.00026734924176707864\n",
      "Epoch 3, Meta Loss: 2.2770049571990967, Synthetic Data Grad Norm: 0.0002901488624047488\n",
      "Epoch 3, Meta Loss: 2.282419204711914, Synthetic Data Grad Norm: 0.0002106600150000304\n",
      "Epoch 3, Meta Loss: 2.2707719802856445, Synthetic Data Grad Norm: 0.00027474912349134684\n",
      "Epoch 3, Meta Loss: 2.2774646282196045, Synthetic Data Grad Norm: 0.0002916058001574129\n",
      "Epoch 3, Meta Loss: 2.267674446105957, Synthetic Data Grad Norm: 0.00027111844974569976\n",
      "Epoch 3, Meta Loss: 2.279698371887207, Synthetic Data Grad Norm: 0.00035991056938655674\n",
      "Epoch 3, Meta Loss: 2.2786314487457275, Synthetic Data Grad Norm: 0.000272818811936304\n",
      "Epoch 3, Meta Loss: 2.285149335861206, Synthetic Data Grad Norm: 0.00033007789170369506\n",
      "Epoch 3, Meta Loss: 2.2861764430999756, Synthetic Data Grad Norm: 0.0002733322908170521\n",
      "Epoch 3, Meta Loss: 2.3047168254852295, Synthetic Data Grad Norm: 0.0002965494350064546\n",
      "Epoch 3, Meta Loss: 2.289613962173462, Synthetic Data Grad Norm: 0.00022150085715111345\n",
      "Epoch 3, Meta Loss: 2.279259443283081, Synthetic Data Grad Norm: 0.00027207640232518315\n",
      "Epoch 3, Meta Loss: 2.2792611122131348, Synthetic Data Grad Norm: 0.00019860417523887008\n",
      "Epoch 3, Meta Loss: 2.2909042835235596, Synthetic Data Grad Norm: 0.000378215714590624\n",
      "Epoch 3, Meta Loss: 2.2637600898742676, Synthetic Data Grad Norm: 0.0002838277432601899\n",
      "Epoch 3, Meta Loss: 2.276043176651001, Synthetic Data Grad Norm: 0.0003175942983943969\n",
      "Epoch 3, Meta Loss: 2.299262046813965, Synthetic Data Grad Norm: 0.00026095096836797893\n",
      "Epoch 3, Meta Loss: 2.2707571983337402, Synthetic Data Grad Norm: 0.0002649597590789199\n",
      "Epoch 3, Meta Loss: 2.28104305267334, Synthetic Data Grad Norm: 0.0003192131407558918\n",
      "Epoch 3, Meta Loss: 2.267658233642578, Synthetic Data Grad Norm: 0.00029855637694709003\n",
      "Epoch 3, Meta Loss: 2.249967098236084, Synthetic Data Grad Norm: 0.000372009671991691\n",
      "Epoch 3, Meta Loss: 2.287559747695923, Synthetic Data Grad Norm: 0.0001966138806892559\n",
      "Epoch 3, Meta Loss: 2.2773776054382324, Synthetic Data Grad Norm: 0.0002812334569171071\n",
      "Epoch 3, Meta Loss: 2.2747960090637207, Synthetic Data Grad Norm: 0.0002742743818089366\n",
      "Epoch 3, Meta Loss: 2.255554676055908, Synthetic Data Grad Norm: 0.0003459345898590982\n",
      "Epoch 3, Meta Loss: 2.255969524383545, Synthetic Data Grad Norm: 0.000309368857415393\n",
      "Epoch 3, Meta Loss: 2.268341541290283, Synthetic Data Grad Norm: 0.00030003662686794996\n",
      "Epoch 3, Meta Loss: 2.2733776569366455, Synthetic Data Grad Norm: 0.000333133531967178\n",
      "Epoch 3, Meta Loss: 2.268540382385254, Synthetic Data Grad Norm: 0.00027406233130022883\n",
      "Epoch 3, Meta Loss: 2.2939820289611816, Synthetic Data Grad Norm: 0.00034151121508330107\n",
      "Epoch 3, Meta Loss: 2.280573844909668, Synthetic Data Grad Norm: 0.0003181037027388811\n",
      "Epoch 3, Meta Loss: 2.26166033744812, Synthetic Data Grad Norm: 0.00020428789139259607\n",
      "Epoch 3, Meta Loss: 2.284914255142212, Synthetic Data Grad Norm: 0.0002656359865795821\n",
      "Epoch 3, Meta Loss: 2.2745864391326904, Synthetic Data Grad Norm: 0.0002805342373903841\n",
      "Epoch 3, Meta Loss: 2.2748944759368896, Synthetic Data Grad Norm: 0.0003677811473608017\n",
      "Epoch 3, Meta Loss: 2.286803722381592, Synthetic Data Grad Norm: 0.0001709625794319436\n",
      "Epoch 3, Meta Loss: 2.273658037185669, Synthetic Data Grad Norm: 0.000231165366130881\n",
      "Epoch 3, Meta Loss: 2.2795233726501465, Synthetic Data Grad Norm: 0.0003299091476947069\n",
      "Epoch 3, Meta Loss: 2.2791967391967773, Synthetic Data Grad Norm: 0.0003075769345741719\n",
      "Epoch 3, Meta Loss: 2.2840728759765625, Synthetic Data Grad Norm: 0.00014924224524293095\n",
      "Epoch 3, Meta Loss: 2.3063321113586426, Synthetic Data Grad Norm: 0.00035861405194737017\n",
      "Epoch 3, Meta Loss: 2.2720556259155273, Synthetic Data Grad Norm: 0.00023877539206296206\n",
      "Epoch 3, Meta Loss: 2.2511303424835205, Synthetic Data Grad Norm: 0.0003791718336287886\n",
      "Epoch 3, Meta Loss: 2.2665083408355713, Synthetic Data Grad Norm: 0.0004800235037691891\n",
      "Epoch 3, Meta Loss: 2.261669397354126, Synthetic Data Grad Norm: 0.00033194205025210977\n",
      "Epoch 3, Meta Loss: 2.2893784046173096, Synthetic Data Grad Norm: 0.0002558455744292587\n",
      "Epoch 3, Meta Loss: 2.291895627975464, Synthetic Data Grad Norm: 0.00047215461381711066\n",
      "Epoch 3, Meta Loss: 2.2691738605499268, Synthetic Data Grad Norm: 0.00035262497840449214\n",
      "Epoch 3, Meta Loss: 2.277191400527954, Synthetic Data Grad Norm: 0.00030239488114602864\n",
      "Epoch 3, Meta Loss: 2.2726399898529053, Synthetic Data Grad Norm: 0.0002968940243590623\n",
      "Epoch 3, Meta Loss: 2.2663300037384033, Synthetic Data Grad Norm: 0.00036115123657509685\n",
      "Epoch 3, Meta Loss: 2.289198160171509, Synthetic Data Grad Norm: 0.00030697358306497335\n",
      "Epoch 3, Meta Loss: 2.2910544872283936, Synthetic Data Grad Norm: 0.00043219586950726807\n",
      "Epoch 3, Meta Loss: 2.2723376750946045, Synthetic Data Grad Norm: 0.00031048787059262395\n",
      "Epoch 3, Meta Loss: 2.282325029373169, Synthetic Data Grad Norm: 0.0002420312084723264\n",
      "Epoch 3, Meta Loss: 2.286224842071533, Synthetic Data Grad Norm: 0.00031043781200423837\n",
      "Epoch 3, Meta Loss: 2.2846083641052246, Synthetic Data Grad Norm: 0.00022408356016967446\n",
      "Epoch 3, Meta Loss: 2.2828822135925293, Synthetic Data Grad Norm: 0.0003125277580693364\n",
      "Epoch 3, Meta Loss: 2.272653341293335, Synthetic Data Grad Norm: 0.0002703953650780022\n",
      "Epoch 3, Meta Loss: 2.2755978107452393, Synthetic Data Grad Norm: 0.00020484004926402122\n",
      "Epoch 3, Meta Loss: 2.279332399368286, Synthetic Data Grad Norm: 0.0004519897047430277\n",
      "Epoch 3, Meta Loss: 2.249037027359009, Synthetic Data Grad Norm: 0.00034146656980738044\n",
      "Epoch 3, Meta Loss: 2.2737045288085938, Synthetic Data Grad Norm: 0.0003210173163097352\n",
      "Epoch 3, Meta Loss: 2.281546115875244, Synthetic Data Grad Norm: 0.0003324614663142711\n",
      "Epoch 3, Meta Loss: 2.274068593978882, Synthetic Data Grad Norm: 0.0003294096968602389\n",
      "Epoch 3, Meta Loss: 2.28493070602417, Synthetic Data Grad Norm: 0.00028593253227882087\n",
      "Epoch 3, Meta Loss: 2.2819254398345947, Synthetic Data Grad Norm: 0.0003652346204034984\n",
      "Epoch 3, Meta Loss: 2.2759344577789307, Synthetic Data Grad Norm: 0.00020549309556372464\n",
      "Epoch 3, Meta Loss: 2.263953685760498, Synthetic Data Grad Norm: 0.00026807229733094573\n",
      "Epoch 3, Meta Loss: 2.2807533740997314, Synthetic Data Grad Norm: 0.0003080997848883271\n",
      "Epoch 3, Meta Loss: 2.2915120124816895, Synthetic Data Grad Norm: 0.00027108791982755065\n",
      "Epoch 3, Meta Loss: 2.2698612213134766, Synthetic Data Grad Norm: 0.00031885880162008107\n",
      "Epoch 3, Meta Loss: 2.258589267730713, Synthetic Data Grad Norm: 0.00029525853460654616\n",
      "Epoch 3, Meta Loss: 2.2701075077056885, Synthetic Data Grad Norm: 0.0003029515210073441\n",
      "Epoch 3, Meta Loss: 2.265687942504883, Synthetic Data Grad Norm: 0.00031792110530659556\n",
      "Epoch 3, Meta Loss: 2.262943744659424, Synthetic Data Grad Norm: 0.0002535145322326571\n",
      "Epoch 3, Meta Loss: 2.2729902267456055, Synthetic Data Grad Norm: 0.0003627981641329825\n",
      "Epoch 3, Meta Loss: 2.2798361778259277, Synthetic Data Grad Norm: 0.00032042793463915586\n",
      "Epoch 3, Meta Loss: 2.2919492721557617, Synthetic Data Grad Norm: 0.0002492003550287336\n",
      "Epoch 3, Meta Loss: 2.3256115913391113, Synthetic Data Grad Norm: 0.0002643191546667367\n",
      "Epoch 3, Meta Loss: 2.2538321018218994, Synthetic Data Grad Norm: 0.0003213509626220912\n",
      "Epoch 3, Meta Loss: 2.2823054790496826, Synthetic Data Grad Norm: 0.0002760732313618064\n",
      "Epoch 3, Meta Loss: 2.2966835498809814, Synthetic Data Grad Norm: 0.00040453270776197314\n",
      "Epoch 3, Meta Loss: 2.288989305496216, Synthetic Data Grad Norm: 0.0002144415775546804\n",
      "Epoch 3, Meta Loss: 2.290320634841919, Synthetic Data Grad Norm: 0.0003280740056652576\n",
      "Epoch 3, Meta Loss: 2.2778446674346924, Synthetic Data Grad Norm: 0.00023196866095531732\n",
      "Epoch 3, Meta Loss: 2.2649683952331543, Synthetic Data Grad Norm: 0.00035660696448758245\n",
      "Epoch 3, Meta Loss: 2.275024652481079, Synthetic Data Grad Norm: 0.00021551930694840848\n",
      "Epoch 3, Meta Loss: 2.272907257080078, Synthetic Data Grad Norm: 0.00026522346888668835\n",
      "Epoch 3, Meta Loss: 2.272351026535034, Synthetic Data Grad Norm: 0.00039921552524901927\n",
      "Epoch 3, Meta Loss: 2.2786567211151123, Synthetic Data Grad Norm: 0.00024782458785921335\n",
      "Epoch 3, Meta Loss: 2.290874481201172, Synthetic Data Grad Norm: 0.00031461616163142025\n",
      "Epoch 3, Meta Loss: 2.2652547359466553, Synthetic Data Grad Norm: 0.0003502075560390949\n",
      "Epoch 3, Meta Loss: 2.275592088699341, Synthetic Data Grad Norm: 0.00028220441890880466\n",
      "Epoch 3, Meta Loss: 2.2801482677459717, Synthetic Data Grad Norm: 0.00029764638748019934\n",
      "Epoch 3, Meta Loss: 2.2664854526519775, Synthetic Data Grad Norm: 0.000332105002598837\n",
      "Epoch 3, Meta Loss: 2.27266001701355, Synthetic Data Grad Norm: 0.00028323562582954764\n",
      "Epoch 3, Meta Loss: 2.2859959602355957, Synthetic Data Grad Norm: 0.0002599650470074266\n",
      "Epoch 3, Meta Loss: 2.2713098526000977, Synthetic Data Grad Norm: 0.00027602846967056394\n",
      "Epoch 3, Meta Loss: 2.2941009998321533, Synthetic Data Grad Norm: 0.0002145317121176049\n",
      "Epoch 3, Meta Loss: 2.2689454555511475, Synthetic Data Grad Norm: 0.0003024986363016069\n",
      "Epoch 3, Meta Loss: 2.262115478515625, Synthetic Data Grad Norm: 0.0003381847345735878\n",
      "Epoch 3, Meta Loss: 2.290820837020874, Synthetic Data Grad Norm: 0.00023607921320945024\n",
      "Epoch 3, Meta Loss: 2.2439444065093994, Synthetic Data Grad Norm: 0.0004107399727217853\n",
      "Epoch 3, Meta Loss: 2.275516986846924, Synthetic Data Grad Norm: 0.0004457848845049739\n",
      "Epoch 3, Meta Loss: 2.279815912246704, Synthetic Data Grad Norm: 0.00021903384185861796\n",
      "Epoch 3, Meta Loss: 2.2655274868011475, Synthetic Data Grad Norm: 0.000305680267047137\n",
      "Epoch 3, Meta Loss: 2.277801275253296, Synthetic Data Grad Norm: 0.00036843400448560715\n",
      "Epoch 3, Meta Loss: 2.2852461338043213, Synthetic Data Grad Norm: 0.00024027939070947468\n",
      "Epoch 3, Meta Loss: 2.2746124267578125, Synthetic Data Grad Norm: 0.00029439706122502685\n",
      "Epoch 3, Meta Loss: 2.277430534362793, Synthetic Data Grad Norm: 0.00027113090618513525\n",
      "Epoch 3, Meta Loss: 2.276308059692383, Synthetic Data Grad Norm: 0.00033237741445191205\n",
      "Epoch 3, Meta Loss: 2.2796926498413086, Synthetic Data Grad Norm: 0.0002639564627315849\n",
      "Epoch 3, Meta Loss: 2.2724685668945312, Synthetic Data Grad Norm: 0.0003639451751951128\n",
      "Epoch 3, Meta Loss: 2.274418592453003, Synthetic Data Grad Norm: 0.000251018296694383\n",
      "Epoch 3, Meta Loss: 2.268799066543579, Synthetic Data Grad Norm: 0.00033273009466938674\n",
      "Epoch 3, Meta Loss: 2.2823476791381836, Synthetic Data Grad Norm: 0.0003118213498964906\n",
      "Epoch 3, Meta Loss: 2.281811237335205, Synthetic Data Grad Norm: 0.00022871390683576465\n",
      "Epoch 3, Meta Loss: 2.2909650802612305, Synthetic Data Grad Norm: 0.00024274925817735493\n",
      "Epoch 3, Meta Loss: 2.261245012283325, Synthetic Data Grad Norm: 0.0004106076085008681\n",
      "Epoch 3, Meta Loss: 2.289107322692871, Synthetic Data Grad Norm: 0.0002655625285115093\n",
      "Epoch 3, Meta Loss: 2.2741858959198, Synthetic Data Grad Norm: 0.0003240274963900447\n",
      "Epoch 3, Meta Loss: 2.2828996181488037, Synthetic Data Grad Norm: 0.00028850167291238904\n",
      "Epoch 3, Meta Loss: 2.272050619125366, Synthetic Data Grad Norm: 0.00031690983450971544\n",
      "Epoch 3, Meta Loss: 2.2756805419921875, Synthetic Data Grad Norm: 0.00031410015071742237\n",
      "Epoch 3, Meta Loss: 2.2804784774780273, Synthetic Data Grad Norm: 0.0002889423631131649\n",
      "Epoch 3, Meta Loss: 2.293208360671997, Synthetic Data Grad Norm: 0.00032501728856004775\n",
      "Epoch 3, Meta Loss: 2.28387188911438, Synthetic Data Grad Norm: 0.00034971683635376394\n",
      "Epoch 3, Meta Loss: 2.294396162033081, Synthetic Data Grad Norm: 0.0002547012991271913\n",
      "Epoch 3, Meta Loss: 2.275407314300537, Synthetic Data Grad Norm: 0.0002522781433071941\n",
      "Epoch 3, Meta Loss: 2.297774076461792, Synthetic Data Grad Norm: 0.0002433447662042454\n",
      "Epoch 3, Meta Loss: 2.2800989151000977, Synthetic Data Grad Norm: 0.00024220315390266478\n",
      "Epoch 3, Meta Loss: 2.2755305767059326, Synthetic Data Grad Norm: 0.0003311325563117862\n",
      "Epoch 3, Meta Loss: 2.263585090637207, Synthetic Data Grad Norm: 0.0002705583465285599\n",
      "Epoch 3, Meta Loss: 2.2751851081848145, Synthetic Data Grad Norm: 0.0003008326457347721\n",
      "Epoch 3, Meta Loss: 2.2843191623687744, Synthetic Data Grad Norm: 0.0002432396140648052\n",
      "Epoch 3, Meta Loss: 2.2883851528167725, Synthetic Data Grad Norm: 0.0003073544939979911\n",
      "Epoch 3, Meta Loss: 2.2794673442840576, Synthetic Data Grad Norm: 0.00037454755511134863\n",
      "Epoch 3, Meta Loss: 2.2791943550109863, Synthetic Data Grad Norm: 0.00029588621691800654\n",
      "Epoch 3, Meta Loss: 2.298234701156616, Synthetic Data Grad Norm: 0.00027508719358593225\n",
      "Epoch 3, Meta Loss: 2.278614044189453, Synthetic Data Grad Norm: 0.00026919596712104976\n",
      "Epoch 3, Meta Loss: 2.280270576477051, Synthetic Data Grad Norm: 0.00033985188929364085\n",
      "Epoch 3, Meta Loss: 2.2847673892974854, Synthetic Data Grad Norm: 0.00033690049895085394\n",
      "Epoch 3, Meta Loss: 2.3050317764282227, Synthetic Data Grad Norm: 0.0003829027118626982\n",
      "Epoch 3, Meta Loss: 2.276280641555786, Synthetic Data Grad Norm: 0.00025986923719756305\n",
      "Epoch 3, Meta Loss: 2.289558172225952, Synthetic Data Grad Norm: 0.00037353194784373045\n",
      "Epoch 3, Meta Loss: 2.271197557449341, Synthetic Data Grad Norm: 0.00028452117112465203\n",
      "Epoch 3, Meta Loss: 2.2888495922088623, Synthetic Data Grad Norm: 0.0002423714759061113\n",
      "Epoch 3, Meta Loss: 2.2868049144744873, Synthetic Data Grad Norm: 0.0003291052707936615\n",
      "Epoch 3, Meta Loss: 2.287238121032715, Synthetic Data Grad Norm: 0.00023473390319850296\n",
      "Epoch 3, Meta Loss: 2.2593560218811035, Synthetic Data Grad Norm: 0.00031183555256575346\n",
      "Epoch 3, Meta Loss: 2.28849196434021, Synthetic Data Grad Norm: 0.00023160759883467108\n",
      "Epoch 3, Meta Loss: 2.2860918045043945, Synthetic Data Grad Norm: 0.0002274862490594387\n",
      "Epoch 3, Meta Loss: 2.2971415519714355, Synthetic Data Grad Norm: 0.00019533986051101238\n",
      "Epoch 3, Meta Loss: 2.2705886363983154, Synthetic Data Grad Norm: 0.00021832139464095235\n",
      "Epoch 3, Meta Loss: 2.2667489051818848, Synthetic Data Grad Norm: 0.0003237521159462631\n",
      "Epoch 3, Meta Loss: 2.288045883178711, Synthetic Data Grad Norm: 0.000268722913460806\n",
      "Epoch 3, Meta Loss: 2.2842719554901123, Synthetic Data Grad Norm: 0.00022557086776942015\n",
      "Epoch 3, Meta Loss: 2.263408899307251, Synthetic Data Grad Norm: 0.0003068250953219831\n",
      "Epoch 3, Meta Loss: 2.2613794803619385, Synthetic Data Grad Norm: 0.00032480532536283135\n",
      "Epoch 3, Meta Loss: 2.2651398181915283, Synthetic Data Grad Norm: 0.0002299830230185762\n",
      "Epoch 3, Meta Loss: 2.2829837799072266, Synthetic Data Grad Norm: 0.000273078796453774\n",
      "Epoch 3, Meta Loss: 2.2965478897094727, Synthetic Data Grad Norm: 0.0002322327927686274\n",
      "Epoch 3, Meta Loss: 2.2781758308410645, Synthetic Data Grad Norm: 0.00022620317758992314\n",
      "Epoch 3, Meta Loss: 2.2701172828674316, Synthetic Data Grad Norm: 0.0003700879169628024\n",
      "Epoch 3, Meta Loss: 2.2924182415008545, Synthetic Data Grad Norm: 0.00019796854758169502\n",
      "Epoch 3, Meta Loss: 2.2722232341766357, Synthetic Data Grad Norm: 0.0002783251111395657\n",
      "Epoch 3, Meta Loss: 2.2767419815063477, Synthetic Data Grad Norm: 0.00032830069540068507\n",
      "Epoch 3, Meta Loss: 2.288067579269409, Synthetic Data Grad Norm: 0.00029351291595958173\n",
      "Epoch 3, Meta Loss: 2.2832560539245605, Synthetic Data Grad Norm: 0.0003027184575330466\n",
      "Epoch 3, Meta Loss: 2.284658432006836, Synthetic Data Grad Norm: 0.0002661418984644115\n",
      "Epoch 3, Meta Loss: 2.3076908588409424, Synthetic Data Grad Norm: 0.0002539364795666188\n",
      "Epoch 3, Meta Loss: 2.2754406929016113, Synthetic Data Grad Norm: 0.00029287717188708484\n",
      "Epoch 3, Meta Loss: 2.2835500240325928, Synthetic Data Grad Norm: 0.0002217665605712682\n",
      "Epoch 3, Meta Loss: 2.2795557975769043, Synthetic Data Grad Norm: 0.0002460426476318389\n",
      "Epoch 3, Meta Loss: 2.2846767902374268, Synthetic Data Grad Norm: 0.0003115974832326174\n",
      "Epoch 3, Meta Loss: 2.2912299633026123, Synthetic Data Grad Norm: 0.0003722115943673998\n",
      "Epoch 3, Meta Loss: 2.275449275970459, Synthetic Data Grad Norm: 0.00025636859936639667\n",
      "Epoch 3, Meta Loss: 2.266141176223755, Synthetic Data Grad Norm: 0.0002423150435788557\n",
      "Epoch 3, Meta Loss: 2.322600841522217, Synthetic Data Grad Norm: 0.00035349815152585506\n",
      "Epoch 3, Meta Loss: 2.294281005859375, Synthetic Data Grad Norm: 0.0003324240678921342\n",
      "Epoch 3, Meta Loss: 2.2765073776245117, Synthetic Data Grad Norm: 0.00026896424242295325\n",
      "Epoch 3, Meta Loss: 2.2894959449768066, Synthetic Data Grad Norm: 0.00017639168072491884\n",
      "Epoch 3, Meta Loss: 2.2747457027435303, Synthetic Data Grad Norm: 0.0002526680182199925\n",
      "Epoch 3, Meta Loss: 2.274421215057373, Synthetic Data Grad Norm: 0.00026720351888798177\n",
      "Epoch 3, Meta Loss: 2.271822929382324, Synthetic Data Grad Norm: 0.000265271111857146\n",
      "Epoch 3, Meta Loss: 2.2844629287719727, Synthetic Data Grad Norm: 0.00024000908888410777\n",
      "Epoch 3, Meta Loss: 2.2943036556243896, Synthetic Data Grad Norm: 0.00028950796695426106\n",
      "Epoch 3, Meta Loss: 2.286710023880005, Synthetic Data Grad Norm: 0.0003400160640012473\n",
      "Epoch 3, Meta Loss: 2.2689335346221924, Synthetic Data Grad Norm: 0.00025393025134690106\n",
      "Epoch 3, Meta Loss: 2.2743887901306152, Synthetic Data Grad Norm: 0.0003069808299187571\n",
      "Epoch 3, Meta Loss: 2.2554244995117188, Synthetic Data Grad Norm: 0.0002810200094245374\n",
      "Epoch 3, Meta Loss: 2.2548484802246094, Synthetic Data Grad Norm: 0.0003304530109744519\n",
      "Epoch 3, Meta Loss: 2.2661890983581543, Synthetic Data Grad Norm: 0.0002720125194173306\n",
      "Epoch 3, Meta Loss: 2.269685745239258, Synthetic Data Grad Norm: 0.00024453658261336386\n",
      "Epoch 3, Meta Loss: 2.2788522243499756, Synthetic Data Grad Norm: 0.0003151324635837227\n",
      "Epoch 3, Meta Loss: 2.288970947265625, Synthetic Data Grad Norm: 0.0002259285975014791\n",
      "Epoch 3, Meta Loss: 2.263270378112793, Synthetic Data Grad Norm: 0.0003853751113638282\n",
      "Epoch 3, Meta Loss: 2.2692856788635254, Synthetic Data Grad Norm: 0.00027425307780504227\n",
      "Epoch 3, Meta Loss: 2.2852437496185303, Synthetic Data Grad Norm: 0.00031107242102734745\n",
      "Epoch 3, Meta Loss: 2.2696499824523926, Synthetic Data Grad Norm: 0.00042942765867337584\n",
      "Epoch 3, Meta Loss: 2.2745819091796875, Synthetic Data Grad Norm: 0.000350428803358227\n",
      "Epoch 3, Meta Loss: 2.284541368484497, Synthetic Data Grad Norm: 0.0003459830186329782\n",
      "Epoch 3, Meta Loss: 2.275733709335327, Synthetic Data Grad Norm: 0.0002705223159864545\n",
      "Epoch 3, Meta Loss: 2.28277587890625, Synthetic Data Grad Norm: 0.00027830403996631503\n",
      "Epoch 3, Meta Loss: 2.265427350997925, Synthetic Data Grad Norm: 0.00028777410625480115\n",
      "Epoch 3, Meta Loss: 2.2562503814697266, Synthetic Data Grad Norm: 0.00038115557981655\n",
      "Epoch 3, Meta Loss: 2.272801637649536, Synthetic Data Grad Norm: 0.0001939497160492465\n",
      "Epoch 3, Meta Loss: 2.2705090045928955, Synthetic Data Grad Norm: 0.00022556867043022066\n",
      "Epoch 3, Meta Loss: 2.2907114028930664, Synthetic Data Grad Norm: 0.00019795537809841335\n",
      "Epoch 3, Meta Loss: 2.2875874042510986, Synthetic Data Grad Norm: 0.00021542428294196725\n",
      "Epoch 3, Meta Loss: 2.2844271659851074, Synthetic Data Grad Norm: 0.0002776395995169878\n",
      "Epoch 3, Meta Loss: 2.270418882369995, Synthetic Data Grad Norm: 0.00044070486910641193\n",
      "Epoch 3, Meta Loss: 2.2777774333953857, Synthetic Data Grad Norm: 0.00030449757468886673\n",
      "Epoch 3, Meta Loss: 2.284726142883301, Synthetic Data Grad Norm: 0.0002252116973977536\n",
      "Epoch 3, Meta Loss: 2.2949459552764893, Synthetic Data Grad Norm: 0.00023281894391402602\n",
      "Epoch 3, Meta Loss: 2.2830440998077393, Synthetic Data Grad Norm: 0.00029552829801104963\n",
      "Epoch 3, Meta Loss: 2.266204357147217, Synthetic Data Grad Norm: 0.0002885234425775707\n",
      "Epoch 3, Meta Loss: 2.2972450256347656, Synthetic Data Grad Norm: 0.00026870035799220204\n",
      "Epoch 3, Meta Loss: 2.292485475540161, Synthetic Data Grad Norm: 0.00023044648696668446\n",
      "Epoch 3, Meta Loss: 2.2490124702453613, Synthetic Data Grad Norm: 0.00036977644776925445\n",
      "Epoch 3, Meta Loss: 2.2814176082611084, Synthetic Data Grad Norm: 0.00025208003353327513\n",
      "Epoch 3, Meta Loss: 2.291231632232666, Synthetic Data Grad Norm: 0.00030877237441018224\n",
      "Epoch 3, Meta Loss: 2.2501301765441895, Synthetic Data Grad Norm: 0.0003267044376116246\n",
      "Epoch 3, Meta Loss: 2.2942230701446533, Synthetic Data Grad Norm: 0.00025117327459156513\n",
      "Epoch 3, Meta Loss: 2.2673444747924805, Synthetic Data Grad Norm: 0.0002617104910314083\n",
      "Epoch 3, Meta Loss: 2.2786459922790527, Synthetic Data Grad Norm: 0.00029645845643244684\n",
      "Epoch 3, Meta Loss: 2.2673792839050293, Synthetic Data Grad Norm: 0.00028046357329003513\n",
      "Epoch 3, Meta Loss: 2.2942087650299072, Synthetic Data Grad Norm: 0.0003267036809120327\n",
      "Epoch 3, Meta Loss: 2.2744016647338867, Synthetic Data Grad Norm: 0.00038155511720106006\n",
      "Epoch 3, Meta Loss: 2.2957465648651123, Synthetic Data Grad Norm: 0.00031015925924293697\n",
      "Epoch 3, Meta Loss: 2.2920467853546143, Synthetic Data Grad Norm: 0.0003336452064104378\n",
      "Epoch 3, Meta Loss: 2.2766149044036865, Synthetic Data Grad Norm: 0.0003087581426370889\n",
      "Epoch 3, Meta Loss: 2.275221347808838, Synthetic Data Grad Norm: 0.0003272688190918416\n",
      "Epoch 3, Meta Loss: 2.281574249267578, Synthetic Data Grad Norm: 0.00028744383598677814\n",
      "Epoch 3, Meta Loss: 2.2762088775634766, Synthetic Data Grad Norm: 0.0002683900820557028\n",
      "Epoch 3, Meta Loss: 2.269968032836914, Synthetic Data Grad Norm: 0.0003779864637181163\n",
      "Epoch 3, Meta Loss: 2.2857301235198975, Synthetic Data Grad Norm: 0.00026543234707787633\n",
      "Epoch 3, Meta Loss: 2.2806758880615234, Synthetic Data Grad Norm: 0.00027706482796929777\n",
      "Epoch 3, Meta Loss: 2.284499168395996, Synthetic Data Grad Norm: 0.00024395741638727486\n",
      "Epoch 3, Meta Loss: 2.2856125831604004, Synthetic Data Grad Norm: 0.0002768301055766642\n",
      "Epoch 3, Meta Loss: 2.2660634517669678, Synthetic Data Grad Norm: 0.00030505729955621064\n",
      "Epoch 3, Meta Loss: 2.2794315814971924, Synthetic Data Grad Norm: 0.000344777392456308\n",
      "Epoch 3, Meta Loss: 2.2851428985595703, Synthetic Data Grad Norm: 0.0002655699208844453\n",
      "Epoch 3, Meta Loss: 2.264113187789917, Synthetic Data Grad Norm: 0.0002519159170333296\n",
      "Epoch 3, Meta Loss: 2.271507740020752, Synthetic Data Grad Norm: 0.0002456475340295583\n",
      "Epoch 3, Meta Loss: 2.232151985168457, Synthetic Data Grad Norm: 0.00038246202166192234\n",
      "Epoch 3, Meta Loss: 2.27327299118042, Synthetic Data Grad Norm: 0.0003224635438527912\n",
      "Epoch 3, Meta Loss: 2.283823013305664, Synthetic Data Grad Norm: 0.0004036017635371536\n",
      "Epoch 3, Meta Loss: 2.2682321071624756, Synthetic Data Grad Norm: 0.00030223705107346177\n",
      "Epoch 3, Meta Loss: 2.265420436859131, Synthetic Data Grad Norm: 0.00026880757650360465\n",
      "Epoch 3, Meta Loss: 2.274902105331421, Synthetic Data Grad Norm: 0.0003046659112442285\n",
      "Epoch 3, Meta Loss: 2.2931439876556396, Synthetic Data Grad Norm: 0.00025139315403066576\n",
      "Epoch 3, Meta Loss: 2.2869863510131836, Synthetic Data Grad Norm: 0.00040130759589374065\n",
      "Epoch 3, Meta Loss: 2.2495903968811035, Synthetic Data Grad Norm: 0.0003638143534772098\n",
      "Epoch 3, Meta Loss: 2.27872633934021, Synthetic Data Grad Norm: 0.00036775885382667184\n",
      "Epoch 3, Meta Loss: 2.2785756587982178, Synthetic Data Grad Norm: 0.00030727210105396807\n",
      "Epoch 3, Meta Loss: 2.266636610031128, Synthetic Data Grad Norm: 0.00032875267788767815\n",
      "Epoch 3, Meta Loss: 2.2622969150543213, Synthetic Data Grad Norm: 0.00027757955831475556\n",
      "Epoch 3, Meta Loss: 2.289698600769043, Synthetic Data Grad Norm: 0.0002500213449820876\n",
      "Epoch 3, Meta Loss: 2.2991151809692383, Synthetic Data Grad Norm: 0.00019318170961923897\n",
      "Epoch 3, Meta Loss: 2.2670512199401855, Synthetic Data Grad Norm: 0.00023108073219191283\n",
      "Epoch 3, Meta Loss: 2.302631378173828, Synthetic Data Grad Norm: 0.00029061242821626365\n",
      "Epoch 3, Meta Loss: 2.2617268562316895, Synthetic Data Grad Norm: 0.0003330945037305355\n",
      "Epoch 3, Meta Loss: 2.2626540660858154, Synthetic Data Grad Norm: 0.00038956591743044555\n",
      "Epoch 3, Meta Loss: 2.269636631011963, Synthetic Data Grad Norm: 0.0002519456611480564\n",
      "Epoch 3, Meta Loss: 2.2784032821655273, Synthetic Data Grad Norm: 0.00025913305580616\n",
      "Epoch 3, Meta Loss: 2.299347400665283, Synthetic Data Grad Norm: 0.0002606974740047008\n",
      "Epoch 3, Meta Loss: 2.287480115890503, Synthetic Data Grad Norm: 0.00026940793031826615\n",
      "Epoch 3, Meta Loss: 2.297961711883545, Synthetic Data Grad Norm: 0.0004747211351059377\n",
      "Epoch 3, Meta Loss: 2.2776849269866943, Synthetic Data Grad Norm: 0.0002443208359181881\n",
      "Epoch 3, Meta Loss: 2.2899789810180664, Synthetic Data Grad Norm: 0.0002823484246619046\n",
      "Epoch 3, Meta Loss: 2.294013738632202, Synthetic Data Grad Norm: 0.0003453853714745492\n",
      "Epoch 3, Meta Loss: 2.2685599327087402, Synthetic Data Grad Norm: 0.00030965503538027406\n",
      "Epoch 3, Meta Loss: 2.2965950965881348, Synthetic Data Grad Norm: 0.00035424434463493526\n",
      "Epoch 3, Meta Loss: 2.285905361175537, Synthetic Data Grad Norm: 0.00029920009546913207\n",
      "Epoch 3, Meta Loss: 2.2994349002838135, Synthetic Data Grad Norm: 0.0002872866461984813\n",
      "Epoch 3, Meta Loss: 2.298675775527954, Synthetic Data Grad Norm: 0.0002629838709253818\n",
      "Epoch 3, Meta Loss: 2.2754595279693604, Synthetic Data Grad Norm: 0.00033469783375039697\n",
      "Epoch 3, Meta Loss: 2.2818543910980225, Synthetic Data Grad Norm: 0.0002472822379786521\n",
      "Epoch 3, Meta Loss: 2.269695520401001, Synthetic Data Grad Norm: 0.0002489255857653916\n",
      "Epoch 3, Meta Loss: 2.278940200805664, Synthetic Data Grad Norm: 0.00034257530933246017\n",
      "Epoch 3, Meta Loss: 2.2782540321350098, Synthetic Data Grad Norm: 0.00041780484025366604\n",
      "Epoch 3, Meta Loss: 2.267298460006714, Synthetic Data Grad Norm: 0.0003265054547227919\n",
      "Epoch 3, Meta Loss: 2.278561592102051, Synthetic Data Grad Norm: 0.00025192624889314175\n",
      "Epoch 3, Meta Loss: 2.3038225173950195, Synthetic Data Grad Norm: 0.00023105397121980786\n",
      "Epoch 3, Meta Loss: 2.268728017807007, Synthetic Data Grad Norm: 0.0002695240546017885\n",
      "Epoch 3, Meta Loss: 2.2926976680755615, Synthetic Data Grad Norm: 0.00022836841526441276\n",
      "Epoch 3, Meta Loss: 2.2558727264404297, Synthetic Data Grad Norm: 0.0002754175802692771\n",
      "Epoch 3, Meta Loss: 2.276080369949341, Synthetic Data Grad Norm: 0.000289388612145558\n",
      "Epoch 3, Meta Loss: 2.262221336364746, Synthetic Data Grad Norm: 0.00037218994111754\n",
      "Epoch 3, Meta Loss: 2.274366617202759, Synthetic Data Grad Norm: 0.0002588783099781722\n",
      "Epoch 3, Meta Loss: 2.2926790714263916, Synthetic Data Grad Norm: 0.0002658548764884472\n",
      "Epoch 3, Meta Loss: 2.2636878490448, Synthetic Data Grad Norm: 0.0002836684579961002\n",
      "Epoch 3, Meta Loss: 2.2917728424072266, Synthetic Data Grad Norm: 0.00031334059895016253\n",
      "Epoch 3, Meta Loss: 2.3010101318359375, Synthetic Data Grad Norm: 0.0002794256142806262\n",
      "Epoch 3, Meta Loss: 2.254505157470703, Synthetic Data Grad Norm: 0.00029561962583102286\n",
      "Epoch 3, Meta Loss: 2.258331775665283, Synthetic Data Grad Norm: 0.0002902105334214866\n",
      "Epoch 3, Meta Loss: 2.282613515853882, Synthetic Data Grad Norm: 0.00041566730942577124\n",
      "Epoch 3, Meta Loss: 2.2679030895233154, Synthetic Data Grad Norm: 0.0002809820289257914\n",
      "Epoch 3, Meta Loss: 2.2930238246917725, Synthetic Data Grad Norm: 0.0002517743851058185\n",
      "Epoch 3, Meta Loss: 2.2804932594299316, Synthetic Data Grad Norm: 0.00027464720187708735\n",
      "Epoch 3, Meta Loss: 2.270548105239868, Synthetic Data Grad Norm: 0.0003928402147721499\n",
      "Epoch 3, Meta Loss: 2.2888522148132324, Synthetic Data Grad Norm: 0.00020894668705295771\n",
      "Epoch 3, Meta Loss: 2.261059284210205, Synthetic Data Grad Norm: 0.0003128717071376741\n",
      "Epoch 3, Meta Loss: 2.2667176723480225, Synthetic Data Grad Norm: 0.00029223060118965805\n",
      "Epoch 3, Meta Loss: 2.2847485542297363, Synthetic Data Grad Norm: 0.0002460142713971436\n",
      "Epoch 3, Meta Loss: 2.2690417766571045, Synthetic Data Grad Norm: 0.00032033820752985775\n",
      "Epoch 3, Meta Loss: 2.289461135864258, Synthetic Data Grad Norm: 0.00034460597089491785\n",
      "Epoch 3, Meta Loss: 2.259768009185791, Synthetic Data Grad Norm: 0.0004406800144352019\n",
      "Epoch 3, Meta Loss: 2.313335657119751, Synthetic Data Grad Norm: 0.00023392659204546362\n",
      "Epoch 3, Meta Loss: 2.252222776412964, Synthetic Data Grad Norm: 0.00039153199759311974\n",
      "Epoch 3, Meta Loss: 2.277940273284912, Synthetic Data Grad Norm: 0.00024862540885806084\n",
      "Epoch 3, Meta Loss: 2.2667360305786133, Synthetic Data Grad Norm: 0.0002606079797260463\n",
      "Epoch 3, Meta Loss: 2.269550085067749, Synthetic Data Grad Norm: 0.00025894827558659017\n",
      "Epoch 3, Meta Loss: 2.2701828479766846, Synthetic Data Grad Norm: 0.0002715653972700238\n",
      "Epoch 3, Meta Loss: 2.2635657787323, Synthetic Data Grad Norm: 0.0003184982342645526\n",
      "Epoch 3, Meta Loss: 2.2744462490081787, Synthetic Data Grad Norm: 0.00034809138742275536\n",
      "Epoch 3, Meta Loss: 2.276963472366333, Synthetic Data Grad Norm: 0.0002523586736060679\n",
      "Epoch 3, Meta Loss: 2.268082857131958, Synthetic Data Grad Norm: 0.00028113063308410347\n",
      "Epoch 3, Meta Loss: 2.2778103351593018, Synthetic Data Grad Norm: 0.00031789831700734794\n",
      "Epoch 3, Meta Loss: 2.287583827972412, Synthetic Data Grad Norm: 0.0002554919046815485\n",
      "Epoch 3, Meta Loss: 2.2671940326690674, Synthetic Data Grad Norm: 0.0003236051124986261\n",
      "Epoch 3, Meta Loss: 2.2899928092956543, Synthetic Data Grad Norm: 0.00023938878439366817\n",
      "Epoch 3, Meta Loss: 2.2958297729492188, Synthetic Data Grad Norm: 0.0002687426458578557\n",
      "Epoch 3, Meta Loss: 2.3073298931121826, Synthetic Data Grad Norm: 0.0002876973303500563\n",
      "Epoch 3, Meta Loss: 2.279139995574951, Synthetic Data Grad Norm: 0.0003298886585980654\n",
      "Epoch 3, Meta Loss: 2.2979798316955566, Synthetic Data Grad Norm: 0.0002171576052205637\n",
      "Epoch 3, Meta Loss: 2.259561061859131, Synthetic Data Grad Norm: 0.00039019298856146634\n",
      "Epoch 3, Meta Loss: 2.2888054847717285, Synthetic Data Grad Norm: 0.0002891716721933335\n",
      "Epoch 3, Meta Loss: 2.272294044494629, Synthetic Data Grad Norm: 0.0002859450178220868\n",
      "Epoch 3, Meta Loss: 2.2618565559387207, Synthetic Data Grad Norm: 0.0004396528238430619\n",
      "Epoch 3, Meta Loss: 2.290327548980713, Synthetic Data Grad Norm: 0.00025383479078300297\n",
      "Epoch 3, Meta Loss: 2.252760648727417, Synthetic Data Grad Norm: 0.0003587648971006274\n",
      "Epoch 3, Meta Loss: 2.275345802307129, Synthetic Data Grad Norm: 0.00029259308939799666\n",
      "Epoch 3, Meta Loss: 2.2801878452301025, Synthetic Data Grad Norm: 0.00018482103769201785\n",
      "Epoch 3, Meta Loss: 2.272096872329712, Synthetic Data Grad Norm: 0.00033554912079125643\n",
      "Epoch 3, Meta Loss: 2.289788007736206, Synthetic Data Grad Norm: 0.00028391150408424437\n",
      "Epoch 3, Meta Loss: 2.2566418647766113, Synthetic Data Grad Norm: 0.00037049176171422005\n",
      "Epoch 3, Meta Loss: 2.2699475288391113, Synthetic Data Grad Norm: 0.00023193653032649308\n",
      "Epoch 3, Meta Loss: 2.279841661453247, Synthetic Data Grad Norm: 0.0002738864568527788\n",
      "Epoch 3, Meta Loss: 2.279632806777954, Synthetic Data Grad Norm: 0.000429383828304708\n",
      "Epoch 3, Meta Loss: 2.2628557682037354, Synthetic Data Grad Norm: 0.0003875900583807379\n",
      "Epoch 3, Meta Loss: 2.27915358543396, Synthetic Data Grad Norm: 0.00020976990344934165\n",
      "Epoch 3, Meta Loss: 2.288513422012329, Synthetic Data Grad Norm: 0.0004271318903192878\n",
      "Epoch 3, Meta Loss: 2.280696392059326, Synthetic Data Grad Norm: 0.0003425573231652379\n",
      "Epoch 3, Meta Loss: 2.265329599380493, Synthetic Data Grad Norm: 0.00032696870039217174\n",
      "Epoch 3, Meta Loss: 2.2791860103607178, Synthetic Data Grad Norm: 0.0002686081570573151\n",
      "Epoch 3, Meta Loss: 2.264453172683716, Synthetic Data Grad Norm: 0.0002519268018659204\n",
      "Epoch 3, Meta Loss: 2.280697822570801, Synthetic Data Grad Norm: 0.00023471929307561368\n",
      "Epoch 3, Meta Loss: 2.243861675262451, Synthetic Data Grad Norm: 0.00033997310674749315\n",
      "Epoch 3, Meta Loss: 2.265432834625244, Synthetic Data Grad Norm: 0.00030090531799942255\n",
      "Epoch 3, Meta Loss: 2.279930591583252, Synthetic Data Grad Norm: 0.00026157047250308096\n",
      "Epoch 3, Meta Loss: 2.2852275371551514, Synthetic Data Grad Norm: 0.0003005976905114949\n",
      "Epoch 3, Meta Loss: 2.2604117393493652, Synthetic Data Grad Norm: 0.00031613465398550034\n",
      "Epoch 3, Meta Loss: 2.2804105281829834, Synthetic Data Grad Norm: 0.0003815798263531178\n",
      "Epoch 3, Meta Loss: 2.289233684539795, Synthetic Data Grad Norm: 0.00025135863688774407\n",
      "Epoch 3, Meta Loss: 2.2689735889434814, Synthetic Data Grad Norm: 0.00026126601733267307\n",
      "Epoch 3, Meta Loss: 2.2746167182922363, Synthetic Data Grad Norm: 0.00027274066815152764\n",
      "Epoch 3, Meta Loss: 2.2982380390167236, Synthetic Data Grad Norm: 0.0002068627072731033\n",
      "Epoch 3, Meta Loss: 2.2864792346954346, Synthetic Data Grad Norm: 0.00037944590440019965\n",
      "Epoch 3, Meta Loss: 2.266432046890259, Synthetic Data Grad Norm: 0.00042401259997859597\n",
      "Epoch 3, Meta Loss: 2.272733211517334, Synthetic Data Grad Norm: 0.0003369032347109169\n",
      "Epoch 3, Meta Loss: 2.290827512741089, Synthetic Data Grad Norm: 0.0003179671766702086\n",
      "Epoch 3, Meta Loss: 2.2634732723236084, Synthetic Data Grad Norm: 0.0003470066003501415\n",
      "Epoch 3, Meta Loss: 2.2761149406433105, Synthetic Data Grad Norm: 0.00024411545018665493\n",
      "Epoch 3, Meta Loss: 2.2728078365325928, Synthetic Data Grad Norm: 0.00025431610993109643\n",
      "Epoch 3, Meta Loss: 2.2771639823913574, Synthetic Data Grad Norm: 0.00023085031716618687\n",
      "Epoch 3, Meta Loss: 2.2854299545288086, Synthetic Data Grad Norm: 0.00020448070426937193\n",
      "Epoch 3, Meta Loss: 2.26249623298645, Synthetic Data Grad Norm: 0.00030519955907948315\n",
      "Epoch 3, Meta Loss: 2.270786762237549, Synthetic Data Grad Norm: 0.00030637599411420524\n",
      "Epoch 3, Meta Loss: 2.2765231132507324, Synthetic Data Grad Norm: 0.00020089275494683534\n",
      "Epoch 3, Meta Loss: 2.2756266593933105, Synthetic Data Grad Norm: 0.0002635658311191946\n",
      "Epoch 3, Meta Loss: 2.265803575515747, Synthetic Data Grad Norm: 0.00024204720102716237\n",
      "Epoch 3, Meta Loss: 2.284752368927002, Synthetic Data Grad Norm: 0.0002670029061846435\n",
      "Epoch 3, Meta Loss: 2.285261392593384, Synthetic Data Grad Norm: 0.0003122696070931852\n",
      "Epoch 3, Meta Loss: 2.2964766025543213, Synthetic Data Grad Norm: 0.00023725800565443933\n",
      "Epoch 3, Meta Loss: 2.2658495903015137, Synthetic Data Grad Norm: 0.00038530456367880106\n",
      "Epoch 3, Meta Loss: 2.2594480514526367, Synthetic Data Grad Norm: 0.00029333418933674693\n",
      "Epoch 3, Meta Loss: 2.270373821258545, Synthetic Data Grad Norm: 0.0003492446558084339\n",
      "Epoch 3, Meta Loss: 2.2721896171569824, Synthetic Data Grad Norm: 0.000306684902170673\n",
      "Epoch 3, Meta Loss: 2.2634737491607666, Synthetic Data Grad Norm: 0.00029909933800809085\n",
      "Epoch 3, Meta Loss: 2.2752201557159424, Synthetic Data Grad Norm: 0.000264788483036682\n",
      "Epoch 3, Meta Loss: 2.279545783996582, Synthetic Data Grad Norm: 0.00025391727103851736\n",
      "Epoch 3, Meta Loss: 2.2635936737060547, Synthetic Data Grad Norm: 0.0004034058947581798\n",
      "Epoch 3, Meta Loss: 2.282261610031128, Synthetic Data Grad Norm: 0.00032722653122618794\n",
      "Epoch 3, Meta Loss: 2.2620272636413574, Synthetic Data Grad Norm: 0.00029941945103928447\n",
      "Epoch 3, Meta Loss: 2.256106376647949, Synthetic Data Grad Norm: 0.00026798495673574507\n",
      "Epoch 3, Meta Loss: 2.2755813598632812, Synthetic Data Grad Norm: 0.000290006457362324\n",
      "Epoch 3, Meta Loss: 2.2860219478607178, Synthetic Data Grad Norm: 0.000274115358479321\n",
      "Epoch 3, Meta Loss: 2.2736754417419434, Synthetic Data Grad Norm: 0.00027484074234962463\n",
      "Epoch 3, Meta Loss: 2.2732412815093994, Synthetic Data Grad Norm: 0.0002903201966546476\n",
      "Epoch 3, Meta Loss: 2.2913684844970703, Synthetic Data Grad Norm: 0.0002478307287674397\n",
      "Epoch 3, Meta Loss: 2.2701845169067383, Synthetic Data Grad Norm: 0.00029455707408487797\n",
      "Epoch 3, Meta Loss: 2.289027690887451, Synthetic Data Grad Norm: 0.00027506492915563285\n",
      "Epoch 3, Meta Loss: 2.2879574298858643, Synthetic Data Grad Norm: 0.00030283816158771515\n",
      "Epoch 3, Meta Loss: 2.2913758754730225, Synthetic Data Grad Norm: 0.00026411598082631826\n",
      "Epoch 3, Meta Loss: 2.3040311336517334, Synthetic Data Grad Norm: 0.0003124121285509318\n",
      "Epoch 3, Meta Loss: 2.26750111579895, Synthetic Data Grad Norm: 0.0002630020899232477\n",
      "Epoch 3, Meta Loss: 2.2719075679779053, Synthetic Data Grad Norm: 0.00033722195075824857\n",
      "Epoch 3, Meta Loss: 2.2699360847473145, Synthetic Data Grad Norm: 0.00037321296986192465\n",
      "Epoch 3, Meta Loss: 2.2829790115356445, Synthetic Data Grad Norm: 0.00023175531532615423\n",
      "Epoch 3, Meta Loss: 2.268770933151245, Synthetic Data Grad Norm: 0.0004181403201073408\n",
      "Epoch 3, Meta Loss: 2.2994158267974854, Synthetic Data Grad Norm: 0.00024292439047712833\n",
      "Epoch 3, Meta Loss: 2.2714009284973145, Synthetic Data Grad Norm: 0.0003170504351146519\n",
      "Epoch 3, Meta Loss: 2.2662718296051025, Synthetic Data Grad Norm: 0.000265982816927135\n",
      "Epoch 3, Meta Loss: 2.2753686904907227, Synthetic Data Grad Norm: 0.0002822402457240969\n",
      "Epoch 3, Meta Loss: 2.2780849933624268, Synthetic Data Grad Norm: 0.00035633635707199574\n",
      "Epoch 3, Meta Loss: 2.260413646697998, Synthetic Data Grad Norm: 0.00028314185328781605\n",
      "Epoch 3, Meta Loss: 2.2730939388275146, Synthetic Data Grad Norm: 0.0002455090289004147\n",
      "Epoch 3, Meta Loss: 2.28830885887146, Synthetic Data Grad Norm: 0.00019287975737825036\n",
      "Epoch 3, Meta Loss: 2.282881498336792, Synthetic Data Grad Norm: 0.00027488538762554526\n",
      "Epoch 3, Meta Loss: 2.283144474029541, Synthetic Data Grad Norm: 0.0002960888668894768\n",
      "Epoch 3, Meta Loss: 2.3010365962982178, Synthetic Data Grad Norm: 0.00025059017934836447\n",
      "Epoch 3, Meta Loss: 2.2611186504364014, Synthetic Data Grad Norm: 0.0003132518322672695\n",
      "Epoch 3, Meta Loss: 2.281341314315796, Synthetic Data Grad Norm: 0.00029395168530754745\n",
      "Epoch 3, Meta Loss: 2.2823450565338135, Synthetic Data Grad Norm: 0.00021769481827504933\n",
      "Epoch 3, Meta Loss: 2.276237964630127, Synthetic Data Grad Norm: 0.00026273608091287315\n",
      "Epoch 3, Meta Loss: 2.277533769607544, Synthetic Data Grad Norm: 0.00033048162003979087\n",
      "Epoch 3, Meta Loss: 2.2683300971984863, Synthetic Data Grad Norm: 0.0003583485959097743\n",
      "Epoch 3, Meta Loss: 2.2888293266296387, Synthetic Data Grad Norm: 0.00028320529963821173\n",
      "Epoch 3, Meta Loss: 2.289602279663086, Synthetic Data Grad Norm: 0.0003346732701174915\n",
      "Epoch 3, Meta Loss: 2.2753512859344482, Synthetic Data Grad Norm: 0.0002448472660034895\n",
      "Epoch 3, Meta Loss: 2.2696781158447266, Synthetic Data Grad Norm: 0.0003158162871841341\n",
      "Epoch 3, Meta Loss: 2.284618616104126, Synthetic Data Grad Norm: 0.0002488211030140519\n",
      "Epoch 3, Meta Loss: 2.2899551391601562, Synthetic Data Grad Norm: 0.00027200320619158447\n",
      "Epoch 3, Meta Loss: 2.275923490524292, Synthetic Data Grad Norm: 0.00025400888989679515\n",
      "Epoch 3, Meta Loss: 2.2870733737945557, Synthetic Data Grad Norm: 0.00028186512645334005\n",
      "Epoch 3, Meta Loss: 2.2684218883514404, Synthetic Data Grad Norm: 0.0002938428951893002\n",
      "Epoch 3, Meta Loss: 2.3014142513275146, Synthetic Data Grad Norm: 0.00035297221620567143\n",
      "Epoch 3, Meta Loss: 2.295121192932129, Synthetic Data Grad Norm: 0.00025817897403612733\n",
      "Epoch 3, Meta Loss: 2.252838373184204, Synthetic Data Grad Norm: 0.00027601371402852237\n",
      "Epoch 3, Meta Loss: 2.2792067527770996, Synthetic Data Grad Norm: 0.00034677714575082064\n",
      "Epoch 3, Meta Loss: 2.270831823348999, Synthetic Data Grad Norm: 0.0002830383600667119\n",
      "Epoch 3, Meta Loss: 2.2655675411224365, Synthetic Data Grad Norm: 0.00021485330944415182\n",
      "Epoch 3, Meta Loss: 2.2787110805511475, Synthetic Data Grad Norm: 0.00030635061557404697\n",
      "Epoch 3, Meta Loss: 2.29449200630188, Synthetic Data Grad Norm: 0.00018807769811246544\n",
      "Epoch 3, Meta Loss: 2.279350757598877, Synthetic Data Grad Norm: 0.00040802531293593347\n",
      "Epoch 3, Meta Loss: 2.289271593093872, Synthetic Data Grad Norm: 0.00023785303346812725\n",
      "Epoch 3, Meta Loss: 2.2790133953094482, Synthetic Data Grad Norm: 0.00026930327294394374\n",
      "Epoch 3, Meta Loss: 2.2897372245788574, Synthetic Data Grad Norm: 0.00024598115123808384\n",
      "Epoch 3, Meta Loss: 2.269620656967163, Synthetic Data Grad Norm: 0.0003509321541059762\n",
      "Epoch 3, Meta Loss: 2.2761595249176025, Synthetic Data Grad Norm: 0.0003434259269852191\n",
      "Epoch 3, Meta Loss: 2.284994602203369, Synthetic Data Grad Norm: 0.0002392184396740049\n",
      "Epoch 3, Meta Loss: 2.283966302871704, Synthetic Data Grad Norm: 0.00025839771842584014\n",
      "Epoch 3, Meta Loss: 2.2830400466918945, Synthetic Data Grad Norm: 0.00022298873227555305\n",
      "Epoch 3, Meta Loss: 2.2922585010528564, Synthetic Data Grad Norm: 0.0003226084227208048\n",
      "Epoch 3, Meta Loss: 2.271320104598999, Synthetic Data Grad Norm: 0.0002637622819747776\n",
      "Epoch 3, Meta Loss: 2.272303581237793, Synthetic Data Grad Norm: 0.00031502157798968256\n",
      "Epoch 3, Meta Loss: 2.2874107360839844, Synthetic Data Grad Norm: 0.0003630213614087552\n",
      "Epoch 3, Meta Loss: 2.2683329582214355, Synthetic Data Grad Norm: 0.00023311398399528116\n",
      "Epoch 3, Meta Loss: 2.2553727626800537, Synthetic Data Grad Norm: 0.0003029264626093209\n",
      "Epoch 3, Meta Loss: 2.2762484550476074, Synthetic Data Grad Norm: 0.00026427998091094196\n",
      "Epoch 3, Meta Loss: 2.2896502017974854, Synthetic Data Grad Norm: 0.0002373730530962348\n",
      "Epoch 3, Meta Loss: 2.281562089920044, Synthetic Data Grad Norm: 0.0002504626172594726\n",
      "Epoch 3, Meta Loss: 2.267465353012085, Synthetic Data Grad Norm: 0.0003021304146386683\n",
      "Epoch 3, Meta Loss: 2.2456014156341553, Synthetic Data Grad Norm: 0.00035918114008381963\n",
      "Epoch 3, Meta Loss: 2.271376371383667, Synthetic Data Grad Norm: 0.0002387373533565551\n",
      "Epoch 3, Meta Loss: 2.300750732421875, Synthetic Data Grad Norm: 0.00028768772608600557\n",
      "Epoch 3, Meta Loss: 2.247971296310425, Synthetic Data Grad Norm: 0.00031655989005230367\n",
      "Epoch 3, Meta Loss: 2.2651000022888184, Synthetic Data Grad Norm: 0.0002627019421197474\n",
      "Epoch 3, Meta Loss: 2.2477500438690186, Synthetic Data Grad Norm: 0.0003170361742377281\n",
      "Epoch 3, Meta Loss: 2.259687900543213, Synthetic Data Grad Norm: 0.0003050814557354897\n",
      "Epoch 3, Meta Loss: 2.2663462162017822, Synthetic Data Grad Norm: 0.00032734539126977324\n",
      "Epoch 3, Meta Loss: 2.299339532852173, Synthetic Data Grad Norm: 0.0003521863545756787\n",
      "Epoch 3, Meta Loss: 2.269627571105957, Synthetic Data Grad Norm: 0.0003201675717718899\n",
      "Epoch 3, Meta Loss: 2.282090902328491, Synthetic Data Grad Norm: 0.00034871703246608377\n",
      "Epoch 3, Meta Loss: 2.2618374824523926, Synthetic Data Grad Norm: 0.00028176914202049375\n",
      "Epoch 3, Meta Loss: 2.296841859817505, Synthetic Data Grad Norm: 0.00024116234271787107\n",
      "Epoch 3, Meta Loss: 2.278059959411621, Synthetic Data Grad Norm: 0.0002751607680693269\n",
      "Epoch 3, Meta Loss: 2.271976947784424, Synthetic Data Grad Norm: 0.0002623345935717225\n",
      "Epoch 3, Meta Loss: 2.284461259841919, Synthetic Data Grad Norm: 0.0002082192077068612\n",
      "Epoch 3, Meta Loss: 2.2730929851531982, Synthetic Data Grad Norm: 0.0002846813586074859\n",
      "Epoch 3, Meta Loss: 2.2703163623809814, Synthetic Data Grad Norm: 0.0002548640768509358\n",
      "Epoch 3, Meta Loss: 2.2525222301483154, Synthetic Data Grad Norm: 0.00034805803443305194\n",
      "Epoch 3, Meta Loss: 2.2819042205810547, Synthetic Data Grad Norm: 0.0003071779210586101\n",
      "Epoch 3, Meta Loss: 2.278019905090332, Synthetic Data Grad Norm: 0.00031995325116440654\n",
      "Epoch 3, Meta Loss: 2.2803893089294434, Synthetic Data Grad Norm: 0.0003538036544341594\n",
      "Epoch 3, Meta Loss: 2.2585549354553223, Synthetic Data Grad Norm: 0.00024222560750786215\n",
      "Epoch 3, Meta Loss: 2.268261432647705, Synthetic Data Grad Norm: 0.00029984128195792437\n",
      "Epoch 3, Meta Loss: 2.27884578704834, Synthetic Data Grad Norm: 0.00028725783340632915\n",
      "Epoch 3, Meta Loss: 2.2682905197143555, Synthetic Data Grad Norm: 0.000330243055941537\n",
      "Epoch 3, Meta Loss: 2.281953811645508, Synthetic Data Grad Norm: 0.0001838257012423128\n",
      "Epoch 3, Meta Loss: 2.2910876274108887, Synthetic Data Grad Norm: 0.000298960687359795\n",
      "Epoch 3, Meta Loss: 2.2774996757507324, Synthetic Data Grad Norm: 0.00020979047985747457\n",
      "Epoch 3, Meta Loss: 2.2647738456726074, Synthetic Data Grad Norm: 0.00025893477140925825\n",
      "Epoch 3, Meta Loss: 2.2751450538635254, Synthetic Data Grad Norm: 0.00027230544947087765\n",
      "Epoch 3, Meta Loss: 2.2707555294036865, Synthetic Data Grad Norm: 0.0002888467279262841\n",
      "Epoch 3, Meta Loss: 2.2744522094726562, Synthetic Data Grad Norm: 0.000309562572510913\n",
      "Epoch 3, Meta Loss: 2.2882509231567383, Synthetic Data Grad Norm: 0.00017928711895365268\n",
      "Epoch 3, Meta Loss: 2.2927238941192627, Synthetic Data Grad Norm: 0.00027955693076364696\n",
      "Epoch 3, Meta Loss: 2.2640268802642822, Synthetic Data Grad Norm: 0.00022494106087833643\n",
      "Epoch 3, Meta Loss: 2.2882089614868164, Synthetic Data Grad Norm: 0.00022729106422048062\n",
      "Epoch 3, Meta Loss: 2.2670531272888184, Synthetic Data Grad Norm: 0.0002699728647712618\n",
      "Epoch 3, Meta Loss: 2.2632699012756348, Synthetic Data Grad Norm: 0.0002283228241140023\n",
      "Epoch 3, Meta Loss: 2.2525429725646973, Synthetic Data Grad Norm: 0.0003274330811109394\n",
      "Epoch 3, Meta Loss: 2.265348196029663, Synthetic Data Grad Norm: 0.00024941383162513375\n",
      "Epoch 3, Meta Loss: 2.2605435848236084, Synthetic Data Grad Norm: 0.00032413977896794677\n",
      "Epoch 3, Meta Loss: 2.3033699989318848, Synthetic Data Grad Norm: 0.00023857677297201008\n",
      "Epoch 3, Meta Loss: 2.2738571166992188, Synthetic Data Grad Norm: 0.0003021909506060183\n",
      "Epoch 3, Meta Loss: 2.2707831859588623, Synthetic Data Grad Norm: 0.00023721424804534763\n",
      "Epoch 3, Meta Loss: 2.284601926803589, Synthetic Data Grad Norm: 0.0002081497514154762\n",
      "Epoch 3, Meta Loss: 2.277414560317993, Synthetic Data Grad Norm: 0.0002815863990690559\n",
      "Epoch 3, Meta Loss: 2.28106951713562, Synthetic Data Grad Norm: 0.00025524903321638703\n",
      "Epoch 3, Meta Loss: 2.2606606483459473, Synthetic Data Grad Norm: 0.00023550435435026884\n",
      "Epoch 3, Meta Loss: 2.2682533264160156, Synthetic Data Grad Norm: 0.00035364707582630217\n",
      "Epoch 3, Meta Loss: 2.2913308143615723, Synthetic Data Grad Norm: 0.00023484880512114614\n",
      "Epoch 3, Meta Loss: 2.2741808891296387, Synthetic Data Grad Norm: 0.0002284500515088439\n",
      "Epoch 3, Meta Loss: 2.277238130569458, Synthetic Data Grad Norm: 0.00027149601373821497\n",
      "Epoch 3, Meta Loss: 2.2942605018615723, Synthetic Data Grad Norm: 0.0002668552042450756\n",
      "Epoch 3, Meta Loss: 2.2834625244140625, Synthetic Data Grad Norm: 0.00021516662673093379\n",
      "Epoch 3, Meta Loss: 2.277683973312378, Synthetic Data Grad Norm: 0.0002458405797369778\n",
      "Epoch 3, Meta Loss: 2.2789299488067627, Synthetic Data Grad Norm: 0.00022410633391700685\n",
      "Epoch 3, Meta Loss: 2.2643048763275146, Synthetic Data Grad Norm: 0.00030035636154934764\n",
      "Epoch 3, Meta Loss: 2.2650339603424072, Synthetic Data Grad Norm: 0.0002789697318803519\n",
      "Epoch 3, Meta Loss: 2.265763521194458, Synthetic Data Grad Norm: 0.00026521511608734727\n",
      "Epoch 3, Meta Loss: 2.283111333847046, Synthetic Data Grad Norm: 0.0002773943415377289\n",
      "Epoch 3, Meta Loss: 2.2648158073425293, Synthetic Data Grad Norm: 0.00026229830109514296\n",
      "Epoch 3, Meta Loss: 2.274411916732788, Synthetic Data Grad Norm: 0.000319721206324175\n",
      "Epoch 3, Meta Loss: 2.2846519947052, Synthetic Data Grad Norm: 0.00024002954887691885\n",
      "Epoch 3, Meta Loss: 2.255136251449585, Synthetic Data Grad Norm: 0.0002638191799633205\n",
      "Epoch 3, Meta Loss: 2.2881834506988525, Synthetic Data Grad Norm: 0.00021551403915509582\n",
      "Epoch 3, Meta Loss: 2.2769906520843506, Synthetic Data Grad Norm: 0.00030921437428332865\n",
      "Epoch 3, Meta Loss: 2.265674591064453, Synthetic Data Grad Norm: 0.0002955182280857116\n",
      "Epoch 3, Meta Loss: 2.277007579803467, Synthetic Data Grad Norm: 0.00026587213505990803\n",
      "Epoch 3, Meta Loss: 2.2493162155151367, Synthetic Data Grad Norm: 0.00034452477120794356\n",
      "Epoch 3, Meta Loss: 2.273179292678833, Synthetic Data Grad Norm: 0.0002290004340466112\n",
      "Epoch 3, Meta Loss: 2.270045518875122, Synthetic Data Grad Norm: 0.0002767952100839466\n",
      "Epoch 3, Meta Loss: 2.290227174758911, Synthetic Data Grad Norm: 0.0002582828456070274\n",
      "Epoch 3, Meta Loss: 2.275472640991211, Synthetic Data Grad Norm: 0.0002487161254975945\n",
      "Epoch 3, Meta Loss: 2.2841579914093018, Synthetic Data Grad Norm: 0.0003128846001345664\n",
      "Epoch 3, Meta Loss: 2.2645089626312256, Synthetic Data Grad Norm: 0.0003216858603991568\n",
      "Epoch 3, Meta Loss: 2.2895290851593018, Synthetic Data Grad Norm: 0.0002161922020604834\n",
      "Epoch 3, Meta Loss: 2.299356460571289, Synthetic Data Grad Norm: 0.00027173871058039367\n",
      "Epoch 3, Meta Loss: 2.2418887615203857, Synthetic Data Grad Norm: 0.00035090549499727786\n",
      "Epoch 3, Meta Loss: 2.262799024581909, Synthetic Data Grad Norm: 0.00028608401771634817\n",
      "Epoch 3, Meta Loss: 2.3082313537597656, Synthetic Data Grad Norm: 0.00035966761060990393\n",
      "Epoch 3, Meta Loss: 2.2584187984466553, Synthetic Data Grad Norm: 0.00030126605997793376\n",
      "Epoch 3, Meta Loss: 2.2816262245178223, Synthetic Data Grad Norm: 0.00022330181673169136\n",
      "Epoch 3, Meta Loss: 2.2733542919158936, Synthetic Data Grad Norm: 0.0002736240567173809\n",
      "Epoch 3, Meta Loss: 2.289764404296875, Synthetic Data Grad Norm: 0.00021830547484569252\n",
      "Epoch 3, Meta Loss: 2.291539192199707, Synthetic Data Grad Norm: 0.00022066610108595341\n",
      "Epoch 3, Meta Loss: 2.2973756790161133, Synthetic Data Grad Norm: 0.00028785542235709727\n",
      "Epoch 3, Meta Loss: 2.2831499576568604, Synthetic Data Grad Norm: 0.000448764709290117\n",
      "Epoch 3, Meta Loss: 2.2658233642578125, Synthetic Data Grad Norm: 0.00030015810625627637\n",
      "Epoch 3, Meta Loss: 2.2648110389709473, Synthetic Data Grad Norm: 0.0002641484315972775\n",
      "Epoch 3, Meta Loss: 2.2828590869903564, Synthetic Data Grad Norm: 0.00030447746394202113\n",
      "Epoch 3, Meta Loss: 2.27504825592041, Synthetic Data Grad Norm: 0.000269524083705619\n",
      "Epoch 3, Meta Loss: 2.26971173286438, Synthetic Data Grad Norm: 0.00024005553859751672\n",
      "Epoch 3, Meta Loss: 2.2386176586151123, Synthetic Data Grad Norm: 0.0003356881788931787\n",
      "Epoch 3, Meta Loss: 2.2841598987579346, Synthetic Data Grad Norm: 0.00027555887936614454\n",
      "Epoch 3, Meta Loss: 2.284081220626831, Synthetic Data Grad Norm: 0.0002989663917105645\n",
      "Epoch 3, Meta Loss: 2.264571189880371, Synthetic Data Grad Norm: 0.00024626069352962077\n",
      "Epoch 3, Meta Loss: 2.2907471656799316, Synthetic Data Grad Norm: 0.0002344624954275787\n",
      "Epoch 3, Meta Loss: 2.267808198928833, Synthetic Data Grad Norm: 0.00029782328056171536\n",
      "Epoch 3, Meta Loss: 2.271904468536377, Synthetic Data Grad Norm: 0.0003448164789006114\n",
      "Epoch 3, Meta Loss: 2.2539286613464355, Synthetic Data Grad Norm: 0.0003373820218257606\n",
      "Epoch 3, Meta Loss: 2.2873640060424805, Synthetic Data Grad Norm: 0.0001741220912663266\n",
      "Epoch 3, Meta Loss: 2.281651258468628, Synthetic Data Grad Norm: 0.000379179953597486\n",
      "Epoch 3, Meta Loss: 2.243568181991577, Synthetic Data Grad Norm: 0.0003612204745877534\n",
      "Epoch 3, Meta Loss: 2.26887583732605, Synthetic Data Grad Norm: 0.000278903404250741\n",
      "Epoch 3, Meta Loss: 2.293912649154663, Synthetic Data Grad Norm: 0.00024116827989928424\n",
      "Epoch 3, Meta Loss: 2.2949278354644775, Synthetic Data Grad Norm: 0.00023390029673464596\n",
      "Epoch 3, Meta Loss: 2.284245491027832, Synthetic Data Grad Norm: 0.00038310367381200194\n",
      "Epoch 3, Meta Loss: 2.256502628326416, Synthetic Data Grad Norm: 0.0003203570668119937\n",
      "Epoch 3, Meta Loss: 2.2734413146972656, Synthetic Data Grad Norm: 0.0002971262438222766\n",
      "Epoch 3, Meta Loss: 2.2862298488616943, Synthetic Data Grad Norm: 0.00034217716893181205\n",
      "Epoch 3, Meta Loss: 2.2860305309295654, Synthetic Data Grad Norm: 0.00024433789076283574\n",
      "Epoch 3, Meta Loss: 2.2592225074768066, Synthetic Data Grad Norm: 0.000445803307229653\n",
      "Epoch 3, Meta Loss: 2.279400110244751, Synthetic Data Grad Norm: 0.0002476218214724213\n",
      "Epoch 3, Meta Loss: 2.294046401977539, Synthetic Data Grad Norm: 0.0002463013515807688\n",
      "Epoch 3, Meta Loss: 2.2850897312164307, Synthetic Data Grad Norm: 0.0002046594163402915\n",
      "Epoch 3, Meta Loss: 2.270535945892334, Synthetic Data Grad Norm: 0.00030119152506813407\n",
      "Epoch 3, Meta Loss: 2.274470806121826, Synthetic Data Grad Norm: 0.00021070327784400433\n",
      "Epoch 3, Meta Loss: 2.2577528953552246, Synthetic Data Grad Norm: 0.00034154480090364814\n",
      "Epoch 3, Meta Loss: 2.2679197788238525, Synthetic Data Grad Norm: 0.00031231489265337586\n",
      "Epoch 3, Meta Loss: 2.2838189601898193, Synthetic Data Grad Norm: 0.0003007747291121632\n",
      "Epoch 3, Meta Loss: 2.2670798301696777, Synthetic Data Grad Norm: 0.00025558011839166284\n",
      "Epoch 3, Meta Loss: 2.283600091934204, Synthetic Data Grad Norm: 0.0002745563688222319\n",
      "Epoch 3, Meta Loss: 2.285060405731201, Synthetic Data Grad Norm: 0.0002884617424570024\n",
      "Epoch 3, Meta Loss: 2.277631998062134, Synthetic Data Grad Norm: 0.0002005319547606632\n",
      "Epoch 3, Meta Loss: 2.2786941528320312, Synthetic Data Grad Norm: 0.000286090187728405\n",
      "Epoch 3, Meta Loss: 2.2620444297790527, Synthetic Data Grad Norm: 0.00026532800984568894\n",
      "Epoch 3, Meta Loss: 2.2423932552337646, Synthetic Data Grad Norm: 0.00031283177668228745\n",
      "Epoch 3, Meta Loss: 2.290529251098633, Synthetic Data Grad Norm: 0.00025562633527442813\n",
      "Epoch 3, Meta Loss: 2.255819320678711, Synthetic Data Grad Norm: 0.0002878519590012729\n",
      "Epoch 3, Meta Loss: 2.270792007446289, Synthetic Data Grad Norm: 0.0003318267408758402\n",
      "Epoch 3, Meta Loss: 2.280716896057129, Synthetic Data Grad Norm: 0.00041049945866689086\n",
      "Epoch 3, Meta Loss: 2.2956881523132324, Synthetic Data Grad Norm: 0.0003721884568221867\n",
      "Epoch 3, Meta Loss: 2.270664691925049, Synthetic Data Grad Norm: 0.00031798548297956586\n",
      "Epoch 3, Meta Loss: 2.266800880432129, Synthetic Data Grad Norm: 0.00029960909159854054\n",
      "Epoch 3, Meta Loss: 2.264772653579712, Synthetic Data Grad Norm: 0.000304488989058882\n",
      "Epoch 3, Meta Loss: 2.2924909591674805, Synthetic Data Grad Norm: 0.0002517985412850976\n",
      "Epoch 3, Meta Loss: 2.2520201206207275, Synthetic Data Grad Norm: 0.00039769188151694834\n",
      "Epoch 3, Meta Loss: 2.275738477706909, Synthetic Data Grad Norm: 0.0002582875022199005\n",
      "Epoch 3, Meta Loss: 2.309401512145996, Synthetic Data Grad Norm: 0.0002145104226656258\n",
      "Epoch 3, Meta Loss: 2.267659902572632, Synthetic Data Grad Norm: 0.0002895142824854702\n",
      "Epoch 3, Meta Loss: 2.270820140838623, Synthetic Data Grad Norm: 0.00031094576115719974\n",
      "Epoch 3, Meta Loss: 2.2679545879364014, Synthetic Data Grad Norm: 0.0002800877846311778\n",
      "Epoch 3, Meta Loss: 2.2900712490081787, Synthetic Data Grad Norm: 0.00027302702073939145\n",
      "Epoch 3, Meta Loss: 2.273725986480713, Synthetic Data Grad Norm: 0.00030930654611438513\n",
      "Epoch 3, Meta Loss: 2.2618842124938965, Synthetic Data Grad Norm: 0.00024925085017457604\n",
      "Epoch 3, Meta Loss: 2.28775954246521, Synthetic Data Grad Norm: 0.00016657356172800064\n",
      "Epoch 3, Meta Loss: 2.2623445987701416, Synthetic Data Grad Norm: 0.00037524517392739654\n",
      "Epoch 3, Meta Loss: 2.254183769226074, Synthetic Data Grad Norm: 0.00028686283621937037\n",
      "Epoch 3, Meta Loss: 2.258136510848999, Synthetic Data Grad Norm: 0.0002998776326421648\n",
      "Epoch 3, Meta Loss: 2.2498390674591064, Synthetic Data Grad Norm: 0.0003663959796540439\n",
      "Epoch 3, Meta Loss: 2.29026460647583, Synthetic Data Grad Norm: 0.0003188576956745237\n",
      "Epoch 3, Meta Loss: 2.2669153213500977, Synthetic Data Grad Norm: 0.0002830292214639485\n",
      "Epoch 3, Meta Loss: 2.2901220321655273, Synthetic Data Grad Norm: 0.0004042964137624949\n",
      "Epoch 3, Meta Loss: 2.2642664909362793, Synthetic Data Grad Norm: 0.00036297502811066806\n",
      "Epoch 3, Meta Loss: 2.2950069904327393, Synthetic Data Grad Norm: 0.00024986968492157757\n",
      "Epoch 3, Meta Loss: 2.263603448867798, Synthetic Data Grad Norm: 0.0004393945855554193\n",
      "Epoch 3, Meta Loss: 2.280639886856079, Synthetic Data Grad Norm: 0.00023617241822648793\n",
      "Epoch 3, Meta Loss: 2.263009548187256, Synthetic Data Grad Norm: 0.00037179214996285737\n",
      "Epoch 3, Meta Loss: 2.271641731262207, Synthetic Data Grad Norm: 0.0002549064811319113\n",
      "Epoch 3, Meta Loss: 2.263270616531372, Synthetic Data Grad Norm: 0.00032099749660119414\n",
      "Epoch 3, Meta Loss: 2.2612318992614746, Synthetic Data Grad Norm: 0.00028163602109998465\n",
      "Epoch 3, Meta Loss: 2.2625179290771484, Synthetic Data Grad Norm: 0.00027839437825605273\n",
      "Epoch 3, Meta Loss: 2.267672538757324, Synthetic Data Grad Norm: 0.00032541813561692834\n",
      "Epoch 3, Meta Loss: 2.2836756706237793, Synthetic Data Grad Norm: 0.00028921529883518815\n",
      "Epoch 3, Meta Loss: 2.2487971782684326, Synthetic Data Grad Norm: 0.00040013089892454445\n",
      "Epoch 3, Meta Loss: 2.2694716453552246, Synthetic Data Grad Norm: 0.00024674664018675685\n",
      "Epoch 3, Meta Loss: 2.2568209171295166, Synthetic Data Grad Norm: 0.0003175038145855069\n",
      "Epoch 3, Meta Loss: 2.2887356281280518, Synthetic Data Grad Norm: 0.0002468228340148926\n",
      "Epoch 3, Meta Loss: 2.271946430206299, Synthetic Data Grad Norm: 0.0003029555664397776\n",
      "Epoch 3, Meta Loss: 2.2539589405059814, Synthetic Data Grad Norm: 0.00037087174132466316\n",
      "Epoch 3, Meta Loss: 2.2698802947998047, Synthetic Data Grad Norm: 0.0002368688874412328\n",
      "Epoch 3, Meta Loss: 2.28108286857605, Synthetic Data Grad Norm: 0.0002546773466747254\n",
      "Epoch 3, Meta Loss: 2.2747983932495117, Synthetic Data Grad Norm: 0.00033982712193392217\n",
      "Epoch 3, Meta Loss: 2.2591054439544678, Synthetic Data Grad Norm: 0.0003401761641725898\n",
      "Epoch 3, Meta Loss: 2.2509167194366455, Synthetic Data Grad Norm: 0.0003035987901967019\n",
      "Epoch 3, Meta Loss: 2.259200096130371, Synthetic Data Grad Norm: 0.0002665588981471956\n",
      "Epoch 3, Meta Loss: 2.2726049423217773, Synthetic Data Grad Norm: 0.0002790916187223047\n",
      "Epoch 3, Meta Loss: 2.278452157974243, Synthetic Data Grad Norm: 0.00029494098271243274\n",
      "Epoch 3, Meta Loss: 2.2508106231689453, Synthetic Data Grad Norm: 0.0003460418665781617\n",
      "Epoch 3, Meta Loss: 2.2757837772369385, Synthetic Data Grad Norm: 0.0003572084242478013\n",
      "Epoch 3, Meta Loss: 2.2717831134796143, Synthetic Data Grad Norm: 0.00026537931989878416\n",
      "Epoch 3, Meta Loss: 2.297356367111206, Synthetic Data Grad Norm: 0.00019222941773477942\n",
      "Epoch 3, Meta Loss: 2.272716760635376, Synthetic Data Grad Norm: 0.00029244922916404903\n",
      "Epoch 3, Meta Loss: 2.2900421619415283, Synthetic Data Grad Norm: 0.00020028118160553277\n",
      "Epoch 3, Meta Loss: 2.263307809829712, Synthetic Data Grad Norm: 0.00039648698293603957\n",
      "Epoch 3, Meta Loss: 2.2839267253875732, Synthetic Data Grad Norm: 0.00036269400152377784\n",
      "Epoch 3, Meta Loss: 2.29887056350708, Synthetic Data Grad Norm: 0.00035584383294917643\n",
      "Epoch 3, Meta Loss: 2.2835068702697754, Synthetic Data Grad Norm: 0.0003346905286889523\n",
      "Epoch 3, Meta Loss: 2.2738852500915527, Synthetic Data Grad Norm: 0.0002720915654208511\n",
      "Epoch 3, Meta Loss: 2.263895273208618, Synthetic Data Grad Norm: 0.00025837699649855494\n",
      "Epoch 3, Meta Loss: 2.2717807292938232, Synthetic Data Grad Norm: 0.0002665627107489854\n",
      "Epoch 3, Meta Loss: 2.23856782913208, Synthetic Data Grad Norm: 0.00044704281026497483\n",
      "Epoch 3, Meta Loss: 2.2723793983459473, Synthetic Data Grad Norm: 0.0003436824190430343\n",
      "Epoch 3, Meta Loss: 2.2767934799194336, Synthetic Data Grad Norm: 0.0003244395775254816\n",
      "Epoch 3, Meta Loss: 2.2723052501678467, Synthetic Data Grad Norm: 0.00023293340927921236\n",
      "Epoch 3, Meta Loss: 2.2549664974212646, Synthetic Data Grad Norm: 0.0003549902467057109\n",
      "Epoch 3, Meta Loss: 2.2597968578338623, Synthetic Data Grad Norm: 0.00032211586949415505\n",
      "Epoch 3, Meta Loss: 2.2709755897521973, Synthetic Data Grad Norm: 0.00024164386559277773\n",
      "Epoch 3, Meta Loss: 2.2841720581054688, Synthetic Data Grad Norm: 0.00032137634116224945\n",
      "Epoch 3, Meta Loss: 2.2831943035125732, Synthetic Data Grad Norm: 0.0002493991341907531\n",
      "Epoch 3, Meta Loss: 2.261134386062622, Synthetic Data Grad Norm: 0.00036676228046417236\n",
      "Epoch 3, Meta Loss: 2.2884016036987305, Synthetic Data Grad Norm: 0.00021418326650746167\n",
      "Epoch 3, Meta Loss: 2.283168315887451, Synthetic Data Grad Norm: 0.00022118039487395436\n",
      "Epoch 3, Meta Loss: 2.292922019958496, Synthetic Data Grad Norm: 0.0003850111970677972\n",
      "Epoch 3, Meta Loss: 2.27744197845459, Synthetic Data Grad Norm: 0.00027620093896985054\n",
      "Epoch 3, Meta Loss: 2.268563985824585, Synthetic Data Grad Norm: 0.00027304349350742996\n",
      "Epoch 3, Meta Loss: 2.271829843521118, Synthetic Data Grad Norm: 0.0002249504905194044\n",
      "Epoch 3, Meta Loss: 2.279603958129883, Synthetic Data Grad Norm: 0.0002919032413046807\n",
      "Epoch 3, Meta Loss: 2.273050546646118, Synthetic Data Grad Norm: 0.0002828756405506283\n",
      "Epoch 3, Meta Loss: 2.273904323577881, Synthetic Data Grad Norm: 0.00034431074163876474\n",
      "Epoch 3, Meta Loss: 2.283764362335205, Synthetic Data Grad Norm: 0.00021704231039620936\n",
      "Epoch 3, Meta Loss: 2.272887945175171, Synthetic Data Grad Norm: 0.0002866232243832201\n",
      "Epoch 3, Meta Loss: 2.2735114097595215, Synthetic Data Grad Norm: 0.0003299535601399839\n",
      "Epoch 3, Meta Loss: 2.27919602394104, Synthetic Data Grad Norm: 0.00023266251082532108\n",
      "Epoch 3, Meta Loss: 2.261439085006714, Synthetic Data Grad Norm: 0.00024195360310841352\n",
      "Epoch 3, Meta Loss: 2.287341833114624, Synthetic Data Grad Norm: 0.0002804865944199264\n",
      "Epoch 3, Meta Loss: 2.269160032272339, Synthetic Data Grad Norm: 0.000332577561493963\n",
      "Epoch 3, Meta Loss: 2.287177085876465, Synthetic Data Grad Norm: 0.00027220870833843946\n",
      "Epoch 3, Meta Loss: 2.2866902351379395, Synthetic Data Grad Norm: 0.00035239398130215704\n",
      "Epoch 3, Meta Loss: 2.2885794639587402, Synthetic Data Grad Norm: 0.0003135167062282562\n",
      "Epoch 3, Meta Loss: 2.282010793685913, Synthetic Data Grad Norm: 0.0002173630491597578\n",
      "Epoch 3, Meta Loss: 2.2823898792266846, Synthetic Data Grad Norm: 0.00033466776949353516\n",
      "Epoch 3, Meta Loss: 2.268282413482666, Synthetic Data Grad Norm: 0.0002611476229503751\n",
      "Epoch 3, Meta Loss: 2.2771995067596436, Synthetic Data Grad Norm: 0.0002768411359284073\n",
      "Epoch 3, Meta Loss: 2.262662410736084, Synthetic Data Grad Norm: 0.00022997299674898386\n",
      "Epoch 3, Meta Loss: 2.284879207611084, Synthetic Data Grad Norm: 0.0002889046154450625\n",
      "Epoch 3, Meta Loss: 2.2711808681488037, Synthetic Data Grad Norm: 0.00031171151204034686\n",
      "Epoch 3, Meta Loss: 2.27302885055542, Synthetic Data Grad Norm: 0.00027806221623905003\n",
      "Epoch 3, Meta Loss: 2.2585434913635254, Synthetic Data Grad Norm: 0.0003161810745950788\n",
      "Epoch 3, Meta Loss: 2.2387847900390625, Synthetic Data Grad Norm: 0.00038927499554120004\n",
      "Epoch 3, Meta Loss: 2.295767307281494, Synthetic Data Grad Norm: 0.00016571138985455036\n",
      "Epoch 3, Meta Loss: 2.268115520477295, Synthetic Data Grad Norm: 0.00037066207733005285\n",
      "Epoch 3, Meta Loss: 2.263681411743164, Synthetic Data Grad Norm: 0.00042446766747161746\n",
      "Epoch 3, Meta Loss: 2.284592390060425, Synthetic Data Grad Norm: 0.0003066200588364154\n",
      "Epoch 3, Meta Loss: 2.2620067596435547, Synthetic Data Grad Norm: 0.0002541936410125345\n",
      "Epoch 3, Meta Loss: 2.290818214416504, Synthetic Data Grad Norm: 0.00023234853870235384\n",
      "Epoch 3, Meta Loss: 2.271174192428589, Synthetic Data Grad Norm: 0.0002861350658349693\n",
      "Epoch 3, Meta Loss: 2.276944637298584, Synthetic Data Grad Norm: 0.00024100088921841234\n",
      "Epoch 3, Meta Loss: 2.28627347946167, Synthetic Data Grad Norm: 0.00023854547180235386\n",
      "Epoch 3, Meta Loss: 2.2712531089782715, Synthetic Data Grad Norm: 0.0003161492641083896\n",
      "Epoch 3, Meta Loss: 2.273749828338623, Synthetic Data Grad Norm: 0.00034764865995384753\n",
      "Epoch 3, Meta Loss: 2.2826616764068604, Synthetic Data Grad Norm: 0.0003357307577971369\n",
      "Epoch 3, Meta Loss: 2.2711522579193115, Synthetic Data Grad Norm: 0.00025659723905846477\n",
      "Epoch 3, Meta Loss: 2.271402359008789, Synthetic Data Grad Norm: 0.000385584105970338\n",
      "Epoch 3, Meta Loss: 2.2634575366973877, Synthetic Data Grad Norm: 0.00026460972731001675\n",
      "Epoch 3, Meta Loss: 2.280601739883423, Synthetic Data Grad Norm: 0.00026421211077831686\n",
      "Epoch 3, Meta Loss: 2.273522138595581, Synthetic Data Grad Norm: 0.00026777363382279873\n",
      "Epoch 3, Meta Loss: 2.285113573074341, Synthetic Data Grad Norm: 0.0002947705506812781\n",
      "Epoch 3, Meta Loss: 2.264868974685669, Synthetic Data Grad Norm: 0.0003814678930211812\n",
      "Epoch 3, Meta Loss: 2.2899067401885986, Synthetic Data Grad Norm: 0.00020932924235239625\n",
      "Epoch 3, Meta Loss: 2.2524538040161133, Synthetic Data Grad Norm: 0.00030181900365278125\n",
      "Epoch 3, Meta Loss: 2.271604537963867, Synthetic Data Grad Norm: 0.00026241166051477194\n",
      "Epoch 3, Meta Loss: 2.2578086853027344, Synthetic Data Grad Norm: 0.0003898024442605674\n",
      "Epoch 3, Meta Loss: 2.274479389190674, Synthetic Data Grad Norm: 0.0002690955298021436\n",
      "Epoch 3, Meta Loss: 2.281963348388672, Synthetic Data Grad Norm: 0.00026295706629753113\n",
      "Epoch 3, Meta Loss: 2.2711269855499268, Synthetic Data Grad Norm: 0.000261347129708156\n",
      "Epoch 3, Meta Loss: 2.2668135166168213, Synthetic Data Grad Norm: 0.00024218144244514406\n",
      "Epoch 3, Meta Loss: 2.265571117401123, Synthetic Data Grad Norm: 0.00023255168343894184\n",
      "Epoch 3, Meta Loss: 2.2874104976654053, Synthetic Data Grad Norm: 0.0002390126173850149\n",
      "Epoch 3, Meta Loss: 2.26029634475708, Synthetic Data Grad Norm: 0.0003353181527927518\n",
      "Epoch 3, Meta Loss: 2.2782235145568848, Synthetic Data Grad Norm: 0.0002634368429426104\n",
      "Epoch 3, Meta Loss: 2.2743654251098633, Synthetic Data Grad Norm: 0.0003380972193554044\n",
      "Epoch 3, Meta Loss: 2.265138864517212, Synthetic Data Grad Norm: 0.00031789662898518145\n",
      "Epoch 3, Meta Loss: 2.2728781700134277, Synthetic Data Grad Norm: 0.0002834877814166248\n",
      "Epoch 3, Meta Loss: 2.2795023918151855, Synthetic Data Grad Norm: 0.0003400849527679384\n",
      "Epoch 3, Meta Loss: 2.2723474502563477, Synthetic Data Grad Norm: 0.00032240248401649296\n",
      "Epoch 3, Meta Loss: 2.278406858444214, Synthetic Data Grad Norm: 0.0003232017043046653\n",
      "Epoch 3, Meta Loss: 2.2751407623291016, Synthetic Data Grad Norm: 0.0003033272223547101\n",
      "Epoch 3, Meta Loss: 2.2779674530029297, Synthetic Data Grad Norm: 0.0003225010877940804\n",
      "Epoch 3, Meta Loss: 2.2828080654144287, Synthetic Data Grad Norm: 0.0002680030302144587\n",
      "Epoch 3, Meta Loss: 2.276506185531616, Synthetic Data Grad Norm: 0.00036663873470388353\n",
      "Epoch 3, Meta Loss: 2.2890677452087402, Synthetic Data Grad Norm: 0.00019802417955361307\n",
      "Epoch 3, Meta Loss: 2.2756729125976562, Synthetic Data Grad Norm: 0.0003277498180978\n",
      "Epoch 3, Meta Loss: 2.2682716846466064, Synthetic Data Grad Norm: 0.0002663434424903244\n",
      "Epoch 3, Meta Loss: 2.2841432094573975, Synthetic Data Grad Norm: 0.00029279637965373695\n",
      "Epoch 3, Meta Loss: 2.275761127471924, Synthetic Data Grad Norm: 0.00024399117683060467\n",
      "Epoch 3, Meta Loss: 2.267779588699341, Synthetic Data Grad Norm: 0.000274354504654184\n",
      "Epoch 3, Meta Loss: 2.271739959716797, Synthetic Data Grad Norm: 0.0002803768147714436\n",
      "Epoch 3, Meta Loss: 2.244255781173706, Synthetic Data Grad Norm: 0.00038911242154426873\n",
      "Epoch 3, Meta Loss: 2.26414155960083, Synthetic Data Grad Norm: 0.0002792146406136453\n",
      "Epoch 3, Meta Loss: 2.2842419147491455, Synthetic Data Grad Norm: 0.0003054130356758833\n",
      "Epoch 3, Meta Loss: 2.2823076248168945, Synthetic Data Grad Norm: 0.00023375925957225263\n",
      "Epoch 3, Meta Loss: 2.279907464981079, Synthetic Data Grad Norm: 0.00025309459306299686\n",
      "Epoch 3, Meta Loss: 2.2724716663360596, Synthetic Data Grad Norm: 0.0003234117466490716\n",
      "Epoch 3, Meta Loss: 2.3009002208709717, Synthetic Data Grad Norm: 0.0003768685564864427\n",
      "Epoch 3, Meta Loss: 2.273456335067749, Synthetic Data Grad Norm: 0.00031547455000691116\n",
      "Epoch 3, Meta Loss: 2.2724320888519287, Synthetic Data Grad Norm: 0.00032159226248040795\n",
      "Epoch 3, Meta Loss: 2.2707221508026123, Synthetic Data Grad Norm: 0.0002880715182982385\n",
      "Epoch 3, Meta Loss: 2.2725069522857666, Synthetic Data Grad Norm: 0.0002998689597006887\n",
      "Epoch 3, Meta Loss: 2.246988296508789, Synthetic Data Grad Norm: 0.000300701183732599\n",
      "Epoch 3, Meta Loss: 2.2868306636810303, Synthetic Data Grad Norm: 0.0003535002761054784\n",
      "Epoch 3, Meta Loss: 2.2779831886291504, Synthetic Data Grad Norm: 0.0003452406672295183\n",
      "Epoch 3, Meta Loss: 2.266814947128296, Synthetic Data Grad Norm: 0.0003035521658603102\n",
      "Epoch 3, Meta Loss: 2.275205135345459, Synthetic Data Grad Norm: 0.00026184835587628186\n",
      "Epoch 3, Meta Loss: 2.2636332511901855, Synthetic Data Grad Norm: 0.0002939860860351473\n",
      "Epoch 3, Meta Loss: 2.2662453651428223, Synthetic Data Grad Norm: 0.00023171371140051633\n",
      "Epoch 3, Meta Loss: 2.2666738033294678, Synthetic Data Grad Norm: 0.0003276066854596138\n",
      "Epoch 3, Meta Loss: 2.2700388431549072, Synthetic Data Grad Norm: 0.00026195909595116973\n",
      "Epoch 3, Meta Loss: 2.2948930263519287, Synthetic Data Grad Norm: 0.00023944278655108064\n",
      "Epoch 3, Meta Loss: 2.272123336791992, Synthetic Data Grad Norm: 0.0002751279389485717\n",
      "Epoch 3, Meta Loss: 2.267681360244751, Synthetic Data Grad Norm: 0.00037322999560274184\n",
      "Epoch 3, Meta Loss: 2.2720911502838135, Synthetic Data Grad Norm: 0.00030349771259352565\n",
      "Epoch 3, Meta Loss: 2.259938955307007, Synthetic Data Grad Norm: 0.00040613810415379703\n",
      "Epoch 3, Meta Loss: 2.2729082107543945, Synthetic Data Grad Norm: 0.00030042463913559914\n",
      "Epoch 3, Meta Loss: 2.2721071243286133, Synthetic Data Grad Norm: 0.00029544683638960123\n",
      "Epoch 3, Meta Loss: 2.2773046493530273, Synthetic Data Grad Norm: 0.0003184652596246451\n",
      "Epoch 3, Meta Loss: 2.2878479957580566, Synthetic Data Grad Norm: 0.00024498699349351227\n",
      "Epoch 3, Meta Loss: 2.25517201423645, Synthetic Data Grad Norm: 0.0003225437249056995\n",
      "Epoch 3, Meta Loss: 2.285630941390991, Synthetic Data Grad Norm: 0.00023638509446755052\n",
      "Epoch 3, Meta Loss: 2.294077157974243, Synthetic Data Grad Norm: 0.00023095106007531285\n",
      "Epoch 3, Meta Loss: 2.2685177326202393, Synthetic Data Grad Norm: 0.00026082908152602613\n",
      "Epoch 3, Meta Loss: 2.2718100547790527, Synthetic Data Grad Norm: 0.0002696479205042124\n",
      "Epoch 3, Meta Loss: 2.2760438919067383, Synthetic Data Grad Norm: 0.00028497629682533443\n",
      "Epoch 3, Meta Loss: 2.2851028442382812, Synthetic Data Grad Norm: 0.00027388057787902653\n",
      "Epoch 3, Meta Loss: 2.2526729106903076, Synthetic Data Grad Norm: 0.00030875069205649197\n",
      "Epoch 3, Meta Loss: 2.293682336807251, Synthetic Data Grad Norm: 0.0002747694670688361\n",
      "Epoch 3, Meta Loss: 2.251265048980713, Synthetic Data Grad Norm: 0.0003740242391359061\n",
      "Epoch 3, Meta Loss: 2.2652604579925537, Synthetic Data Grad Norm: 0.0002721133059822023\n",
      "Epoch 3, Meta Loss: 2.264664649963379, Synthetic Data Grad Norm: 0.00041183113353326917\n",
      "Epoch 3, Meta Loss: 2.2700376510620117, Synthetic Data Grad Norm: 0.00028356577968224883\n",
      "Epoch 3, Meta Loss: 2.2963805198669434, Synthetic Data Grad Norm: 0.0002751972933765501\n",
      "Epoch 3, Meta Loss: 2.2737338542938232, Synthetic Data Grad Norm: 0.0002957515825983137\n",
      "Epoch 3, Meta Loss: 2.2755210399627686, Synthetic Data Grad Norm: 0.0002832415630109608\n",
      "Epoch 3, Meta Loss: 2.2713000774383545, Synthetic Data Grad Norm: 0.0002992085355799645\n",
      "Epoch 3, Meta Loss: 2.269012451171875, Synthetic Data Grad Norm: 0.00029701186576858163\n",
      "Epoch 3, Meta Loss: 2.2656023502349854, Synthetic Data Grad Norm: 0.00034643334220163524\n",
      "Epoch 3, Meta Loss: 2.27453351020813, Synthetic Data Grad Norm: 0.00035108349402435124\n",
      "Epoch 3, Meta Loss: 2.268279790878296, Synthetic Data Grad Norm: 0.0002891395124606788\n",
      "Epoch 3, Meta Loss: 2.265949249267578, Synthetic Data Grad Norm: 0.00027593964478001\n",
      "Epoch 3, Meta Loss: 2.270864248275757, Synthetic Data Grad Norm: 0.0002546398027334362\n",
      "Epoch 3, Meta Loss: 2.2595622539520264, Synthetic Data Grad Norm: 0.00032551499316468835\n",
      "Epoch 3, Meta Loss: 2.2599453926086426, Synthetic Data Grad Norm: 0.0004033764998894185\n",
      "Epoch 3, Meta Loss: 2.2799038887023926, Synthetic Data Grad Norm: 0.0002904558496084064\n",
      "Epoch 3, Meta Loss: 2.2653398513793945, Synthetic Data Grad Norm: 0.00028344220481812954\n",
      "Epoch 3, Meta Loss: 2.2766597270965576, Synthetic Data Grad Norm: 0.0002785608230624348\n",
      "Epoch 3, Meta Loss: 2.2688941955566406, Synthetic Data Grad Norm: 0.00029492174508050084\n",
      "Epoch 3, Meta Loss: 2.2576839923858643, Synthetic Data Grad Norm: 0.0002936984528787434\n",
      "Epoch 3, Meta Loss: 2.262131690979004, Synthetic Data Grad Norm: 0.000286203867290169\n",
      "Epoch 3, Meta Loss: 2.276711940765381, Synthetic Data Grad Norm: 0.00026928025181405246\n",
      "Epoch 3, Meta Loss: 2.2680811882019043, Synthetic Data Grad Norm: 0.0003160970227327198\n",
      "Epoch 3, Meta Loss: 2.2794394493103027, Synthetic Data Grad Norm: 0.0004093679308425635\n",
      "Epoch 3, Meta Loss: 2.265613555908203, Synthetic Data Grad Norm: 0.00033389529562555254\n",
      "Epoch 3, Meta Loss: 2.267353057861328, Synthetic Data Grad Norm: 0.0003627146070357412\n",
      "Epoch 3, Meta Loss: 2.2838146686553955, Synthetic Data Grad Norm: 0.0002961615100502968\n",
      "Epoch 3, Meta Loss: 2.2634835243225098, Synthetic Data Grad Norm: 0.00030013450304977596\n",
      "Epoch 3, Meta Loss: 2.260610342025757, Synthetic Data Grad Norm: 0.00034793169470503926\n",
      "Epoch 3, Meta Loss: 2.2557220458984375, Synthetic Data Grad Norm: 0.0003176865284331143\n",
      "Epoch 3, Meta Loss: 2.2692904472351074, Synthetic Data Grad Norm: 0.00032676217961125076\n",
      "Epoch 3, Meta Loss: 2.266291618347168, Synthetic Data Grad Norm: 0.0002230397949460894\n",
      "Epoch 3, Meta Loss: 2.261078357696533, Synthetic Data Grad Norm: 0.0003121804620604962\n",
      "Epoch 3, Meta Loss: 2.2799150943756104, Synthetic Data Grad Norm: 0.0003517520672176033\n",
      "Epoch 3, Meta Loss: 2.2841989994049072, Synthetic Data Grad Norm: 0.00023407700064126402\n",
      "Epoch 3, Meta Loss: 2.2539241313934326, Synthetic Data Grad Norm: 0.0002756489848252386\n",
      "Epoch 3, Meta Loss: 2.2534501552581787, Synthetic Data Grad Norm: 0.0002730169799178839\n",
      "Epoch 3, Meta Loss: 2.2643485069274902, Synthetic Data Grad Norm: 0.0003556451993063092\n",
      "Epoch 3, Meta Loss: 2.281768798828125, Synthetic Data Grad Norm: 0.00030481451540254056\n",
      "Epoch 3, Meta Loss: 2.260586977005005, Synthetic Data Grad Norm: 0.0002818482171278447\n",
      "Epoch 3, Meta Loss: 2.2748608589172363, Synthetic Data Grad Norm: 0.0002903166168835014\n",
      "Epoch 3, Meta Loss: 2.2722203731536865, Synthetic Data Grad Norm: 0.0001784179185051471\n",
      "Epoch 3, Meta Loss: 2.260356903076172, Synthetic Data Grad Norm: 0.0003499902959447354\n",
      "Epoch 3, Meta Loss: 2.2764625549316406, Synthetic Data Grad Norm: 0.0003545603540260345\n",
      "Epoch 3, Meta Loss: 2.288213014602661, Synthetic Data Grad Norm: 0.00027894473168998957\n",
      "Epoch 4, Meta Loss: 2.27467679977417, Synthetic Data Grad Norm: 0.00035443081287667155\n",
      "Epoch 4, Meta Loss: 2.3001017570495605, Synthetic Data Grad Norm: 0.00034085396328009665\n",
      "Epoch 4, Meta Loss: 2.245750904083252, Synthetic Data Grad Norm: 0.00030459757545031607\n",
      "Epoch 4, Meta Loss: 2.2628355026245117, Synthetic Data Grad Norm: 0.000391605484765023\n",
      "Epoch 4, Meta Loss: 2.2809410095214844, Synthetic Data Grad Norm: 0.0002539681445341557\n",
      "Epoch 4, Meta Loss: 2.272494316101074, Synthetic Data Grad Norm: 0.0002958450932055712\n",
      "Epoch 4, Meta Loss: 2.2943596839904785, Synthetic Data Grad Norm: 0.0002890164323616773\n",
      "Epoch 4, Meta Loss: 2.2576239109039307, Synthetic Data Grad Norm: 0.0003130648110527545\n",
      "Epoch 4, Meta Loss: 2.258066415786743, Synthetic Data Grad Norm: 0.0003096341388300061\n",
      "Epoch 4, Meta Loss: 2.276887893676758, Synthetic Data Grad Norm: 0.00036695663584396243\n",
      "Epoch 4, Meta Loss: 2.2752115726470947, Synthetic Data Grad Norm: 0.0002689075190573931\n",
      "Epoch 4, Meta Loss: 2.273632049560547, Synthetic Data Grad Norm: 0.0002500033297110349\n",
      "Epoch 4, Meta Loss: 2.2598540782928467, Synthetic Data Grad Norm: 0.0002752312575466931\n",
      "Epoch 4, Meta Loss: 2.268176794052124, Synthetic Data Grad Norm: 0.00036463383003138006\n",
      "Epoch 4, Meta Loss: 2.2726168632507324, Synthetic Data Grad Norm: 0.00022647969308309257\n",
      "Epoch 4, Meta Loss: 2.290515661239624, Synthetic Data Grad Norm: 0.0002399330260232091\n",
      "Epoch 4, Meta Loss: 2.2463040351867676, Synthetic Data Grad Norm: 0.0004059240163769573\n",
      "Epoch 4, Meta Loss: 2.2755799293518066, Synthetic Data Grad Norm: 0.0002483132993802428\n",
      "Epoch 4, Meta Loss: 2.2568812370300293, Synthetic Data Grad Norm: 0.00032512538018636405\n",
      "Epoch 4, Meta Loss: 2.285649538040161, Synthetic Data Grad Norm: 0.0002541780995670706\n",
      "Epoch 4, Meta Loss: 2.2844173908233643, Synthetic Data Grad Norm: 0.0003123911446891725\n",
      "Epoch 4, Meta Loss: 2.273267984390259, Synthetic Data Grad Norm: 0.00024033820955082774\n",
      "Epoch 4, Meta Loss: 2.270528793334961, Synthetic Data Grad Norm: 0.0003110832767561078\n",
      "Epoch 4, Meta Loss: 2.265679121017456, Synthetic Data Grad Norm: 0.00027271726867184043\n",
      "Epoch 4, Meta Loss: 2.2755653858184814, Synthetic Data Grad Norm: 0.0002668574161361903\n",
      "Epoch 4, Meta Loss: 2.296329975128174, Synthetic Data Grad Norm: 0.0002579039428383112\n",
      "Epoch 4, Meta Loss: 2.273622989654541, Synthetic Data Grad Norm: 0.0002495858061593026\n",
      "Epoch 4, Meta Loss: 2.262523651123047, Synthetic Data Grad Norm: 0.00027969558141194284\n",
      "Epoch 4, Meta Loss: 2.2743308544158936, Synthetic Data Grad Norm: 0.00024877709802240133\n",
      "Epoch 4, Meta Loss: 2.2920308113098145, Synthetic Data Grad Norm: 0.00034468513331376016\n",
      "Epoch 4, Meta Loss: 2.2587690353393555, Synthetic Data Grad Norm: 0.0002932355273514986\n",
      "Epoch 4, Meta Loss: 2.277134895324707, Synthetic Data Grad Norm: 0.0003210873401258141\n",
      "Epoch 4, Meta Loss: 2.260655164718628, Synthetic Data Grad Norm: 0.0002830932498909533\n",
      "Epoch 4, Meta Loss: 2.266155242919922, Synthetic Data Grad Norm: 0.0003255690389778465\n",
      "Epoch 4, Meta Loss: 2.285074472427368, Synthetic Data Grad Norm: 0.00027777053765021265\n",
      "Epoch 4, Meta Loss: 2.282376527786255, Synthetic Data Grad Norm: 0.0002556451945565641\n",
      "Epoch 4, Meta Loss: 2.2669429779052734, Synthetic Data Grad Norm: 0.0004012013378087431\n",
      "Epoch 4, Meta Loss: 2.2774100303649902, Synthetic Data Grad Norm: 0.00025188716244883835\n",
      "Epoch 4, Meta Loss: 2.2861647605895996, Synthetic Data Grad Norm: 0.0002859680389519781\n",
      "Epoch 4, Meta Loss: 2.2779855728149414, Synthetic Data Grad Norm: 0.0002468074089847505\n",
      "Epoch 4, Meta Loss: 2.2576746940612793, Synthetic Data Grad Norm: 0.00035900811781175435\n",
      "Epoch 4, Meta Loss: 2.2816267013549805, Synthetic Data Grad Norm: 0.00030204892391338944\n",
      "Epoch 4, Meta Loss: 2.2845041751861572, Synthetic Data Grad Norm: 0.00023449157015420496\n",
      "Epoch 4, Meta Loss: 2.279674530029297, Synthetic Data Grad Norm: 0.00025349450879730284\n",
      "Epoch 4, Meta Loss: 2.25524640083313, Synthetic Data Grad Norm: 0.00030637194868177176\n",
      "Epoch 4, Meta Loss: 2.2662715911865234, Synthetic Data Grad Norm: 0.0002590616059023887\n",
      "Epoch 4, Meta Loss: 2.270164728164673, Synthetic Data Grad Norm: 0.0003098029410466552\n",
      "Epoch 4, Meta Loss: 2.2771546840667725, Synthetic Data Grad Norm: 0.00043598172487691045\n",
      "Epoch 4, Meta Loss: 2.2486937046051025, Synthetic Data Grad Norm: 0.00035066777491010725\n",
      "Epoch 4, Meta Loss: 2.2773454189300537, Synthetic Data Grad Norm: 0.0002627651847433299\n",
      "Epoch 4, Meta Loss: 2.289973020553589, Synthetic Data Grad Norm: 0.0002751393476501107\n",
      "Epoch 4, Meta Loss: 2.2631375789642334, Synthetic Data Grad Norm: 0.0003222391242161393\n",
      "Epoch 4, Meta Loss: 2.2837657928466797, Synthetic Data Grad Norm: 0.000330309325363487\n",
      "Epoch 4, Meta Loss: 2.2778851985931396, Synthetic Data Grad Norm: 0.00030067400075495243\n",
      "Epoch 4, Meta Loss: 2.2890264987945557, Synthetic Data Grad Norm: 0.0002281689376104623\n",
      "Epoch 4, Meta Loss: 2.2642691135406494, Synthetic Data Grad Norm: 0.0002760629286058247\n",
      "Epoch 4, Meta Loss: 2.277125358581543, Synthetic Data Grad Norm: 0.00035376838059164584\n",
      "Epoch 4, Meta Loss: 2.2778663635253906, Synthetic Data Grad Norm: 0.00022989866556599736\n",
      "Epoch 4, Meta Loss: 2.250112533569336, Synthetic Data Grad Norm: 0.00035684925387613475\n",
      "Epoch 4, Meta Loss: 2.284909963607788, Synthetic Data Grad Norm: 0.0002061799168586731\n",
      "Epoch 4, Meta Loss: 2.2655839920043945, Synthetic Data Grad Norm: 0.0003513135015964508\n",
      "Epoch 4, Meta Loss: 2.2638819217681885, Synthetic Data Grad Norm: 0.00036096060648560524\n",
      "Epoch 4, Meta Loss: 2.2534966468811035, Synthetic Data Grad Norm: 0.00032723377807997167\n",
      "Epoch 4, Meta Loss: 2.2700884342193604, Synthetic Data Grad Norm: 0.000277478713542223\n",
      "Epoch 4, Meta Loss: 2.2976133823394775, Synthetic Data Grad Norm: 0.00016066459647845477\n",
      "Epoch 4, Meta Loss: 2.2535808086395264, Synthetic Data Grad Norm: 0.00027398893143981695\n",
      "Epoch 4, Meta Loss: 2.27953839302063, Synthetic Data Grad Norm: 0.0002238886518171057\n",
      "Epoch 4, Meta Loss: 2.2766354084014893, Synthetic Data Grad Norm: 0.00037268432788550854\n",
      "Epoch 4, Meta Loss: 2.292104959487915, Synthetic Data Grad Norm: 0.00033726292895153165\n",
      "Epoch 4, Meta Loss: 2.28448486328125, Synthetic Data Grad Norm: 0.0002743681543506682\n",
      "Epoch 4, Meta Loss: 2.2688205242156982, Synthetic Data Grad Norm: 0.0002759142080321908\n",
      "Epoch 4, Meta Loss: 2.278578042984009, Synthetic Data Grad Norm: 0.0002786345430649817\n",
      "Epoch 4, Meta Loss: 2.2689640522003174, Synthetic Data Grad Norm: 0.00031456531723961234\n",
      "Epoch 4, Meta Loss: 2.265432596206665, Synthetic Data Grad Norm: 0.00030511687509715557\n",
      "Epoch 4, Meta Loss: 2.2696850299835205, Synthetic Data Grad Norm: 0.0004266836913302541\n",
      "Epoch 4, Meta Loss: 2.2695560455322266, Synthetic Data Grad Norm: 0.00030832478660158813\n",
      "Epoch 4, Meta Loss: 2.284149646759033, Synthetic Data Grad Norm: 0.00025278699467889965\n",
      "Epoch 4, Meta Loss: 2.2721195220947266, Synthetic Data Grad Norm: 0.0002997719566337764\n",
      "Epoch 4, Meta Loss: 2.2618863582611084, Synthetic Data Grad Norm: 0.0003274836053606123\n",
      "Epoch 4, Meta Loss: 2.284006118774414, Synthetic Data Grad Norm: 0.00022199486556928605\n",
      "Epoch 4, Meta Loss: 2.277599334716797, Synthetic Data Grad Norm: 0.0002507776953279972\n",
      "Epoch 4, Meta Loss: 2.26190447807312, Synthetic Data Grad Norm: 0.0002728380495682359\n",
      "Epoch 4, Meta Loss: 2.290053606033325, Synthetic Data Grad Norm: 0.00027805499848909676\n",
      "Epoch 4, Meta Loss: 2.2659754753112793, Synthetic Data Grad Norm: 0.0005002121324650943\n",
      "Epoch 4, Meta Loss: 2.2845401763916016, Synthetic Data Grad Norm: 0.00034304530709050596\n",
      "Epoch 4, Meta Loss: 2.2645976543426514, Synthetic Data Grad Norm: 0.000439582800026983\n",
      "Epoch 4, Meta Loss: 2.2745611667633057, Synthetic Data Grad Norm: 0.0002929999609477818\n",
      "Epoch 4, Meta Loss: 2.272873878479004, Synthetic Data Grad Norm: 0.00030630218680016696\n",
      "Epoch 4, Meta Loss: 2.2993133068084717, Synthetic Data Grad Norm: 0.00027989954105578363\n",
      "Epoch 4, Meta Loss: 2.2616419792175293, Synthetic Data Grad Norm: 0.00024129022494889796\n",
      "Epoch 4, Meta Loss: 2.253023147583008, Synthetic Data Grad Norm: 0.0002523400471545756\n",
      "Epoch 4, Meta Loss: 2.2629034519195557, Synthetic Data Grad Norm: 0.0002957556862384081\n",
      "Epoch 4, Meta Loss: 2.280337333679199, Synthetic Data Grad Norm: 0.0002796088519971818\n",
      "Epoch 4, Meta Loss: 2.2674379348754883, Synthetic Data Grad Norm: 0.00029442188679240644\n",
      "Epoch 4, Meta Loss: 2.270434617996216, Synthetic Data Grad Norm: 0.00024379849492106587\n",
      "Epoch 4, Meta Loss: 2.261436700820923, Synthetic Data Grad Norm: 0.00038187476457096636\n",
      "Epoch 4, Meta Loss: 2.272585391998291, Synthetic Data Grad Norm: 0.00036301251384429634\n",
      "Epoch 4, Meta Loss: 2.2663309574127197, Synthetic Data Grad Norm: 0.0002513157087378204\n",
      "Epoch 4, Meta Loss: 2.2427453994750977, Synthetic Data Grad Norm: 0.000390329078072682\n",
      "Epoch 4, Meta Loss: 2.291835308074951, Synthetic Data Grad Norm: 0.0002415319613646716\n",
      "Epoch 4, Meta Loss: 2.2936172485351562, Synthetic Data Grad Norm: 0.0002650211681611836\n",
      "Epoch 4, Meta Loss: 2.2810256481170654, Synthetic Data Grad Norm: 0.0004014106816612184\n",
      "Epoch 4, Meta Loss: 2.255439043045044, Synthetic Data Grad Norm: 0.00024342589313164353\n",
      "Epoch 4, Meta Loss: 2.2888238430023193, Synthetic Data Grad Norm: 0.00029838961199857295\n",
      "Epoch 4, Meta Loss: 2.2615833282470703, Synthetic Data Grad Norm: 0.00024721285444684327\n",
      "Epoch 4, Meta Loss: 2.2721107006073, Synthetic Data Grad Norm: 0.0003471624222584069\n",
      "Epoch 4, Meta Loss: 2.277452230453491, Synthetic Data Grad Norm: 0.0003058866714127362\n",
      "Epoch 4, Meta Loss: 2.2757375240325928, Synthetic Data Grad Norm: 0.00031018105801194906\n",
      "Epoch 4, Meta Loss: 2.2691893577575684, Synthetic Data Grad Norm: 0.0003570526314433664\n",
      "Epoch 4, Meta Loss: 2.258100748062134, Synthetic Data Grad Norm: 0.00033923235605470836\n",
      "Epoch 4, Meta Loss: 2.296967029571533, Synthetic Data Grad Norm: 0.0002502515271771699\n",
      "Epoch 4, Meta Loss: 2.263603687286377, Synthetic Data Grad Norm: 0.0003356517117936164\n",
      "Epoch 4, Meta Loss: 2.2797648906707764, Synthetic Data Grad Norm: 0.00026820143102668226\n",
      "Epoch 4, Meta Loss: 2.2952880859375, Synthetic Data Grad Norm: 0.00021650780399795622\n",
      "Epoch 4, Meta Loss: 2.2727158069610596, Synthetic Data Grad Norm: 0.0003048351500183344\n",
      "Epoch 4, Meta Loss: 2.2685306072235107, Synthetic Data Grad Norm: 0.00025380615261383355\n",
      "Epoch 4, Meta Loss: 2.2575511932373047, Synthetic Data Grad Norm: 0.0002430828899377957\n",
      "Epoch 4, Meta Loss: 2.2717225551605225, Synthetic Data Grad Norm: 0.00028273198404349387\n",
      "Epoch 4, Meta Loss: 2.273277759552002, Synthetic Data Grad Norm: 0.000388957851100713\n",
      "Epoch 4, Meta Loss: 2.2798664569854736, Synthetic Data Grad Norm: 0.0003288783773314208\n",
      "Epoch 4, Meta Loss: 2.2739391326904297, Synthetic Data Grad Norm: 0.000255775434197858\n",
      "Epoch 4, Meta Loss: 2.280519962310791, Synthetic Data Grad Norm: 0.00026967888697981834\n",
      "Epoch 4, Meta Loss: 2.2803194522857666, Synthetic Data Grad Norm: 0.0002247126103611663\n",
      "Epoch 4, Meta Loss: 2.2819366455078125, Synthetic Data Grad Norm: 0.00026224934845231473\n",
      "Epoch 4, Meta Loss: 2.2477943897247314, Synthetic Data Grad Norm: 0.00031423650216311216\n",
      "Epoch 4, Meta Loss: 2.2729263305664062, Synthetic Data Grad Norm: 0.00027006500749848783\n",
      "Epoch 4, Meta Loss: 2.274324417114258, Synthetic Data Grad Norm: 0.0003477524733170867\n",
      "Epoch 4, Meta Loss: 2.266514301300049, Synthetic Data Grad Norm: 0.00026499058003537357\n",
      "Epoch 4, Meta Loss: 2.258552074432373, Synthetic Data Grad Norm: 0.00038426544051617384\n",
      "Epoch 4, Meta Loss: 2.2722861766815186, Synthetic Data Grad Norm: 0.0002542771981097758\n",
      "Epoch 4, Meta Loss: 2.2620561122894287, Synthetic Data Grad Norm: 0.0002611835370771587\n",
      "Epoch 4, Meta Loss: 2.2598445415496826, Synthetic Data Grad Norm: 0.00030751858139410615\n",
      "Epoch 4, Meta Loss: 2.26731276512146, Synthetic Data Grad Norm: 0.0003159507177770138\n",
      "Epoch 4, Meta Loss: 2.2833755016326904, Synthetic Data Grad Norm: 0.00024230728740803897\n",
      "Epoch 4, Meta Loss: 2.270613670349121, Synthetic Data Grad Norm: 0.00022755915415473282\n",
      "Epoch 4, Meta Loss: 2.26472806930542, Synthetic Data Grad Norm: 0.00025286077288910747\n",
      "Epoch 4, Meta Loss: 2.2849478721618652, Synthetic Data Grad Norm: 0.000280150183243677\n",
      "Epoch 4, Meta Loss: 2.27837872505188, Synthetic Data Grad Norm: 0.00026603537844493985\n",
      "Epoch 4, Meta Loss: 2.2652575969696045, Synthetic Data Grad Norm: 0.00022399226145353168\n",
      "Epoch 4, Meta Loss: 2.2701916694641113, Synthetic Data Grad Norm: 0.0002981421712320298\n",
      "Epoch 4, Meta Loss: 2.293788194656372, Synthetic Data Grad Norm: 0.0003205602406524122\n",
      "Epoch 4, Meta Loss: 2.275752544403076, Synthetic Data Grad Norm: 0.00021441020362544805\n",
      "Epoch 4, Meta Loss: 2.274552822113037, Synthetic Data Grad Norm: 0.0002843681431841105\n",
      "Epoch 4, Meta Loss: 2.2885496616363525, Synthetic Data Grad Norm: 0.0003221287333872169\n",
      "Epoch 4, Meta Loss: 2.264380693435669, Synthetic Data Grad Norm: 0.0002442466211505234\n",
      "Epoch 4, Meta Loss: 2.279961347579956, Synthetic Data Grad Norm: 0.00022669369354844093\n",
      "Epoch 4, Meta Loss: 2.269242763519287, Synthetic Data Grad Norm: 0.0003776927478611469\n",
      "Epoch 4, Meta Loss: 2.2572336196899414, Synthetic Data Grad Norm: 0.0002759888011496514\n",
      "Epoch 4, Meta Loss: 2.252682685852051, Synthetic Data Grad Norm: 0.0002461256517563015\n",
      "Epoch 4, Meta Loss: 2.2759315967559814, Synthetic Data Grad Norm: 0.0002758494229055941\n",
      "Epoch 4, Meta Loss: 2.2836763858795166, Synthetic Data Grad Norm: 0.0003040134033653885\n",
      "Epoch 4, Meta Loss: 2.280522108078003, Synthetic Data Grad Norm: 0.00021229950652923435\n",
      "Epoch 4, Meta Loss: 2.2660610675811768, Synthetic Data Grad Norm: 0.00028305521118454635\n",
      "Epoch 4, Meta Loss: 2.26861834526062, Synthetic Data Grad Norm: 0.000255819148151204\n",
      "Epoch 4, Meta Loss: 2.2775752544403076, Synthetic Data Grad Norm: 0.0002849793527275324\n",
      "Epoch 4, Meta Loss: 2.2707040309906006, Synthetic Data Grad Norm: 0.0002708043029997498\n",
      "Epoch 4, Meta Loss: 2.275513172149658, Synthetic Data Grad Norm: 0.0002666258660610765\n",
      "Epoch 4, Meta Loss: 2.2489962577819824, Synthetic Data Grad Norm: 0.0002769310667645186\n",
      "Epoch 4, Meta Loss: 2.266591787338257, Synthetic Data Grad Norm: 0.00025152985472232103\n",
      "Epoch 4, Meta Loss: 2.267981767654419, Synthetic Data Grad Norm: 0.0003892960958182812\n",
      "Epoch 4, Meta Loss: 2.251769781112671, Synthetic Data Grad Norm: 0.0003172466531395912\n",
      "Epoch 4, Meta Loss: 2.265679359436035, Synthetic Data Grad Norm: 0.0002530908677726984\n",
      "Epoch 4, Meta Loss: 2.2800238132476807, Synthetic Data Grad Norm: 0.0003251572197768837\n",
      "Epoch 4, Meta Loss: 2.2609636783599854, Synthetic Data Grad Norm: 0.0003565282095223665\n",
      "Epoch 4, Meta Loss: 2.2793314456939697, Synthetic Data Grad Norm: 0.0003422854351811111\n",
      "Epoch 4, Meta Loss: 2.2763919830322266, Synthetic Data Grad Norm: 0.0002690500405151397\n",
      "Epoch 4, Meta Loss: 2.2737178802490234, Synthetic Data Grad Norm: 0.0002568983181845397\n",
      "Epoch 4, Meta Loss: 2.27880859375, Synthetic Data Grad Norm: 0.0002574227110017091\n",
      "Epoch 4, Meta Loss: 2.270852565765381, Synthetic Data Grad Norm: 0.0002759514027275145\n",
      "Epoch 4, Meta Loss: 2.2631351947784424, Synthetic Data Grad Norm: 0.00024116429267451167\n",
      "Epoch 4, Meta Loss: 2.268462896347046, Synthetic Data Grad Norm: 0.0003661317750811577\n",
      "Epoch 4, Meta Loss: 2.278517007827759, Synthetic Data Grad Norm: 0.00032979491516016424\n",
      "Epoch 4, Meta Loss: 2.2771496772766113, Synthetic Data Grad Norm: 0.0002796693588607013\n",
      "Epoch 4, Meta Loss: 2.2499420642852783, Synthetic Data Grad Norm: 0.00034985135425813496\n",
      "Epoch 4, Meta Loss: 2.2738118171691895, Synthetic Data Grad Norm: 0.00023226201301440597\n",
      "Epoch 4, Meta Loss: 2.2752251625061035, Synthetic Data Grad Norm: 0.00026574419462122023\n",
      "Epoch 4, Meta Loss: 2.264744758605957, Synthetic Data Grad Norm: 0.0002683119964785874\n",
      "Epoch 4, Meta Loss: 2.2662949562072754, Synthetic Data Grad Norm: 0.000288917392026633\n",
      "Epoch 4, Meta Loss: 2.270671844482422, Synthetic Data Grad Norm: 0.0003334448265377432\n",
      "Epoch 4, Meta Loss: 2.2731761932373047, Synthetic Data Grad Norm: 0.0003430978104006499\n",
      "Epoch 4, Meta Loss: 2.260573625564575, Synthetic Data Grad Norm: 0.0003019149007741362\n",
      "Epoch 4, Meta Loss: 2.2738821506500244, Synthetic Data Grad Norm: 0.0003513519768603146\n",
      "Epoch 4, Meta Loss: 2.2765769958496094, Synthetic Data Grad Norm: 0.00029507739236578345\n",
      "Epoch 4, Meta Loss: 2.2784461975097656, Synthetic Data Grad Norm: 0.0002643366751726717\n",
      "Epoch 4, Meta Loss: 2.265115737915039, Synthetic Data Grad Norm: 0.0003384293813724071\n",
      "Epoch 4, Meta Loss: 2.271331548690796, Synthetic Data Grad Norm: 0.00023375886667054147\n",
      "Epoch 4, Meta Loss: 2.272254705429077, Synthetic Data Grad Norm: 0.00021680437203031033\n",
      "Epoch 4, Meta Loss: 2.252716064453125, Synthetic Data Grad Norm: 0.0002609971270430833\n",
      "Epoch 4, Meta Loss: 2.3012759685516357, Synthetic Data Grad Norm: 0.0003811427450273186\n",
      "Epoch 4, Meta Loss: 2.269347667694092, Synthetic Data Grad Norm: 0.0003778770915232599\n",
      "Epoch 4, Meta Loss: 2.2774786949157715, Synthetic Data Grad Norm: 0.0003287905710749328\n",
      "Epoch 4, Meta Loss: 2.2540571689605713, Synthetic Data Grad Norm: 0.0002816433843690902\n",
      "Epoch 4, Meta Loss: 2.2833786010742188, Synthetic Data Grad Norm: 0.00026102870469912887\n",
      "Epoch 4, Meta Loss: 2.242544651031494, Synthetic Data Grad Norm: 0.0003346097655594349\n",
      "Epoch 4, Meta Loss: 2.260483741760254, Synthetic Data Grad Norm: 0.00029742857441306114\n",
      "Epoch 4, Meta Loss: 2.2885923385620117, Synthetic Data Grad Norm: 0.00036306848051026464\n",
      "Epoch 4, Meta Loss: 2.2641923427581787, Synthetic Data Grad Norm: 0.0002723175275605172\n",
      "Epoch 4, Meta Loss: 2.2604711055755615, Synthetic Data Grad Norm: 0.0003565748338587582\n",
      "Epoch 4, Meta Loss: 2.2584147453308105, Synthetic Data Grad Norm: 0.0002906499139498919\n",
      "Epoch 4, Meta Loss: 2.2751829624176025, Synthetic Data Grad Norm: 0.00030710099963471293\n",
      "Epoch 4, Meta Loss: 2.2683942317962646, Synthetic Data Grad Norm: 0.00026214210083708167\n",
      "Epoch 4, Meta Loss: 2.2512168884277344, Synthetic Data Grad Norm: 0.0003065859782509506\n",
      "Epoch 4, Meta Loss: 2.277280569076538, Synthetic Data Grad Norm: 0.00021840193949174136\n",
      "Epoch 4, Meta Loss: 2.2473080158233643, Synthetic Data Grad Norm: 0.0003119904431514442\n",
      "Epoch 4, Meta Loss: 2.2521469593048096, Synthetic Data Grad Norm: 0.00028492408455349505\n",
      "Epoch 4, Meta Loss: 2.2631571292877197, Synthetic Data Grad Norm: 0.0002908304741140455\n",
      "Epoch 4, Meta Loss: 2.267260789871216, Synthetic Data Grad Norm: 0.0002755495370365679\n",
      "Epoch 4, Meta Loss: 2.2632336616516113, Synthetic Data Grad Norm: 0.0003064258780796081\n",
      "Epoch 4, Meta Loss: 2.264673948287964, Synthetic Data Grad Norm: 0.00037721855915151536\n",
      "Epoch 4, Meta Loss: 2.275376796722412, Synthetic Data Grad Norm: 0.0004046521207783371\n",
      "Epoch 4, Meta Loss: 2.277045726776123, Synthetic Data Grad Norm: 0.00023612019140273333\n",
      "Epoch 4, Meta Loss: 2.2791388034820557, Synthetic Data Grad Norm: 0.0002442187105771154\n",
      "Epoch 4, Meta Loss: 2.243884563446045, Synthetic Data Grad Norm: 0.00042838495573960245\n",
      "Epoch 4, Meta Loss: 2.241318702697754, Synthetic Data Grad Norm: 0.0003137518069706857\n",
      "Epoch 4, Meta Loss: 2.276954412460327, Synthetic Data Grad Norm: 0.0003990395343862474\n",
      "Epoch 4, Meta Loss: 2.281642436981201, Synthetic Data Grad Norm: 0.00022258024546317756\n",
      "Epoch 4, Meta Loss: 2.2872695922851562, Synthetic Data Grad Norm: 0.00031533665605820715\n",
      "Epoch 4, Meta Loss: 2.2722184658050537, Synthetic Data Grad Norm: 0.0002363465027883649\n",
      "Epoch 4, Meta Loss: 2.290634870529175, Synthetic Data Grad Norm: 0.0002979247074108571\n",
      "Epoch 4, Meta Loss: 2.2830402851104736, Synthetic Data Grad Norm: 0.00023096715449355543\n",
      "Epoch 4, Meta Loss: 2.27657413482666, Synthetic Data Grad Norm: 0.0003182729706168175\n",
      "Epoch 4, Meta Loss: 2.285356283187866, Synthetic Data Grad Norm: 0.00045466364827007055\n",
      "Epoch 4, Meta Loss: 2.2943356037139893, Synthetic Data Grad Norm: 0.000304599292576313\n",
      "Epoch 4, Meta Loss: 2.2813313007354736, Synthetic Data Grad Norm: 0.00024139824381563812\n",
      "Epoch 4, Meta Loss: 2.26822566986084, Synthetic Data Grad Norm: 0.00035151830525137484\n",
      "Epoch 4, Meta Loss: 2.244325637817383, Synthetic Data Grad Norm: 0.00048268676619045436\n",
      "Epoch 4, Meta Loss: 2.2893331050872803, Synthetic Data Grad Norm: 0.0002502351126167923\n",
      "Epoch 4, Meta Loss: 2.287616014480591, Synthetic Data Grad Norm: 0.00022463178902398795\n",
      "Epoch 4, Meta Loss: 2.2831475734710693, Synthetic Data Grad Norm: 0.00030362207326106727\n",
      "Epoch 4, Meta Loss: 2.263725757598877, Synthetic Data Grad Norm: 0.00025326525792479515\n",
      "Epoch 4, Meta Loss: 2.260133743286133, Synthetic Data Grad Norm: 0.0003016041300725192\n",
      "Epoch 4, Meta Loss: 2.2527477741241455, Synthetic Data Grad Norm: 0.0003655584587249905\n",
      "Epoch 4, Meta Loss: 2.26007342338562, Synthetic Data Grad Norm: 0.00025313071091659367\n",
      "Epoch 4, Meta Loss: 2.270467758178711, Synthetic Data Grad Norm: 0.00022111868020147085\n",
      "Epoch 4, Meta Loss: 2.274686574935913, Synthetic Data Grad Norm: 0.00028839067090302706\n",
      "Epoch 4, Meta Loss: 2.2719650268554688, Synthetic Data Grad Norm: 0.0002675344585441053\n",
      "Epoch 4, Meta Loss: 2.261166572570801, Synthetic Data Grad Norm: 0.0002890604082494974\n",
      "Epoch 4, Meta Loss: 2.2857370376586914, Synthetic Data Grad Norm: 0.00033606428769417107\n",
      "Epoch 4, Meta Loss: 2.2645466327667236, Synthetic Data Grad Norm: 0.00027880319976247847\n",
      "Epoch 4, Meta Loss: 2.263592481613159, Synthetic Data Grad Norm: 0.00025857510627247393\n",
      "Epoch 4, Meta Loss: 2.2795090675354004, Synthetic Data Grad Norm: 0.00028694883803837\n",
      "Epoch 4, Meta Loss: 2.267646551132202, Synthetic Data Grad Norm: 0.0002857874205801636\n",
      "Epoch 4, Meta Loss: 2.286200523376465, Synthetic Data Grad Norm: 0.00025325946626253426\n",
      "Epoch 4, Meta Loss: 2.2836661338806152, Synthetic Data Grad Norm: 0.00023510807659476995\n",
      "Epoch 4, Meta Loss: 2.2682533264160156, Synthetic Data Grad Norm: 0.00028829812072217464\n",
      "Epoch 4, Meta Loss: 2.289301872253418, Synthetic Data Grad Norm: 0.00024858833057805896\n",
      "Epoch 4, Meta Loss: 2.2731094360351562, Synthetic Data Grad Norm: 0.0002874394413083792\n",
      "Epoch 4, Meta Loss: 2.2713849544525146, Synthetic Data Grad Norm: 0.00025894943973980844\n",
      "Epoch 4, Meta Loss: 2.2574331760406494, Synthetic Data Grad Norm: 0.0002517606772016734\n",
      "Epoch 4, Meta Loss: 2.278738498687744, Synthetic Data Grad Norm: 0.0003142410423606634\n",
      "Epoch 4, Meta Loss: 2.2466771602630615, Synthetic Data Grad Norm: 0.00035034530446864665\n",
      "Epoch 4, Meta Loss: 2.275080680847168, Synthetic Data Grad Norm: 0.0002673631825018674\n",
      "Epoch 4, Meta Loss: 2.2573182582855225, Synthetic Data Grad Norm: 0.00023791100829839706\n",
      "Epoch 4, Meta Loss: 2.2660434246063232, Synthetic Data Grad Norm: 0.00023158587282523513\n",
      "Epoch 4, Meta Loss: 2.2706334590911865, Synthetic Data Grad Norm: 0.00034657210926525295\n",
      "Epoch 4, Meta Loss: 2.274310350418091, Synthetic Data Grad Norm: 0.00030373738263733685\n",
      "Epoch 4, Meta Loss: 2.2687368392944336, Synthetic Data Grad Norm: 0.0002667465014383197\n",
      "Epoch 4, Meta Loss: 2.2639927864074707, Synthetic Data Grad Norm: 0.0002686824300326407\n",
      "Epoch 4, Meta Loss: 2.2793772220611572, Synthetic Data Grad Norm: 0.0003820585261564702\n",
      "Epoch 4, Meta Loss: 2.2368297576904297, Synthetic Data Grad Norm: 0.0004195798246655613\n",
      "Epoch 4, Meta Loss: 2.2888362407684326, Synthetic Data Grad Norm: 0.0002081863203784451\n",
      "Epoch 4, Meta Loss: 2.2623062133789062, Synthetic Data Grad Norm: 0.00032522701076231897\n",
      "Epoch 4, Meta Loss: 2.2790446281433105, Synthetic Data Grad Norm: 0.00024057137488853186\n",
      "Epoch 4, Meta Loss: 2.260669708251953, Synthetic Data Grad Norm: 0.0003531383990775794\n",
      "Epoch 4, Meta Loss: 2.273819923400879, Synthetic Data Grad Norm: 0.000209511534194462\n",
      "Epoch 4, Meta Loss: 2.260045289993286, Synthetic Data Grad Norm: 0.00024884368758648634\n",
      "Epoch 4, Meta Loss: 2.2716383934020996, Synthetic Data Grad Norm: 0.00026999920373782516\n",
      "Epoch 4, Meta Loss: 2.2616488933563232, Synthetic Data Grad Norm: 0.0003685773117467761\n",
      "Epoch 4, Meta Loss: 2.2790534496307373, Synthetic Data Grad Norm: 0.00022495200391858816\n",
      "Epoch 4, Meta Loss: 2.2537178993225098, Synthetic Data Grad Norm: 0.00028042602934874594\n",
      "Epoch 4, Meta Loss: 2.273411512374878, Synthetic Data Grad Norm: 0.0002615045814309269\n",
      "Epoch 4, Meta Loss: 2.2778048515319824, Synthetic Data Grad Norm: 0.000345543579896912\n",
      "Epoch 4, Meta Loss: 2.26761794090271, Synthetic Data Grad Norm: 0.00026939090457744896\n",
      "Epoch 4, Meta Loss: 2.2593796253204346, Synthetic Data Grad Norm: 0.00025133040617220104\n",
      "Epoch 4, Meta Loss: 2.2766237258911133, Synthetic Data Grad Norm: 0.00020550993212964386\n",
      "Epoch 4, Meta Loss: 2.272381067276001, Synthetic Data Grad Norm: 0.0003345829318277538\n",
      "Epoch 4, Meta Loss: 2.281186103820801, Synthetic Data Grad Norm: 0.0003091959224548191\n",
      "Epoch 4, Meta Loss: 2.2787647247314453, Synthetic Data Grad Norm: 0.00023247426724992692\n",
      "Epoch 4, Meta Loss: 2.2605834007263184, Synthetic Data Grad Norm: 0.0005017233197577298\n",
      "Epoch 4, Meta Loss: 2.275182008743286, Synthetic Data Grad Norm: 0.00023324595531448722\n",
      "Epoch 4, Meta Loss: 2.259326219558716, Synthetic Data Grad Norm: 0.0003307207953184843\n",
      "Epoch 4, Meta Loss: 2.274937391281128, Synthetic Data Grad Norm: 0.0002836707280948758\n",
      "Epoch 4, Meta Loss: 2.278104066848755, Synthetic Data Grad Norm: 0.000280689011560753\n",
      "Epoch 4, Meta Loss: 2.250701904296875, Synthetic Data Grad Norm: 0.0003273668116889894\n",
      "Epoch 4, Meta Loss: 2.284743070602417, Synthetic Data Grad Norm: 0.00025726930471137166\n",
      "Epoch 4, Meta Loss: 2.2682690620422363, Synthetic Data Grad Norm: 0.00034671553294174373\n",
      "Epoch 4, Meta Loss: 2.28874135017395, Synthetic Data Grad Norm: 0.0002924810687545687\n",
      "Epoch 4, Meta Loss: 2.2364559173583984, Synthetic Data Grad Norm: 0.0003937143483199179\n",
      "Epoch 4, Meta Loss: 2.267942428588867, Synthetic Data Grad Norm: 0.0002812598249875009\n",
      "Epoch 4, Meta Loss: 2.2821950912475586, Synthetic Data Grad Norm: 0.0003625959507189691\n",
      "Epoch 4, Meta Loss: 2.27109432220459, Synthetic Data Grad Norm: 0.0003014309622813016\n",
      "Epoch 4, Meta Loss: 2.262935161590576, Synthetic Data Grad Norm: 0.000352937204297632\n",
      "Epoch 4, Meta Loss: 2.2792694568634033, Synthetic Data Grad Norm: 0.0002601301239337772\n",
      "Epoch 4, Meta Loss: 2.276578426361084, Synthetic Data Grad Norm: 0.0004021287022624165\n",
      "Epoch 4, Meta Loss: 2.268458127975464, Synthetic Data Grad Norm: 0.0003001604345627129\n",
      "Epoch 4, Meta Loss: 2.2756052017211914, Synthetic Data Grad Norm: 0.0003355996741447598\n",
      "Epoch 4, Meta Loss: 2.261096715927124, Synthetic Data Grad Norm: 0.0002882484986912459\n",
      "Epoch 4, Meta Loss: 2.284170150756836, Synthetic Data Grad Norm: 0.0003623709490057081\n",
      "Epoch 4, Meta Loss: 2.2780308723449707, Synthetic Data Grad Norm: 0.00030565334600396454\n",
      "Epoch 4, Meta Loss: 2.2726056575775146, Synthetic Data Grad Norm: 0.000267452938714996\n",
      "Epoch 4, Meta Loss: 2.2769711017608643, Synthetic Data Grad Norm: 0.00027269183192402124\n",
      "Epoch 4, Meta Loss: 2.2659926414489746, Synthetic Data Grad Norm: 0.0003056649293284863\n",
      "Epoch 4, Meta Loss: 2.2791221141815186, Synthetic Data Grad Norm: 0.00030842761043459177\n",
      "Epoch 4, Meta Loss: 2.2718312740325928, Synthetic Data Grad Norm: 0.00029611983336508274\n",
      "Epoch 4, Meta Loss: 2.2357258796691895, Synthetic Data Grad Norm: 0.00030500683351419866\n",
      "Epoch 4, Meta Loss: 2.268547773361206, Synthetic Data Grad Norm: 0.0003567328385543078\n",
      "Epoch 4, Meta Loss: 2.2705321311950684, Synthetic Data Grad Norm: 0.00025040123728103936\n",
      "Epoch 4, Meta Loss: 2.2504637241363525, Synthetic Data Grad Norm: 0.0003189787094015628\n",
      "Epoch 4, Meta Loss: 2.257883071899414, Synthetic Data Grad Norm: 0.0003265110426582396\n",
      "Epoch 4, Meta Loss: 2.277836561203003, Synthetic Data Grad Norm: 0.0003318237722851336\n",
      "Epoch 4, Meta Loss: 2.2736573219299316, Synthetic Data Grad Norm: 0.00035100331297144294\n",
      "Epoch 4, Meta Loss: 2.270977735519409, Synthetic Data Grad Norm: 0.00023351507843472064\n",
      "Epoch 4, Meta Loss: 2.2661798000335693, Synthetic Data Grad Norm: 0.0003496333083603531\n",
      "Epoch 4, Meta Loss: 2.271528720855713, Synthetic Data Grad Norm: 0.00027384000713936985\n",
      "Epoch 4, Meta Loss: 2.2681334018707275, Synthetic Data Grad Norm: 0.00032468189601786435\n",
      "Epoch 4, Meta Loss: 2.240806818008423, Synthetic Data Grad Norm: 0.0002739917254075408\n",
      "Epoch 4, Meta Loss: 2.2791168689727783, Synthetic Data Grad Norm: 0.00037155006430111825\n",
      "Epoch 4, Meta Loss: 2.276959180831909, Synthetic Data Grad Norm: 0.00031917422893457115\n",
      "Epoch 4, Meta Loss: 2.2795376777648926, Synthetic Data Grad Norm: 0.00030511963996104896\n",
      "Epoch 4, Meta Loss: 2.2750041484832764, Synthetic Data Grad Norm: 0.00032941781682893634\n",
      "Epoch 4, Meta Loss: 2.2389378547668457, Synthetic Data Grad Norm: 0.00031683724955655634\n",
      "Epoch 4, Meta Loss: 2.2948644161224365, Synthetic Data Grad Norm: 0.0003018513962160796\n",
      "Epoch 4, Meta Loss: 2.2815158367156982, Synthetic Data Grad Norm: 0.00031998383929021657\n",
      "Epoch 4, Meta Loss: 2.274683952331543, Synthetic Data Grad Norm: 0.0003147156094200909\n",
      "Epoch 4, Meta Loss: 2.260834217071533, Synthetic Data Grad Norm: 0.00033456060918979347\n",
      "Epoch 4, Meta Loss: 2.280672550201416, Synthetic Data Grad Norm: 0.0002586838963907212\n",
      "Epoch 4, Meta Loss: 2.271757125854492, Synthetic Data Grad Norm: 0.00030390764004550874\n",
      "Epoch 4, Meta Loss: 2.2569432258605957, Synthetic Data Grad Norm: 0.00028448665398173034\n",
      "Epoch 4, Meta Loss: 2.2914981842041016, Synthetic Data Grad Norm: 0.00042804834083653986\n",
      "Epoch 4, Meta Loss: 2.2564682960510254, Synthetic Data Grad Norm: 0.0002723113284446299\n",
      "Epoch 4, Meta Loss: 2.2701942920684814, Synthetic Data Grad Norm: 0.0002665384381543845\n",
      "Epoch 4, Meta Loss: 2.261770009994507, Synthetic Data Grad Norm: 0.00025696965167298913\n",
      "Epoch 4, Meta Loss: 2.290811061859131, Synthetic Data Grad Norm: 0.0003027691855095327\n",
      "Epoch 4, Meta Loss: 2.2911083698272705, Synthetic Data Grad Norm: 0.0002681732294149697\n",
      "Epoch 4, Meta Loss: 2.2692127227783203, Synthetic Data Grad Norm: 0.00033208748209290206\n",
      "Epoch 4, Meta Loss: 2.267934560775757, Synthetic Data Grad Norm: 0.00030250867712311447\n",
      "Epoch 4, Meta Loss: 2.245816469192505, Synthetic Data Grad Norm: 0.0003332117048557848\n",
      "Epoch 4, Meta Loss: 2.2793025970458984, Synthetic Data Grad Norm: 0.0003523866180330515\n",
      "Epoch 4, Meta Loss: 2.2679038047790527, Synthetic Data Grad Norm: 0.0002854317135643214\n",
      "Epoch 4, Meta Loss: 2.2847883701324463, Synthetic Data Grad Norm: 0.0004334676777943969\n",
      "Epoch 4, Meta Loss: 2.261411428451538, Synthetic Data Grad Norm: 0.0003706898423843086\n",
      "Epoch 4, Meta Loss: 2.261535882949829, Synthetic Data Grad Norm: 0.00027604345814324915\n",
      "Epoch 4, Meta Loss: 2.2964398860931396, Synthetic Data Grad Norm: 0.00027569278609007597\n",
      "Epoch 4, Meta Loss: 2.290170431137085, Synthetic Data Grad Norm: 0.00031095033045858145\n",
      "Epoch 4, Meta Loss: 2.257086992263794, Synthetic Data Grad Norm: 0.0003320967953186482\n",
      "Epoch 4, Meta Loss: 2.258864164352417, Synthetic Data Grad Norm: 0.0002799128706101328\n",
      "Epoch 4, Meta Loss: 2.2588722705841064, Synthetic Data Grad Norm: 0.00036215787986293435\n",
      "Epoch 4, Meta Loss: 2.268937110900879, Synthetic Data Grad Norm: 0.00022803733008913696\n",
      "Epoch 4, Meta Loss: 2.2780253887176514, Synthetic Data Grad Norm: 0.00023333876742981374\n",
      "Epoch 4, Meta Loss: 2.276569366455078, Synthetic Data Grad Norm: 0.0002354984899284318\n",
      "Epoch 4, Meta Loss: 2.277202606201172, Synthetic Data Grad Norm: 0.0002385040424996987\n",
      "Epoch 4, Meta Loss: 2.2841286659240723, Synthetic Data Grad Norm: 0.00026192114455625415\n",
      "Epoch 4, Meta Loss: 2.2670862674713135, Synthetic Data Grad Norm: 0.00030315350159071386\n",
      "Epoch 4, Meta Loss: 2.2704381942749023, Synthetic Data Grad Norm: 0.00040365528548136353\n",
      "Epoch 4, Meta Loss: 2.263071060180664, Synthetic Data Grad Norm: 0.0002692757989279926\n",
      "Epoch 4, Meta Loss: 2.2891688346862793, Synthetic Data Grad Norm: 0.00025041206390596926\n",
      "Epoch 4, Meta Loss: 2.261430501937866, Synthetic Data Grad Norm: 0.0002862250548787415\n",
      "Epoch 4, Meta Loss: 2.260629892349243, Synthetic Data Grad Norm: 0.0002992530935443938\n",
      "Epoch 4, Meta Loss: 2.2806849479675293, Synthetic Data Grad Norm: 0.00026112908381037414\n",
      "Epoch 4, Meta Loss: 2.267906904220581, Synthetic Data Grad Norm: 0.00028381121228449047\n",
      "Epoch 4, Meta Loss: 2.2617123126983643, Synthetic Data Grad Norm: 0.00034891432733274996\n",
      "Epoch 4, Meta Loss: 2.25935959815979, Synthetic Data Grad Norm: 0.00027966927154920995\n",
      "Epoch 4, Meta Loss: 2.253021717071533, Synthetic Data Grad Norm: 0.0003813988296315074\n",
      "Epoch 4, Meta Loss: 2.2599010467529297, Synthetic Data Grad Norm: 0.00027516824775375426\n",
      "Epoch 4, Meta Loss: 2.2776997089385986, Synthetic Data Grad Norm: 0.000255324732279405\n",
      "Epoch 4, Meta Loss: 2.266068696975708, Synthetic Data Grad Norm: 0.0002977875410579145\n",
      "Epoch 4, Meta Loss: 2.251005172729492, Synthetic Data Grad Norm: 0.0002675980213098228\n",
      "Epoch 4, Meta Loss: 2.2601778507232666, Synthetic Data Grad Norm: 0.00026799377519637346\n",
      "Epoch 4, Meta Loss: 2.2607614994049072, Synthetic Data Grad Norm: 0.00027556857094168663\n",
      "Epoch 4, Meta Loss: 2.2732930183410645, Synthetic Data Grad Norm: 0.00022525203530676663\n",
      "Epoch 4, Meta Loss: 2.2542057037353516, Synthetic Data Grad Norm: 0.0003525259089656174\n",
      "Epoch 4, Meta Loss: 2.257935047149658, Synthetic Data Grad Norm: 0.0003556718584150076\n",
      "Epoch 4, Meta Loss: 2.2380754947662354, Synthetic Data Grad Norm: 0.00046266033314168453\n",
      "Epoch 4, Meta Loss: 2.264676570892334, Synthetic Data Grad Norm: 0.0003293750633019954\n",
      "Epoch 4, Meta Loss: 2.238898992538452, Synthetic Data Grad Norm: 0.00046740699326619506\n",
      "Epoch 4, Meta Loss: 2.2613682746887207, Synthetic Data Grad Norm: 0.00023532389604952186\n",
      "Epoch 4, Meta Loss: 2.277003765106201, Synthetic Data Grad Norm: 0.0003191454743500799\n",
      "Epoch 4, Meta Loss: 2.27882981300354, Synthetic Data Grad Norm: 0.0002862513647414744\n",
      "Epoch 4, Meta Loss: 2.272592306137085, Synthetic Data Grad Norm: 0.00024928702623583376\n",
      "Epoch 4, Meta Loss: 2.2757651805877686, Synthetic Data Grad Norm: 0.00032553935307078063\n",
      "Epoch 4, Meta Loss: 2.2665610313415527, Synthetic Data Grad Norm: 0.0002754132146947086\n",
      "Epoch 4, Meta Loss: 2.266188859939575, Synthetic Data Grad Norm: 0.00025257759261876345\n",
      "Epoch 4, Meta Loss: 2.279477596282959, Synthetic Data Grad Norm: 0.00027317559579387307\n",
      "Epoch 4, Meta Loss: 2.2590324878692627, Synthetic Data Grad Norm: 0.0003649334830697626\n",
      "Epoch 4, Meta Loss: 2.2554032802581787, Synthetic Data Grad Norm: 0.00036590511444956064\n",
      "Epoch 4, Meta Loss: 2.270498514175415, Synthetic Data Grad Norm: 0.00032867936533875763\n",
      "Epoch 4, Meta Loss: 2.2824835777282715, Synthetic Data Grad Norm: 0.0002705344813875854\n",
      "Epoch 4, Meta Loss: 2.2820827960968018, Synthetic Data Grad Norm: 0.00026805890956893563\n",
      "Epoch 4, Meta Loss: 2.2728822231292725, Synthetic Data Grad Norm: 0.00023529607278760523\n",
      "Epoch 4, Meta Loss: 2.285275936126709, Synthetic Data Grad Norm: 0.00028309450135566294\n",
      "Epoch 4, Meta Loss: 2.2597124576568604, Synthetic Data Grad Norm: 0.0002698412863537669\n",
      "Epoch 4, Meta Loss: 2.279679775238037, Synthetic Data Grad Norm: 0.0002461299882270396\n",
      "Epoch 4, Meta Loss: 2.2680206298828125, Synthetic Data Grad Norm: 0.0002635240089148283\n",
      "Epoch 4, Meta Loss: 2.250746965408325, Synthetic Data Grad Norm: 0.0004016781458631158\n",
      "Epoch 4, Meta Loss: 2.2756175994873047, Synthetic Data Grad Norm: 0.00020467540889512748\n",
      "Epoch 4, Meta Loss: 2.2688496112823486, Synthetic Data Grad Norm: 0.00023530070029664785\n",
      "Epoch 4, Meta Loss: 2.256398916244507, Synthetic Data Grad Norm: 0.00035218452103435993\n",
      "Epoch 4, Meta Loss: 2.2805862426757812, Synthetic Data Grad Norm: 0.0002046971203526482\n",
      "Epoch 4, Meta Loss: 2.268345832824707, Synthetic Data Grad Norm: 0.00030183469061739743\n",
      "Epoch 4, Meta Loss: 2.2498583793640137, Synthetic Data Grad Norm: 0.00031517239403910935\n",
      "Epoch 4, Meta Loss: 2.2836999893188477, Synthetic Data Grad Norm: 0.0002017925144173205\n",
      "Epoch 4, Meta Loss: 2.29982590675354, Synthetic Data Grad Norm: 0.00034645837149582803\n",
      "Epoch 4, Meta Loss: 2.2599759101867676, Synthetic Data Grad Norm: 0.0002975349489133805\n",
      "Epoch 4, Meta Loss: 2.2481157779693604, Synthetic Data Grad Norm: 0.0002957540564239025\n",
      "Epoch 4, Meta Loss: 2.259718894958496, Synthetic Data Grad Norm: 0.0003296150534879416\n",
      "Epoch 4, Meta Loss: 2.275559186935425, Synthetic Data Grad Norm: 0.0003005519392900169\n",
      "Epoch 4, Meta Loss: 2.276679754257202, Synthetic Data Grad Norm: 0.00027215597219765186\n",
      "Epoch 4, Meta Loss: 2.2628533840179443, Synthetic Data Grad Norm: 0.00031213575857691467\n",
      "Epoch 4, Meta Loss: 2.27540922164917, Synthetic Data Grad Norm: 0.00032918050419539213\n",
      "Epoch 4, Meta Loss: 2.2740535736083984, Synthetic Data Grad Norm: 0.0003075188724324107\n",
      "Epoch 4, Meta Loss: 2.2641892433166504, Synthetic Data Grad Norm: 0.0002653687261044979\n",
      "Epoch 4, Meta Loss: 2.291029214859009, Synthetic Data Grad Norm: 0.00031445929198525846\n",
      "Epoch 4, Meta Loss: 2.283815860748291, Synthetic Data Grad Norm: 0.00026750864344649017\n",
      "Epoch 4, Meta Loss: 2.274183750152588, Synthetic Data Grad Norm: 0.0002903155400417745\n",
      "Epoch 4, Meta Loss: 2.2514777183532715, Synthetic Data Grad Norm: 0.0003074787382502109\n",
      "Epoch 4, Meta Loss: 2.2667887210845947, Synthetic Data Grad Norm: 0.00038826928357593715\n",
      "Epoch 4, Meta Loss: 2.2825822830200195, Synthetic Data Grad Norm: 0.0003461519372649491\n",
      "Epoch 4, Meta Loss: 2.2944998741149902, Synthetic Data Grad Norm: 0.00020070951723027974\n",
      "Epoch 4, Meta Loss: 2.2679624557495117, Synthetic Data Grad Norm: 0.00023161903664004058\n",
      "Epoch 4, Meta Loss: 2.2800495624542236, Synthetic Data Grad Norm: 0.00026931939646601677\n",
      "Epoch 4, Meta Loss: 2.2642626762390137, Synthetic Data Grad Norm: 0.00028779832064174116\n",
      "Epoch 4, Meta Loss: 2.267197847366333, Synthetic Data Grad Norm: 0.00021422190184239298\n",
      "Epoch 4, Meta Loss: 2.2691383361816406, Synthetic Data Grad Norm: 0.0003762392734643072\n",
      "Epoch 4, Meta Loss: 2.265531301498413, Synthetic Data Grad Norm: 0.00023208210768643767\n",
      "Epoch 4, Meta Loss: 2.2740044593811035, Synthetic Data Grad Norm: 0.0002745552337728441\n",
      "Epoch 4, Meta Loss: 2.2568795680999756, Synthetic Data Grad Norm: 0.0003340071125421673\n",
      "Epoch 4, Meta Loss: 2.2850522994995117, Synthetic Data Grad Norm: 0.00025304369046352804\n",
      "Epoch 4, Meta Loss: 2.2790496349334717, Synthetic Data Grad Norm: 0.0002886812435463071\n",
      "Epoch 4, Meta Loss: 2.2758407592773438, Synthetic Data Grad Norm: 0.00023852121375966817\n",
      "Epoch 4, Meta Loss: 2.2618863582611084, Synthetic Data Grad Norm: 0.00031758868135511875\n",
      "Epoch 4, Meta Loss: 2.271350622177124, Synthetic Data Grad Norm: 0.00031534855952486396\n",
      "Epoch 4, Meta Loss: 2.253615617752075, Synthetic Data Grad Norm: 0.0003014230460394174\n",
      "Epoch 4, Meta Loss: 2.285649538040161, Synthetic Data Grad Norm: 0.000354913470800966\n",
      "Epoch 4, Meta Loss: 2.25915265083313, Synthetic Data Grad Norm: 0.0003336146764922887\n",
      "Epoch 4, Meta Loss: 2.289977550506592, Synthetic Data Grad Norm: 0.0001683268346823752\n",
      "Epoch 4, Meta Loss: 2.287372589111328, Synthetic Data Grad Norm: 0.000223525712499395\n",
      "Epoch 4, Meta Loss: 2.266098737716675, Synthetic Data Grad Norm: 0.00032620260026305914\n",
      "Epoch 4, Meta Loss: 2.2653841972351074, Synthetic Data Grad Norm: 0.00020967723685316741\n",
      "Epoch 4, Meta Loss: 2.275546073913574, Synthetic Data Grad Norm: 0.00030518369749188423\n",
      "Epoch 4, Meta Loss: 2.262967348098755, Synthetic Data Grad Norm: 0.0003371887723915279\n",
      "Epoch 4, Meta Loss: 2.2610561847686768, Synthetic Data Grad Norm: 0.0002631956012919545\n",
      "Epoch 4, Meta Loss: 2.2689712047576904, Synthetic Data Grad Norm: 0.00033865415025502443\n",
      "Epoch 4, Meta Loss: 2.2785425186157227, Synthetic Data Grad Norm: 0.00023297643929254264\n",
      "Epoch 4, Meta Loss: 2.254502534866333, Synthetic Data Grad Norm: 0.00035153437056578696\n",
      "Epoch 4, Meta Loss: 2.261197566986084, Synthetic Data Grad Norm: 0.0003722761757671833\n",
      "Epoch 4, Meta Loss: 2.3116207122802734, Synthetic Data Grad Norm: 0.0003756368823815137\n",
      "Epoch 4, Meta Loss: 2.2654075622558594, Synthetic Data Grad Norm: 0.00031874910928308964\n",
      "Epoch 4, Meta Loss: 2.303446054458618, Synthetic Data Grad Norm: 0.0002399040968157351\n",
      "Epoch 4, Meta Loss: 2.258798360824585, Synthetic Data Grad Norm: 0.00035290324012748897\n",
      "Epoch 4, Meta Loss: 2.261183977127075, Synthetic Data Grad Norm: 0.0003202156804036349\n",
      "Epoch 4, Meta Loss: 2.262254238128662, Synthetic Data Grad Norm: 0.000330375594785437\n",
      "Epoch 4, Meta Loss: 2.260974168777466, Synthetic Data Grad Norm: 0.000344579282682389\n",
      "Epoch 4, Meta Loss: 2.2813639640808105, Synthetic Data Grad Norm: 0.00024312727327924222\n",
      "Epoch 4, Meta Loss: 2.2852392196655273, Synthetic Data Grad Norm: 0.00027186726219952106\n",
      "Epoch 4, Meta Loss: 2.2672879695892334, Synthetic Data Grad Norm: 0.0002658701268956065\n",
      "Epoch 4, Meta Loss: 2.2569496631622314, Synthetic Data Grad Norm: 0.0002713469439186156\n",
      "Epoch 4, Meta Loss: 2.286426067352295, Synthetic Data Grad Norm: 0.0002591344527900219\n",
      "Epoch 4, Meta Loss: 2.278728485107422, Synthetic Data Grad Norm: 0.0002763948286883533\n",
      "Epoch 4, Meta Loss: 2.2671618461608887, Synthetic Data Grad Norm: 0.00038692771340720356\n",
      "Epoch 4, Meta Loss: 2.226641893386841, Synthetic Data Grad Norm: 0.0003680189838632941\n",
      "Epoch 4, Meta Loss: 2.2762999534606934, Synthetic Data Grad Norm: 0.0002690244000405073\n",
      "Epoch 4, Meta Loss: 2.2513720989227295, Synthetic Data Grad Norm: 0.00030908125336281955\n",
      "Epoch 4, Meta Loss: 2.2551333904266357, Synthetic Data Grad Norm: 0.0003766569425351918\n",
      "Epoch 4, Meta Loss: 2.2787821292877197, Synthetic Data Grad Norm: 0.00024327202118001878\n",
      "Epoch 4, Meta Loss: 2.240116596221924, Synthetic Data Grad Norm: 0.000299473904306069\n",
      "Epoch 4, Meta Loss: 2.2564666271209717, Synthetic Data Grad Norm: 0.00029092939803376794\n",
      "Epoch 4, Meta Loss: 2.265983819961548, Synthetic Data Grad Norm: 0.000291081698378548\n",
      "Epoch 4, Meta Loss: 2.2889928817749023, Synthetic Data Grad Norm: 0.0004353851545602083\n",
      "Epoch 4, Meta Loss: 2.279029369354248, Synthetic Data Grad Norm: 0.00042891717748716474\n",
      "Epoch 4, Meta Loss: 2.262291193008423, Synthetic Data Grad Norm: 0.00032427915721200407\n",
      "Epoch 4, Meta Loss: 2.3111021518707275, Synthetic Data Grad Norm: 0.0002870165335480124\n",
      "Epoch 4, Meta Loss: 2.2565174102783203, Synthetic Data Grad Norm: 0.00030304203392006457\n",
      "Epoch 4, Meta Loss: 2.2758877277374268, Synthetic Data Grad Norm: 0.00031326618045568466\n",
      "Epoch 4, Meta Loss: 2.2469382286071777, Synthetic Data Grad Norm: 0.00033354281913489103\n",
      "Epoch 4, Meta Loss: 2.266200065612793, Synthetic Data Grad Norm: 0.00032511312747374177\n",
      "Epoch 4, Meta Loss: 2.2642977237701416, Synthetic Data Grad Norm: 0.00028513200231827796\n",
      "Epoch 4, Meta Loss: 2.268343687057495, Synthetic Data Grad Norm: 0.0003554697032086551\n",
      "Epoch 4, Meta Loss: 2.2609751224517822, Synthetic Data Grad Norm: 0.00034955632872879505\n",
      "Epoch 4, Meta Loss: 2.27742075920105, Synthetic Data Grad Norm: 0.00031422864412888885\n",
      "Epoch 4, Meta Loss: 2.2619476318359375, Synthetic Data Grad Norm: 0.0003131873963866383\n",
      "Epoch 4, Meta Loss: 2.2749266624450684, Synthetic Data Grad Norm: 0.00030127016361802816\n",
      "Epoch 4, Meta Loss: 2.2524991035461426, Synthetic Data Grad Norm: 0.000348415196640417\n",
      "Epoch 4, Meta Loss: 2.273806571960449, Synthetic Data Grad Norm: 0.0003361810522619635\n",
      "Epoch 4, Meta Loss: 2.3011958599090576, Synthetic Data Grad Norm: 0.0004091538139618933\n",
      "Epoch 4, Meta Loss: 2.276465892791748, Synthetic Data Grad Norm: 0.00030937945120967925\n",
      "Epoch 4, Meta Loss: 2.2751879692077637, Synthetic Data Grad Norm: 0.00020751032570842654\n",
      "Epoch 4, Meta Loss: 2.2615370750427246, Synthetic Data Grad Norm: 0.0003310221654828638\n",
      "Epoch 4, Meta Loss: 2.27165150642395, Synthetic Data Grad Norm: 0.00034860565210692585\n",
      "Epoch 4, Meta Loss: 2.271660089492798, Synthetic Data Grad Norm: 0.0002774796448647976\n",
      "Epoch 4, Meta Loss: 2.2624030113220215, Synthetic Data Grad Norm: 0.0003673677856568247\n",
      "Epoch 4, Meta Loss: 2.260971784591675, Synthetic Data Grad Norm: 0.00024935646797530353\n",
      "Epoch 4, Meta Loss: 2.2678120136260986, Synthetic Data Grad Norm: 0.00022108067059889436\n",
      "Epoch 4, Meta Loss: 2.2848246097564697, Synthetic Data Grad Norm: 0.0003102082118857652\n",
      "Epoch 4, Meta Loss: 2.262709140777588, Synthetic Data Grad Norm: 0.0002958257682621479\n",
      "Epoch 4, Meta Loss: 2.267578125, Synthetic Data Grad Norm: 0.000261793116806075\n",
      "Epoch 4, Meta Loss: 2.2576534748077393, Synthetic Data Grad Norm: 0.0003353911451995373\n",
      "Epoch 4, Meta Loss: 2.2859365940093994, Synthetic Data Grad Norm: 0.000327674817526713\n",
      "Epoch 4, Meta Loss: 2.2734217643737793, Synthetic Data Grad Norm: 0.0003968133532907814\n",
      "Epoch 4, Meta Loss: 2.250286817550659, Synthetic Data Grad Norm: 0.00042849426972679794\n",
      "Epoch 4, Meta Loss: 2.2749340534210205, Synthetic Data Grad Norm: 0.0002750073908828199\n",
      "Epoch 4, Meta Loss: 2.26351261138916, Synthetic Data Grad Norm: 0.00022456039732787758\n",
      "Epoch 4, Meta Loss: 2.2713239192962646, Synthetic Data Grad Norm: 0.00023279167362488806\n",
      "Epoch 4, Meta Loss: 2.260484218597412, Synthetic Data Grad Norm: 0.00029140248079784214\n",
      "Epoch 4, Meta Loss: 2.267423629760742, Synthetic Data Grad Norm: 0.00030290253926068544\n",
      "Epoch 4, Meta Loss: 2.279965400695801, Synthetic Data Grad Norm: 0.0005279880133457482\n",
      "Epoch 4, Meta Loss: 2.258394241333008, Synthetic Data Grad Norm: 0.0003785269509535283\n",
      "Epoch 4, Meta Loss: 2.2591676712036133, Synthetic Data Grad Norm: 0.0002344690728932619\n",
      "Epoch 4, Meta Loss: 2.2691526412963867, Synthetic Data Grad Norm: 0.0002477191446814686\n",
      "Epoch 4, Meta Loss: 2.2477035522460938, Synthetic Data Grad Norm: 0.0003019911819137633\n",
      "Epoch 4, Meta Loss: 2.2832424640655518, Synthetic Data Grad Norm: 0.0003744900459423661\n",
      "Epoch 4, Meta Loss: 2.267742156982422, Synthetic Data Grad Norm: 0.00034909413079731166\n",
      "Epoch 4, Meta Loss: 2.2454254627227783, Synthetic Data Grad Norm: 0.00032522380934096873\n",
      "Epoch 4, Meta Loss: 2.2613234519958496, Synthetic Data Grad Norm: 0.0003857865813188255\n",
      "Epoch 4, Meta Loss: 2.2902376651763916, Synthetic Data Grad Norm: 0.0004947077250108123\n",
      "Epoch 4, Meta Loss: 2.2736213207244873, Synthetic Data Grad Norm: 0.0002534399973228574\n",
      "Epoch 4, Meta Loss: 2.296164035797119, Synthetic Data Grad Norm: 0.0003304978890810162\n",
      "Epoch 4, Meta Loss: 2.2661080360412598, Synthetic Data Grad Norm: 0.00028048866079188883\n",
      "Epoch 4, Meta Loss: 2.256897449493408, Synthetic Data Grad Norm: 0.0002554027596488595\n",
      "Epoch 4, Meta Loss: 2.273336887359619, Synthetic Data Grad Norm: 0.0002751193242147565\n",
      "Epoch 4, Meta Loss: 2.2772200107574463, Synthetic Data Grad Norm: 0.0002923114225268364\n",
      "Epoch 4, Meta Loss: 2.2715442180633545, Synthetic Data Grad Norm: 0.0002457348455209285\n",
      "Epoch 4, Meta Loss: 2.274289846420288, Synthetic Data Grad Norm: 0.00028312657377682626\n",
      "Epoch 4, Meta Loss: 2.249861240386963, Synthetic Data Grad Norm: 0.0002449284365866333\n",
      "Epoch 4, Meta Loss: 2.2615997791290283, Synthetic Data Grad Norm: 0.0003097796579822898\n",
      "Epoch 4, Meta Loss: 2.2772624492645264, Synthetic Data Grad Norm: 0.00026349042309448123\n",
      "Epoch 4, Meta Loss: 2.2575278282165527, Synthetic Data Grad Norm: 0.0003648988495115191\n",
      "Epoch 4, Meta Loss: 2.295583963394165, Synthetic Data Grad Norm: 0.00021071730589028448\n",
      "Epoch 4, Meta Loss: 2.277128219604492, Synthetic Data Grad Norm: 0.0003004026657436043\n",
      "Epoch 4, Meta Loss: 2.282435894012451, Synthetic Data Grad Norm: 0.00025245139840990305\n",
      "Epoch 4, Meta Loss: 2.2809369564056396, Synthetic Data Grad Norm: 0.0002128866035491228\n",
      "Epoch 4, Meta Loss: 2.2758913040161133, Synthetic Data Grad Norm: 0.00026833804440684617\n",
      "Epoch 4, Meta Loss: 2.3022637367248535, Synthetic Data Grad Norm: 0.00023556554515380412\n",
      "Epoch 4, Meta Loss: 2.2324423789978027, Synthetic Data Grad Norm: 0.00033788426662795246\n",
      "Epoch 4, Meta Loss: 2.248976945877075, Synthetic Data Grad Norm: 0.00030018194229342043\n",
      "Epoch 4, Meta Loss: 2.2782328128814697, Synthetic Data Grad Norm: 0.000324589287629351\n",
      "Epoch 4, Meta Loss: 2.295356273651123, Synthetic Data Grad Norm: 0.0003675274201668799\n",
      "Epoch 4, Meta Loss: 2.2533464431762695, Synthetic Data Grad Norm: 0.00033504958264529705\n",
      "Epoch 4, Meta Loss: 2.2936174869537354, Synthetic Data Grad Norm: 0.0003775017394218594\n",
      "Epoch 4, Meta Loss: 2.2792139053344727, Synthetic Data Grad Norm: 0.00020458971266634762\n",
      "Epoch 4, Meta Loss: 2.2912847995758057, Synthetic Data Grad Norm: 0.00025222630938515067\n",
      "Epoch 4, Meta Loss: 2.2900161743164062, Synthetic Data Grad Norm: 0.00027208964456804097\n",
      "Epoch 4, Meta Loss: 2.2777938842773438, Synthetic Data Grad Norm: 0.00031130926799960434\n",
      "Epoch 4, Meta Loss: 2.276599645614624, Synthetic Data Grad Norm: 0.0002958383993245661\n",
      "Epoch 4, Meta Loss: 2.258937120437622, Synthetic Data Grad Norm: 0.000312420423142612\n",
      "Epoch 4, Meta Loss: 2.2875609397888184, Synthetic Data Grad Norm: 0.00028409544029273093\n",
      "Epoch 4, Meta Loss: 2.2748043537139893, Synthetic Data Grad Norm: 0.00032789676333777606\n",
      "Epoch 4, Meta Loss: 2.2657947540283203, Synthetic Data Grad Norm: 0.0003167036338709295\n",
      "Epoch 4, Meta Loss: 2.2663700580596924, Synthetic Data Grad Norm: 0.00031540769850835204\n",
      "Epoch 4, Meta Loss: 2.2563767433166504, Synthetic Data Grad Norm: 0.0003159663174301386\n",
      "Epoch 4, Meta Loss: 2.2816171646118164, Synthetic Data Grad Norm: 0.00029120087856426835\n",
      "Epoch 4, Meta Loss: 2.269598960876465, Synthetic Data Grad Norm: 0.00027244564262218773\n",
      "Epoch 4, Meta Loss: 2.2696595191955566, Synthetic Data Grad Norm: 0.00027899740962311625\n",
      "Epoch 4, Meta Loss: 2.2663190364837646, Synthetic Data Grad Norm: 0.0002691151457838714\n",
      "Epoch 4, Meta Loss: 2.2888011932373047, Synthetic Data Grad Norm: 0.00035796561860479414\n",
      "Epoch 4, Meta Loss: 2.260650157928467, Synthetic Data Grad Norm: 0.00031172478338703513\n",
      "Epoch 4, Meta Loss: 2.240464925765991, Synthetic Data Grad Norm: 0.00039520495920442045\n",
      "Epoch 4, Meta Loss: 2.2743916511535645, Synthetic Data Grad Norm: 0.00040477339643985033\n",
      "Epoch 4, Meta Loss: 2.2604973316192627, Synthetic Data Grad Norm: 0.0004169737221673131\n",
      "Epoch 4, Meta Loss: 2.2746002674102783, Synthetic Data Grad Norm: 0.0003087096265517175\n",
      "Epoch 4, Meta Loss: 2.2820558547973633, Synthetic Data Grad Norm: 0.00027751040761359036\n",
      "Epoch 4, Meta Loss: 2.267744541168213, Synthetic Data Grad Norm: 0.0002852777251973748\n",
      "Epoch 4, Meta Loss: 2.2655789852142334, Synthetic Data Grad Norm: 0.0003065539931412786\n",
      "Epoch 4, Meta Loss: 2.2686729431152344, Synthetic Data Grad Norm: 0.00026592632639221847\n",
      "Epoch 4, Meta Loss: 2.255631923675537, Synthetic Data Grad Norm: 0.00028475280851125717\n",
      "Epoch 4, Meta Loss: 2.295020818710327, Synthetic Data Grad Norm: 0.0002684741630218923\n",
      "Epoch 4, Meta Loss: 2.2380964756011963, Synthetic Data Grad Norm: 0.00039001708501018584\n",
      "Epoch 4, Meta Loss: 2.2835304737091064, Synthetic Data Grad Norm: 0.00032907590502873063\n",
      "Epoch 4, Meta Loss: 2.28871488571167, Synthetic Data Grad Norm: 0.00023372063878923655\n",
      "Epoch 4, Meta Loss: 2.267731189727783, Synthetic Data Grad Norm: 0.0002989153144881129\n",
      "Epoch 4, Meta Loss: 2.2738208770751953, Synthetic Data Grad Norm: 0.0003048317157663405\n",
      "Epoch 4, Meta Loss: 2.288633346557617, Synthetic Data Grad Norm: 0.00023685743508394808\n",
      "Epoch 4, Meta Loss: 2.2581348419189453, Synthetic Data Grad Norm: 0.0002652234979905188\n",
      "Epoch 4, Meta Loss: 2.2659108638763428, Synthetic Data Grad Norm: 0.0003149828116875142\n",
      "Epoch 4, Meta Loss: 2.269076347351074, Synthetic Data Grad Norm: 0.00029087686561979353\n",
      "Epoch 4, Meta Loss: 2.2705941200256348, Synthetic Data Grad Norm: 0.00019267902825959027\n",
      "Epoch 4, Meta Loss: 2.2799386978149414, Synthetic Data Grad Norm: 0.00020245570340193808\n",
      "Epoch 4, Meta Loss: 2.2560086250305176, Synthetic Data Grad Norm: 0.0003250516892876476\n",
      "Epoch 4, Meta Loss: 2.2627601623535156, Synthetic Data Grad Norm: 0.00030744497780688107\n",
      "Epoch 4, Meta Loss: 2.2721269130706787, Synthetic Data Grad Norm: 0.00030395982321351767\n",
      "Epoch 4, Meta Loss: 2.272709846496582, Synthetic Data Grad Norm: 0.0003313547349534929\n",
      "Epoch 4, Meta Loss: 2.2623302936553955, Synthetic Data Grad Norm: 0.0003444551257416606\n",
      "Epoch 4, Meta Loss: 2.27205753326416, Synthetic Data Grad Norm: 0.00026727374643087387\n",
      "Epoch 4, Meta Loss: 2.2759227752685547, Synthetic Data Grad Norm: 0.0002934611984528601\n",
      "Epoch 4, Meta Loss: 2.244161605834961, Synthetic Data Grad Norm: 0.0003187684342265129\n",
      "Epoch 4, Meta Loss: 2.2579452991485596, Synthetic Data Grad Norm: 0.00036422081757336855\n",
      "Epoch 4, Meta Loss: 2.2846009731292725, Synthetic Data Grad Norm: 0.00030149935628287494\n",
      "Epoch 4, Meta Loss: 2.2757275104522705, Synthetic Data Grad Norm: 0.0003145259397570044\n",
      "Epoch 4, Meta Loss: 2.265162706375122, Synthetic Data Grad Norm: 0.0002115022361977026\n",
      "Epoch 4, Meta Loss: 2.2693827152252197, Synthetic Data Grad Norm: 0.00023971288464963436\n",
      "Epoch 4, Meta Loss: 2.266620397567749, Synthetic Data Grad Norm: 0.00038527356809936464\n",
      "Epoch 4, Meta Loss: 2.280437707901001, Synthetic Data Grad Norm: 0.00033862204873003066\n",
      "Epoch 4, Meta Loss: 2.275520086288452, Synthetic Data Grad Norm: 0.0002235672000097111\n",
      "Epoch 4, Meta Loss: 2.242433786392212, Synthetic Data Grad Norm: 0.00040582535439170897\n",
      "Epoch 4, Meta Loss: 2.261784315109253, Synthetic Data Grad Norm: 0.0002461218391545117\n",
      "Epoch 4, Meta Loss: 2.262099266052246, Synthetic Data Grad Norm: 0.0003147170355077833\n",
      "Epoch 4, Meta Loss: 2.261122703552246, Synthetic Data Grad Norm: 0.00031702383421361446\n",
      "Epoch 4, Meta Loss: 2.274406909942627, Synthetic Data Grad Norm: 0.0003012912056874484\n",
      "Epoch 4, Meta Loss: 2.2563745975494385, Synthetic Data Grad Norm: 0.0002537124964874238\n",
      "Epoch 4, Meta Loss: 2.2707815170288086, Synthetic Data Grad Norm: 0.00024439103435724974\n",
      "Epoch 4, Meta Loss: 2.2803609371185303, Synthetic Data Grad Norm: 0.00029092992190271616\n",
      "Epoch 4, Meta Loss: 2.2465152740478516, Synthetic Data Grad Norm: 0.00031726135057397187\n",
      "Epoch 4, Meta Loss: 2.2675766944885254, Synthetic Data Grad Norm: 0.00027332190074957907\n",
      "Epoch 4, Meta Loss: 2.2570912837982178, Synthetic Data Grad Norm: 0.0003460532461758703\n",
      "Epoch 4, Meta Loss: 2.254136085510254, Synthetic Data Grad Norm: 0.0003062276809941977\n",
      "Epoch 4, Meta Loss: 2.261744499206543, Synthetic Data Grad Norm: 0.0004025909292977303\n",
      "Epoch 4, Meta Loss: 2.2543952465057373, Synthetic Data Grad Norm: 0.0002914509386755526\n",
      "Epoch 4, Meta Loss: 2.2640933990478516, Synthetic Data Grad Norm: 0.00026367756072431803\n",
      "Epoch 4, Meta Loss: 2.2695488929748535, Synthetic Data Grad Norm: 0.0003211223229300231\n",
      "Epoch 4, Meta Loss: 2.2588233947753906, Synthetic Data Grad Norm: 0.0003573157300706953\n",
      "Epoch 4, Meta Loss: 2.2584123611450195, Synthetic Data Grad Norm: 0.00033880388946272433\n",
      "Epoch 4, Meta Loss: 2.265181064605713, Synthetic Data Grad Norm: 0.0003044246695935726\n",
      "Epoch 4, Meta Loss: 2.251603126525879, Synthetic Data Grad Norm: 0.00022714278020430356\n",
      "Epoch 4, Meta Loss: 2.266326427459717, Synthetic Data Grad Norm: 0.00031817826675251126\n",
      "Epoch 4, Meta Loss: 2.2676138877868652, Synthetic Data Grad Norm: 0.00020767725072801113\n",
      "Epoch 4, Meta Loss: 2.2640366554260254, Synthetic Data Grad Norm: 0.0003446547198109329\n",
      "Epoch 4, Meta Loss: 2.278341054916382, Synthetic Data Grad Norm: 0.00027615757426247\n",
      "Epoch 4, Meta Loss: 2.2685790061950684, Synthetic Data Grad Norm: 0.0002524136216379702\n",
      "Epoch 4, Meta Loss: 2.2798104286193848, Synthetic Data Grad Norm: 0.0002879645035136491\n",
      "Epoch 4, Meta Loss: 2.2608702182769775, Synthetic Data Grad Norm: 0.00040010991506278515\n",
      "Epoch 4, Meta Loss: 2.2942755222320557, Synthetic Data Grad Norm: 0.0002925063017755747\n",
      "Epoch 4, Meta Loss: 2.254634380340576, Synthetic Data Grad Norm: 0.0003327331505715847\n",
      "Epoch 4, Meta Loss: 2.274521827697754, Synthetic Data Grad Norm: 0.00020674349798355252\n",
      "Epoch 4, Meta Loss: 2.242283582687378, Synthetic Data Grad Norm: 0.00036153392284177244\n",
      "Epoch 4, Meta Loss: 2.2808079719543457, Synthetic Data Grad Norm: 0.0002817122149281204\n",
      "Epoch 4, Meta Loss: 2.274351119995117, Synthetic Data Grad Norm: 0.000284580368315801\n",
      "Epoch 4, Meta Loss: 2.251842498779297, Synthetic Data Grad Norm: 0.0002774724271148443\n",
      "Epoch 4, Meta Loss: 2.2665157318115234, Synthetic Data Grad Norm: 0.0002836529747582972\n",
      "Epoch 4, Meta Loss: 2.280397653579712, Synthetic Data Grad Norm: 0.0002766899415291846\n",
      "Epoch 4, Meta Loss: 2.2576403617858887, Synthetic Data Grad Norm: 0.00027106478228233755\n",
      "Epoch 4, Meta Loss: 2.2868576049804688, Synthetic Data Grad Norm: 0.00022197783982846886\n",
      "Epoch 4, Meta Loss: 2.28637433052063, Synthetic Data Grad Norm: 0.00029628266929648817\n",
      "Epoch 4, Meta Loss: 2.255662679672241, Synthetic Data Grad Norm: 0.0003969375102315098\n",
      "Epoch 4, Meta Loss: 2.2558181285858154, Synthetic Data Grad Norm: 0.00030759081710129976\n",
      "Epoch 4, Meta Loss: 2.2659878730773926, Synthetic Data Grad Norm: 0.0002487367601133883\n",
      "Epoch 4, Meta Loss: 2.2724945545196533, Synthetic Data Grad Norm: 0.00017153422231785953\n",
      "Epoch 4, Meta Loss: 2.2388694286346436, Synthetic Data Grad Norm: 0.00030596848228015006\n",
      "Epoch 4, Meta Loss: 2.271580934524536, Synthetic Data Grad Norm: 0.00032116236980073154\n",
      "Epoch 4, Meta Loss: 2.2944164276123047, Synthetic Data Grad Norm: 0.0002587854105513543\n",
      "Epoch 4, Meta Loss: 2.2461414337158203, Synthetic Data Grad Norm: 0.00027981013408862054\n",
      "Epoch 4, Meta Loss: 2.2585175037384033, Synthetic Data Grad Norm: 0.00025077888858504593\n",
      "Epoch 4, Meta Loss: 2.295755386352539, Synthetic Data Grad Norm: 0.0003535468131303787\n",
      "Epoch 4, Meta Loss: 2.2541537284851074, Synthetic Data Grad Norm: 0.0004441786732058972\n",
      "Epoch 4, Meta Loss: 2.2746169567108154, Synthetic Data Grad Norm: 0.00024486161419190466\n",
      "Epoch 4, Meta Loss: 2.2687175273895264, Synthetic Data Grad Norm: 0.00031350142671726644\n",
      "Epoch 4, Meta Loss: 2.2721807956695557, Synthetic Data Grad Norm: 0.0002806634292937815\n",
      "Epoch 4, Meta Loss: 2.274824380874634, Synthetic Data Grad Norm: 0.00026758972671814263\n",
      "Epoch 4, Meta Loss: 2.276963949203491, Synthetic Data Grad Norm: 0.0003636713663581759\n",
      "Epoch 4, Meta Loss: 2.2705323696136475, Synthetic Data Grad Norm: 0.00038003188092261553\n",
      "Epoch 4, Meta Loss: 2.2557790279388428, Synthetic Data Grad Norm: 0.0002892008633352816\n",
      "Epoch 4, Meta Loss: 2.245234251022339, Synthetic Data Grad Norm: 0.00042393134208396077\n",
      "Epoch 4, Meta Loss: 2.26996111869812, Synthetic Data Grad Norm: 0.0002825292176567018\n",
      "Epoch 4, Meta Loss: 2.2614195346832275, Synthetic Data Grad Norm: 0.0002524418814573437\n",
      "Epoch 4, Meta Loss: 2.2731246948242188, Synthetic Data Grad Norm: 0.000268815754679963\n",
      "Epoch 4, Meta Loss: 2.249823570251465, Synthetic Data Grad Norm: 0.0003877654962707311\n",
      "Epoch 4, Meta Loss: 2.2878499031066895, Synthetic Data Grad Norm: 0.0002824577677529305\n",
      "Epoch 4, Meta Loss: 2.2410104274749756, Synthetic Data Grad Norm: 0.0002702180645428598\n",
      "Epoch 4, Meta Loss: 2.28731632232666, Synthetic Data Grad Norm: 0.0003490016970317811\n",
      "Epoch 4, Meta Loss: 2.2711777687072754, Synthetic Data Grad Norm: 0.000256796192843467\n",
      "Epoch 4, Meta Loss: 2.2358577251434326, Synthetic Data Grad Norm: 0.00032947363797575235\n",
      "Epoch 4, Meta Loss: 2.283470392227173, Synthetic Data Grad Norm: 0.00030705303652212024\n",
      "Epoch 4, Meta Loss: 2.251737594604492, Synthetic Data Grad Norm: 0.0004057740734424442\n",
      "Epoch 4, Meta Loss: 2.280411958694458, Synthetic Data Grad Norm: 0.0002932428033091128\n",
      "Epoch 4, Meta Loss: 2.2800517082214355, Synthetic Data Grad Norm: 0.0002933848008979112\n",
      "Epoch 4, Meta Loss: 2.256406545639038, Synthetic Data Grad Norm: 0.000303387176245451\n",
      "Epoch 4, Meta Loss: 2.2722198963165283, Synthetic Data Grad Norm: 0.0002914090873673558\n",
      "Epoch 4, Meta Loss: 2.286799192428589, Synthetic Data Grad Norm: 0.0002526410389691591\n",
      "Epoch 4, Meta Loss: 2.250694990158081, Synthetic Data Grad Norm: 0.0003111553960479796\n",
      "Epoch 4, Meta Loss: 2.259500503540039, Synthetic Data Grad Norm: 0.0003468222566880286\n",
      "Epoch 4, Meta Loss: 2.2807629108428955, Synthetic Data Grad Norm: 0.0002760576317086816\n",
      "Epoch 4, Meta Loss: 2.2732138633728027, Synthetic Data Grad Norm: 0.00023215591500047594\n",
      "Epoch 4, Meta Loss: 2.2911128997802734, Synthetic Data Grad Norm: 0.00024412960920017213\n",
      "Epoch 4, Meta Loss: 2.260385751724243, Synthetic Data Grad Norm: 0.00025899879983626306\n",
      "Epoch 4, Meta Loss: 2.2592389583587646, Synthetic Data Grad Norm: 0.00027143245097249746\n",
      "Epoch 4, Meta Loss: 2.2550342082977295, Synthetic Data Grad Norm: 0.0002677548327483237\n",
      "Epoch 4, Meta Loss: 2.251399517059326, Synthetic Data Grad Norm: 0.0003771687624976039\n",
      "Epoch 4, Meta Loss: 2.2514419555664062, Synthetic Data Grad Norm: 0.00032507782452739775\n",
      "Epoch 4, Meta Loss: 2.2690842151641846, Synthetic Data Grad Norm: 0.0002263855712953955\n",
      "Epoch 4, Meta Loss: 2.267918348312378, Synthetic Data Grad Norm: 0.00022942402574699372\n",
      "Epoch 4, Meta Loss: 2.2568154335021973, Synthetic Data Grad Norm: 0.00034294844954274595\n",
      "Epoch 4, Meta Loss: 2.28259015083313, Synthetic Data Grad Norm: 0.000300113286357373\n",
      "Epoch 4, Meta Loss: 2.2729523181915283, Synthetic Data Grad Norm: 0.00027771780150942504\n",
      "Epoch 4, Meta Loss: 2.270622968673706, Synthetic Data Grad Norm: 0.00024217719328589737\n",
      "Epoch 4, Meta Loss: 2.261178731918335, Synthetic Data Grad Norm: 0.0002282682544318959\n",
      "Epoch 4, Meta Loss: 2.2663443088531494, Synthetic Data Grad Norm: 0.0003574233269318938\n",
      "Epoch 4, Meta Loss: 2.2667953968048096, Synthetic Data Grad Norm: 0.0003291968605481088\n",
      "Epoch 4, Meta Loss: 2.2804954051971436, Synthetic Data Grad Norm: 0.00033593823900446296\n",
      "Epoch 4, Meta Loss: 2.2588584423065186, Synthetic Data Grad Norm: 0.00031306056189350784\n",
      "Epoch 4, Meta Loss: 2.282682180404663, Synthetic Data Grad Norm: 0.00019681418780237436\n",
      "Epoch 4, Meta Loss: 2.283799886703491, Synthetic Data Grad Norm: 0.0003074606356676668\n",
      "Epoch 4, Meta Loss: 2.2973275184631348, Synthetic Data Grad Norm: 0.00029930981690995395\n",
      "Epoch 4, Meta Loss: 2.242504358291626, Synthetic Data Grad Norm: 0.00035604232107289135\n",
      "Epoch 4, Meta Loss: 2.2549829483032227, Synthetic Data Grad Norm: 0.00027369093731977046\n",
      "Epoch 4, Meta Loss: 2.278419017791748, Synthetic Data Grad Norm: 0.00026478973450139165\n",
      "Epoch 4, Meta Loss: 2.265991449356079, Synthetic Data Grad Norm: 0.00021854389342479408\n",
      "Epoch 4, Meta Loss: 2.279247760772705, Synthetic Data Grad Norm: 0.00025898587773554027\n",
      "Epoch 4, Meta Loss: 2.2798867225646973, Synthetic Data Grad Norm: 0.0002839474764186889\n",
      "Epoch 4, Meta Loss: 2.28338360786438, Synthetic Data Grad Norm: 0.00029675461701117456\n",
      "Epoch 4, Meta Loss: 2.235355854034424, Synthetic Data Grad Norm: 0.0003836794930975884\n",
      "Epoch 4, Meta Loss: 2.254289150238037, Synthetic Data Grad Norm: 0.000365047570085153\n",
      "Epoch 4, Meta Loss: 2.258136510848999, Synthetic Data Grad Norm: 0.00029522477416321635\n",
      "Epoch 4, Meta Loss: 2.2788050174713135, Synthetic Data Grad Norm: 0.00028229758027009666\n",
      "Epoch 4, Meta Loss: 2.265411376953125, Synthetic Data Grad Norm: 0.00020896685600746423\n",
      "Epoch 4, Meta Loss: 2.2724361419677734, Synthetic Data Grad Norm: 0.00020646193297579885\n",
      "Epoch 4, Meta Loss: 2.261160373687744, Synthetic Data Grad Norm: 0.000283832720015198\n",
      "Epoch 4, Meta Loss: 2.2649118900299072, Synthetic Data Grad Norm: 0.00027819140814244747\n",
      "Epoch 4, Meta Loss: 2.2518527507781982, Synthetic Data Grad Norm: 0.00034391533699817955\n",
      "Epoch 4, Meta Loss: 2.2838897705078125, Synthetic Data Grad Norm: 0.00029077037470415235\n",
      "Epoch 4, Meta Loss: 2.258970022201538, Synthetic Data Grad Norm: 0.00026697313296608627\n",
      "Epoch 4, Meta Loss: 2.25447154045105, Synthetic Data Grad Norm: 0.00027372350450605154\n",
      "Epoch 4, Meta Loss: 2.250861167907715, Synthetic Data Grad Norm: 0.00027803488774225116\n",
      "Epoch 4, Meta Loss: 2.2720863819122314, Synthetic Data Grad Norm: 0.00029870469006709754\n",
      "Epoch 4, Meta Loss: 2.2554001808166504, Synthetic Data Grad Norm: 0.000253175909165293\n",
      "Epoch 4, Meta Loss: 2.2766683101654053, Synthetic Data Grad Norm: 0.0002897987433243543\n",
      "Epoch 4, Meta Loss: 2.2660329341888428, Synthetic Data Grad Norm: 0.00030469687771983445\n",
      "Epoch 4, Meta Loss: 2.2464189529418945, Synthetic Data Grad Norm: 0.0003277047071605921\n",
      "Epoch 4, Meta Loss: 2.2601325511932373, Synthetic Data Grad Norm: 0.00025256272056140006\n",
      "Epoch 4, Meta Loss: 2.2578537464141846, Synthetic Data Grad Norm: 0.00034379493445158005\n",
      "Epoch 4, Meta Loss: 2.2954139709472656, Synthetic Data Grad Norm: 0.00029374638688750565\n",
      "Epoch 4, Meta Loss: 2.2695717811584473, Synthetic Data Grad Norm: 0.00022157664352562279\n",
      "Epoch 4, Meta Loss: 2.2963674068450928, Synthetic Data Grad Norm: 0.00019649106252472848\n",
      "Epoch 4, Meta Loss: 2.2672088146209717, Synthetic Data Grad Norm: 0.0002794541069306433\n",
      "Epoch 4, Meta Loss: 2.2920494079589844, Synthetic Data Grad Norm: 0.0002313646546099335\n",
      "Epoch 4, Meta Loss: 2.2808117866516113, Synthetic Data Grad Norm: 0.0002152903616661206\n",
      "Epoch 4, Meta Loss: 2.276444435119629, Synthetic Data Grad Norm: 0.00028862367616966367\n",
      "Epoch 4, Meta Loss: 2.2886414527893066, Synthetic Data Grad Norm: 0.00019236479420214891\n",
      "Epoch 4, Meta Loss: 2.265150308609009, Synthetic Data Grad Norm: 0.00027516434784047306\n",
      "Epoch 4, Meta Loss: 2.2621119022369385, Synthetic Data Grad Norm: 0.0003072404069826007\n",
      "Epoch 4, Meta Loss: 2.2563915252685547, Synthetic Data Grad Norm: 0.00031826645135879517\n",
      "Epoch 4, Meta Loss: 2.254911422729492, Synthetic Data Grad Norm: 0.0002594292163848877\n",
      "Epoch 4, Meta Loss: 2.267702579498291, Synthetic Data Grad Norm: 0.0002614407567307353\n",
      "Epoch 4, Meta Loss: 2.274423599243164, Synthetic Data Grad Norm: 0.00025873424601741135\n",
      "Epoch 4, Meta Loss: 2.2648837566375732, Synthetic Data Grad Norm: 0.00035849466803483665\n",
      "Epoch 4, Meta Loss: 2.2743356227874756, Synthetic Data Grad Norm: 0.0002800018119160086\n",
      "Epoch 4, Meta Loss: 2.265197515487671, Synthetic Data Grad Norm: 0.00026443746173754334\n",
      "Epoch 4, Meta Loss: 2.260399341583252, Synthetic Data Grad Norm: 0.00032438323250971735\n",
      "Epoch 4, Meta Loss: 2.2533953189849854, Synthetic Data Grad Norm: 0.0003142638597637415\n",
      "Epoch 4, Meta Loss: 2.26009202003479, Synthetic Data Grad Norm: 0.0003421547298785299\n",
      "Epoch 4, Meta Loss: 2.2373721599578857, Synthetic Data Grad Norm: 0.0003057059948332608\n",
      "Epoch 4, Meta Loss: 2.2854232788085938, Synthetic Data Grad Norm: 0.00023386746761389077\n",
      "Epoch 4, Meta Loss: 2.252552032470703, Synthetic Data Grad Norm: 0.0003637351910583675\n",
      "Epoch 4, Meta Loss: 2.2729437351226807, Synthetic Data Grad Norm: 0.0003757132508326322\n",
      "Epoch 4, Meta Loss: 2.277409076690674, Synthetic Data Grad Norm: 0.00025753219961188734\n",
      "Epoch 4, Meta Loss: 2.262678861618042, Synthetic Data Grad Norm: 0.0003196087200194597\n",
      "Epoch 4, Meta Loss: 2.2496631145477295, Synthetic Data Grad Norm: 0.00031992606818675995\n",
      "Epoch 4, Meta Loss: 2.2575619220733643, Synthetic Data Grad Norm: 0.0002727447426877916\n",
      "Epoch 4, Meta Loss: 2.2596938610076904, Synthetic Data Grad Norm: 0.00027548629441298544\n",
      "Epoch 4, Meta Loss: 2.2572224140167236, Synthetic Data Grad Norm: 0.0002926075248979032\n",
      "Epoch 4, Meta Loss: 2.2551259994506836, Synthetic Data Grad Norm: 0.00027609721291810274\n",
      "Epoch 4, Meta Loss: 2.270899534225464, Synthetic Data Grad Norm: 0.0002715296286623925\n",
      "Epoch 4, Meta Loss: 2.2554287910461426, Synthetic Data Grad Norm: 0.0003593970322981477\n",
      "Epoch 4, Meta Loss: 2.2805347442626953, Synthetic Data Grad Norm: 0.00018722320965025574\n",
      "Epoch 4, Meta Loss: 2.2515640258789062, Synthetic Data Grad Norm: 0.0003349187318235636\n",
      "Epoch 4, Meta Loss: 2.262769937515259, Synthetic Data Grad Norm: 0.0002721537312027067\n",
      "Epoch 4, Meta Loss: 2.2766506671905518, Synthetic Data Grad Norm: 0.00028753248625434935\n",
      "Epoch 4, Meta Loss: 2.281036138534546, Synthetic Data Grad Norm: 0.00026148048345930874\n",
      "Epoch 4, Meta Loss: 2.243152141571045, Synthetic Data Grad Norm: 0.00025925185764208436\n",
      "Epoch 4, Meta Loss: 2.2918341159820557, Synthetic Data Grad Norm: 0.00024528897483833134\n",
      "Epoch 4, Meta Loss: 2.2576024532318115, Synthetic Data Grad Norm: 0.0002632268297020346\n",
      "Epoch 4, Meta Loss: 2.2385058403015137, Synthetic Data Grad Norm: 0.0003428921627346426\n",
      "Epoch 4, Meta Loss: 2.2425036430358887, Synthetic Data Grad Norm: 0.0003892492677550763\n",
      "Epoch 4, Meta Loss: 2.277536153793335, Synthetic Data Grad Norm: 0.00023234976106323302\n",
      "Epoch 4, Meta Loss: 2.2568726539611816, Synthetic Data Grad Norm: 0.0003171847201883793\n",
      "Epoch 4, Meta Loss: 2.2567696571350098, Synthetic Data Grad Norm: 0.00033776869531720877\n",
      "Epoch 4, Meta Loss: 2.2684221267700195, Synthetic Data Grad Norm: 0.00029501167591661215\n",
      "Epoch 4, Meta Loss: 2.2819085121154785, Synthetic Data Grad Norm: 0.0002722808567341417\n",
      "Epoch 4, Meta Loss: 2.250979423522949, Synthetic Data Grad Norm: 0.0003209295100532472\n",
      "Epoch 4, Meta Loss: 2.2678000926971436, Synthetic Data Grad Norm: 0.00028128011035732925\n",
      "Epoch 4, Meta Loss: 2.258833408355713, Synthetic Data Grad Norm: 0.00039256131276488304\n",
      "Epoch 4, Meta Loss: 2.2803614139556885, Synthetic Data Grad Norm: 0.0002169106010114774\n",
      "Epoch 4, Meta Loss: 2.269627571105957, Synthetic Data Grad Norm: 0.00025143567472696304\n",
      "Epoch 4, Meta Loss: 2.2688112258911133, Synthetic Data Grad Norm: 0.000232800462981686\n",
      "Epoch 4, Meta Loss: 2.2595374584198, Synthetic Data Grad Norm: 0.0003008370695170015\n",
      "Epoch 4, Meta Loss: 2.2590203285217285, Synthetic Data Grad Norm: 0.00037619369686581194\n",
      "Epoch 4, Meta Loss: 2.2699508666992188, Synthetic Data Grad Norm: 0.000367628235835582\n",
      "Epoch 4, Meta Loss: 2.293959856033325, Synthetic Data Grad Norm: 0.00034500841866247356\n",
      "Epoch 4, Meta Loss: 2.232356548309326, Synthetic Data Grad Norm: 0.0003106273652520031\n",
      "Epoch 4, Meta Loss: 2.271318197250366, Synthetic Data Grad Norm: 0.0002479662070982158\n",
      "Epoch 4, Meta Loss: 2.282271146774292, Synthetic Data Grad Norm: 0.0004380196623969823\n",
      "Epoch 4, Meta Loss: 2.2734789848327637, Synthetic Data Grad Norm: 0.00030496218823827803\n",
      "Epoch 4, Meta Loss: 2.264922857284546, Synthetic Data Grad Norm: 0.0002795075415633619\n",
      "Epoch 4, Meta Loss: 2.2499680519104004, Synthetic Data Grad Norm: 0.0002994307433255017\n",
      "Epoch 4, Meta Loss: 2.2777204513549805, Synthetic Data Grad Norm: 0.00020663964096456766\n",
      "Epoch 4, Meta Loss: 2.2635865211486816, Synthetic Data Grad Norm: 0.00032699317671358585\n",
      "Epoch 4, Meta Loss: 2.2654483318328857, Synthetic Data Grad Norm: 0.00029260266455821693\n",
      "Epoch 4, Meta Loss: 2.2451670169830322, Synthetic Data Grad Norm: 0.00026113324565812945\n",
      "Epoch 4, Meta Loss: 2.2595860958099365, Synthetic Data Grad Norm: 0.00027669931296259165\n",
      "Epoch 4, Meta Loss: 2.2524936199188232, Synthetic Data Grad Norm: 0.00033131102100014687\n",
      "Epoch 4, Meta Loss: 2.266596555709839, Synthetic Data Grad Norm: 0.00033675821032375097\n",
      "Epoch 4, Meta Loss: 2.2910377979278564, Synthetic Data Grad Norm: 0.00032736026332713664\n",
      "Epoch 4, Meta Loss: 2.2598514556884766, Synthetic Data Grad Norm: 0.0003303929988760501\n",
      "Epoch 4, Meta Loss: 2.2778890132904053, Synthetic Data Grad Norm: 0.0003321302938275039\n",
      "Epoch 4, Meta Loss: 2.2491941452026367, Synthetic Data Grad Norm: 0.0003195182653144002\n",
      "Epoch 4, Meta Loss: 2.27225399017334, Synthetic Data Grad Norm: 0.0002414685150142759\n",
      "Epoch 4, Meta Loss: 2.252171516418457, Synthetic Data Grad Norm: 0.0003167905379086733\n",
      "Epoch 4, Meta Loss: 2.240513324737549, Synthetic Data Grad Norm: 0.0003747768350876868\n",
      "Epoch 4, Meta Loss: 2.273026943206787, Synthetic Data Grad Norm: 0.0002564180176705122\n",
      "Epoch 4, Meta Loss: 2.2441534996032715, Synthetic Data Grad Norm: 0.00043635733891278505\n",
      "Epoch 4, Meta Loss: 2.242893934249878, Synthetic Data Grad Norm: 0.00030657986644655466\n",
      "Epoch 4, Meta Loss: 2.2792985439300537, Synthetic Data Grad Norm: 0.00024992390535771847\n",
      "Epoch 4, Meta Loss: 2.2378621101379395, Synthetic Data Grad Norm: 0.00028885004576295614\n",
      "Epoch 4, Meta Loss: 2.2637133598327637, Synthetic Data Grad Norm: 0.00025776983238756657\n",
      "Epoch 4, Meta Loss: 2.2674612998962402, Synthetic Data Grad Norm: 0.00029459010693244636\n",
      "Epoch 4, Meta Loss: 2.260096311569214, Synthetic Data Grad Norm: 0.00030783007969148457\n",
      "Epoch 4, Meta Loss: 2.2785186767578125, Synthetic Data Grad Norm: 0.0003208793350495398\n",
      "Epoch 4, Meta Loss: 2.259178638458252, Synthetic Data Grad Norm: 0.0003043956821784377\n",
      "Epoch 4, Meta Loss: 2.2729439735412598, Synthetic Data Grad Norm: 0.00026938560768030584\n",
      "Epoch 4, Meta Loss: 2.251039505004883, Synthetic Data Grad Norm: 0.00027003142167814076\n",
      "Epoch 4, Meta Loss: 2.257784605026245, Synthetic Data Grad Norm: 0.00027135631535202265\n",
      "Epoch 4, Meta Loss: 2.2805826663970947, Synthetic Data Grad Norm: 0.00019347938359715044\n",
      "Epoch 4, Meta Loss: 2.2763705253601074, Synthetic Data Grad Norm: 0.00030237631290219724\n",
      "Epoch 4, Meta Loss: 2.260755777359009, Synthetic Data Grad Norm: 0.000251339835813269\n",
      "Epoch 4, Meta Loss: 2.286433458328247, Synthetic Data Grad Norm: 0.0005173584213480353\n",
      "Epoch 4, Meta Loss: 2.265620231628418, Synthetic Data Grad Norm: 0.00024075133842416108\n",
      "Epoch 4, Meta Loss: 2.2472081184387207, Synthetic Data Grad Norm: 0.00029309612000361085\n",
      "Epoch 4, Meta Loss: 2.252469301223755, Synthetic Data Grad Norm: 0.00027473035152070224\n",
      "Epoch 4, Meta Loss: 2.2767906188964844, Synthetic Data Grad Norm: 0.0002074376679956913\n",
      "Epoch 4, Meta Loss: 2.273145914077759, Synthetic Data Grad Norm: 0.00033949996577575803\n",
      "Epoch 4, Meta Loss: 2.252324104309082, Synthetic Data Grad Norm: 0.0003820406855084002\n",
      "Epoch 4, Meta Loss: 2.261171340942383, Synthetic Data Grad Norm: 0.0003602416254580021\n",
      "Epoch 4, Meta Loss: 2.287691116333008, Synthetic Data Grad Norm: 0.00033917499240487814\n",
      "Epoch 4, Meta Loss: 2.2603676319122314, Synthetic Data Grad Norm: 0.00029179235571064055\n",
      "Epoch 4, Meta Loss: 2.283494710922241, Synthetic Data Grad Norm: 0.0003567793173715472\n",
      "Epoch 4, Meta Loss: 2.257282018661499, Synthetic Data Grad Norm: 0.0003860658616758883\n",
      "Epoch 4, Meta Loss: 2.2906575202941895, Synthetic Data Grad Norm: 0.0002188720682170242\n",
      "Epoch 4, Meta Loss: 2.250865936279297, Synthetic Data Grad Norm: 0.0004223860742058605\n",
      "Epoch 4, Meta Loss: 2.2582271099090576, Synthetic Data Grad Norm: 0.0003024173201993108\n",
      "Epoch 4, Meta Loss: 2.246424674987793, Synthetic Data Grad Norm: 0.0004222805146127939\n",
      "Epoch 4, Meta Loss: 2.2639577388763428, Synthetic Data Grad Norm: 0.00022034462017472833\n",
      "Epoch 4, Meta Loss: 2.2513375282287598, Synthetic Data Grad Norm: 0.0002938728139270097\n",
      "Epoch 4, Meta Loss: 2.299999713897705, Synthetic Data Grad Norm: 0.00027641531778499484\n",
      "Epoch 4, Meta Loss: 2.2666590213775635, Synthetic Data Grad Norm: 0.00028686667792499065\n",
      "Epoch 4, Meta Loss: 2.2880053520202637, Synthetic Data Grad Norm: 0.00024144798226188868\n",
      "Epoch 4, Meta Loss: 2.2893309593200684, Synthetic Data Grad Norm: 0.000302252359688282\n",
      "Epoch 4, Meta Loss: 2.2766335010528564, Synthetic Data Grad Norm: 0.0003263255930505693\n",
      "Epoch 4, Meta Loss: 2.277332305908203, Synthetic Data Grad Norm: 0.00026193741359747946\n",
      "Epoch 4, Meta Loss: 2.2493395805358887, Synthetic Data Grad Norm: 0.0003852008667308837\n",
      "Epoch 4, Meta Loss: 2.2700891494750977, Synthetic Data Grad Norm: 0.000256790139246732\n",
      "Epoch 4, Meta Loss: 2.2700753211975098, Synthetic Data Grad Norm: 0.00033783414983190596\n",
      "Epoch 4, Meta Loss: 2.2695000171661377, Synthetic Data Grad Norm: 0.00025077792815864086\n",
      "Epoch 4, Meta Loss: 2.264357566833496, Synthetic Data Grad Norm: 0.0003305712016299367\n",
      "Epoch 4, Meta Loss: 2.262634754180908, Synthetic Data Grad Norm: 0.0003778109676204622\n",
      "Epoch 4, Meta Loss: 2.2503204345703125, Synthetic Data Grad Norm: 0.00029444892425090075\n",
      "Epoch 4, Meta Loss: 2.258134365081787, Synthetic Data Grad Norm: 0.00030783264082856476\n",
      "Epoch 4, Meta Loss: 2.287153959274292, Synthetic Data Grad Norm: 0.0002934715594165027\n",
      "Epoch 4, Meta Loss: 2.2547879219055176, Synthetic Data Grad Norm: 0.00029293217812664807\n",
      "Epoch 4, Meta Loss: 2.2639458179473877, Synthetic Data Grad Norm: 0.00037437715218402445\n",
      "Epoch 4, Meta Loss: 2.276445150375366, Synthetic Data Grad Norm: 0.00022845501371193677\n",
      "Epoch 4, Meta Loss: 2.2754733562469482, Synthetic Data Grad Norm: 0.00025294238002970815\n",
      "Epoch 4, Meta Loss: 2.2599828243255615, Synthetic Data Grad Norm: 0.00020646081247832626\n",
      "Epoch 4, Meta Loss: 2.265528678894043, Synthetic Data Grad Norm: 0.0004081804654560983\n",
      "Epoch 4, Meta Loss: 2.259899139404297, Synthetic Data Grad Norm: 0.000361250335117802\n",
      "Epoch 4, Meta Loss: 2.2734875679016113, Synthetic Data Grad Norm: 0.00032203903538174927\n",
      "Epoch 4, Meta Loss: 2.280996084213257, Synthetic Data Grad Norm: 0.00023448244610335678\n",
      "Epoch 4, Meta Loss: 2.2662315368652344, Synthetic Data Grad Norm: 0.0002912510826718062\n",
      "Epoch 4, Meta Loss: 2.2639782428741455, Synthetic Data Grad Norm: 0.0002739558694884181\n",
      "Epoch 4, Meta Loss: 2.27143931388855, Synthetic Data Grad Norm: 0.00025941093917936087\n",
      "Epoch 4, Meta Loss: 2.2523252964019775, Synthetic Data Grad Norm: 0.00034688174491748214\n",
      "Epoch 4, Meta Loss: 2.252178192138672, Synthetic Data Grad Norm: 0.00032256345730274916\n",
      "Epoch 4, Meta Loss: 2.2580654621124268, Synthetic Data Grad Norm: 0.0002536341198720038\n",
      "Epoch 4, Meta Loss: 2.254674196243286, Synthetic Data Grad Norm: 0.00039790692972019315\n",
      "Epoch 4, Meta Loss: 2.257906436920166, Synthetic Data Grad Norm: 0.0002815470506902784\n",
      "Epoch 4, Meta Loss: 2.268495559692383, Synthetic Data Grad Norm: 0.00021138673764653504\n",
      "Epoch 4, Meta Loss: 2.2242937088012695, Synthetic Data Grad Norm: 0.0003351619525346905\n",
      "Epoch 4, Meta Loss: 2.2593839168548584, Synthetic Data Grad Norm: 0.00031431877869181335\n",
      "Epoch 4, Meta Loss: 2.2772600650787354, Synthetic Data Grad Norm: 0.00035128448507748544\n",
      "Epoch 4, Meta Loss: 2.2557318210601807, Synthetic Data Grad Norm: 0.00043622319935820997\n",
      "Epoch 4, Meta Loss: 2.2523534297943115, Synthetic Data Grad Norm: 0.0003190198331139982\n",
      "Epoch 4, Meta Loss: 2.2756481170654297, Synthetic Data Grad Norm: 0.00030569673981517553\n",
      "Epoch 4, Meta Loss: 2.287397623062134, Synthetic Data Grad Norm: 0.00029837299371138215\n",
      "Epoch 4, Meta Loss: 2.2541251182556152, Synthetic Data Grad Norm: 0.00026437375345267355\n",
      "Epoch 4, Meta Loss: 2.2870607376098633, Synthetic Data Grad Norm: 0.000338435813318938\n",
      "Epoch 4, Meta Loss: 2.283737897872925, Synthetic Data Grad Norm: 0.00020797696197405457\n",
      "Epoch 4, Meta Loss: 2.2818851470947266, Synthetic Data Grad Norm: 0.00028395894332788885\n",
      "Epoch 4, Meta Loss: 2.262909173965454, Synthetic Data Grad Norm: 0.00039380311500281096\n",
      "Epoch 4, Meta Loss: 2.265669822692871, Synthetic Data Grad Norm: 0.0002761883952189237\n",
      "Epoch 4, Meta Loss: 2.287526845932007, Synthetic Data Grad Norm: 0.00029456999618560076\n",
      "Epoch 4, Meta Loss: 2.251021146774292, Synthetic Data Grad Norm: 0.00034445413621142507\n",
      "Epoch 4, Meta Loss: 2.2540581226348877, Synthetic Data Grad Norm: 0.0003186394751537591\n",
      "Epoch 4, Meta Loss: 2.2565298080444336, Synthetic Data Grad Norm: 0.00029248165083117783\n",
      "Epoch 4, Meta Loss: 2.2673604488372803, Synthetic Data Grad Norm: 0.0003596646129153669\n",
      "Epoch 4, Meta Loss: 2.2588706016540527, Synthetic Data Grad Norm: 0.00034126968239434063\n",
      "Epoch 4, Meta Loss: 2.258216142654419, Synthetic Data Grad Norm: 0.0002925927110482007\n",
      "Epoch 4, Meta Loss: 2.273465871810913, Synthetic Data Grad Norm: 0.0003067224461119622\n",
      "Epoch 4, Meta Loss: 2.2842090129852295, Synthetic Data Grad Norm: 0.0003570166591089219\n",
      "Epoch 4, Meta Loss: 2.269099473953247, Synthetic Data Grad Norm: 0.0002508025791030377\n",
      "Epoch 4, Meta Loss: 2.2696280479431152, Synthetic Data Grad Norm: 0.0002848068834282458\n",
      "Epoch 4, Meta Loss: 2.268394947052002, Synthetic Data Grad Norm: 0.00037986846291460097\n",
      "Epoch 4, Meta Loss: 2.25166654586792, Synthetic Data Grad Norm: 0.00031490743276663125\n",
      "Epoch 4, Meta Loss: 2.2377238273620605, Synthetic Data Grad Norm: 0.00030497738043777645\n",
      "Epoch 4, Meta Loss: 2.2850425243377686, Synthetic Data Grad Norm: 0.00041876817704178393\n",
      "Epoch 4, Meta Loss: 2.247009754180908, Synthetic Data Grad Norm: 0.00032131632906384766\n",
      "Epoch 4, Meta Loss: 2.2668700218200684, Synthetic Data Grad Norm: 0.0003352553176227957\n",
      "Epoch 4, Meta Loss: 2.2843711376190186, Synthetic Data Grad Norm: 0.000274878490017727\n",
      "Epoch 4, Meta Loss: 2.254744291305542, Synthetic Data Grad Norm: 0.0003517273289617151\n",
      "Epoch 4, Meta Loss: 2.274010181427002, Synthetic Data Grad Norm: 0.0002276102313771844\n",
      "Epoch 4, Meta Loss: 2.2669320106506348, Synthetic Data Grad Norm: 0.0002597458951640874\n",
      "Epoch 4, Meta Loss: 2.2755186557769775, Synthetic Data Grad Norm: 0.0003464585170149803\n",
      "Epoch 4, Meta Loss: 2.258263349533081, Synthetic Data Grad Norm: 0.00021801139519084245\n",
      "Epoch 4, Meta Loss: 2.2302558422088623, Synthetic Data Grad Norm: 0.00037444508052431047\n",
      "Epoch 4, Meta Loss: 2.2812302112579346, Synthetic Data Grad Norm: 0.00024095676781143993\n",
      "Epoch 4, Meta Loss: 2.2849724292755127, Synthetic Data Grad Norm: 0.00022147603158373386\n",
      "Epoch 4, Meta Loss: 2.259230136871338, Synthetic Data Grad Norm: 0.00031809473875910044\n",
      "Epoch 4, Meta Loss: 2.2591261863708496, Synthetic Data Grad Norm: 0.0002896227524615824\n",
      "Epoch 4, Meta Loss: 2.2753102779388428, Synthetic Data Grad Norm: 0.0002639945305418223\n",
      "Epoch 4, Meta Loss: 2.2638931274414062, Synthetic Data Grad Norm: 0.00034674626658670604\n",
      "Epoch 4, Meta Loss: 2.2529244422912598, Synthetic Data Grad Norm: 0.00027470666100271046\n",
      "Epoch 4, Meta Loss: 2.264252185821533, Synthetic Data Grad Norm: 0.00026286448701284826\n",
      "Epoch 4, Meta Loss: 2.2849643230438232, Synthetic Data Grad Norm: 0.00027303426759317517\n",
      "Epoch 4, Meta Loss: 2.2830753326416016, Synthetic Data Grad Norm: 0.00027016267995350063\n",
      "Epoch 4, Meta Loss: 2.2652735710144043, Synthetic Data Grad Norm: 0.00023344276996795088\n",
      "Epoch 4, Meta Loss: 2.275017738342285, Synthetic Data Grad Norm: 0.0002914010838139802\n",
      "Epoch 4, Meta Loss: 2.2669765949249268, Synthetic Data Grad Norm: 0.00023189328203443438\n",
      "Epoch 4, Meta Loss: 2.275425434112549, Synthetic Data Grad Norm: 0.0003223045205231756\n",
      "Epoch 4, Meta Loss: 2.2676167488098145, Synthetic Data Grad Norm: 0.00028107184334658086\n",
      "Epoch 4, Meta Loss: 2.298227310180664, Synthetic Data Grad Norm: 0.00022519940102938563\n",
      "Epoch 4, Meta Loss: 2.260918140411377, Synthetic Data Grad Norm: 0.0003098559973295778\n",
      "Epoch 4, Meta Loss: 2.2702322006225586, Synthetic Data Grad Norm: 0.0002241905458504334\n",
      "Epoch 4, Meta Loss: 2.2789065837860107, Synthetic Data Grad Norm: 0.00026903144316747785\n",
      "Epoch 4, Meta Loss: 2.255479097366333, Synthetic Data Grad Norm: 0.00031792695517651737\n",
      "Epoch 4, Meta Loss: 2.268528938293457, Synthetic Data Grad Norm: 0.0003544983337633312\n",
      "Epoch 4, Meta Loss: 2.2708418369293213, Synthetic Data Grad Norm: 0.0003952598781324923\n",
      "Epoch 4, Meta Loss: 2.254643440246582, Synthetic Data Grad Norm: 0.00026903604157269\n",
      "Epoch 4, Meta Loss: 2.272653102874756, Synthetic Data Grad Norm: 0.00023374416923616081\n",
      "Epoch 4, Meta Loss: 2.25278639793396, Synthetic Data Grad Norm: 0.00035407496034167707\n",
      "Epoch 4, Meta Loss: 2.264981985092163, Synthetic Data Grad Norm: 0.00032544040004722774\n",
      "Epoch 4, Meta Loss: 2.272972345352173, Synthetic Data Grad Norm: 0.00023180386051535606\n",
      "Epoch 4, Meta Loss: 2.258166551589966, Synthetic Data Grad Norm: 0.0003455474798101932\n",
      "Epoch 4, Meta Loss: 2.2604498863220215, Synthetic Data Grad Norm: 0.00026816685567609966\n",
      "Epoch 4, Meta Loss: 2.252991199493408, Synthetic Data Grad Norm: 0.00039179876330308616\n",
      "Epoch 4, Meta Loss: 2.2637906074523926, Synthetic Data Grad Norm: 0.0003058807924389839\n",
      "Epoch 4, Meta Loss: 2.250004291534424, Synthetic Data Grad Norm: 0.00030785772833041847\n",
      "Epoch 4, Meta Loss: 2.2679710388183594, Synthetic Data Grad Norm: 0.00022632059699390084\n",
      "Epoch 4, Meta Loss: 2.247239589691162, Synthetic Data Grad Norm: 0.00032109752646647394\n",
      "Epoch 4, Meta Loss: 2.2452445030212402, Synthetic Data Grad Norm: 0.0002958140685223043\n",
      "Epoch 4, Meta Loss: 2.254575252532959, Synthetic Data Grad Norm: 0.0002693757996894419\n",
      "Epoch 4, Meta Loss: 2.269580125808716, Synthetic Data Grad Norm: 0.0002578570565674454\n",
      "Epoch 4, Meta Loss: 2.2718048095703125, Synthetic Data Grad Norm: 0.00025978765916079283\n",
      "Epoch 4, Meta Loss: 2.2507472038269043, Synthetic Data Grad Norm: 0.00037559703923761845\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the network with an optional fast-weights dictionary.\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 14 * 14)\n",
    "        self.fc2 = nn.Linear(14 * 14, 7 * 7)\n",
    "        self.fc3 = nn.Linear(7 * 7, 10)\n",
    "    \n",
    "    def forward(self, x, params=None):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        if params is None:\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "        else:\n",
    "            x = F.linear(x, params['fc1.weight'], params['fc1.bias'])\n",
    "            x = F.relu(x)\n",
    "            x = F.linear(x, params['fc2.weight'], params['fc2.bias'])\n",
    "            x = F.relu(x)\n",
    "            x = F.linear(x, params['fc3.weight'], params['fc3.bias'])\n",
    "        return x\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Synthetic Data Initialization (using a smaller variance)\n",
    "num_classes = 10\n",
    "images_per_class = 10  # 10 synthetic images per class\n",
    "total_syn = num_classes * images_per_class\n",
    "synthetic_data = nn.Parameter(torch.randn(total_syn, 1, 28, 28, device=device) * 0.1)\n",
    "synthetic_labels = torch.tensor([i for i in range(num_classes) for _ in range(images_per_class)], device=device)\n",
    "\n",
    "# Real Data Loader\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "real_loader = DataLoader(mnist_train, batch_size=64, shuffle=True)\n",
    "\n",
    "# Outer optimizer: using Adam for more stable updates\n",
    "outer_optimizer = optim.Adam([synthetic_data], lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Hyperparameters for the inner loop\n",
    "num_inner_steps = 20   # increased from 5 to 20 steps\n",
    "inner_lr = 0.01\n",
    "\n",
    "# Training loop: meta model matching process\n",
    "for epoch in range(5):\n",
    "    for real_images, real_labels in real_loader:\n",
    "        real_images, real_labels = real_images.to(device), real_labels.to(device)\n",
    "        \n",
    "        # Initialize a fresh meta-model for each iteration\n",
    "        model = SimpleNet().to(device)\n",
    "        fast_weights = {name: param.clone().detach().requires_grad_(True)\n",
    "                        for name, param in model.named_parameters()}\n",
    "        \n",
    "        # ---- Inner Loop: Perform multiple gradient updates on synthetic data ----\n",
    "        for _ in range(num_inner_steps):\n",
    "            syn_logits = model.forward(synthetic_data, params=fast_weights)\n",
    "            inner_loss = criterion(syn_logits, synthetic_labels)\n",
    "            \n",
    "            grads = torch.autograd.grad(\n",
    "                inner_loss, list(fast_weights.values()), create_graph=True, allow_unused=True\n",
    "            )\n",
    "            \n",
    "            fast_weights = {\n",
    "                name: param - inner_lr * (grad if grad is not None else torch.zeros_like(param))\n",
    "                for (name, param), grad in zip(fast_weights.items(), grads)\n",
    "            }\n",
    "        \n",
    "        # ---- Meta Evaluation: Compute loss on real data using updated fast weights ----\n",
    "        meta_logits = model.forward(real_images, params=fast_weights)\n",
    "        meta_loss = criterion(meta_logits, real_labels)\n",
    "        \n",
    "        # ---- Outer Loop: Update synthetic data to minimize the meta loss ----\n",
    "        outer_optimizer.zero_grad()\n",
    "        meta_loss.backward()\n",
    "        outer_optimizer.step()\n",
    "        \n",
    "        # Debugging: Check gradient norm of synthetic_data\n",
    "        grad_norm = synthetic_data.grad.norm().item() if synthetic_data.grad is not None else 0.0\n",
    "        print(f\"Epoch {epoch}, Meta Loss: {meta_loss.item()}, Synthetic Data Grad Norm: {grad_norm}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [0/1500], Loss: 0.0046\n",
      "Step [100/1500], Loss: 0.0045\n",
      "Step [200/1500], Loss: 0.0046\n",
      "Step [300/1500], Loss: 0.0047\n",
      "Step [400/1500], Loss: 0.0047\n",
      "Step [500/1500], Loss: 0.0046\n",
      "Step [600/1500], Loss: 0.0048\n",
      "Step [700/1500], Loss: 0.0047\n",
      "Step [800/1500], Loss: 0.0045\n",
      "Step [900/1500], Loss: 0.0048\n",
      "Step [1000/1500], Loss: 0.0046\n",
      "Step [1100/1500], Loss: 0.0047\n",
      "Step [1200/1500], Loss: 0.0047\n",
      "Step [1300/1500], Loss: 0.0047\n",
      "Step [1400/1500], Loss: 0.0047\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.2859\n",
      "Epoch [2/10], Loss: 2.2038\n",
      "Epoch [3/10], Loss: 2.1286\n",
      "Epoch [4/10], Loss: 2.0506\n",
      "Epoch [5/10], Loss: 1.9695\n",
      "Epoch [6/10], Loss: 1.8799\n",
      "Epoch [7/10], Loss: 1.7825\n",
      "Epoch [8/10], Loss: 1.6783\n",
      "Epoch [9/10], Loss: 1.5695\n",
      "Epoch [10/10], Loss: 1.4561\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Corrected SimpleNet\n",
    "class BetterNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        return self.fc3(x)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "num_classes = 10\n",
    "input_dim = 28 * 28\n",
    "syn_size = 50  # 50 synthetic images\n",
    "inner_steps = 150  # Inner loop steps\n",
    "outer_steps = 1500  # Outer loop steps\n",
    "lr_syn = 0.01  # Reduced from 0.1\n",
    "lr_model = 0.001  # Reduced from 0.01\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Initialize synthetic data with real images (critical for MNIST)\n",
    "real_images, real_labels = next(iter(train_loader))\n",
    "syn_images = real_images[:syn_size].clone().detach().requires_grad_(True).to(device)\n",
    "syn_labels = nn.functional.one_hot(real_labels[:syn_size], num_classes).float().requires_grad_(True).to(device)\n",
    "\n",
    "# Optimizer for synthetic data\n",
    "optimizer_syn = optim.Adam([syn_images, syn_labels], lr=lr_syn)  # Use Adam instead of SGD\n",
    "\n",
    "# Loss tracking\n",
    "meta_losses = []\n",
    "\n",
    "\n",
    "for outer_step in range(outer_steps):\n",
    "    # Initialize fresh model\n",
    "    model = BetterNet().to(device)\n",
    "    optimizer_model = optim.Adam(model.parameters(), lr=lr_model)\n",
    "    \n",
    "    # --------------------------------------\n",
    "    # Inner loop: Train on synthetic data\n",
    "    # --------------------------------------\n",
    "    inner_steps = 3  # Reduced from 5 (prevent overfitting to synthetic data)\n",
    "    # Add to training loop:\n",
    "    for _ in range(inner_steps):\n",
    "        outputs = model(syn_images)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, syn_labels.argmax(dim=1)) + 0.001 * torch.norm(syn_images)  # L2 regularization\n",
    "\n",
    "        # Update model parameters\n",
    "        optimizer_model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_model.step()\n",
    "    \n",
    "    # --------------------------------------\n",
    "    # Outer loop: Meta-optimization\n",
    "    # --------------------------------------\n",
    "    # Outer loop with gradient clipping\n",
    "    meta_loss = 0.0\n",
    "    for real_images, real_labels in train_loader:\n",
    "        real_images, real_labels = real_images.to(device), real_labels.to(device)\n",
    "        outputs_real = model(real_images)\n",
    "        loss_real = nn.CrossEntropyLoss()(outputs_real, real_labels)\n",
    "        \n",
    "        optimizer_syn.zero_grad()\n",
    "        loss_real.backward()\n",
    "        torch.nn.utils.clip_grad_norm_([syn_images, syn_labels], 1.0)\n",
    "        optimizer_syn.step()\n",
    "        \n",
    "        meta_loss += loss_real.item()\n",
    "        meta_losses.append(meta_loss)\n",
    "        break\n",
    "    \n",
    "    meta_loss /= len(train_loader)\n",
    "    if outer_step % 100 == 0:\n",
    "        print(f'Step [{outer_step}/{outer_steps}], Loss: {meta_loss:.4f}')\n",
    "        \n",
    "        \n",
    "# Plot learning curve\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(meta_losses)\n",
    "plt.xlabel('Outer Step')\n",
    "plt.ylabel('Meta Loss')\n",
    "plt.title('Dataset Distillation Progress')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(syn_images[i].detach().cpu().squeeze(), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# Validate distilled data\n",
    "syn_dataset = TensorDataset(syn_images.detach(), syn_labels.argmax(dim=1))\n",
    "syn_loader = DataLoader(syn_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Train final model\n",
    "final_model = SimpleNet().to(device)\n",
    "optimizer_final = optim.SGD(final_model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(10):\n",
    "    for images, labels in syn_loader:\n",
    "        outputs = final_model(images)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        \n",
    "        optimizer_final.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_final.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/10], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch [1/10], Loss: 2.2916 \n",
    "\n",
    "Epoch [2/10], Loss: 2.2182 \n",
    "\n",
    "Epoch [3/10], Loss: 2.1520  \n",
    "\n",
    "Epoch [4/10], Loss: 2.0835 \n",
    "\n",
    "Epoch [5/10], Loss: 2.0089 \n",
    "\n",
    "Epoch [6/10], Loss: 1.9247 \n",
    "\n",
    "Epoch [7/10], Loss: 1.8318 \n",
    "\n",
    "Epoch [8/10], Loss: 1.7310 \n",
    "\n",
    "Epoch [9/10], Loss: 1.6245 \n",
    "\n",
    "Epoch [10/10], Loss: 1.5150 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta iteration 000 | Meta loss (real data loss): 2.3123\n",
      "Meta iteration 050 | Meta loss (real data loss): 2.2965\n",
      "Meta iteration 100 | Meta loss (real data loss): 2.3074\n",
      "Meta iteration 150 | Meta loss (real data loss): 2.3307\n",
      "Meta iteration 200 | Meta loss (real data loss): 2.2900\n",
      "Meta iteration 250 | Meta loss (real data loss): 2.3089\n",
      "Meta iteration 300 | Meta loss (real data loss): 2.3162\n",
      "Meta iteration 350 | Meta loss (real data loss): 2.2939\n",
      "Meta iteration 400 | Meta loss (real data loss): 2.3046\n",
      "Meta iteration 450 | Meta loss (real data loss): 2.3015\n",
      "Meta iteration 500 | Meta loss (real data loss): 2.2970\n",
      "Meta iteration 550 | Meta loss (real data loss): 2.3034\n",
      "Meta iteration 600 | Meta loss (real data loss): 2.3112\n",
      "Meta iteration 650 | Meta loss (real data loss): 2.3167\n",
      "Meta iteration 700 | Meta loss (real data loss): 2.2960\n",
      "Meta iteration 750 | Meta loss (real data loss): 2.2991\n",
      "Meta iteration 800 | Meta loss (real data loss): 2.2900\n",
      "Meta iteration 850 | Meta loss (real data loss): 2.3177\n",
      "Meta iteration 900 | Meta loss (real data loss): 2.3273\n",
      "Meta iteration 950 | Meta loss (real data loss): 2.3116\n",
      "Meta iteration 1000 | Meta loss (real data loss): 2.3236\n",
      "Meta iteration 1050 | Meta loss (real data loss): 2.3248\n",
      "Meta iteration 1100 | Meta loss (real data loss): 2.2909\n",
      "Meta iteration 1150 | Meta loss (real data loss): 2.3006\n",
      "Meta iteration 1200 | Meta loss (real data loss): 2.3013\n",
      "Meta iteration 1250 | Meta loss (real data loss): 2.3168\n",
      "Meta iteration 1300 | Meta loss (real data loss): 2.3138\n",
      "Meta iteration 1350 | Meta loss (real data loss): 2.2999\n",
      "Meta iteration 1400 | Meta loss (real data loss): 2.2912\n",
      "Meta iteration 1450 | Meta loss (real data loss): 2.3022\n",
      "Meta iteration 1500 | Meta loss (real data loss): 2.3393\n",
      "Meta iteration 1550 | Meta loss (real data loss): 2.2932\n",
      "Meta iteration 1600 | Meta loss (real data loss): 2.3087\n",
      "Meta iteration 1650 | Meta loss (real data loss): 2.3126\n",
      "Meta iteration 1700 | Meta loss (real data loss): 2.3099\n",
      "Meta iteration 1750 | Meta loss (real data loss): 2.3230\n",
      "Meta iteration 1800 | Meta loss (real data loss): 2.2950\n",
      "Meta iteration 1850 | Meta loss (real data loss): 2.3335\n",
      "Meta iteration 1900 | Meta loss (real data loss): 2.3219\n",
      "Meta iteration 1950 | Meta loss (real data loss): 2.3139\n",
      "Meta iteration 2000 | Meta loss (real data loss): 2.2954\n",
      "Meta iteration 2050 | Meta loss (real data loss): 2.2783\n",
      "Meta iteration 2100 | Meta loss (real data loss): 2.3080\n",
      "Meta iteration 2150 | Meta loss (real data loss): 2.3189\n",
      "Meta iteration 2200 | Meta loss (real data loss): 2.3101\n",
      "Meta iteration 2250 | Meta loss (real data loss): 2.3187\n",
      "Meta iteration 2300 | Meta loss (real data loss): 2.3310\n",
      "Meta iteration 2350 | Meta loss (real data loss): 2.3074\n",
      "Meta iteration 2400 | Meta loss (real data loss): 2.2948\n",
      "Meta iteration 2450 | Meta loss (real data loss): 2.3098\n",
      "Meta iteration 2500 | Meta loss (real data loss): 2.3058\n",
      "Meta iteration 2550 | Meta loss (real data loss): 2.3242\n",
      "Meta iteration 2600 | Meta loss (real data loss): 2.3035\n",
      "Meta iteration 2650 | Meta loss (real data loss): 2.3262\n",
      "Meta iteration 2700 | Meta loss (real data loss): 2.3230\n",
      "Meta iteration 2750 | Meta loss (real data loss): 2.3176\n",
      "Meta iteration 2800 | Meta loss (real data loss): 2.3023\n",
      "Meta iteration 2850 | Meta loss (real data loss): 2.3112\n",
      "Meta iteration 2900 | Meta loss (real data loss): 2.3064\n",
      "Meta iteration 2950 | Meta loss (real data loss): 2.2995\n",
      "Distilled images saved to distilled_mnist.png\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# ---------------------------\n",
    "# Define the simple neural network\n",
    "# ---------------------------\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the input image\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# ---------------------------\n",
    "# Functional forward that uses a given parameter dictionary.\n",
    "# This allows us to “simulate” an inner update on the model parameters.\n",
    "# ---------------------------\n",
    "def functional_forward(x, params):\n",
    "    # x: [batch, 1, 28, 28] -> flatten to [batch, 28*28]\n",
    "    x = x.view(x.size(0), -1)\n",
    "    x = F.linear(x, params['fc1.weight'], params['fc1.bias'])\n",
    "    x = F.relu(x)\n",
    "    x = F.linear(x, params['fc2.weight'], params['fc2.bias'])\n",
    "    x = F.relu(x)\n",
    "    x = F.linear(x, params['fc3.weight'], params['fc3.bias'])\n",
    "    return x\n",
    "\n",
    "# ---------------------------\n",
    "# Main training loop for meta-model matching based distillation.\n",
    "# ---------------------------\n",
    "def main():\n",
    "    # Hyperparameters\n",
    "    num_meta_iterations = 3000         # number of meta-iterations (outer loop)\n",
    "    num_inner_steps = 50               # number of inner gradient steps (can be >1)\n",
    "    lr_inner = 0.01                   # inner-loop (model) learning rate\n",
    "    lr_meta = 0.01                     # meta (synthetic data) learning rate\n",
    "\n",
    "    num_synthetic_per_class = 10      # number of synthetic examples per class\n",
    "    num_classes = 10\n",
    "    num_synthetic = num_synthetic_per_class * num_classes\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # ---------------------------\n",
    "    # Create the learnable synthetic dataset\n",
    "    # ---------------------------\n",
    "    # Initialize synthetic images as learnable parameters.\n",
    "    synthetic_images = torch.nn.Parameter(torch.randn(num_synthetic, 1, 28, 28, device=device))\n",
    "    # For simplicity, we fix the synthetic labels (e.g. 10 examples per class)\n",
    "    synthetic_labels = torch.tensor(np.repeat(np.arange(num_classes), num_synthetic_per_class), dtype=torch.long, device=device)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Prepare the real MNIST training data\n",
    "    # ---------------------------\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    real_loader = DataLoader(mnist_train, batch_size=64, shuffle=True, drop_last=True)\n",
    "    real_loader_iter = iter(real_loader)\n",
    "\n",
    "    # Meta-optimizer for the synthetic images\n",
    "    optimizer_syn = optim.SGD([synthetic_images], lr=lr_meta)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Meta-training loop\n",
    "    # ---------------------------\n",
    "    for meta_iter in range(num_meta_iterations):\n",
    "        # Initialize a fresh model\n",
    "        model = SimpleNN().to(device)\n",
    "        # Extract initial parameters into a dictionary.\n",
    "        # We use a fixed ordering to ensure consistency.\n",
    "        params = {name: param for name, param in model.named_parameters()}\n",
    "        param_names = list(params.keys())\n",
    "\n",
    "        # ---------------------------\n",
    "        # Inner loop: update model parameters using synthetic data\n",
    "        # ---------------------------\n",
    "        for step in range(num_inner_steps):\n",
    "            # Forward pass on synthetic data using the current parameters.\n",
    "            outputs_syn = functional_forward(synthetic_images, params)\n",
    "            loss_syn = F.cross_entropy(outputs_syn, synthetic_labels)\n",
    "            # Compute gradients w.r.t. the model parameters (create_graph=True for meta-gradient)\n",
    "            grads = torch.autograd.grad(loss_syn, [params[name] for name in param_names], create_graph=True)\n",
    "            # Perform a gradient descent update on the parameters (inner update)\n",
    "            params = {name: params[name] - lr_inner * grad for name, grad in zip(param_names, grads)}\n",
    "\n",
    "        # ---------------------------\n",
    "        # Outer loop: evaluate updated model on a batch of real data\n",
    "        # ---------------------------\n",
    "        # Get a batch from the real MNIST training set\n",
    "        try:\n",
    "            real_images, real_labels = next(real_loader_iter)\n",
    "        except StopIteration:\n",
    "            real_loader_iter = iter(real_loader)\n",
    "            real_images, real_labels = next(real_loader_iter)\n",
    "        real_images, real_labels = real_images.to(device), real_labels.to(device)\n",
    "        \n",
    "        # Compute the loss on the real data using the updated model parameters.\n",
    "        outputs_real = functional_forward(real_images, params)\n",
    "        loss_real = F.cross_entropy(outputs_real, real_labels)\n",
    "        \n",
    "        # Backpropagate the meta-loss through the inner loop update to update synthetic images.\n",
    "        optimizer_syn.zero_grad()\n",
    "        loss_real.backward()\n",
    "        optimizer_syn.step()\n",
    "\n",
    "        if meta_iter % 50 == 0:\n",
    "            print(f'Meta iteration {meta_iter:03d} | Meta loss (real data loss): {loss_real.item():.4f}')\n",
    "\n",
    "    # ---------------------------\n",
    "    # Save or visualize the distilled (synthetic) images\n",
    "    # ---------------------------\n",
    "    # Clamp the synthetic images to a valid range for visualization (e.g., [0,1])\n",
    "    distilled_images = synthetic_images.detach().cpu().clamp(0, 1)\n",
    "    # Optionally, save the synthetic images using torchvision's utils\n",
    "    from torchvision.utils import save_image\n",
    "    save_image(distilled_images, 'distilled_mnist.png', nrow=num_synthetic_per_class)\n",
    "    print(\"Distilled images saved to distilled_mnist.png\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting meta-training (dataset distillation)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/22/gxvfn3cx2_v64ngzhq52h2180000gn/T/ipykernel_57375/355010041.py:71: FutureWarning: `torch.nn.utils.stateless.functional_call` is deprecated as of PyTorch 2.0 and will be removed in a future version of PyTorch. Please use `torch.func.functional_call` instead which is a drop-in replacement.\n",
      "  outputs = functional_call(model, params, syn_images)\n",
      "/var/folders/22/gxvfn3cx2_v64ngzhq52h2180000gn/T/ipykernel_57375/355010041.py:103: FutureWarning: `torch.nn.utils.stateless.functional_call` is deprecated as of PyTorch 2.0 and will be removed in a future version of PyTorch. Please use `torch.func.functional_call` instead which is a drop-in replacement.\n",
      "  meta_outputs = functional_call(model, final_params, real_imgs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta iteration 0: Meta loss = 2.3981\n",
      "Meta iteration 100: Meta loss = 2.3102\n",
      "Meta iteration 200: Meta loss = 2.2653\n",
      "Meta iteration 300: Meta loss = 2.2586\n",
      "Meta iteration 400: Meta loss = 2.1784\n",
      "Meta iteration 500: Meta loss = 2.1683\n",
      "Meta iteration 600: Meta loss = 2.1695\n",
      "Meta iteration 700: Meta loss = 2.1318\n",
      "Meta iteration 800: Meta loss = 2.1251\n",
      "Meta iteration 900: Meta loss = 2.0605\n",
      "Meta-training finished.\n",
      "Training evaluation model on distilled synthetic dataset...\n",
      "Epoch 1/10, Synthetic training loss: 2.3476\n",
      "Epoch 2/10, Synthetic training loss: 2.3302\n",
      "Epoch 3/10, Synthetic training loss: 2.2944\n",
      "Epoch 4/10, Synthetic training loss: 2.3114\n",
      "Epoch 5/10, Synthetic training loss: 2.2747\n",
      "Epoch 6/10, Synthetic training loss: 2.2407\n",
      "Epoch 7/10, Synthetic training loss: 2.2218\n",
      "Epoch 8/10, Synthetic training loss: 2.2263\n",
      "Epoch 9/10, Synthetic training loss: 2.2010\n",
      "Epoch 10/10, Synthetic training loss: 2.1987\n",
      "Evaluating on MNIST test set...\n",
      "Test accuracy of model trained on distilled data: 13.54%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.func import functional_call\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "##############################\n",
    "# Define a simple CNN model\n",
    "##############################\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)  # Output: (32, 26, 26)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2)          # Output: (32, 13, 13)\n",
    "        self.fc = nn.Linear(32 * 13 * 13, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "##############################\n",
    "# Hyperparameters\n",
    "##############################\n",
    "num_classes = 10\n",
    "ipc = 10                         # images per class in synthetic set\n",
    "num_syn = num_classes * ipc      # total synthetic images\n",
    "inner_steps = 100                # number of inner-loop (synthetic training) steps\n",
    "meta_iterations = 1000           # meta-iterations for distillation\n",
    "lr_model = 0.01                  # inner-loop learning rate\n",
    "lr_syn = 0.1                     # synthetic data learning rate\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "##############################\n",
    "# Load MNIST dataset (real data)\n",
    "##############################\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # converts images to [0,1] tensors\n",
    "])\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "real_loader = DataLoader(mnist_train, batch_size=256, shuffle=True)\n",
    "\n",
    "##############################\n",
    "# Initialize synthetic dataset\n",
    "##############################\n",
    "# Synthetic images: parameter tensor of shape (num_syn, 1, 28, 28)\n",
    "syn_images = torch.randn(num_syn, 1, 28, 28, device=device, requires_grad=True)\n",
    "# Synthetic labels: for each class repeated ipc times (0,...,9)\n",
    "syn_labels = torch.tensor([i for i in range(num_classes) for _ in range(ipc)], device=device)\n",
    "\n",
    "# Optimizer for synthetic images\n",
    "syn_optimizer = optim.SGD([syn_images], lr=lr_syn)\n",
    "\n",
    "##############################\n",
    "# Helper: Inner-loop update (using functional updates)\n",
    "##############################\n",
    "def inner_loop(model, init_params, syn_images, syn_labels, inner_steps, lr_model):\n",
    "    params = init_params\n",
    "    for t in range(inner_steps):\n",
    "        # Forward pass on synthetic data using the current parameters\n",
    "        outputs = functional_call(model, params, syn_images)\n",
    "        loss = criterion(outputs, syn_labels)\n",
    "        # Compute gradients w.r.t. model parameters (create_graph=True to enable second-order gradients)\n",
    "        grads = torch.autograd.grad(loss, params.values(), create_graph=True)\n",
    "        # Update each parameter functionally\n",
    "        params = {name: param - lr_model * grad \n",
    "                  for (name, param), grad in zip(params.items(), grads)}\n",
    "    return params\n",
    "\n",
    "##############################\n",
    "# Meta-training loop (distillation)\n",
    "##############################\n",
    "print(\"Starting meta-training (dataset distillation)...\")\n",
    "for meta_iter in range(meta_iterations):\n",
    "    # Initialize a new model and get its parameters as a dict (these are the \"inner-loop\" model parameters)\n",
    "    model = SimpleCNN().to(device)\n",
    "    model.train()\n",
    "    init_params = {name: param.clone() for name, param in model.named_parameters()}\n",
    "\n",
    "    # Perform inner-loop updates using the current synthetic dataset\n",
    "    for t in range(inner_steps):\n",
    "        # Forward pass on synthetic data using the current parameters\n",
    "        outputs = functional_call(model, init_params, syn_images)\n",
    "        loss = criterion(outputs, syn_labels)\n",
    "        # Compute gradients w.r.t. model parameters (create_graph=True to enable second-order gradients)\n",
    "        grads = torch.autograd.grad(loss, init_params.values(), create_graph=True)\n",
    "        # Update each parameter functionally\n",
    "        final_params = {name: param - lr_model * grad \n",
    "                  for (name, param), grad in zip(init_params.items(), grads)}\n",
    "    \n",
    "    # Sample a batch from the real dataset to compute meta-loss\n",
    "    try:\n",
    "        real_batch = next(real_iter)\n",
    "    except Exception:\n",
    "        real_iter = iter(real_loader)\n",
    "        real_batch = next(real_iter)\n",
    "    real_imgs, real_lbls = real_batch\n",
    "    real_imgs, real_lbls = real_imgs.to(device), real_lbls.to(device)\n",
    "    \n",
    "    # Evaluate the model (with final_params) on real data and compute meta-loss\n",
    "    meta_outputs = functional_call(model, final_params, real_imgs)\n",
    "    meta_loss = criterion(meta_outputs, real_lbls)\n",
    "    \n",
    "    # Backpropagate meta-loss through the inner loop to update synthetic images\n",
    "    syn_optimizer.zero_grad()\n",
    "    meta_loss.backward()\n",
    "    syn_optimizer.step()\n",
    "\n",
    "    # Clamp synthetic images to [0,1] for valid pixel values\n",
    "    with torch.no_grad():\n",
    "        syn_images.clamp_(0, 1)\n",
    "\n",
    "    if meta_iter % 100 == 0:\n",
    "        print(f\"Meta iteration {meta_iter}: Meta loss = {meta_loss.item():.4f}\")\n",
    "\n",
    "print(\"Meta-training finished.\")\n",
    "\n",
    "##############################\n",
    "# Evaluation: Train a new model on the distilled synthetic dataset\n",
    "##############################\n",
    "print(\"Training evaluation model on distilled synthetic dataset...\")\n",
    "\n",
    "# Create a TensorDataset and DataLoader from the distilled synthetic images\n",
    "syn_dataset = TensorDataset(syn_images.detach().cpu(), syn_labels.cpu())\n",
    "syn_loader = DataLoader(syn_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Initialize a new model for evaluation\n",
    "eval_model = SimpleCNN().to(device)\n",
    "eval_model.train()\n",
    "eval_optimizer = optim.SGD(eval_model.parameters(), lr=lr_model)\n",
    "\n",
    "# Train on synthetic data for a few epochs\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for imgs, labels in syn_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        eval_optimizer.zero_grad()\n",
    "        outputs = eval_model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        eval_optimizer.step()\n",
    "        epoch_loss += loss.item() * imgs.size(0)\n",
    "    epoch_loss /= len(syn_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Synthetic training loss: {epoch_loss:.4f}\")\n",
    "\n",
    "##############################\n",
    "# Test the evaluation model on the MNIST test set\n",
    "##############################\n",
    "print(\"Evaluating on MNIST test set...\")\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "eval_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = eval_model(imgs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "test_acc = 100.0 * correct / total\n",
    "print(f\"Test accuracy of model trained on distilled data: {test_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
